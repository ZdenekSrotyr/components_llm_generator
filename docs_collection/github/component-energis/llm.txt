Directory structure:
└── keboola-component-energis/
    ├── README.md
    ├── docker-compose.yml
    ├── Dockerfile
    ├── flake8.cfg
    ├── LICENSE.md
    ├── pyproject.toml
    ├── pytest.ini
    ├── uv.lock
    ├── component_config/
    │   ├── component_long_description.md
    │   ├── component_short_description.md
    │   ├── configSchema.json
    │   ├── configuration_description.md
    │   ├── documentationUrl.md
    │   ├── licenseUrl.md
    │   ├── logger
    │   ├── loggerConfiguration.json
    │   └── sourceCodeUrl.md
    ├── scripts/
    │   ├── build_n_run.ps1
    │   ├── build_n_test.sh
    │   ├── run_kbc_tests.ps1
    │   └── developer_portal/
    │       ├── fn_actions_md_update.sh
    │       └── update_properties.sh
    ├── src/
    │   ├── api_client.py
    │   ├── component.py
    │   └── configuration.py
    ├── tests/
    │   ├── __init__.py
    │   ├── test_api_client.py
    │   └── test_configuration.py
    └── .github/
        └── workflows/
            └── push.yml

================================================
FILE: README.md
================================================
# **Energis Extractor**
=============

## **Description**

The **Energis Extractor** retrieves energy-related data from the **Energis API** and loads it into **Keboola Connection** for further analysis. It supports **incremental loading**, **various data granularities**, and **date range filtering** to allow precise data extraction.

---

## **Table of Contents**

- [Functionality Notes](#functionality-notes)
- [Prerequisites](#prerequisites)
- [Features](#features)
- [Supported Endpoints](#supported-endpoints)
- [Configuration](#configuration)
  - [Authentication Settings](#authentication-settings)
  - [Synchronization Options](#synchronization-options)
  - [Debug Mode](#debug-mode)
- [Output](#output)
- [Development](#development)
  - [Running Locally](#running-locally)
  - [Running Tests](#running-tests)
- [Integration](#integration)

---

## **Functionality Notes**

- Extracts **energy consumption and related metrics** from Energis.
- Supports **incremental data fetching** to avoid duplicate records.
- Allows **date-based filtering** to control extracted data ranges.
- Provides **structured output tables** ready for analysis.

---

## **Prerequisites**

Before using this component, ensure that:

1. You have **valid API credentials** for the Energis system.
2. Your user account has **appropriate permissions** to access required datasets.
3. You have registered the **Keboola Connection application** (if required).

---

## **Supported Endpoints**

This extractor currently supports the **`xexport` dataset**. If you require additional endpoints, submit your request at [ideas.keboola.com](https://ideas.keboola.com/).

---

## **Configuration**

For a full breakdown of configuration options, refer to the [Configuration Documentation](#).

### **Authentication Settings**

| **Property**        | **Required** | **Type**     | **Default** | **Description** |
|--------------------|------------|------------|------------|---------------|
| `authentication.username` | Yes | String | _(None)_ | Username for API authentication. |
| `authentication.#password` | Yes | String (password) | _(None)_ | Password for API authentication. |
| `authentication.environment` | Yes | Enum (`dev` / `prod`) | `prod` | Selects the API environment (development or production). |

> Note: Dev environment points to https://webenergis.eu/test/1.wsc/soap.r and prod one to: https://bilance.c-energy.cz/cgi-bin/1.wsc/soap.r

### **Synchronization Options**

| **Property**        | **Required** | **Type**     | **Default**  | **Description**                                                                               |
|--------------------|------------|------------|--------------|-----------------------------------------------------------------------------------------------|
| `sync_options.dataset` | Yes | Enum (`xexport`) | `xexport`    | Specifies the dataset for extraction.                                                         |
| `sync_options.nodes` | Yes | Array of Integers | `[]`         | List of node IDs for data retrieval.                                                          |
| `sync_options.date_from` | Yes | Date (`YYYY-MM-DD`) | `2024-12-01` | Start date for data extraction.                                                               |
| `sync_options.date_to` | No | Date (`YYYY-MM-DD`) | _(Today)_    | End date for data extraction. If not set, defaults to today.                                  |
| `sync_options.granularity` | Yes | Enum (`year`, `quarterYear`, `month`, `day`, `hour`, `quarterHour`, `minute`) | `day`        | Defines data granularity for extraction.                                                      |
| `sync_options.reload_full_data` | No | Boolean| _False_      | When enabled, retrieves the complete dataset from 'date_from', bypassing incremental loading. |

### **Debug Mode**
| **Property** | **Required** | **Type** | **Default** | **Description** |
|-------------|--------------|--------|------------|---------------|
| `debug` | No         | Boolean | `false` | Enables debug mode for additional logging. |

---

## **Output**

The extracted data is stored in **CSV tables** within **Keboola Storage**. Each dataset includes structured fields with **timestamps, node identifiers, and recorded values**.

For the exact output schema, refer to the [Output Schema Documentation](#).

---

## **Development**

This component uses **Python 3.13** and **UV** for dependency management.

### **Running Locally**

Build and run using Docker:

```bash
docker-compose build
docker-compose run --rm dev
```

To customize the local data folder path, modify the `docker-compose.yml` file:

```yaml
volumes:
  - ./:/code
  - ./CUSTOM_FOLDER:/data
```

Or use the provided script:

```bash
./scripts/build_n_test.sh
```

### **Running Tests**

```bash
# Using Docker (recommended, matches CI)
docker-compose run --rm dev python -m pytest tests/

# Or locally with UV
uv run python -m pytest tests/
```

### **Linting**

```bash
# Flake8 (used in CI)
docker-compose run --rm dev flake8 . --config=flake8.cfg
```

---

## **Integration**

This component integrates with **Keboola Connection** and is available in the Keboola marketplace.



================================================
FILE: docker-compose.yml
================================================
version: "2"
services:
  # for development purposes
  dev:
    build: .
    volumes:
        - ./:/code
        - ./data:/data
    environment:
      - KBC_DATADIR=./data
  test:
    # Use to run flake8 and unittests checks
    build: .
    volumes:
      - ./:/code
      - ./data:/data
    environment:
      - KBC_DATADIR=./data
    command:
      - /bin/sh
      - /code/scripts/build_n_test.sh


================================================
FILE: Dockerfile
================================================
FROM python:3.13-slim
COPY --from=ghcr.io/astral-sh/uv:latest /uv /uvx /bin/

WORKDIR /code/

COPY pyproject.toml .
COPY uv.lock .

ENV UV_PROJECT_ENVIRONMENT="/usr/local/"
ENV PYTHONPATH="/code/src"
RUN uv sync --all-groups --frozen

COPY src/ src/
COPY tests/ tests/
COPY scripts/ scripts/
COPY flake8.cfg .

CMD ["python", "-u", "src/component.py"]



================================================
FILE: flake8.cfg
================================================
[flake8]
exclude =
    .git,
    __pycache__,
    tests,
    example
    venv
    .venv
max-line-length = 120

# F812: list comprehension redefines ...
# H101: Use TODO(NAME)
# H202: assertRaises Exception too broad
# H233: Python 3.x incompatible use of print operator
# H301: one import per line
# H306: imports not in alphabetical order (time, os)
# H401: docstring should not start with a space
# H403: multi line docstrings should end on a new line
# H404: multi line docstring should start without a leading new line
# H405: multi line docstring summary not separated with an empty line
# H501: Do not use self.__dict__ for string formatting



================================================
FILE: LICENSE.md
================================================
The MIT License (MIT)

Copyright (c) 2018 Keboola DS, http://keboola.com

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files, to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is furnished
to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
THE SOFTWARE.


================================================
FILE: pyproject.toml
================================================
[project]
name = "component-energis"
version = "0.1.0"
description = "Keboola Energis extractor component"
readme = "README.md"
requires-python = "~=3.13.0"
dependencies = [
    "flake8>=7.2.0",
    "freezegun>=1.5.1",
    "httpx>=0.28.0",
    "keboola-component>=1.6.10",
    "keboola-http-client>=1.0.1",
    "keboola-utils>=1.1.0",
    "lxml>=5.3.1",
    "mock>=5.1.0",
    "pydantic>=2.10.6",
    "pytest>=8.3.5",
    "pytest-asyncio>=0.24.0",
    "urllib3>=2.6.0",
]



================================================
FILE: pytest.ini
================================================
[pytest]
pythonpath = src


================================================
FILE: uv.lock
================================================
version = 1
revision = 3
requires-python = "==3.13.*"

[[package]]
name = "aiolimiter"
version = "1.2.1"
source = { registry = "https://pypi.org/simple" }
sdist = { url = "https://files.pythonhosted.org/packages/f1/23/b52debf471f7a1e42e362d959a3982bdcb4fe13a5d46e63d28868807a79c/aiolimiter-1.2.1.tar.gz", hash = "sha256:e02a37ea1a855d9e832252a105420ad4d15011505512a1a1d814647451b5cca9", size = 7185, upload-time = "2024-12-08T15:31:51.496Z" }
wheels = [
    { url = "https://files.pythonhosted.org/packages/f3/ba/df6e8e1045aebc4778d19b8a3a9bc1808adb1619ba94ca354d9ba17d86c3/aiolimiter-1.2.1-py3-none-any.whl", hash = "sha256:d3f249e9059a20badcb56b61601a83556133655c11d1eb3dd3e04ff069e5f3c7", size = 6711, upload-time = "2024-12-08T15:31:49.874Z" },
]

[[package]]
name = "annotated-types"
version = "0.7.0"
source = { registry = "https://pypi.org/simple" }
sdist = { url = "https://files.pythonhosted.org/packages/ee/67/531ea369ba64dcff5ec9c3402f9f51bf748cec26dde048a2f973a4eea7f5/annotated_types-0.7.0.tar.gz", hash = "sha256:aff07c09a53a08bc8cfccb9c85b05f1aa9a2a6f23728d790723543408344ce89", size = 16081, upload-time = "2024-05-20T21:33:25.928Z" }
wheels = [
    { url = "https://files.pythonhosted.org/packages/78/b6/6307fbef88d9b5ee7421e68d78a9f162e0da4900bc5f5793f6d3d0e34fb8/annotated_types-0.7.0-py3-none-any.whl", hash = "sha256:1f02e8b43a8fbbc3f3e0d4f0f4bfc8131bcb4eebe8849b8e5c773f3a1c582a53", size = 13643, upload-time = "2024-05-20T21:33:24.1Z" },
]

[[package]]
name = "anyio"
version = "4.12.0"
source = { registry = "https://pypi.org/simple" }
dependencies = [
    { name = "idna" },
]
sdist = { url = "https://files.pythonhosted.org/packages/16/ce/8a777047513153587e5434fd752e89334ac33e379aa3497db860eeb60377/anyio-4.12.0.tar.gz", hash = "sha256:73c693b567b0c55130c104d0b43a9baf3aa6a31fc6110116509f27bf75e21ec0", size = 228266, upload-time = "2025-11-28T23:37:38.911Z" }
wheels = [
    { url = "https://files.pythonhosted.org/packages/7f/9c/36c5c37947ebfb8c7f22e0eb6e4d188ee2d53aa3880f3f2744fb894f0cb1/anyio-4.12.0-py3-none-any.whl", hash = "sha256:dad2376a628f98eeca4881fc56cd06affd18f659b17a747d3ff0307ced94b1bb", size = 113362, upload-time = "2025-11-28T23:36:57.897Z" },
]

[[package]]
name = "certifi"
version = "2025.11.12"
source = { registry = "https://pypi.org/simple" }
sdist = { url = "https://files.pythonhosted.org/packages/a2/8c/58f469717fa48465e4a50c014a0400602d3c437d7c0c468e17ada824da3a/certifi-2025.11.12.tar.gz", hash = "sha256:d8ab5478f2ecd78af242878415affce761ca6bc54a22a27e026d7c25357c3316", size = 160538, upload-time = "2025-11-12T02:54:51.517Z" }
wheels = [
    { url = "https://files.pythonhosted.org/packages/70/7d/9bc192684cea499815ff478dfcdc13835ddf401365057044fb721ec6bddb/certifi-2025.11.12-py3-none-any.whl", hash = "sha256:97de8790030bbd5c2d96b7ec782fc2f7820ef8dba6db909ccf95449f2d062d4b", size = 159438, upload-time = "2025-11-12T02:54:49.735Z" },
]

[[package]]
name = "charset-normalizer"
version = "3.4.4"
source = { registry = "https://pypi.org/simple" }
sdist = { url = "https://files.pythonhosted.org/packages/13/69/33ddede1939fdd074bce5434295f38fae7136463422fe4fd3e0e89b98062/charset_normalizer-3.4.4.tar.gz", hash = "sha256:94537985111c35f28720e43603b8e7b43a6ecfb2ce1d3058bbe955b73404e21a", size = 129418, upload-time = "2025-10-14T04:42:32.879Z" }
wheels = [
    { url = "https://files.pythonhosted.org/packages/97/45/4b3a1239bbacd321068ea6e7ac28875b03ab8bc0aa0966452db17cd36714/charset_normalizer-3.4.4-cp313-cp313-macosx_10_13_universal2.whl", hash = "sha256:e1f185f86a6f3403aa2420e815904c67b2f9ebc443f045edd0de921108345794", size = 208091, upload-time = "2025-10-14T04:41:13.346Z" },
    { url = "https://files.pythonhosted.org/packages/7d/62/73a6d7450829655a35bb88a88fca7d736f9882a27eacdca2c6d505b57e2e/charset_normalizer-3.4.4-cp313-cp313-manylinux2014_aarch64.manylinux_2_17_aarch64.manylinux_2_28_aarch64.whl", hash = "sha256:6b39f987ae8ccdf0d2642338faf2abb1862340facc796048b604ef14919e55ed", size = 147936, upload-time = "2025-10-14T04:41:14.461Z" },
    { url = "https://files.pythonhosted.org/packages/89/c5/adb8c8b3d6625bef6d88b251bbb0d95f8205831b987631ab0c8bb5d937c2/charset_normalizer-3.4.4-cp313-cp313-manylinux2014_armv7l.manylinux_2_17_armv7l.manylinux_2_31_armv7l.whl", hash = "sha256:3162d5d8ce1bb98dd51af660f2121c55d0fa541b46dff7bb9b9f86ea1d87de72", size = 144180, upload-time = "2025-10-14T04:41:15.588Z" },
    { url = "https://files.pythonhosted.org/packages/91/ed/9706e4070682d1cc219050b6048bfd293ccf67b3d4f5a4f39207453d4b99/charset_normalizer-3.4.4-cp313-cp313-manylinux2014_ppc64le.manylinux_2_17_ppc64le.manylinux_2_28_ppc64le.whl", hash = "sha256:81d5eb2a312700f4ecaa977a8235b634ce853200e828fbadf3a9c50bab278328", size = 161346, upload-time = "2025-10-14T04:41:16.738Z" },
    { url = "https://files.pythonhosted.org/packages/d5/0d/031f0d95e4972901a2f6f09ef055751805ff541511dc1252ba3ca1f80cf5/charset_normalizer-3.4.4-cp313-cp313-manylinux2014_s390x.manylinux_2_17_s390x.manylinux_2_28_s390x.whl", hash = "sha256:5bd2293095d766545ec1a8f612559f6b40abc0eb18bb2f5d1171872d34036ede", size = 158874, upload-time = "2025-10-14T04:41:17.923Z" },
    { url = "https://files.pythonhosted.org/packages/f5/83/6ab5883f57c9c801ce5e5677242328aa45592be8a00644310a008d04f922/charset_normalizer-3.4.4-cp313-cp313-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl", hash = "sha256:a8a8b89589086a25749f471e6a900d3f662d1d3b6e2e59dcecf787b1cc3a1894", size = 153076, upload-time = "2025-10-14T04:41:19.106Z" },
    { url = "https://files.pythonhosted.org/packages/75/1e/5ff781ddf5260e387d6419959ee89ef13878229732732ee73cdae01800f2/charset_normalizer-3.4.4-cp313-cp313-manylinux_2_31_riscv64.manylinux_2_39_riscv64.whl", hash = "sha256:bc7637e2f80d8530ee4a78e878bce464f70087ce73cf7c1caf142416923b98f1", size = 150601, upload-time = "2025-10-14T04:41:20.245Z" },
    { url = "https://files.pythonhosted.org/packages/d7/57/71be810965493d3510a6ca79b90c19e48696fb1ff964da319334b12677f0/charset_normalizer-3.4.4-cp313-cp313-musllinux_1_2_aarch64.whl", hash = "sha256:f8bf04158c6b607d747e93949aa60618b61312fe647a6369f88ce2ff16043490", size = 150376, upload-time = "2025-10-14T04:41:21.398Z" },
    { url = "https://files.pythonhosted.org/packages/e5/d5/c3d057a78c181d007014feb7e9f2e65905a6c4ef182c0ddf0de2924edd65/charset_normalizer-3.4.4-cp313-cp313-musllinux_1_2_armv7l.whl", hash = "sha256:554af85e960429cf30784dd47447d5125aaa3b99a6f0683589dbd27e2f45da44", size = 144825, upload-time = "2025-10-14T04:41:22.583Z" },
    { url = "https://files.pythonhosted.org/packages/e6/8c/d0406294828d4976f275ffbe66f00266c4b3136b7506941d87c00cab5272/charset_normalizer-3.4.4-cp313-cp313-musllinux_1_2_ppc64le.whl", hash = "sha256:74018750915ee7ad843a774364e13a3db91682f26142baddf775342c3f5b1133", size = 162583, upload-time = "2025-10-14T04:41:23.754Z" },
    { url = "https://files.pythonhosted.org/packages/d7/24/e2aa1f18c8f15c4c0e932d9287b8609dd30ad56dbe41d926bd846e22fb8d/charset_normalizer-3.4.4-cp313-cp313-musllinux_1_2_riscv64.whl", hash = "sha256:c0463276121fdee9c49b98908b3a89c39be45d86d1dbaa22957e38f6321d4ce3", size = 150366, upload-time = "2025-10-14T04:41:25.27Z" },
    { url = "https://files.pythonhosted.org/packages/e4/5b/1e6160c7739aad1e2df054300cc618b06bf784a7a164b0f238360721ab86/charset_normalizer-3.4.4-cp313-cp313-musllinux_1_2_s390x.whl", hash = "sha256:362d61fd13843997c1c446760ef36f240cf81d3ebf74ac62652aebaf7838561e", size = 160300, upload-time = "2025-10-14T04:41:26.725Z" },
    { url = "https://files.pythonhosted.org/packages/7a/10/f882167cd207fbdd743e55534d5d9620e095089d176d55cb22d5322f2afd/charset_normalizer-3.4.4-cp313-cp313-musllinux_1_2_x86_64.whl", hash = "sha256:9a26f18905b8dd5d685d6d07b0cdf98a79f3c7a918906af7cc143ea2e164c8bc", size = 154465, upload-time = "2025-10-14T04:41:28.322Z" },
    { url = "https://files.pythonhosted.org/packages/89/66/c7a9e1b7429be72123441bfdbaf2bc13faab3f90b933f664db506dea5915/charset_normalizer-3.4.4-cp313-cp313-win32.whl", hash = "sha256:9b35f4c90079ff2e2edc5b26c0c77925e5d2d255c42c74fdb70fb49b172726ac", size = 99404, upload-time = "2025-10-14T04:41:29.95Z" },
    { url = "https://files.pythonhosted.org/packages/c4/26/b9924fa27db384bdcd97ab83b4f0a8058d96ad9626ead570674d5e737d90/charset_normalizer-3.4.4-cp313-cp313-win_amd64.whl", hash = "sha256:b435cba5f4f750aa6c0a0d92c541fb79f69a387c91e61f1795227e4ed9cece14", size = 107092, upload-time = "2025-10-14T04:41:31.188Z" },
    { url = "https://files.pythonhosted.org/packages/af/8f/3ed4bfa0c0c72a7ca17f0380cd9e4dd842b09f664e780c13cff1dcf2ef1b/charset_normalizer-3.4.4-cp313-cp313-win_arm64.whl", hash = "sha256:542d2cee80be6f80247095cc36c418f7bddd14f4a6de45af91dfad36d817bba2", size = 100408, upload-time = "2025-10-14T04:41:32.624Z" },
    { url = "https://files.pythonhosted.org/packages/0a/4c/925909008ed5a988ccbb72dcc897407e5d6d3bd72410d69e051fc0c14647/charset_normalizer-3.4.4-py3-none-any.whl", hash = "sha256:7a32c560861a02ff789ad905a2fe94e3f840803362c84fecf1851cb4cf3dc37f", size = 53402, upload-time = "2025-10-14T04:42:31.76Z" },
]

[[package]]
name = "colorama"
version = "0.4.6"
source = { registry = "https://pypi.org/simple" }
sdist = { url = "https://files.pythonhosted.org/packages/d8/53/6f443c9a4a8358a93a6792e2acffb9d9d5cb0a5cfd8802644b7b1c9a02e4/colorama-0.4.6.tar.gz", hash = "sha256:08695f5cb7ed6e0531a20572697297273c47b8cae5a63ffc6d6ed5c201be6e44", size = 27697, upload-time = "2022-10-25T02:36:22.414Z" }
wheels = [
    { url = "https://files.pythonhosted.org/packages/d1/d6/3965ed04c63042e047cb6a3e6ed1a63a35087b6a609aa3a15ed8ac56c221/colorama-0.4.6-py2.py3-none-any.whl", hash = "sha256:4f1d9991f5acc0ca119f9d443620b77f9d6b33703e51011c16baf57afb285fc6", size = 25335, upload-time = "2022-10-25T02:36:20.889Z" },
]

[[package]]
name = "component-energis"
version = "0.1.0"
source = { virtual = "." }
dependencies = [
    { name = "flake8" },
    { name = "freezegun" },
    { name = "httpx" },
    { name = "keboola-component" },
    { name = "keboola-http-client" },
    { name = "keboola-utils" },
    { name = "lxml" },
    { name = "mock" },
    { name = "pydantic" },
    { name = "pytest" },
    { name = "pytest-asyncio" },
    { name = "urllib3" },
]

[package.metadata]
requires-dist = [
    { name = "flake8", specifier = ">=7.2.0" },
    { name = "freezegun", specifier = ">=1.5.1" },
    { name = "httpx", specifier = ">=0.28.0" },
    { name = "keboola-component", specifier = ">=1.6.10" },
    { name = "keboola-http-client", specifier = ">=1.0.1" },
    { name = "keboola-utils", specifier = ">=1.1.0" },
    { name = "lxml", specifier = ">=5.3.1" },
    { name = "mock", specifier = ">=5.1.0" },
    { name = "pydantic", specifier = ">=2.10.6" },
    { name = "pytest", specifier = ">=8.3.5" },
    { name = "pytest-asyncio", specifier = ">=0.24.0" },
    { name = "urllib3", specifier = ">=2.6.0" },
]

[[package]]
name = "dateparser"
version = "1.2.2"
source = { registry = "https://pypi.org/simple" }
dependencies = [
    { name = "python-dateutil" },
    { name = "pytz" },
    { name = "regex" },
    { name = "tzlocal" },
]
sdist = { url = "https://files.pythonhosted.org/packages/a9/30/064144f0df1749e7bb5faaa7f52b007d7c2d08ec08fed8411aba87207f68/dateparser-1.2.2.tar.gz", hash = "sha256:986316f17cb8cdc23ea8ce563027c5ef12fc725b6fb1d137c14ca08777c5ecf7", size = 329840, upload-time = "2025-06-26T09:29:23.211Z" }
wheels = [
    { url = "https://files.pythonhosted.org/packages/87/22/f020c047ae1346613db9322638186468238bcfa8849b4668a22b97faad65/dateparser-1.2.2-py3-none-any.whl", hash = "sha256:5a5d7211a09013499867547023a2a0c91d5a27d15dd4dbcea676ea9fe66f2482", size = 315453, upload-time = "2025-06-26T09:29:21.412Z" },
]

[[package]]
name = "deprecated"
version = "1.3.1"
source = { registry = "https://pypi.org/simple" }
dependencies = [
    { name = "wrapt" },
]
sdist = { url = "https://files.pythonhosted.org/packages/49/85/12f0a49a7c4ffb70572b6c2ef13c90c88fd190debda93b23f026b25f9634/deprecated-1.3.1.tar.gz", hash = "sha256:b1b50e0ff0c1fddaa5708a2c6b0a6588bb09b892825ab2b214ac9ea9d92a5223", size = 2932523, upload-time = "2025-10-30T08:19:02.757Z" }
wheels = [
    { url = "https://files.pythonhosted.org/packages/84/d0/205d54408c08b13550c733c4b85429e7ead111c7f0014309637425520a9a/deprecated-1.3.1-py2.py3-none-any.whl", hash = "sha256:597bfef186b6f60181535a29fbe44865ce137a5079f295b479886c82729d5f3f", size = 11298, upload-time = "2025-10-30T08:19:00.758Z" },
]

[[package]]
name = "flake8"
version = "7.3.0"
source = { registry = "https://pypi.org/simple" }
dependencies = [
    { name = "mccabe" },
    { name = "pycodestyle" },
    { name = "pyflakes" },
]
sdist = { url = "https://files.pythonhosted.org/packages/9b/af/fbfe3c4b5a657d79e5c47a2827a362f9e1b763336a52f926126aa6dc7123/flake8-7.3.0.tar.gz", hash = "sha256:fe044858146b9fc69b551a4b490d69cf960fcb78ad1edcb84e7fbb1b4a8e3872", size = 48326, upload-time = "2025-06-20T19:31:35.838Z" }
wheels = [
    { url = "https://files.pythonhosted.org/packages/9f/56/13ab06b4f93ca7cac71078fbe37fcea175d3216f31f85c3168a6bbd0bb9a/flake8-7.3.0-py2.py3-none-any.whl", hash = "sha256:b9696257b9ce8beb888cdbe31cf885c90d31928fe202be0889a7cdafad32f01e", size = 57922, upload-time = "2025-06-20T19:31:34.425Z" },
]

[[package]]
name = "freezegun"
version = "1.5.5"
source = { registry = "https://pypi.org/simple" }
dependencies = [
    { name = "python-dateutil" },
]
sdist = { url = "https://files.pythonhosted.org/packages/95/dd/23e2f4e357f8fd3bdff613c1fe4466d21bfb00a6177f238079b17f7b1c84/freezegun-1.5.5.tar.gz", hash = "sha256:ac7742a6cc6c25a2c35e9292dfd554b897b517d2dec26891a2e8debf205cb94a", size = 35914, upload-time = "2025-08-09T10:39:08.338Z" }
wheels = [
    { url = "https://files.pythonhosted.org/packages/5e/2e/b41d8a1a917d6581fc27a35d05561037b048e47df50f27f8ac9c7e27a710/freezegun-1.5.5-py3-none-any.whl", hash = "sha256:cd557f4a75cf074e84bc374249b9dd491eaeacd61376b9eb3c423282211619d2", size = 19266, upload-time = "2025-08-09T10:39:06.636Z" },
]

[[package]]
name = "h11"
version = "0.16.0"
source = { registry = "https://pypi.org/simple" }
sdist = { url = "https://files.pythonhosted.org/packages/01/ee/02a2c011bdab74c6fb3c75474d40b3052059d95df7e73351460c8588d963/h11-0.16.0.tar.gz", hash = "sha256:4e35b956cf45792e4caa5885e69fba00bdbc6ffafbfa020300e549b208ee5ff1", size = 101250, upload-time = "2025-04-24T03:35:25.427Z" }
wheels = [
    { url = "https://files.pythonhosted.org/packages/04/4b/29cac41a4d98d144bf5f6d33995617b185d14b22401f75ca86f384e87ff1/h11-0.16.0-py3-none-any.whl", hash = "sha256:63cf8bbe7522de3bf65932fda1d9c2772064ffb3dae62d55932da54b31cb6c86", size = 37515, upload-time = "2025-04-24T03:35:24.344Z" },
]

[[package]]
name = "httpcore"
version = "1.0.9"
source = { registry = "https://pypi.org/simple" }
dependencies = [
    { name = "certifi" },
    { name = "h11" },
]
sdist = { url = "https://files.pythonhosted.org/packages/06/94/82699a10bca87a5556c9c59b5963f2d039dbd239f25bc2a63907a05a14cb/httpcore-1.0.9.tar.gz", hash = "sha256:6e34463af53fd2ab5d807f399a9b45ea31c3dfa2276f15a2c3f00afff6e176e8", size = 85484, upload-time = "2025-04-24T22:06:22.219Z" }
wheels = [
    { url = "https://files.pythonhosted.org/packages/7e/f5/f66802a942d491edb555dd61e3a9961140fd64c90bce1eafd741609d334d/httpcore-1.0.9-py3-none-any.whl", hash = "sha256:2d400746a40668fc9dec9810239072b40b4484b640a8c38fd654a024c7a1bf55", size = 78784, upload-time = "2025-04-24T22:06:20.566Z" },
]

[[package]]
name = "httpx"
version = "0.28.1"
source = { registry = "https://pypi.org/simple" }
dependencies = [
    { name = "anyio" },
    { name = "certifi" },
    { name = "httpcore" },
    { name = "idna" },
]
sdist = { url = "https://files.pythonhosted.org/packages/b1/df/48c586a5fe32a0f01324ee087459e112ebb7224f646c0b5023f5e79e9956/httpx-0.28.1.tar.gz", hash = "sha256:75e98c5f16b0f35b567856f597f06ff2270a374470a5c2392242528e3e3e42fc", size = 141406, upload-time = "2024-12-06T15:37:23.222Z" }
wheels = [
    { url = "https://files.pythonhosted.org/packages/2a/39/e50c7c3a983047577ee07d2a9e53faf5a69493943ec3f6a384bdc792deb2/httpx-0.28.1-py3-none-any.whl", hash = "sha256:d909fcccc110f8c7faf814ca82a9a4d816bc5a6dbfea25d6591d6985b8ba59ad", size = 73517, upload-time = "2024-12-06T15:37:21.509Z" },
]

[[package]]
name = "idna"
version = "3.11"
source = { registry = "https://pypi.org/simple" }
sdist = { url = "https://files.pythonhosted.org/packages/6f/6d/0703ccc57f3a7233505399edb88de3cbd678da106337b9fcde432b65ed60/idna-3.11.tar.gz", hash = "sha256:795dafcc9c04ed0c1fb032c2aa73654d8e8c5023a7df64a53f39190ada629902", size = 194582, upload-time = "2025-10-12T14:55:20.501Z" }
wheels = [
    { url = "https://files.pythonhosted.org/packages/0e/61/66938bbb5fc52dbdf84594873d5b51fb1f7c7794e9c0f5bd885f30bc507b/idna-3.11-py3-none-any.whl", hash = "sha256:771a87f49d9defaf64091e6e6fe9c18d4833f140bd19464795bc32d966ca37ea", size = 71008, upload-time = "2025-10-12T14:55:18.883Z" },
]

[[package]]
name = "iniconfig"
version = "2.3.0"
source = { registry = "https://pypi.org/simple" }
sdist = { url = "https://files.pythonhosted.org/packages/72/34/14ca021ce8e5dfedc35312d08ba8bf51fdd999c576889fc2c24cb97f4f10/iniconfig-2.3.0.tar.gz", hash = "sha256:c76315c77db068650d49c5b56314774a7804df16fee4402c1f19d6d15d8c4730", size = 20503, upload-time = "2025-10-18T21:55:43.219Z" }
wheels = [
    { url = "https://files.pythonhosted.org/packages/cb/b1/3846dd7f199d53cb17f49cba7e651e9ce294d8497c8c150530ed11865bb8/iniconfig-2.3.0-py3-none-any.whl", hash = "sha256:f631c04d2c48c52b84d0d0549c99ff3859c98df65b3101406327ecc7d53fbf12", size = 7484, upload-time = "2025-10-18T21:55:41.639Z" },
]

[[package]]
name = "keboola-component"
version = "1.6.13"
source = { registry = "https://pypi.org/simple" }
dependencies = [
    { name = "deprecated" },
    { name = "pygelf" },
    { name = "pytz" },
]
sdist = { url = "https://files.pythonhosted.org/packages/91/e9/80a83c04bccaad7f5d7b6e8b9c0305085db2bd22838f7323f57aaaefd2f4/keboola.component-1.6.13.tar.gz", hash = "sha256:11b072da1cab39233ff798217a876cdacf17f446decdb89735f295ca20662874", size = 59550, upload-time = "2025-09-15T14:00:47.874Z" }
wheels = [
    { url = "https://files.pythonhosted.org/packages/a4/35/f4dab3d75a155260b90c72bb37d03a9bfd24dc18f52ccea2d61e587dbef6/keboola.component-1.6.13-py3-none-any.whl", hash = "sha256:eceda4c2d083b3857d6eb98e30d7bfe48a48ed0f8567e6898218cee4d9391318", size = 44151, upload-time = "2025-09-15T14:00:46.291Z" },
]

[[package]]
name = "keboola-http-client"
version = "1.2.0"
source = { registry = "https://pypi.org/simple" }
dependencies = [
    { name = "aiolimiter" },
    { name = "httpx" },
    { name = "requests" },
]
sdist = { url = "https://files.pythonhosted.org/packages/0f/b9/8e43e2b7c1f2667a9bc40b96a0098dcdd5d77b8d937fa1312ebd99ad9561/keboola_http_client-1.2.0.tar.gz", hash = "sha256:b3a3bcdc096ab84cff19ffa65d2ee303032c73d2d8d8b8aa93a82fb5ba6da484", size = 18369, upload-time = "2025-11-19T13:19:39.454Z" }
wheels = [
    { url = "https://files.pythonhosted.org/packages/09/7d/1d2b64896f9fff44de82783194a0def1e683dbfe7a8491db6d88d9a403c9/keboola_http_client-1.2.0-py3-none-any.whl", hash = "sha256:de80f5866d4d0aafc3a67492dc3e2d31d6c7e53f79406d7130620c952a4da493", size = 12632, upload-time = "2025-11-19T13:19:38.003Z" },
]

[[package]]
name = "keboola-utils"
version = "1.1.0"
source = { registry = "https://pypi.org/simple" }
dependencies = [
    { name = "dateparser" },
    { name = "pytz" },
]
sdist = { url = "https://files.pythonhosted.org/packages/a7/b8/ccfddc2eb510f7a6ab878ab8a6249a23494194780a436676da6c2f5d23c7/keboola.utils-1.1.0.tar.gz", hash = "sha256:e943dbda932d945bcd5edd51283eea8f7035249c9dac769d3e96d2f507b52f60", size = 9830, upload-time = "2021-04-09T11:11:49.828Z" }
wheels = [
    { url = "https://files.pythonhosted.org/packages/f9/f4/6697a0c2ff512baa7b84413972e51d5449a0a145f68dc750f05a8b1da39d/keboola.utils-1.1.0-py3-none-any.whl", hash = "sha256:8c73faa4a81f371a2eecd8465b08a51b3f7608969dd91d38d5b3bcfad7ef0da5", size = 10131, upload-time = "2021-04-09T11:11:48.826Z" },
]

[[package]]
name = "lxml"
version = "6.0.2"
source = { registry = "https://pypi.org/simple" }
sdist = { url = "https://files.pythonhosted.org/packages/aa/88/262177de60548e5a2bfc46ad28232c9e9cbde697bd94132aeb80364675cb/lxml-6.0.2.tar.gz", hash = "sha256:cd79f3367bd74b317dda655dc8fcfa304d9eb6e4fb06b7168c5cf27f96e0cd62", size = 4073426, upload-time = "2025-09-22T04:04:59.287Z" }
wheels = [
    { url = "https://files.pythonhosted.org/packages/53/fd/4e8f0540608977aea078bf6d79f128e0e2c2bba8af1acf775c30baa70460/lxml-6.0.2-cp313-cp313-macosx_10_13_universal2.whl", hash = "sha256:9b33d21594afab46f37ae58dfadd06636f154923c4e8a4d754b0127554eb2e77", size = 8648494, upload-time = "2025-09-22T04:01:54.242Z" },
    { url = "https://files.pythonhosted.org/packages/5d/f4/2a94a3d3dfd6c6b433501b8d470a1960a20ecce93245cf2db1706adf6c19/lxml-6.0.2-cp313-cp313-macosx_10_13_x86_64.whl", hash = "sha256:6c8963287d7a4c5c9a432ff487c52e9c5618667179c18a204bdedb27310f022f", size = 4661146, upload-time = "2025-09-22T04:01:56.282Z" },
    { url = "https://files.pythonhosted.org/packages/25/2e/4efa677fa6b322013035d38016f6ae859d06cac67437ca7dc708a6af7028/lxml-6.0.2-cp313-cp313-manylinux2014_aarch64.manylinux_2_17_aarch64.whl", hash = "sha256:1941354d92699fb5ffe6ed7b32f9649e43c2feb4b97205f75866f7d21aa91452", size = 4946932, upload-time = "2025-09-22T04:01:58.989Z" },
    { url = "https://files.pythonhosted.org/packages/ce/0f/526e78a6d38d109fdbaa5049c62e1d32fdd70c75fb61c4eadf3045d3d124/lxml-6.0.2-cp313-cp313-manylinux2014_x86_64.manylinux_2_17_x86_64.whl", hash = "sha256:bb2f6ca0ae2d983ded09357b84af659c954722bbf04dea98030064996d156048", size = 5100060, upload-time = "2025-09-22T04:02:00.812Z" },
    { url = "https://files.pythonhosted.org/packages/81/76/99de58d81fa702cc0ea7edae4f4640416c2062813a00ff24bd70ac1d9c9b/lxml-6.0.2-cp313-cp313-manylinux_2_26_aarch64.manylinux_2_28_aarch64.whl", hash = "sha256:eb2a12d704f180a902d7fa778c6d71f36ceb7b0d317f34cdc76a5d05aa1dd1df", size = 5019000, upload-time = "2025-09-22T04:02:02.671Z" },
    { url = "https://files.pythonhosted.org/packages/b5/35/9e57d25482bc9a9882cb0037fdb9cc18f4b79d85df94fa9d2a89562f1d25/lxml-6.0.2-cp313-cp313-manylinux_2_26_i686.manylinux_2_28_i686.whl", hash = "sha256:6ec0e3f745021bfed19c456647f0298d60a24c9ff86d9d051f52b509663feeb1", size = 5348496, upload-time = "2025-09-22T04:02:04.904Z" },
    { url = "https://files.pythonhosted.org/packages/a6/8e/cb99bd0b83ccc3e8f0f528e9aa1f7a9965dfec08c617070c5db8d63a87ce/lxml-6.0.2-cp313-cp313-manylinux_2_26_ppc64le.manylinux_2_28_ppc64le.whl", hash = "sha256:846ae9a12d54e368933b9759052d6206a9e8b250291109c48e350c1f1f49d916", size = 5643779, upload-time = "2025-09-22T04:02:06.689Z" },
    { url = "https://files.pythonhosted.org/packages/d0/34/9e591954939276bb679b73773836c6684c22e56d05980e31d52a9a8deb18/lxml-6.0.2-cp313-cp313-manylinux_2_26_x86_64.manylinux_2_28_x86_64.whl", hash = "sha256:ef9266d2aa545d7374938fb5c484531ef5a2ec7f2d573e62f8ce722c735685fd", size = 5244072, upload-time = "2025-09-22T04:02:08.587Z" },
    { url = "https://files.pythonhosted.org/packages/8d/27/b29ff065f9aaca443ee377aff699714fcbffb371b4fce5ac4ca759e436d5/lxml-6.0.2-cp313-cp313-manylinux_2_31_armv7l.whl", hash = "sha256:4077b7c79f31755df33b795dc12119cb557a0106bfdab0d2c2d97bd3cf3dffa6", size = 4718675, upload-time = "2025-09-22T04:02:10.783Z" },
    { url = "https://files.pythonhosted.org/packages/2b/9f/f756f9c2cd27caa1a6ef8c32ae47aadea697f5c2c6d07b0dae133c244fbe/lxml-6.0.2-cp313-cp313-manylinux_2_38_riscv64.manylinux_2_39_riscv64.whl", hash = "sha256:a7c5d5e5f1081955358533be077166ee97ed2571d6a66bdba6ec2f609a715d1a", size = 5255171, upload-time = "2025-09-22T04:02:12.631Z" },
    { url = "https://files.pythonhosted.org/packages/61/46/bb85ea42d2cb1bd8395484fd72f38e3389611aa496ac7772da9205bbda0e/lxml-6.0.2-cp313-cp313-musllinux_1_2_aarch64.whl", hash = "sha256:8f8d0cbd0674ee89863a523e6994ac25fd5be9c8486acfc3e5ccea679bad2679", size = 5057175, upload-time = "2025-09-22T04:02:14.718Z" },
    { url = "https://files.pythonhosted.org/packages/95/0c/443fc476dcc8e41577f0af70458c50fe299a97bb6b7505bb1ae09aa7f9ac/lxml-6.0.2-cp313-cp313-musllinux_1_2_armv7l.whl", hash = "sha256:2cbcbf6d6e924c28f04a43f3b6f6e272312a090f269eff68a2982e13e5d57659", size = 4785688, upload-time = "2025-09-22T04:02:16.957Z" },
    { url = "https://files.pythonhosted.org/packages/48/78/6ef0b359d45bb9697bc5a626e1992fa5d27aa3f8004b137b2314793b50a0/lxml-6.0.2-cp313-cp313-musllinux_1_2_ppc64le.whl", hash = "sha256:dfb874cfa53340009af6bdd7e54ebc0d21012a60a4e65d927c2e477112e63484", size = 5660655, upload-time = "2025-09-22T04:02:18.815Z" },
    { url = "https://files.pythonhosted.org/packages/ff/ea/e1d33808f386bc1339d08c0dcada6e4712d4ed8e93fcad5f057070b7988a/lxml-6.0.2-cp313-cp313-musllinux_1_2_riscv64.whl", hash = "sha256:fb8dae0b6b8b7f9e96c26fdd8121522ce5de9bb5538010870bd538683d30e9a2", size = 5247695, upload-time = "2025-09-22T04:02:20.593Z" },
    { url = "https://files.pythonhosted.org/packages/4f/47/eba75dfd8183673725255247a603b4ad606f4ae657b60c6c145b381697da/lxml-6.0.2-cp313-cp313-musllinux_1_2_x86_64.whl", hash = "sha256:358d9adae670b63e95bc59747c72f4dc97c9ec58881d4627fe0120da0f90d314", size = 5269841, upload-time = "2025-09-22T04:02:22.489Z" },
    { url = "https://files.pythonhosted.org/packages/76/04/5c5e2b8577bc936e219becb2e98cdb1aca14a4921a12995b9d0c523502ae/lxml-6.0.2-cp313-cp313-win32.whl", hash = "sha256:e8cd2415f372e7e5a789d743d133ae474290a90b9023197fd78f32e2dc6873e2", size = 3610700, upload-time = "2025-09-22T04:02:24.465Z" },
    { url = "https://files.pythonhosted.org/packages/fe/0a/4643ccc6bb8b143e9f9640aa54e38255f9d3b45feb2cbe7ae2ca47e8782e/lxml-6.0.2-cp313-cp313-win_amd64.whl", hash = "sha256:b30d46379644fbfc3ab81f8f82ae4de55179414651f110a1514f0b1f8f6cb2d7", size = 4010347, upload-time = "2025-09-22T04:02:26.286Z" },
    { url = "https://files.pythonhosted.org/packages/31/ef/dcf1d29c3f530577f61e5fe2f1bd72929acf779953668a8a47a479ae6f26/lxml-6.0.2-cp313-cp313-win_arm64.whl", hash = "sha256:13dcecc9946dca97b11b7c40d29fba63b55ab4170d3c0cf8c0c164343b9bfdcf", size = 3671248, upload-time = "2025-09-22T04:02:27.918Z" },
]

[[package]]
name = "mccabe"
version = "0.7.0"
source = { registry = "https://pypi.org/simple" }
sdist = { url = "https://files.pythonhosted.org/packages/e7/ff/0ffefdcac38932a54d2b5eed4e0ba8a408f215002cd178ad1df0f2806ff8/mccabe-0.7.0.tar.gz", hash = "sha256:348e0240c33b60bbdf4e523192ef919f28cb2c3d7d5c7794f74009290f236325", size = 9658, upload-time = "2022-01-24T01:14:51.113Z" }
wheels = [
    { url = "https://files.pythonhosted.org/packages/27/1a/1f68f9ba0c207934b35b86a8ca3aad8395a3d6dd7921c0686e23853ff5a9/mccabe-0.7.0-py2.py3-none-any.whl", hash = "sha256:6c2d30ab6be0e4a46919781807b4f0d834ebdd6c6e3dca0bda5a15f863427b6e", size = 7350, upload-time = "2022-01-24T01:14:49.62Z" },
]

[[package]]
name = "mock"
version = "5.2.0"
source = { registry = "https://pypi.org/simple" }
sdist = { url = "https://files.pythonhosted.org/packages/07/8c/14c2ae915e5f9dca5a22edd68b35be94400719ccfa068a03e0fb63d0f6f6/mock-5.2.0.tar.gz", hash = "sha256:4e460e818629b4b173f32d08bf30d3af8123afbb8e04bb5707a1fd4799e503f0", size = 92796, upload-time = "2025-03-03T12:31:42.911Z" }
wheels = [
    { url = "https://files.pythonhosted.org/packages/bd/d9/617e6af809bf3a1d468e0d58c3997b1dc219a9a9202e650d30c2fc85d481/mock-5.2.0-py3-none-any.whl", hash = "sha256:7ba87f72ca0e915175596069dbbcc7c75af7b5e9b9bc107ad6349ede0819982f", size = 31617, upload-time = "2025-03-03T12:31:41.518Z" },
]

[[package]]
name = "packaging"
version = "25.0"
source = { registry = "https://pypi.org/simple" }
sdist = { url = "https://files.pythonhosted.org/packages/a1/d4/1fc4078c65507b51b96ca8f8c3ba19e6a61c8253c72794544580a7b6c24d/packaging-25.0.tar.gz", hash = "sha256:d443872c98d677bf60f6a1f2f8c1cb748e8fe762d2bf9d3148b5599295b0fc4f", size = 165727, upload-time = "2025-04-19T11:48:59.673Z" }
wheels = [
    { url = "https://files.pythonhosted.org/packages/20/12/38679034af332785aac8774540895e234f4d07f7545804097de4b666afd8/packaging-25.0-py3-none-any.whl", hash = "sha256:29572ef2b1f17581046b3a2227d5c611fb25ec70ca1ba8554b24b0e69331a484", size = 66469, upload-time = "2025-04-19T11:48:57.875Z" },
]

[[package]]
name = "pluggy"
version = "1.6.0"
source = { registry = "https://pypi.org/simple" }
sdist = { url = "https://files.pythonhosted.org/packages/f9/e2/3e91f31a7d2b083fe6ef3fa267035b518369d9511ffab804f839851d2779/pluggy-1.6.0.tar.gz", hash = "sha256:7dcc130b76258d33b90f61b658791dede3486c3e6bfb003ee5c9bfb396dd22f3", size = 69412, upload-time = "2025-05-15T12:30:07.975Z" }
wheels = [
    { url = "https://files.pythonhosted.org/packages/54/20/4d324d65cc6d9205fabedc306948156824eb9f0ee1633355a8f7ec5c66bf/pluggy-1.6.0-py3-none-any.whl", hash = "sha256:e920276dd6813095e9377c0bc5566d94c932c33b27a3e3945d8389c374dd4746", size = 20538, upload-time = "2025-05-15T12:30:06.134Z" },
]

[[package]]
name = "pycodestyle"
version = "2.14.0"
source = { registry = "https://pypi.org/simple" }
sdist = { url = "https://files.pythonhosted.org/packages/11/e0/abfd2a0d2efe47670df87f3e3a0e2edda42f055053c85361f19c0e2c1ca8/pycodestyle-2.14.0.tar.gz", hash = "sha256:c4b5b517d278089ff9d0abdec919cd97262a3367449ea1c8b49b91529167b783", size = 39472, upload-time = "2025-06-20T18:49:48.75Z" }
wheels = [
    { url = "https://files.pythonhosted.org/packages/d7/27/a58ddaf8c588a3ef080db9d0b7e0b97215cee3a45df74f3a94dbbf5c893a/pycodestyle-2.14.0-py2.py3-none-any.whl", hash = "sha256:dd6bf7cb4ee77f8e016f9c8e74a35ddd9f67e1d5fd4184d86c3b98e07099f42d", size = 31594, upload-time = "2025-06-20T18:49:47.491Z" },
]

[[package]]
name = "pydantic"
version = "2.12.5"
source = { registry = "https://pypi.org/simple" }
dependencies = [
    { name = "annotated-types" },
    { name = "pydantic-core" },
    { name = "typing-extensions" },
    { name = "typing-inspection" },
]
sdist = { url = "https://files.pythonhosted.org/packages/69/44/36f1a6e523abc58ae5f928898e4aca2e0ea509b5aa6f6f392a5d882be928/pydantic-2.12.5.tar.gz", hash = "sha256:4d351024c75c0f085a9febbb665ce8c0c6ec5d30e903bdb6394b7ede26aebb49", size = 821591, upload-time = "2025-11-26T15:11:46.471Z" }
wheels = [
    { url = "https://files.pythonhosted.org/packages/5a/87/b70ad306ebb6f9b585f114d0ac2137d792b48be34d732d60e597c2f8465a/pydantic-2.12.5-py3-none-any.whl", hash = "sha256:e561593fccf61e8a20fc46dfc2dfe075b8be7d0188df33f221ad1f0139180f9d", size = 463580, upload-time = "2025-11-26T15:11:44.605Z" },
]

[[package]]
name = "pydantic-core"
version = "2.41.5"
source = { registry = "https://pypi.org/simple" }
dependencies = [
    { name = "typing-extensions" },
]
sdist = { url = "https://files.pythonhosted.org/packages/71/70/23b021c950c2addd24ec408e9ab05d59b035b39d97cdc1130e1bce647bb6/pydantic_core-2.41.5.tar.gz", hash = "sha256:08daa51ea16ad373ffd5e7606252cc32f07bc72b28284b6bc9c6df804816476e", size = 460952, upload-time = "2025-11-04T13:43:49.098Z" }
wheels = [
    { url = "https://files.pythonhosted.org/packages/87/06/8806241ff1f70d9939f9af039c6c35f2360cf16e93c2ca76f184e76b1564/pydantic_core-2.41.5-cp313-cp313-macosx_10_12_x86_64.whl", hash = "sha256:941103c9be18ac8daf7b7adca8228f8ed6bb7a1849020f643b3a14d15b1924d9", size = 2120403, upload-time = "2025-11-04T13:40:25.248Z" },
    { url = "https://files.pythonhosted.org/packages/94/02/abfa0e0bda67faa65fef1c84971c7e45928e108fe24333c81f3bfe35d5f5/pydantic_core-2.41.5-cp313-cp313-macosx_11_0_arm64.whl", hash = "sha256:112e305c3314f40c93998e567879e887a3160bb8689ef3d2c04b6cc62c33ac34", size = 1896206, upload-time = "2025-11-04T13:40:27.099Z" },
    { url = "https://files.pythonhosted.org/packages/15/df/a4c740c0943e93e6500f9eb23f4ca7ec9bf71b19e608ae5b579678c8d02f/pydantic_core-2.41.5-cp313-cp313-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:0cbaad15cb0c90aa221d43c00e77bb33c93e8d36e0bf74760cd00e732d10a6a0", size = 1919307, upload-time = "2025-11-04T13:40:29.806Z" },
    { url = "https://files.pythonhosted.org/packages/9a/e3/6324802931ae1d123528988e0e86587c2072ac2e5394b4bc2bc34b61ff6e/pydantic_core-2.41.5-cp313-cp313-manylinux_2_17_armv7l.manylinux2014_armv7l.whl", hash = "sha256:03ca43e12fab6023fc79d28ca6b39b05f794ad08ec2feccc59a339b02f2b3d33", size = 2063258, upload-time = "2025-11-04T13:40:33.544Z" },
    { url = "https://files.pythonhosted.org/packages/c9/d4/2230d7151d4957dd79c3044ea26346c148c98fbf0ee6ebd41056f2d62ab5/pydantic_core-2.41.5-cp313-cp313-manylinux_2_17_ppc64le.manylinux2014_ppc64le.whl", hash = "sha256:dc799088c08fa04e43144b164feb0c13f9a0bc40503f8df3e9fde58a3c0c101e", size = 2214917, upload-time = "2025-11-04T13:40:35.479Z" },
    { url = "https://files.pythonhosted.org/packages/e6/9f/eaac5df17a3672fef0081b6c1bb0b82b33ee89aa5cec0d7b05f52fd4a1fa/pydantic_core-2.41.5-cp313-cp313-manylinux_2_17_s390x.manylinux2014_s390x.whl", hash = "sha256:97aeba56665b4c3235a0e52b2c2f5ae9cd071b8a8310ad27bddb3f7fb30e9aa2", size = 2332186, upload-time = "2025-11-04T13:40:37.436Z" },
    { url = "https://files.pythonhosted.org/packages/cf/4e/35a80cae583a37cf15604b44240e45c05e04e86f9cfd766623149297e971/pydantic_core-2.41.5-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:406bf18d345822d6c21366031003612b9c77b3e29ffdb0f612367352aab7d586", size = 2073164, upload-time = "2025-11-04T13:40:40.289Z" },
    { url = "https://files.pythonhosted.org/packages/bf/e3/f6e262673c6140dd3305d144d032f7bd5f7497d3871c1428521f19f9efa2/pydantic_core-2.41.5-cp313-cp313-manylinux_2_5_i686.manylinux1_i686.whl", hash = "sha256:b93590ae81f7010dbe380cdeab6f515902ebcbefe0b9327cc4804d74e93ae69d", size = 2179146, upload-time = "2025-11-04T13:40:42.809Z" },
    { url = "https://files.pythonhosted.org/packages/75/c7/20bd7fc05f0c6ea2056a4565c6f36f8968c0924f19b7d97bbfea55780e73/pydantic_core-2.41.5-cp313-cp313-musllinux_1_1_aarch64.whl", hash = "sha256:01a3d0ab748ee531f4ea6c3e48ad9dac84ddba4b0d82291f87248f2f9de8d740", size = 2137788, upload-time = "2025-11-04T13:40:44.752Z" },
    { url = "https://files.pythonhosted.org/packages/3a/8d/34318ef985c45196e004bc46c6eab2eda437e744c124ef0dbe1ff2c9d06b/pydantic_core-2.41.5-cp313-cp313-musllinux_1_1_armv7l.whl", hash = "sha256:6561e94ba9dacc9c61bce40e2d6bdc3bfaa0259d3ff36ace3b1e6901936d2e3e", size = 2340133, upload-time = "2025-11-04T13:40:46.66Z" },
    { url = "https://files.pythonhosted.org/packages/9c/59/013626bf8c78a5a5d9350d12e7697d3d4de951a75565496abd40ccd46bee/pydantic_core-2.41.5-cp313-cp313-musllinux_1_1_x86_64.whl", hash = "sha256:915c3d10f81bec3a74fbd4faebe8391013ba61e5a1a8d48c4455b923bdda7858", size = 2324852, upload-time = "2025-11-04T13:40:48.575Z" },
    { url = "https://files.pythonhosted.org/packages/1a/d9/c248c103856f807ef70c18a4f986693a46a8ffe1602e5d361485da502d20/pydantic_core-2.41.5-cp313-cp313-win32.whl", hash = "sha256:650ae77860b45cfa6e2cdafc42618ceafab3a2d9a3811fcfbd3bbf8ac3c40d36", size = 1994679, upload-time = "2025-11-04T13:40:50.619Z" },
    { url = "https://files.pythonhosted.org/packages/9e/8b/341991b158ddab181cff136acd2552c9f35bd30380422a639c0671e99a91/pydantic_core-2.41.5-cp313-cp313-win_amd64.whl", hash = "sha256:79ec52ec461e99e13791ec6508c722742ad745571f234ea6255bed38c6480f11", size = 2019766, upload-time = "2025-11-04T13:40:52.631Z" },
    { url = "https://files.pythonhosted.org/packages/73/7d/f2f9db34af103bea3e09735bb40b021788a5e834c81eedb541991badf8f5/pydantic_core-2.41.5-cp313-cp313-win_arm64.whl", hash = "sha256:3f84d5c1b4ab906093bdc1ff10484838aca54ef08de4afa9de0f5f14d69639cd", size = 1981005, upload-time = "2025-11-04T13:40:54.734Z" },
]

[[package]]
name = "pyflakes"
version = "3.4.0"
source = { registry = "https://pypi.org/simple" }
sdist = { url = "https://files.pythonhosted.org/packages/45/dc/fd034dc20b4b264b3d015808458391acbf9df40b1e54750ef175d39180b1/pyflakes-3.4.0.tar.gz", hash = "sha256:b24f96fafb7d2ab0ec5075b7350b3d2d2218eab42003821c06344973d3ea2f58", size = 64669, upload-time = "2025-06-20T18:45:27.834Z" }
wheels = [
    { url = "https://files.pythonhosted.org/packages/c2/2f/81d580a0fb83baeb066698975cb14a618bdbed7720678566f1b046a95fe8/pyflakes-3.4.0-py2.py3-none-any.whl", hash = "sha256:f742a7dbd0d9cb9ea41e9a24a918996e8170c799fa528688d40dd582c8265f4f", size = 63551, upload-time = "2025-06-20T18:45:26.937Z" },
]

[[package]]
name = "pygelf"
version = "0.4.3"
source = { registry = "https://pypi.org/simple" }
sdist = { url = "https://files.pythonhosted.org/packages/49/91/ac1605bb40092ae41fbb833ee55447f72e19ce5459efa6bd3beecc67e971/pygelf-0.4.3.tar.gz", hash = "sha256:8ed972563be3c8f168483f01dbf522b6bc697959c97a3f4881324b3f79638911", size = 11017, upload-time = "2025-06-14T19:21:19.832Z" }
wheels = [
    { url = "https://files.pythonhosted.org/packages/d4/ee/ebac3de919431912e0be380fafd01059a091a489f6b5d7896c2a04548895/pygelf-0.4.3-py3-none-any.whl", hash = "sha256:0876c99a77f9f021834982c9808205b3239fabf5886788d701f31b495b65c8ae", size = 8750, upload-time = "2025-06-14T19:21:16.953Z" },
]

[[package]]
name = "pygments"
version = "2.19.2"
source = { registry = "https://pypi.org/simple" }
sdist = { url = "https://files.pythonhosted.org/packages/b0/77/a5b8c569bf593b0140bde72ea885a803b82086995367bf2037de0159d924/pygments-2.19.2.tar.gz", hash = "sha256:636cb2477cec7f8952536970bc533bc43743542f70392ae026374600add5b887", size = 4968631, upload-time = "2025-06-21T13:39:12.283Z" }
wheels = [
    { url = "https://files.pythonhosted.org/packages/c7/21/705964c7812476f378728bdf590ca4b771ec72385c533964653c68e86bdc/pygments-2.19.2-py3-none-any.whl", hash = "sha256:86540386c03d588bb81d44bc3928634ff26449851e99741617ecb9037ee5ec0b", size = 1225217, upload-time = "2025-06-21T13:39:07.939Z" },
]

[[package]]
name = "pytest"
version = "9.0.2"
source = { registry = "https://pypi.org/simple" }
dependencies = [
    { name = "colorama", marker = "sys_platform == 'win32'" },
    { name = "iniconfig" },
    { name = "packaging" },
    { name = "pluggy" },
    { name = "pygments" },
]
sdist = { url = "https://files.pythonhosted.org/packages/d1/db/7ef3487e0fb0049ddb5ce41d3a49c235bf9ad299b6a25d5780a89f19230f/pytest-9.0.2.tar.gz", hash = "sha256:75186651a92bd89611d1d9fc20f0b4345fd827c41ccd5c299a868a05d70edf11", size = 1568901, upload-time = "2025-12-06T21:30:51.014Z" }
wheels = [
    { url = "https://files.pythonhosted.org/packages/3b/ab/b3226f0bd7cdcf710fbede2b3548584366da3b19b5021e74f5bde2a8fa3f/pytest-9.0.2-py3-none-any.whl", hash = "sha256:711ffd45bf766d5264d487b917733b453d917afd2b0ad65223959f59089f875b", size = 374801, upload-time = "2025-12-06T21:30:49.154Z" },
]

[[package]]
name = "pytest-asyncio"
version = "1.3.0"
source = { registry = "https://pypi.org/simple" }
dependencies = [
    { name = "pytest" },
]
sdist = { url = "https://files.pythonhosted.org/packages/90/2c/8af215c0f776415f3590cac4f9086ccefd6fd463befeae41cd4d3f193e5a/pytest_asyncio-1.3.0.tar.gz", hash = "sha256:d7f52f36d231b80ee124cd216ffb19369aa168fc10095013c6b014a34d3ee9e5", size = 50087, upload-time = "2025-11-10T16:07:47.256Z" }
wheels = [
    { url = "https://files.pythonhosted.org/packages/e5/35/f8b19922b6a25bc0880171a2f1a003eaeb93657475193ab516fd87cac9da/pytest_asyncio-1.3.0-py3-none-any.whl", hash = "sha256:611e26147c7f77640e6d0a92a38ed17c3e9848063698d5c93d5aa7aa11cebff5", size = 15075, upload-time = "2025-11-10T16:07:45.537Z" },
]

[[package]]
name = "python-dateutil"
version = "2.9.0.post0"
source = { registry = "https://pypi.org/simple" }
dependencies = [
    { name = "six" },
]
sdist = { url = "https://files.pythonhosted.org/packages/66/c0/0c8b6ad9f17a802ee498c46e004a0eb49bc148f2fd230864601a86dcf6db/python-dateutil-2.9.0.post0.tar.gz", hash = "sha256:37dd54208da7e1cd875388217d5e00ebd4179249f90fb72437e91a35459a0ad3", size = 342432, upload-time = "2024-03-01T18:36:20.211Z" }
wheels = [
    { url = "https://files.pythonhosted.org/packages/ec/57/56b9bcc3c9c6a792fcbaf139543cee77261f3651ca9da0c93f5c1221264b/python_dateutil-2.9.0.post0-py2.py3-none-any.whl", hash = "sha256:a8b2bc7bffae282281c8140a97d3aa9c14da0b136dfe83f850eea9a5f7470427", size = 229892, upload-time = "2024-03-01T18:36:18.57Z" },
]

[[package]]
name = "pytz"
version = "2025.2"
source = { registry = "https://pypi.org/simple" }
sdist = { url = "https://files.pythonhosted.org/packages/f8/bf/abbd3cdfb8fbc7fb3d4d38d320f2441b1e7cbe29be4f23797b4a2b5d8aac/pytz-2025.2.tar.gz", hash = "sha256:360b9e3dbb49a209c21ad61809c7fb453643e048b38924c765813546746e81c3", size = 320884, upload-time = "2025-03-25T02:25:00.538Z" }
wheels = [
    { url = "https://files.pythonhosted.org/packages/81/c4/34e93fe5f5429d7570ec1fa436f1986fb1f00c3e0f43a589fe2bbcd22c3f/pytz-2025.2-py2.py3-none-any.whl", hash = "sha256:5ddf76296dd8c44c26eb8f4b6f35488f3ccbf6fbbd7adee0b7262d43f0ec2f00", size = 509225, upload-time = "2025-03-25T02:24:58.468Z" },
]

[[package]]
name = "regex"
version = "2025.11.3"
source = { registry = "https://pypi.org/simple" }
sdist = { url = "https://files.pythonhosted.org/packages/cc/a9/546676f25e573a4cf00fe8e119b78a37b6a8fe2dc95cda877b30889c9c45/regex-2025.11.3.tar.gz", hash = "sha256:1fedc720f9bb2494ce31a58a1631f9c82df6a09b49c19517ea5cc280b4541e01", size = 414669, upload-time = "2025-11-03T21:34:22.089Z" }
wheels = [
    { url = "https://files.pythonhosted.org/packages/e1/a7/dda24ebd49da46a197436ad96378f17df30ceb40e52e859fc42cac45b850/regex-2025.11.3-cp313-cp313-macosx_10_13_universal2.whl", hash = "sha256:c1e448051717a334891f2b9a620fe36776ebf3dd8ec46a0b877c8ae69575feb4", size = 489081, upload-time = "2025-11-03T21:31:55.9Z" },
    { url = "https://files.pythonhosted.org/packages/19/22/af2dc751aacf88089836aa088a1a11c4f21a04707eb1b0478e8e8fb32847/regex-2025.11.3-cp313-cp313-macosx_10_13_x86_64.whl", hash = "sha256:9b5aca4d5dfd7fbfbfbdaf44850fcc7709a01146a797536a8f84952e940cca76", size = 291123, upload-time = "2025-11-03T21:31:57.758Z" },
    { url = "https://files.pythonhosted.org/packages/a3/88/1a3ea5672f4b0a84802ee9891b86743438e7c04eb0b8f8c4e16a42375327/regex-2025.11.3-cp313-cp313-macosx_11_0_arm64.whl", hash = "sha256:04d2765516395cf7dda331a244a3282c0f5ae96075f728629287dfa6f76ba70a", size = 288814, upload-time = "2025-11-03T21:32:01.12Z" },
    { url = "https://files.pythonhosted.org/packages/fb/8c/f5987895bf42b8ddeea1b315c9fedcfe07cadee28b9c98cf50d00adcb14d/regex-2025.11.3-cp313-cp313-manylinux2014_aarch64.manylinux_2_17_aarch64.manylinux_2_28_aarch64.whl", hash = "sha256:5d9903ca42bfeec4cebedba8022a7c97ad2aab22e09573ce9976ba01b65e4361", size = 798592, upload-time = "2025-11-03T21:32:03.006Z" },
    { url = "https://files.pythonhosted.org/packages/99/2a/6591ebeede78203fa77ee46a1c36649e02df9eaa77a033d1ccdf2fcd5d4e/regex-2025.11.3-cp313-cp313-manylinux2014_ppc64le.manylinux_2_17_ppc64le.manylinux_2_28_ppc64le.whl", hash = "sha256:639431bdc89d6429f6721625e8129413980ccd62e9d3f496be618a41d205f160", size = 864122, upload-time = "2025-11-03T21:32:04.553Z" },
    { url = "https://files.pythonhosted.org/packages/94/d6/be32a87cf28cf8ed064ff281cfbd49aefd90242a83e4b08b5a86b38e8eb4/regex-2025.11.3-cp313-cp313-manylinux2014_s390x.manylinux_2_17_s390x.manylinux_2_28_s390x.whl", hash = "sha256:f117efad42068f9715677c8523ed2be1518116d1c49b1dd17987716695181efe", size = 912272, upload-time = "2025-11-03T21:32:06.148Z" },
    { url = "https://files.pythonhosted.org/packages/62/11/9bcef2d1445665b180ac7f230406ad80671f0fc2a6ffb93493b5dd8cd64c/regex-2025.11.3-cp313-cp313-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl", hash = "sha256:4aecb6f461316adf9f1f0f6a4a1a3d79e045f9b71ec76055a791affa3b285850", size = 803497, upload-time = "2025-11-03T21:32:08.162Z" },
    { url = "https://files.pythonhosted.org/packages/e5/a7/da0dc273d57f560399aa16d8a68ae7f9b57679476fc7ace46501d455fe84/regex-2025.11.3-cp313-cp313-musllinux_1_2_aarch64.whl", hash = "sha256:3b3a5f320136873cc5561098dfab677eea139521cb9a9e8db98b7e64aef44cbc", size = 787892, upload-time = "2025-11-03T21:32:09.769Z" },
    { url = "https://files.pythonhosted.org/packages/da/4b/732a0c5a9736a0b8d6d720d4945a2f1e6f38f87f48f3173559f53e8d5d82/regex-2025.11.3-cp313-cp313-musllinux_1_2_ppc64le.whl", hash = "sha256:75fa6f0056e7efb1f42a1c34e58be24072cb9e61a601340cc1196ae92326a4f9", size = 858462, upload-time = "2025-11-03T21:32:11.769Z" },
    { url = "https://files.pythonhosted.org/packages/0c/f5/a2a03df27dc4c2d0c769220f5110ba8c4084b0bfa9ab0f9b4fcfa3d2b0fc/regex-2025.11.3-cp313-cp313-musllinux_1_2_s390x.whl", hash = "sha256:dbe6095001465294f13f1adcd3311e50dd84e5a71525f20a10bd16689c61ce0b", size = 850528, upload-time = "2025-11-03T21:32:13.906Z" },
    { url = "https://files.pythonhosted.org/packages/d6/09/e1cd5bee3841c7f6eb37d95ca91cdee7100b8f88b81e41c2ef426910891a/regex-2025.11.3-cp313-cp313-musllinux_1_2_x86_64.whl", hash = "sha256:454d9b4ae7881afbc25015b8627c16d88a597479b9dea82b8c6e7e2e07240dc7", size = 789866, upload-time = "2025-11-03T21:32:15.748Z" },
    { url = "https://files.pythonhosted.org/packages/eb/51/702f5ea74e2a9c13d855a6a85b7f80c30f9e72a95493260193c07f3f8d74/regex-2025.11.3-cp313-cp313-win32.whl", hash = "sha256:28ba4d69171fc6e9896337d4fc63a43660002b7da53fc15ac992abcf3410917c", size = 266189, upload-time = "2025-11-03T21:32:17.493Z" },
    { url = "https://files.pythonhosted.org/packages/8b/00/6e29bb314e271a743170e53649db0fdb8e8ff0b64b4f425f5602f4eb9014/regex-2025.11.3-cp313-cp313-win_amd64.whl", hash = "sha256:bac4200befe50c670c405dc33af26dad5a3b6b255dd6c000d92fe4629f9ed6a5", size = 277054, upload-time = "2025-11-03T21:32:19.042Z" },
    { url = "https://files.pythonhosted.org/packages/25/f1/b156ff9f2ec9ac441710764dda95e4edaf5f36aca48246d1eea3f1fd96ec/regex-2025.11.3-cp313-cp313-win_arm64.whl", hash = "sha256:2292cd5a90dab247f9abe892ac584cb24f0f54680c73fcb4a7493c66c2bf2467", size = 270325, upload-time = "2025-11-03T21:32:21.338Z" },
    { url = "https://files.pythonhosted.org/packages/20/28/fd0c63357caefe5680b8ea052131acbd7f456893b69cc2a90cc3e0dc90d4/regex-2025.11.3-cp313-cp313t-macosx_10_13_universal2.whl", hash = "sha256:1eb1ebf6822b756c723e09f5186473d93236c06c579d2cc0671a722d2ab14281", size = 491984, upload-time = "2025-11-03T21:32:23.466Z" },
    { url = "https://files.pythonhosted.org/packages/df/ec/7014c15626ab46b902b3bcc4b28a7bae46d8f281fc7ea9c95e22fcaaa917/regex-2025.11.3-cp313-cp313t-macosx_10_13_x86_64.whl", hash = "sha256:1e00ec2970aab10dc5db34af535f21fcf32b4a31d99e34963419636e2f85ae39", size = 292673, upload-time = "2025-11-03T21:32:25.034Z" },
    { url = "https://files.pythonhosted.org/packages/23/ab/3b952ff7239f20d05f1f99e9e20188513905f218c81d52fb5e78d2bf7634/regex-2025.11.3-cp313-cp313t-macosx_11_0_arm64.whl", hash = "sha256:a4cb042b615245d5ff9b3794f56be4138b5adc35a4166014d31d1814744148c7", size = 291029, upload-time = "2025-11-03T21:32:26.528Z" },
    { url = "https://files.pythonhosted.org/packages/21/7e/3dc2749fc684f455f162dcafb8a187b559e2614f3826877d3844a131f37b/regex-2025.11.3-cp313-cp313t-manylinux2014_aarch64.manylinux_2_17_aarch64.manylinux_2_28_aarch64.whl", hash = "sha256:44f264d4bf02f3176467d90b294d59bf1db9fe53c141ff772f27a8b456b2a9ed", size = 807437, upload-time = "2025-11-03T21:32:28.363Z" },
    { url = "https://files.pythonhosted.org/packages/1b/0b/d529a85ab349c6a25d1ca783235b6e3eedf187247eab536797021f7126c6/regex-2025.11.3-cp313-cp313t-manylinux2014_ppc64le.manylinux_2_17_ppc64le.manylinux_2_28_ppc64le.whl", hash = "sha256:7be0277469bf3bd7a34a9c57c1b6a724532a0d235cd0dc4e7f4316f982c28b19", size = 873368, upload-time = "2025-11-03T21:32:30.4Z" },
    { url = "https://files.pythonhosted.org/packages/7d/18/2d868155f8c9e3e9d8f9e10c64e9a9f496bb8f7e037a88a8bed26b435af6/regex-2025.11.3-cp313-cp313t-manylinux2014_s390x.manylinux_2_17_s390x.manylinux_2_28_s390x.whl", hash = "sha256:0d31e08426ff4b5b650f68839f5af51a92a5b51abd8554a60c2fbc7c71f25d0b", size = 914921, upload-time = "2025-11-03T21:32:32.123Z" },
    { url = "https://files.pythonhosted.org/packages/2d/71/9d72ff0f354fa783fe2ba913c8734c3b433b86406117a8db4ea2bf1c7a2f/regex-2025.11.3-cp313-cp313t-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl", hash = "sha256:e43586ce5bd28f9f285a6e729466841368c4a0353f6fd08d4ce4630843d3648a", size = 812708, upload-time = "2025-11-03T21:32:34.305Z" },
    { url = "https://files.pythonhosted.org/packages/e7/19/ce4bf7f5575c97f82b6e804ffb5c4e940c62609ab2a0d9538d47a7fdf7d4/regex-2025.11.3-cp313-cp313t-musllinux_1_2_aarch64.whl", hash = "sha256:0f9397d561a4c16829d4e6ff75202c1c08b68a3bdbfe29dbfcdb31c9830907c6", size = 795472, upload-time = "2025-11-03T21:32:36.364Z" },
    { url = "https://files.pythonhosted.org/packages/03/86/fd1063a176ffb7b2315f9a1b08d17b18118b28d9df163132615b835a26ee/regex-2025.11.3-cp313-cp313t-musllinux_1_2_ppc64le.whl", hash = "sha256:dd16e78eb18ffdb25ee33a0682d17912e8cc8a770e885aeee95020046128f1ce", size = 868341, upload-time = "2025-11-03T21:32:38.042Z" },
    { url = "https://files.pythonhosted.org/packages/12/43/103fb2e9811205e7386366501bc866a164a0430c79dd59eac886a2822950/regex-2025.11.3-cp313-cp313t-musllinux_1_2_s390x.whl", hash = "sha256:ffcca5b9efe948ba0661e9df0fa50d2bc4b097c70b9810212d6b62f05d83b2dd", size = 854666, upload-time = "2025-11-03T21:32:40.079Z" },
    { url = "https://files.pythonhosted.org/packages/7d/22/e392e53f3869b75804762c7c848bd2dd2abf2b70fb0e526f58724638bd35/regex-2025.11.3-cp313-cp313t-musllinux_1_2_x86_64.whl", hash = "sha256:c56b4d162ca2b43318ac671c65bd4d563e841a694ac70e1a976ac38fcf4ca1d2", size = 799473, upload-time = "2025-11-03T21:32:42.148Z" },
    { url = "https://files.pythonhosted.org/packages/4f/f9/8bd6b656592f925b6845fcbb4d57603a3ac2fb2373344ffa1ed70aa6820a/regex-2025.11.3-cp313-cp313t-win32.whl", hash = "sha256:9ddc42e68114e161e51e272f667d640f97e84a2b9ef14b7477c53aac20c2d59a", size = 268792, upload-time = "2025-11-03T21:32:44.13Z" },
    { url = "https://files.pythonhosted.org/packages/e5/87/0e7d603467775ff65cd2aeabf1b5b50cc1c3708556a8b849a2fa4dd1542b/regex-2025.11.3-cp313-cp313t-win_amd64.whl", hash = "sha256:7a7c7fdf755032ffdd72c77e3d8096bdcb0eb92e89e17571a196f03d88b11b3c", size = 280214, upload-time = "2025-11-03T21:32:45.853Z" },
    { url = "https://files.pythonhosted.org/packages/8d/d0/2afc6f8e94e2b64bfb738a7c2b6387ac1699f09f032d363ed9447fd2bb57/regex-2025.11.3-cp313-cp313t-win_arm64.whl", hash = "sha256:df9eb838c44f570283712e7cff14c16329a9f0fb19ca492d21d4b7528ee6821e", size = 271469, upload-time = "2025-11-03T21:32:48.026Z" },
]

[[package]]
name = "requests"
version = "2.32.5"
source = { registry = "https://pypi.org/simple" }
dependencies = [
    { name = "certifi" },
    { name = "charset-normalizer" },
    { name = "idna" },
    { name = "urllib3" },
]
sdist = { url = "https://files.pythonhosted.org/packages/c9/74/b3ff8e6c8446842c3f5c837e9c3dfcfe2018ea6ecef224c710c85ef728f4/requests-2.32.5.tar.gz", hash = "sha256:dbba0bac56e100853db0ea71b82b4dfd5fe2bf6d3754a8893c3af500cec7d7cf", size = 134517, upload-time = "2025-08-18T20:46:02.573Z" }
wheels = [
    { url = "https://files.pythonhosted.org/packages/1e/db/4254e3eabe8020b458f1a747140d32277ec7a271daf1d235b70dc0b4e6e3/requests-2.32.5-py3-none-any.whl", hash = "sha256:2462f94637a34fd532264295e186976db0f5d453d1cdd31473c85a6a161affb6", size = 64738, upload-time = "2025-08-18T20:46:00.542Z" },
]

[[package]]
name = "six"
version = "1.17.0"
source = { registry = "https://pypi.org/simple" }
sdist = { url = "https://files.pythonhosted.org/packages/94/e7/b2c673351809dca68a0e064b6af791aa332cf192da575fd474ed7d6f16a2/six-1.17.0.tar.gz", hash = "sha256:ff70335d468e7eb6ec65b95b99d3a2836546063f63acc5171de367e834932a81", size = 34031, upload-time = "2024-12-04T17:35:28.174Z" }
wheels = [
    { url = "https://files.pythonhosted.org/packages/b7/ce/149a00dd41f10bc29e5921b496af8b574d8413afcd5e30dfa0ed46c2cc5e/six-1.17.0-py2.py3-none-any.whl", hash = "sha256:4721f391ed90541fddacab5acf947aa0d3dc7d27b2e1e8eda2be8970586c3274", size = 11050, upload-time = "2024-12-04T17:35:26.475Z" },
]

[[package]]
name = "typing-extensions"
version = "4.15.0"
source = { registry = "https://pypi.org/simple" }
sdist = { url = "https://files.pythonhosted.org/packages/72/94/1a15dd82efb362ac84269196e94cf00f187f7ed21c242792a923cdb1c61f/typing_extensions-4.15.0.tar.gz", hash = "sha256:0cea48d173cc12fa28ecabc3b837ea3cf6f38c6d1136f85cbaaf598984861466", size = 109391, upload-time = "2025-08-25T13:49:26.313Z" }
wheels = [
    { url = "https://files.pythonhosted.org/packages/18/67/36e9267722cc04a6b9f15c7f3441c2363321a3ea07da7ae0c0707beb2a9c/typing_extensions-4.15.0-py3-none-any.whl", hash = "sha256:f0fa19c6845758ab08074a0cfa8b7aecb71c999ca73d62883bc25cc018c4e548", size = 44614, upload-time = "2025-08-25T13:49:24.86Z" },
]

[[package]]
name = "typing-inspection"
version = "0.4.2"
source = { registry = "https://pypi.org/simple" }
dependencies = [
    { name = "typing-extensions" },
]
sdist = { url = "https://files.pythonhosted.org/packages/55/e3/70399cb7dd41c10ac53367ae42139cf4b1ca5f36bb3dc6c9d33acdb43655/typing_inspection-0.4.2.tar.gz", hash = "sha256:ba561c48a67c5958007083d386c3295464928b01faa735ab8547c5692e87f464", size = 75949, upload-time = "2025-10-01T02:14:41.687Z" }
wheels = [
    { url = "https://files.pythonhosted.org/packages/dc/9b/47798a6c91d8bdb567fe2698fe81e0c6b7cb7ef4d13da4114b41d239f65d/typing_inspection-0.4.2-py3-none-any.whl", hash = "sha256:4ed1cacbdc298c220f1bd249ed5287caa16f34d44ef4e9c3d0cbad5b521545e7", size = 14611, upload-time = "2025-10-01T02:14:40.154Z" },
]

[[package]]
name = "tzdata"
version = "2025.3"
source = { registry = "https://pypi.org/simple" }
sdist = { url = "https://files.pythonhosted.org/packages/5e/a7/c202b344c5ca7daf398f3b8a477eeb205cf3b6f32e7ec3a6bac0629ca975/tzdata-2025.3.tar.gz", hash = "sha256:de39c2ca5dc7b0344f2eba86f49d614019d29f060fc4ebc8a417896a620b56a7", size = 196772, upload-time = "2025-12-13T17:45:35.667Z" }
wheels = [
    { url = "https://files.pythonhosted.org/packages/c7/b0/003792df09decd6849a5e39c28b513c06e84436a54440380862b5aeff25d/tzdata-2025.3-py2.py3-none-any.whl", hash = "sha256:06a47e5700f3081aab02b2e513160914ff0694bce9947d6b76ebd6bf57cfc5d1", size = 348521, upload-time = "2025-12-13T17:45:33.889Z" },
]

[[package]]
name = "tzlocal"
version = "5.3.1"
source = { registry = "https://pypi.org/simple" }
dependencies = [
    { name = "tzdata", marker = "sys_platform == 'win32'" },
]
sdist = { url = "https://files.pythonhosted.org/packages/8b/2e/c14812d3d4d9cd1773c6be938f89e5735a1f11a9f184ac3639b93cef35d5/tzlocal-5.3.1.tar.gz", hash = "sha256:cceffc7edecefea1f595541dbd6e990cb1ea3d19bf01b2809f362a03dd7921fd", size = 30761, upload-time = "2025-03-05T21:17:41.549Z" }
wheels = [
    { url = "https://files.pythonhosted.org/packages/c2/14/e2a54fabd4f08cd7af1c07030603c3356b74da07f7cc056e600436edfa17/tzlocal-5.3.1-py3-none-any.whl", hash = "sha256:eb1a66c3ef5847adf7a834f1be0800581b683b5608e74f86ecbcef8ab91bb85d", size = 18026, upload-time = "2025-03-05T21:17:39.857Z" },
]

[[package]]
name = "urllib3"
version = "2.6.2"
source = { registry = "https://pypi.org/simple" }
sdist = { url = "https://files.pythonhosted.org/packages/1e/24/a2a2ed9addd907787d7aa0355ba36a6cadf1768b934c652ea78acbd59dcd/urllib3-2.6.2.tar.gz", hash = "sha256:016f9c98bb7e98085cb2b4b17b87d2c702975664e4f060c6532e64d1c1a5e797", size = 432930, upload-time = "2025-12-11T15:56:40.252Z" }
wheels = [
    { url = "https://files.pythonhosted.org/packages/6d/b9/4095b668ea3678bf6a0af005527f39de12fb026516fb3df17495a733b7f8/urllib3-2.6.2-py3-none-any.whl", hash = "sha256:ec21cddfe7724fc7cb4ba4bea7aa8e2ef36f607a4bab81aa6ce42a13dc3f03dd", size = 131182, upload-time = "2025-12-11T15:56:38.584Z" },
]

[[package]]
name = "wrapt"
version = "2.0.1"
source = { registry = "https://pypi.org/simple" }
sdist = { url = "https://files.pythonhosted.org/packages/49/2a/6de8a50cb435b7f42c46126cf1a54b2aab81784e74c8595c8e025e8f36d3/wrapt-2.0.1.tar.gz", hash = "sha256:9c9c635e78497cacb81e84f8b11b23e0aacac7a136e73b8e5b2109a1d9fc468f", size = 82040, upload-time = "2025-11-07T00:45:33.312Z" }
wheels = [
    { url = "https://files.pythonhosted.org/packages/ad/fe/41af4c46b5e498c90fc87981ab2972fbd9f0bccda597adb99d3d3441b94b/wrapt-2.0.1-cp313-cp313-macosx_10_13_universal2.whl", hash = "sha256:47b0f8bafe90f7736151f61482c583c86b0693d80f075a58701dd1549b0010a9", size = 78132, upload-time = "2025-11-07T00:44:04.628Z" },
    { url = "https://files.pythonhosted.org/packages/1c/92/d68895a984a5ebbbfb175512b0c0aad872354a4a2484fbd5552e9f275316/wrapt-2.0.1-cp313-cp313-macosx_10_13_x86_64.whl", hash = "sha256:cbeb0971e13b4bd81d34169ed57a6dda017328d1a22b62fda45e1d21dd06148f", size = 61211, upload-time = "2025-11-07T00:44:05.626Z" },
    { url = "https://files.pythonhosted.org/packages/e8/26/ba83dc5ae7cf5aa2b02364a3d9cf74374b86169906a1f3ade9a2d03cf21c/wrapt-2.0.1-cp313-cp313-macosx_11_0_arm64.whl", hash = "sha256:eb7cffe572ad0a141a7886a1d2efa5bef0bf7fe021deeea76b3ab334d2c38218", size = 61689, upload-time = "2025-11-07T00:44:06.719Z" },
    { url = "https://files.pythonhosted.org/packages/cf/67/d7a7c276d874e5d26738c22444d466a3a64ed541f6ef35f740dbd865bab4/wrapt-2.0.1-cp313-cp313-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl", hash = "sha256:c8d60527d1ecfc131426b10d93ab5d53e08a09c5fa0175f6b21b3252080c70a9", size = 121502, upload-time = "2025-11-07T00:44:09.557Z" },
    { url = "https://files.pythonhosted.org/packages/0f/6b/806dbf6dd9579556aab22fc92908a876636e250f063f71548a8660382184/wrapt-2.0.1-cp313-cp313-manylinux2014_aarch64.manylinux_2_17_aarch64.manylinux_2_28_aarch64.whl", hash = "sha256:c654eafb01afac55246053d67a4b9a984a3567c3808bb7df2f8de1c1caba2e1c", size = 123110, upload-time = "2025-11-07T00:44:10.64Z" },
    { url = "https://files.pythonhosted.org/packages/e5/08/cdbb965fbe4c02c5233d185d070cabed2ecc1f1e47662854f95d77613f57/wrapt-2.0.1-cp313-cp313-manylinux_2_31_riscv64.manylinux_2_39_riscv64.whl", hash = "sha256:98d873ed6c8b4ee2418f7afce666751854d6d03e3c0ec2a399bb039cd2ae89db", size = 117434, upload-time = "2025-11-07T00:44:08.138Z" },
    { url = "https://files.pythonhosted.org/packages/2d/d1/6aae2ce39db4cb5216302fa2e9577ad74424dfbe315bd6669725569e048c/wrapt-2.0.1-cp313-cp313-musllinux_1_2_aarch64.whl", hash = "sha256:c9e850f5b7fc67af856ff054c71690d54fa940c3ef74209ad9f935b4f66a0233", size = 121533, upload-time = "2025-11-07T00:44:12.142Z" },
    { url = "https://files.pythonhosted.org/packages/79/35/565abf57559fbe0a9155c29879ff43ce8bd28d2ca61033a3a3dd67b70794/wrapt-2.0.1-cp313-cp313-musllinux_1_2_riscv64.whl", hash = "sha256:e505629359cb5f751e16e30cf3f91a1d3ddb4552480c205947da415d597f7ac2", size = 116324, upload-time = "2025-11-07T00:44:13.28Z" },
    { url = "https://files.pythonhosted.org/packages/e1/e0/53ff5e76587822ee33e560ad55876d858e384158272cd9947abdd4ad42ca/wrapt-2.0.1-cp313-cp313-musllinux_1_2_x86_64.whl", hash = "sha256:2879af909312d0baf35f08edeea918ee3af7ab57c37fe47cb6a373c9f2749c7b", size = 120627, upload-time = "2025-11-07T00:44:14.431Z" },
    { url = "https://files.pythonhosted.org/packages/7c/7b/38df30fd629fbd7612c407643c63e80e1c60bcc982e30ceeae163a9800e7/wrapt-2.0.1-cp313-cp313-win32.whl", hash = "sha256:d67956c676be5a24102c7407a71f4126d30de2a569a1c7871c9f3cabc94225d7", size = 58252, upload-time = "2025-11-07T00:44:17.814Z" },
    { url = "https://files.pythonhosted.org/packages/85/64/d3954e836ea67c4d3ad5285e5c8fd9d362fd0a189a2db622df457b0f4f6a/wrapt-2.0.1-cp313-cp313-win_amd64.whl", hash = "sha256:9ca66b38dd642bf90c59b6738af8070747b610115a39af2498535f62b5cdc1c3", size = 60500, upload-time = "2025-11-07T00:44:15.561Z" },
    { url = "https://files.pythonhosted.org/packages/89/4e/3c8b99ac93527cfab7f116089db120fef16aac96e5f6cdb724ddf286086d/wrapt-2.0.1-cp313-cp313-win_arm64.whl", hash = "sha256:5a4939eae35db6b6cec8e7aa0e833dcca0acad8231672c26c2a9ab7a0f8ac9c8", size = 58993, upload-time = "2025-11-07T00:44:16.65Z" },
    { url = "https://files.pythonhosted.org/packages/f9/f4/eff2b7d711cae20d220780b9300faa05558660afb93f2ff5db61fe725b9a/wrapt-2.0.1-cp313-cp313t-macosx_10_13_universal2.whl", hash = "sha256:a52f93d95c8d38fed0669da2ebdb0b0376e895d84596a976c15a9eb45e3eccb3", size = 82028, upload-time = "2025-11-07T00:44:18.944Z" },
    { url = "https://files.pythonhosted.org/packages/0c/67/cb945563f66fd0f61a999339460d950f4735c69f18f0a87ca586319b1778/wrapt-2.0.1-cp313-cp313t-macosx_10_13_x86_64.whl", hash = "sha256:4e54bbf554ee29fcceee24fa41c4d091398b911da6e7f5d7bffda963c9aed2e1", size = 62949, upload-time = "2025-11-07T00:44:20.074Z" },
    { url = "https://files.pythonhosted.org/packages/ec/ca/f63e177f0bbe1e5cf5e8d9b74a286537cd709724384ff20860f8f6065904/wrapt-2.0.1-cp313-cp313t-macosx_11_0_arm64.whl", hash = "sha256:908f8c6c71557f4deaa280f55d0728c3bca0960e8c3dd5ceeeafb3c19942719d", size = 63681, upload-time = "2025-11-07T00:44:21.345Z" },
    { url = "https://files.pythonhosted.org/packages/39/a1/1b88fcd21fd835dca48b556daef750952e917a2794fa20c025489e2e1f0f/wrapt-2.0.1-cp313-cp313t-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl", hash = "sha256:e2f84e9af2060e3904a32cea9bb6db23ce3f91cfd90c6b426757cf7cc01c45c7", size = 152696, upload-time = "2025-11-07T00:44:24.318Z" },
    { url = "https://files.pythonhosted.org/packages/62/1c/d9185500c1960d9f5f77b9c0b890b7fc62282b53af7ad1b6bd779157f714/wrapt-2.0.1-cp313-cp313t-manylinux2014_aarch64.manylinux_2_17_aarch64.manylinux_2_28_aarch64.whl", hash = "sha256:e3612dc06b436968dfb9142c62e5dfa9eb5924f91120b3c8ff501ad878f90eb3", size = 158859, upload-time = "2025-11-07T00:44:25.494Z" },
    { url = "https://files.pythonhosted.org/packages/91/60/5d796ed0f481ec003220c7878a1d6894652efe089853a208ea0838c13086/wrapt-2.0.1-cp313-cp313t-manylinux_2_31_riscv64.manylinux_2_39_riscv64.whl", hash = "sha256:6d2d947d266d99a1477cd005b23cbd09465276e302515e122df56bb9511aca1b", size = 146068, upload-time = "2025-11-07T00:44:22.81Z" },
    { url = "https://files.pythonhosted.org/packages/04/f8/75282dd72f102ddbfba137e1e15ecba47b40acff32c08ae97edbf53f469e/wrapt-2.0.1-cp313-cp313t-musllinux_1_2_aarch64.whl", hash = "sha256:7d539241e87b650cbc4c3ac9f32c8d1ac8a54e510f6dca3f6ab60dcfd48c9b10", size = 155724, upload-time = "2025-11-07T00:44:26.634Z" },
    { url = "https://files.pythonhosted.org/packages/5a/27/fe39c51d1b344caebb4a6a9372157bdb8d25b194b3561b52c8ffc40ac7d1/wrapt-2.0.1-cp313-cp313t-musllinux_1_2_riscv64.whl", hash = "sha256:4811e15d88ee62dbf5c77f2c3ff3932b1e3ac92323ba3912f51fc4016ce81ecf", size = 144413, upload-time = "2025-11-07T00:44:27.939Z" },
    { url = "https://files.pythonhosted.org/packages/83/2b/9f6b643fe39d4505c7bf926d7c2595b7cb4b607c8c6b500e56c6b36ac238/wrapt-2.0.1-cp313-cp313t-musllinux_1_2_x86_64.whl", hash = "sha256:c1c91405fcf1d501fa5d55df21e58ea49e6b879ae829f1039faaf7e5e509b41e", size = 150325, upload-time = "2025-11-07T00:44:29.29Z" },
    { url = "https://files.pythonhosted.org/packages/bb/b6/20ffcf2558596a7f58a2e69c89597128781f0b88e124bf5a4cadc05b8139/wrapt-2.0.1-cp313-cp313t-win32.whl", hash = "sha256:e76e3f91f864e89db8b8d2a8311d57df93f01ad6bb1e9b9976d1f2e83e18315c", size = 59943, upload-time = "2025-11-07T00:44:33.211Z" },
    { url = "https://files.pythonhosted.org/packages/87/6a/0e56111cbb3320151eed5d3821ee1373be13e05b376ea0870711f18810c3/wrapt-2.0.1-cp313-cp313t-win_amd64.whl", hash = "sha256:83ce30937f0ba0d28818807b303a412440c4b63e39d3d8fc036a94764b728c92", size = 63240, upload-time = "2025-11-07T00:44:30.935Z" },
    { url = "https://files.pythonhosted.org/packages/1d/54/5ab4c53ea1f7f7e5c3e7c1095db92932cc32fd62359d285486d00c2884c3/wrapt-2.0.1-cp313-cp313t-win_arm64.whl", hash = "sha256:4b55cacc57e1dc2d0991dbe74c6419ffd415fb66474a02335cb10efd1aa3f84f", size = 60416, upload-time = "2025-11-07T00:44:32.002Z" },
    { url = "https://files.pythonhosted.org/packages/15/d1/b51471c11592ff9c012bd3e2f7334a6ff2f42a7aed2caffcf0bdddc9cb89/wrapt-2.0.1-py3-none-any.whl", hash = "sha256:4d2ce1bf1a48c5277d7969259232b57645aae5686dba1eaeade39442277afbca", size = 44046, upload-time = "2025-11-07T00:45:32.116Z" },
]



================================================
FILE: component_config/component_long_description.md
================================================
The Energis API Extractor is a Keboola component that enables users to seamlessly retrieve and process energy consumption 
data from the Energis platform. The component is designed for efficient data extraction, supporting multiple 
levels of granularity, including:

- Yearly (`year`)
- Quarterly (`quarterYear`)
- Monthly (`month`)
- Daily (`day`)
- Hourly (`hour`)
- Quarter-hour (`quarterHour`)
- Minute (`minute`)

## 🔧 Features & Functionality

- **Secure Authentication**: Uses username/password authentication for API access.
- **Flexible Data Selection**: Users can specify nodes, time range, and granularity for precise data extraction.
- **Incremental Fetching**: The component remembers the last processed date and fetches only new data.
- **Automatic Data Parsing**: Converts API responses into a structured format, handling various timestamp formats.
- **CSV Output & Manifest Generation**: Saves data as CSV and generates metadata for seamless integration into Keboola Storage.

## 📂 Output Format

The extracted data is stored in Keboola Storage, with each dataset containing:

- **Node ID (uzel)** – Unique identifier of the energy node.
- **Value (hodnota)** – The recorded energy consumption or measurement.
- **Timestamp (cas)** – The formatted date/time of the measurement.

## 🚀 Use Cases

- **Energy Monitoring & Reporting** – Retrieve historical and real-time energy consumption data.
- **Data Integration for Analysis** – Combine Energis data with other sources in Keboola for advanced analytics.
- **Automated ETL Pipelines** – Automate data ingestion into data warehouses and BI tools.

## 🔒 Security & Logging

Sensitive credentials are **masked in logs**, ensuring security. Detailed logging allows debugging and monitoring of API requests.

This component simplifies **data extraction from Energis**, enabling automated, scalable, and structured energy data processing within Keboola.


================================================
FILE: component_config/component_short_description.md
================================================
Energis API Extractor is a Keboola component designed to fetch energy data from the Energis API, 
process it according to user-defined parameters (nodes, granularity, and time range), 
and store it in Keboola Storage.


================================================
FILE: component_config/configSchema.json
================================================
{
    "type": "object",
    "title": "Energis Component Configuration",
    "required": ["authentication", "sync_options", "debug"],
    "properties": {
        "authentication": {
            "type": "object",
            "title": "Authentication Settings",
            "propertyOrder": 1,
            "required": ["username", "#password", "environment"],
            "properties": {
                "username": {
                    "type": "string",
                    "title": "Username",
                    "default": "",
                    "propertyOrder": 1
                },
                "#password": {
                    "type": "string",
                    "title": "Password",
                    "format": "password",
                    "propertyOrder": 2
                },
                "environment": {
                    "type": "string",
                    "title": "API Environment",
                    "enum": ["dev", "prod"],
                    "default": "prod",
                    "propertyOrder": 3,
                    "description": "Choose 'dev' for testing or 'prod' for production."
                }
            }
        },
        "sync_options": {
            "type": "object",
            "title": "Synchronization Options",
            "propertyOrder": 2,
            "required": ["dataset", "nodes", "date_from", "granularity"],
            "properties": {
                "dataset": {
                    "type": "string",
                    "title": "Dataset",
                    "enum": [
                        "xexport"
                    ],
                    "default": "xexport",
                    "propertyOrder": 1
                },
                "nodes": {
                    "type": "array",
                    "items": {
                        "type": "integer",
                        "title": "Node ID"
                    },
                    "options": {
                        "tags": true
                    },
                    "title": "List of Nodes",
                    "format": "select",
                    "default": [],
                    "uniqueItems": true,
                    "propertyOrder": 2
                },
                "date_from": {
                    "type": "string",
                    "format": "date",
                    "title": "Date From",
                    "default": "2024-12-01",
                    "propertyOrder": 3
                },
                "date_to": {
                    "type": "string",
                    "format": "date",
                    "title": "Date To",
                    "description": "If not set, defaults to today's date dynamically",
                    "propertyOrder": 4
                },
                "granularity": {
                    "type": "string",
                    "title": "Data Granularity",
                    "enum": [
                        "year",
                        "quarterYear",
                        "month",
                        "day",
                        "hour",
                        "quarterHour",
                        "minute"
                    ],
                    "default": "day",
                    "propertyOrder": 5
                },
                "reload_full_data": {
                    "type": "boolean",
                    "title": "Reload Full Data",
                    "description": "When enabled, retrieves the complete dataset from 'date_from', bypassing incremental loading",
                    "default": false,
                    "propertyOrder": 6
                }
            }
        },
        "debug": {
            "type": "boolean",
            "title": "Enable Debug Mode",
            "default": false,
            "propertyOrder": 3
        }
    }
}



================================================
FILE: component_config/configuration_description.md
================================================
# 🔧 Energis Component Configuration

This component allows you to retrieve energy data from the Energis API, process it based on defined criteria, and store 
it in Keboola Storage. Configure the authentication, data selection, and granularity settings as needed.

## Authentication Settings

> **Required:** ✅ Yes  
> **Description:** Provides API credentials for authentication.

| **Section**        | **Required** | **Description** |
|--------------------|-------------|---------------|
| **Authentication** | ✅ Yes       | Provides API credentials for authentication. |
| **Sync Options**   | ✅ Yes       | Defines data extraction settings, including dataset, nodes, and date range. |
| **Debug Mode**     | ❌ No         | Enables or disables debug logging for troubleshooting. |

## Synchronization Options

> **Required:** ✅ Yes  
> **Description:** Define the dataset, time range, and data granularity for extraction.

| **Property**                      | **Required** | **Type**     | **Default** | **Description** |
|-----------------------------------|--------------|------------|------------|---------------|
| **authentication.username**       | ✅ Yes        | String | _(None)_ | Username for API authentication. |
| **authentication.#password**      | ✅ Yes        | String (password) | _(None)_ | Password for API authentication. |
| **authentication.environment**    | ✅ Yes        | Enum (`dev` / `prod`) | `prod` | Selects the API environment (development or production). |
| **sync_options.dataset**          | ✅ Yes        | Enum (`xexport`) | `xexport` | Specifies the dataset for extraction. |
| **sync_options.nodes**            | ✅ Yes        | Array of Integers | `[]` | List of node IDs for data retrieval. |
| **sync_options.date_from**        | ✅ Yes        | Date (`YYYY-MM-DD`) | `2024-12-01` | Start date for data extraction. |
| **sync_options.date_to**          | ❌ No         | Date (`YYYY-MM-DD`) | _(Today)_ | End date for data extraction. If not set, defaults to today. |
| **sync_options.granularity**      | ✅ Yes        | Enum (`year`, `quarterYear`, `month`, `day`, `hour`, `quarterHour`, `minute`) | `day` | Defines data granularity for extraction. |
| **sync_options.reload_full_data** | ❌ No | Boolean| _False_      | When enabled, retrieves the complete dataset from 'date_from', bypassing incremental loading. |

## Debug Mode

> **Required:** ❌ No  
> **Description:** Enables debug logging for troubleshooting.
 
| **Property**        | **Required** | **Type**     | **Default** | **Description** |
|--------------------|-----------|------------|------------|---------------|
| **debug** | ❌ Yes | Boolean | `false` | Enables debug mode for additional logging. |


## Example configuration

```json
{
  "authentication": {
    "username": "your_username",
    "#password": "your_password",
    "environment": "prod"
  },
  "sync_options": {
    "dataset": "xexport",
    "nodes": [7090001, 7090002],
    "date_from": "2024-01-01",
    "date_to": "2024-12-31",
    "granularity": "hour"
  },
  "debug": false
}
```


================================================
FILE: component_config/documentationUrl.md
================================================
https://github.com/keboola/component-energis/blob/master/README.md


================================================
FILE: component_config/licenseUrl.md
================================================
https://github.com/keboola/component-energis/blob/master/LICENSE.md


================================================
FILE: component_config/logger
================================================
gelf


================================================
FILE: component_config/loggerConfiguration.json
================================================
{
  "verbosity": {
    "100": "normal",
    "200": "normal",
    "250": "normal",
    "300": "verbose",
    "400": "verbose",
    "500": "camouflage",
    "550": "camouflage",
    "600": "camouflage"
  },
  "gelf_server_type": "tcp"
}


================================================
FILE: component_config/sourceCodeUrl.md
================================================
https://github.com/keboola/component-energis


================================================
FILE: scripts/build_n_run.ps1
================================================
echo Building component...
$COMP_TAG = Read-Host -Prompt 'Input Docker tag name:'
docker build -rm -t $COMP_TAG ../

echo Running component...
Write-host "Would you like to use default data folder? (../data)" -ForegroundColor Yellow 
    $Readhost = Read-Host " ( y / n ) " 
    Switch ($ReadHost) 
     { 
       Y {Write-host "Yes use: " (join-path (Split-Path -Path (Get-Location).Path) "data"); $DATA_PATH = (join-path (Split-Path -Path (Get-Location).Path) "data") } 
       N {Write-Host "No, I'll specify myself"; $DATA_PATH = Read-Host -Prompt 'Input data folder path:'} 
       Default {Write-Host "Default, run app"; docker run -v $DATA_PATH`:/data -e KBC_DATADIR=/data $COMP_TAG} 
     } 

Write-host "Would you like to execute the container to Bash, skipping the execution?" -ForegroundColor Yellow 
    $Readhost = Read-Host " ( y / n ) " 
    Switch ($ReadHost) 
     { 
       Y {Write-host "Yes, get me to the bash"; docker run -ti -v $DATA_PATH`:/data --entrypoint=//bin//bash $COMP_TAG} 
       N {Write-Host "No, execute the app normally"; 
		    echo $DATA_PATH
			docker run -v $DATA_PATH`:/data -e KBC_DATADIR=/data $COMP_TAG
	   } 
       Default {Write-Host "Default, run app"; docker run -v $DATA_PATH`:/data -e KBC_DATADIR=/data $COMP_TAG} 
     } 





================================================
FILE: scripts/build_n_test.sh
================================================
#!/bin/sh
set -e

flake8 --config=flake8.cfg
python -m unittest discover


================================================
FILE: scripts/run_kbc_tests.ps1
================================================
echo "Preparing KBC test image"
# set env vars
$KBC_DEVELOPERPORTAL_USERNAME  = Read-Host -Prompt 'Input your service account user name'
$KBC_DEVELOPERPORTAL_PASSWORD  = Read-Host -Prompt 'Input your service account pass'
$KBC_DEVELOPERPORTAL_VENDOR = 'esnerda'
$KBC_DEVELOPERPORTAL_APP = 'esnerda.ex-gusto-export'
$BASE_KBC_CONFIG = '455568423'
$KBC_STORAGE_TOKEN = Read-Host -Prompt 'Input your storage token'


#build app
$APP_IMAGE='keboola-comp-test'
docker build ..\ --tag=$APP_IMAGE
docker images
docker -v
#docker run $APP_IMAGE flake8 --config=./deployment/flake8.cfg
echo "Running unit-tests..."
docker run $APP_IMAGE python -m unittest discover

docker pull quay.io/keboola/developer-portal-cli-v2:latest
$REPOSITORY= docker run --rm -e KBC_DEVELOPERPORTAL_USERNAME=$KBC_DEVELOPERPORTAL_USERNAME -e KBC_DEVELOPERPORTAL_PASSWORD=$KBC_DEVELOPERPORTAL_PASSWORD quay.io/keboola/developer-portal-cli-v2:latest ecr:get-repository $KBC_DEVELOPERPORTAL_VENDOR $KBC_DEVELOPERPORTAL_APP

docker tag $APP_IMAGE`:latest $REPOSITORY`:test

echo 'running login'
$(docker run --rm -e KBC_DEVELOPERPORTAL_USERNAME=$KBC_DEVELOPERPORTAL_USERNAME -e KBC_DEVELOPERPORTAL_PASSWORD=$KBC_DEVELOPERPORTAL_PASSWORD -e KBC_DEVELOPERPORTAL_URL quay.io/keboola/developer-portal-cli-v2:latest ecr:get-login $KBC_DEVELOPERPORTAL_VENDOR $KBC_DEVELOPERPORTAL_APP)

echo 'pushing test image'
docker push $REPOSITORY`:test

echo 'running test config in KBC'
docker run --rm -e KBC_STORAGE_TOKEN=$KBC_STORAGE_TOKEN quay.io/keboola/syrup-cli:latest run-job $KBC_DEVELOPERPORTAL_APP $BASE_KBC_CONFIG test



================================================
FILE: scripts/developer_portal/fn_actions_md_update.sh
================================================
#!/bin/bash

# Set the path to the Python script file
PYTHON_FILE="src/component.py"
# Set the path to the Markdown file containing actions
MD_FILE="component_config/actions.md"

# Check if the file exists before creating it
if [ ! -e "$MD_FILE" ]; then
    touch "$MD_FILE"
else
    echo "File already exists: $MD_FILE"
    exit 1
fi

# Get all occurrences of lines containing @sync_action('XXX') from the .py file
SYNC_ACTIONS=$(grep -o -E "@sync_action\(['\"][^'\"]*['\"]\)" "$PYTHON_FILE" | sed "s/@sync_action(\(['\"]\)\([^'\"]*\)\(['\"]\))/\2/" | sort | uniq)

# Check if any sync actions were found
if [ -n "$SYNC_ACTIONS" ]; then
    # Iterate over each occurrence of @sync_action('XXX')
    for sync_action in $SYNC_ACTIONS; do
        EXISTING_ACTIONS+=("$sync_action")
    done

    # Convert the array to JSON format
    JSON_ACTIONS=$(printf '"%s",' "${EXISTING_ACTIONS[@]}")
    JSON_ACTIONS="[${JSON_ACTIONS%,}]"

    # Update the content of the actions.md file
    echo "$JSON_ACTIONS" > "$MD_FILE"
else
    echo "No sync actions found. Not creating the file."
fi


================================================
FILE: scripts/developer_portal/update_properties.sh
================================================
#!/usr/bin/env bash

set -e

# Check if the KBC_DEVELOPERPORTAL_APP environment variable is set
if [ -z "$KBC_DEVELOPERPORTAL_APP" ]; then
    echo "Error: KBC_DEVELOPERPORTAL_APP environment variable is not set."
    exit 1
fi

# Pull the latest version of the developer portal CLI Docker image
docker pull quay.io/keboola/developer-portal-cli-v2:latest

# Function to update a property for the given app ID
update_property() {
    local app_id="$1"
    local prop_name="$2"
    local file_path="$3"

    if [ ! -f "$file_path" ]; then
        echo "File '$file_path' not found. Skipping update for property '$prop_name' of application '$app_id'."
        return
    fi

    # shellcheck disable=SC2155
    local value=$(<"$file_path")

    echo "Updating $prop_name for $app_id"
    echo "$value"

    if [ -n "$value" ]; then
        docker run --rm \
            -e KBC_DEVELOPERPORTAL_USERNAME \
            -e KBC_DEVELOPERPORTAL_PASSWORD \
            quay.io/keboola/developer-portal-cli-v2:latest \
            update-app-property "$KBC_DEVELOPERPORTAL_VENDOR" "$app_id" "$prop_name" --value="$value"
        echo "Property $prop_name updated successfully for $app_id"
    else
        echo "$prop_name is empty for $app_id, skipping..."
    fi
}

app_id="$KBC_DEVELOPERPORTAL_APP"

update_property "$app_id" "isDeployReady" "component_config/isDeployReady.md"
update_property "$app_id" "longDescription" "component_config/component_long_description.md"
update_property "$app_id" "configurationSchema" "component_config/configSchema.json"
update_property "$app_id" "configurationRowSchema" "component_config/configRowSchema.json"
update_property "$app_id" "configurationDescription" "component_config/configuration_description.md"
update_property "$app_id" "shortDescription" "component_config/component_short_description.md"
update_property "$app_id" "logger" "component_config/logger"
update_property "$app_id" "loggerConfiguration" "component_config/loggerConfiguration.json"
update_property "$app_id" "licenseUrl" "component_config/licenseUrl.md"
update_property "$app_id" "documentationUrl" "component_config/documentationUrl.md"
update_property "$app_id" "sourceCodeUrl" "component_config/sourceCodeUrl.md"
update_property "$app_id" "uiOptions" "component_config/uiOptions.md"

# Update the actions.md file
source "$(dirname "$0")/fn_actions_md_update.sh"
# update_property actions
update_property "$app_id" "actions" "component_config/actions.md"


================================================
FILE: src/api_client.py
================================================
import asyncio
import csv
import logging
import re
import time
from dataclasses import dataclass
from datetime import datetime, timedelta
from typing import Any, Iterator

import httpx
from lxml import etree

from configuration import Configuration, DatasetEnum, GranularityEnum


@dataclass(frozen=True)
class GranularityMeta:
    """
    Metadata for each granularity level.

    Attributes:
        short_code: Single-letter API code (r, v, m, d, h, c, t)
        points_per_day: Number of data points per node per day
    """

    short_code: str
    points_per_day: int


# Data points per day for each granularity level
# Based on time intervals:
# - minute: 24h × 60min = 1440 points/day
# - quarterHour: 24h × 4 quarters = 96 points/day
# - hour: 24 points/day
# - day/month/quarterYear/year: 1 point per period
GRANULARITY_META: dict[GranularityEnum, GranularityMeta] = {
    GranularityEnum.year: GranularityMeta("r", 1),
    GranularityEnum.quarterYear: GranularityMeta("v", 1),
    GranularityEnum.month: GranularityMeta("m", 1),
    GranularityEnum.day: GranularityMeta("d", 1),
    GranularityEnum.hour: GranularityMeta("h", 24),
    GranularityEnum.quarterHour: GranularityMeta("c", 96),
    GranularityEnum.minute: GranularityMeta("t", 1440),
}


class EnergisClient:
    """API Client for Energis API using async httpx with streaming CSV output."""

    # Number of concurrent requests for chunk processing
    MAX_CONCURRENT = 4

    # HTTP timeouts (connect, read) in seconds
    CONNECT_TIMEOUT = 30
    READ_TIMEOUT = 300

    # Memory limit per chunk (in MB)
    MAX_CHUNK_SIZE_MB = 10

    # Average size of one row in memory (3 columns: uzel, hodnota, cas)
    BYTES_PER_ROW = 200

    # Calculate max rows per chunk from memory limit
    MAX_ROWS_PER_CHUNK = (MAX_CHUNK_SIZE_MB * 1024 * 1024) // BYTES_PER_ROW

    @staticmethod
    def mask_sensitive_data(body: str, mask_char: str = "*") -> str:
        """Masks sensitive fields in the SOAP XML body."""
        fields_to_mask = ["username", "password", "exuziv", "exklic"]
        for field in fields_to_mask:
            pattern = f"<{field}>(.*?)</{field}>"

            def mask_match(match: re.Match) -> str:
                value = match.group(1)
                if len(value) > 1:
                    masked_value = f"{value[0].lower()}{mask_char * (len(value))}"
                else:
                    masked_value = mask_char
                return f"<{field}>{masked_value}</{field}>"

            body = re.sub(pattern, mask_match, body, flags=re.IGNORECASE)
        return body

    @staticmethod
    def generate_logon_request(
        username: str, password: str
    ) -> tuple[str, dict[str, str]]:
        """Generates the SOAP request body and headers for the logonex operation."""
        soap_body = f"""
        <soap:Envelope xmlns:soap="http://schemas.xmlsoap.org/soap/envelope/"
               soap:encodingStyle="http://schemas.xmlsoap.org/soap/encoding/"
               xmlns:ene="ENERGIS-URL">
            <soap:Body>
                <ene:logonex>
                    <username>{username}</username>
                    <password>{password}</password>
                </ene:logonex>
            </soap:Body>
        </soap:Envelope>
        """
        headers = {"Content-Type": "text/xml; charset=utf-8", "SOAPAction": "logonex"}
        return soap_body, headers

    @staticmethod
    def generate_xexport_request(
        username: str,
        key: str,
        nodes: list[int],
        date_from: str,
        date_to: str,
        granularity: str,
    ) -> tuple[str, dict[str, str]]:
        """Generates the SOAP request body and headers for the xexport operation."""
        nodes_str = ",".join(map(str, nodes))
        soap_body = f"""<?xml version="1.0" encoding="UTF-8"?>
        <soap:Envelope xmlns:soap="http://schemas.xmlsoap.org/soap/envelope/"
                       soap:encodingStyle="http://schemas.xmlsoap.org/soap/encoding/"
                       xmlns:ene="ENERGIS-URL">
            <soap:Header>
                <ene:Auth>
                    <exuziv>{username}</exuziv>
                    <exklic>{key}</exklic>
                </ene:Auth>
            </soap:Header>
            <soap:Body>
                <ene:xexport>
                    <uzel>{nodes_str}</uzel>
                    <typuz>2</typuz>
                    <per>{granularity}</per>
                    <cas>{date_from},{date_to}</cas>
                    <typhodn>hodnota</typhodn>
                </ene:xexport>
            </soap:Body>
        </soap:Envelope>"""
        headers = {"Content-Type": "text/xml; charset=utf-8", "SOAPAction": "xexport"}
        return soap_body, headers

    @staticmethod
    def granularity_to_short_code(granularity: GranularityEnum) -> str:
        """Returns a single-letter string based on the GranularityEnum value."""
        return GRANULARITY_META[granularity].short_code

    @staticmethod
    def convert_date_to_mmddyyyyhhmm(date_str: str) -> str:
        """Converts a date string from 'YYYY-MM-DD' format to 'MMDDYYYYHHMM'."""
        try:
            date_obj = datetime.strptime(date_str, "%Y-%m-%d")
            return date_obj.strftime("%m%d%Y0000")
        except ValueError:
            raise ValueError(
                f"Invalid date format: {date_str}. Expected format: YYYY-MM-DD"
            )

    @staticmethod
    def format_datetime(value: str, granularity: GranularityEnum) -> str:
        """Formats datetime value based on granularity."""
        match granularity:
            case GranularityEnum.year:
                return value
            case GranularityEnum.quarterYear:
                quarter_map = {"I": "Q1", "II": "Q2", "III": "Q3", "IV": "Q4"}
                quarter, year = value.split("/")
                return f"{quarter_map.get(quarter, quarter)}/{year}"
            case GranularityEnum.month:
                return value
            case GranularityEnum.day:
                return datetime.strptime(value, "%d.%m.%Y").strftime("%Y-%m-%d")
            case (
                GranularityEnum.hour
                | GranularityEnum.quarterHour
                | GranularityEnum.minute
            ):
                day_part, time_part = value.split(" ")
                day = datetime.strptime(day_part, "%d.%m.%Y").strftime("%Y-%m-%d")
                start_time = time_part.split("-")[0]
                return (
                    f"{day} {start_time}:00"
                    if ":" not in start_time
                    else f"{day} {start_time}"
                )
            case _:
                raise ValueError(f"Unsupported granularity: {granularity}")

    def __init__(self, config: "Configuration"):
        self.config = config

        logging.getLogger("httpx").setLevel(logging.WARNING)
        logging.getLogger("httpcore").setLevel(logging.WARNING)

        # Sync HTTP client for authentication
        self.auth_client = httpx.Client(
            verify=False,
            timeout=httpx.Timeout(self.READ_TIMEOUT, connect=self.CONNECT_TIMEOUT),
        )
        self.max_retries = 5
        self.retry_delay = 120
        self.auth_key = None

    def authenticate(self) -> str:
        """Calls the auth endpoint and retrieves the key for further requests."""
        body, headers = self.generate_logon_request(
            *self.config.authentication.credentials
        )
        auth_url = f"{self.config.authentication.api_base_url}?logon"

        if self.config.debug:
            masked_body = self.mask_sensitive_data(body)
            logging.debug("Request auth url: %s", auth_url)
            logging.debug("Request header: %s", headers)
            logging.debug("Request body: %s", masked_body)

        retries = 0
        response = None

        while retries < self.max_retries:
            try:
                response = self.auth_client.post(
                    auth_url, content=body, headers=headers
                )

                if response.status_code != 200:
                    logging.error(
                        "Authentication failed with status code %s",
                        response.status_code,
                    )
                    raise Exception(f"Authentication failed: {response.status_code}")

                logging.debug("Authentication response: %s", response.text)

                xml_response = etree.fromstring(response.content)
                key = xml_response.xpath("//key/text()")

                if key:
                    logging.debug(
                        "Authentication successful, received key: %s",
                        key[0][:4] + "****",
                    )
                    return key[0]

                raise Exception("Authentication failed: No key found in the response.")

            except Exception as e:
                logging.error(
                    "Authentication attempt %d failed: %s", retries + 1, str(e)
                )

                # Only try to parse SOAP fault if we have a response
                if response is not None:
                    try:
                        xml_response = etree.fromstring(response.content)
                        fault_string = xml_response.xpath("//faultstring/text()")

                        if (
                            fault_string
                            and "již v systému přihlášen" in fault_string[0]
                        ):
                            logging.warning(
                                "User already logged in. Waiting %d seconds before retrying...",
                                self.retry_delay,
                            )
                            time.sleep(self.retry_delay)
                            retries += 1
                            response = None
                            continue
                    except Exception:
                        pass  # Failed to parse SOAP fault response, will re-raise original exception

                raise e

        raise Exception("Maximum retries reached. Unable to authenticate.")

    def _calculate_chunk_days(
        self, granularity: GranularityEnum, num_nodes: int
    ) -> int:
        """
        Calculates chunk size in days based on memory limit.

        Args:
            granularity: Data granularity level
            num_nodes: Number of nodes being queried

        Returns:
            Number of days per chunk (minimum 1)
        """
        meta = GRANULARITY_META[granularity]
        rows_per_day = meta.points_per_day * num_nodes
        chunk_days = max(1, self.MAX_ROWS_PER_CHUNK // rows_per_day)

        logging.info(
            "Chunk size: %d days (%d nodes × %d points/day = %d rows/day)",
            chunk_days,
            num_nodes,
            meta.points_per_day,
            rows_per_day,
        )

        return chunk_days

    def _generate_date_chunks(
        self, date_from: str, date_to: str, granularity: GranularityEnum, num_nodes: int
    ) -> Iterator[tuple[str, str]]:
        """
        Generates date range chunks based on memory limit.

        Args:
            date_from: Start date in YYYY-MM-DD format
            date_to: End date in YYYY-MM-DD format
            granularity: Data granularity level
            num_nodes: Number of nodes being queried

        Yields:
            Tuples of (chunk_start, chunk_end) dates in YYYY-MM-DD format
        """
        chunk_days = self._calculate_chunk_days(granularity, num_nodes)
        start = datetime.strptime(date_from, "%Y-%m-%d")
        end = datetime.strptime(date_to, "%Y-%m-%d")

        current_start = start
        while current_start < end:
            current_end = min(current_start + timedelta(days=chunk_days), end)
            yield current_start.strftime("%Y-%m-%d"), current_end.strftime("%Y-%m-%d")
            current_start = current_end + timedelta(days=1)

    async def _fetch_chunk_streaming(
        self,
        client: httpx.AsyncClient,
        semaphore: asyncio.Semaphore,
        chunk_idx: int,
        total_chunks: int,
        chunk_start: str,
        chunk_end: str,
        key: str,
        data_url: str,
    ) -> tuple[int, list[dict[str, Any]]]:
        """
        Fetches data for a single chunk using streaming HTTP and incremental XML parsing.

        Uses httpx.stream() to avoid loading entire response into memory,
        and XMLPullParser to parse XML incrementally as bytes arrive.

        Args:
            client: Shared httpx AsyncClient
            semaphore: Semaphore to limit concurrency
            chunk_idx: Index of this chunk (1-based)
            total_chunks: Total number of chunks
            chunk_start: Start date for this chunk
            chunk_end: End date for this chunk
            key: Authentication key
            data_url: URL for data requests

        Returns:
            Tuple of (chunk_idx, list of row dictionaries)
        """
        async with semaphore:
            logging.info(
                "Processing chunk %d/%d: %s to %s",
                chunk_idx,
                total_chunks,
                chunk_start,
                chunk_end,
            )

            body, headers = self.generate_xexport_request(
                username=self.config.authentication.username,
                key=key,
                nodes=self.config.sync_options.nodes,
                date_from=self.convert_date_to_mmddyyyyhhmm(chunk_start),
                date_to=self.convert_date_to_mmddyyyyhhmm(chunk_end),
                granularity=self.granularity_to_short_code(
                    self.config.sync_options.granularity
                ),
            )

            if self.config.debug:
                masked_body = self.mask_sensitive_data(body)
                logging.debug("Request url: %s", data_url)
                logging.debug("Request header: %s", headers)
                logging.debug("Request body: %s", masked_body)

            rows: list[dict[str, Any]] = []

            async with client.stream(
                "POST", data_url, content=body, headers=headers
            ) as response:
                if response.status_code != 200:
                    error_content = await response.aread()
                    try:
                        xml_response = etree.fromstring(error_content)
                        fault_string = xml_response.find(".//faultstring")
                        if fault_string is not None:
                            error_message = fault_string.text
                            logging.error("SOAP Fault: %s", error_message)
                            raise Exception(f"Data request failed: {error_message}")
                    except etree.XMLSyntaxError:
                        pass
                    raise Exception(
                        f"Data request failed: {error_content.decode('utf-8', errors='replace')}"
                    )

                parser = etree.XMLPullParser(events=("end",))
                granularity = self.config.sync_options.granularity

                async for chunk in response.aiter_bytes():
                    parser.feed(chunk)
                    for _, elem in parser.read_events():
                        if elem.tag == "responseData":
                            uzel = elem.findtext("uzel")
                            hodnota = elem.findtext("hodnota")
                            cas = elem.findtext("cas")
                            if uzel and hodnota and cas:
                                rows.append(
                                    {
                                        "uzel": uzel,
                                        "hodnota": hodnota,
                                        "cas": self.format_datetime(cas, granularity),
                                    }
                                )
                            elem.clear()
                            while elem.getprevious() is not None:
                                parent = elem.getparent()
                                if parent is not None:
                                    del parent[0]

            if len(rows) > 0:
                logging.info(
                    "Chunk %d/%d fetched: %d rows", chunk_idx, total_chunks, len(rows)
                )
            else:
                logging.debug(
                    "Chunk %d/%d fetched: no data for this period",
                    chunk_idx,
                    total_chunks,
                )
            return chunk_idx, rows

    def _parse_xexport_response(self, content: bytes) -> list[dict[str, Any]]:
        """
        Parses the xexport SOAP response and extracts data rows.
        Used for testing and fallback scenarios.

        Args:
            content: Raw response content bytes

        Returns:
            List of row dictionaries
        """
        rows = []
        parser = etree.XMLPullParser(events=("end",))
        parser.feed(content)
        for _, elem in parser.read_events():
            if elem.tag == "responseData":
                uzel = elem.findtext("uzel")
                hodnota = elem.findtext("hodnota")
                cas = elem.findtext("cas")
                if uzel and hodnota and cas:
                    rows.append(
                        {
                            "uzel": uzel,
                            "hodnota": hodnota,
                            "cas": self.format_datetime(
                                cas, self.config.sync_options.granularity
                            ),
                        }
                    )
                elem.clear()
        return rows

    async def _fetch_and_write_chunks(
        self,
        chunks: list[tuple[str, str]],
        key: str,
        data_url: str,
        csv_writer: csv.DictWriter,
    ) -> int:
        """
        Fetches all chunks concurrently and writes rows directly to CSV.

        Writes each chunk immediately as it completes (no ordering guarantee).
        This minimizes memory usage since we don't buffer completed chunks.

        Args:
            chunks: List of (chunk_start, chunk_end) tuples
            key: Authentication key
            data_url: URL for data requests
            csv_writer: CSV DictWriter to write rows to

        Returns:
            Total number of rows written
        """
        semaphore = asyncio.Semaphore(self.MAX_CONCURRENT)
        total_chunks = len(chunks)
        total_rows = 0

        logging.info("Using %d concurrent requests", self.MAX_CONCURRENT)

        async with httpx.AsyncClient(
            verify=False,
            timeout=httpx.Timeout(self.READ_TIMEOUT, connect=self.CONNECT_TIMEOUT),
        ) as client:
            tasks = [
                asyncio.create_task(
                    self._fetch_chunk_streaming(
                        client,
                        semaphore,
                        idx,
                        total_chunks,
                        chunk_start,
                        chunk_end,
                        key,
                        data_url,
                    )
                )
                for idx, (chunk_start, chunk_end) in enumerate(chunks, 1)
            ]
            for completed_task in asyncio.as_completed(tasks):
                _, rows = await completed_task
                for row in rows:
                    csv_writer.writerow(row)
                total_rows += len(rows)
        return total_rows

    def fetch_data(self, csv_writer: csv.DictWriter) -> int:
        """
        Fetches data from the Energis API and writes directly to CSV.

        Args:
            csv_writer: CSV DictWriter to write rows to

        Returns:
            Total number of rows written
        """
        key = self.authenticate()
        dataset = self.config.sync_options.dataset
        date_from = self.config.sync_options.date_from
        date_to = self.config.sync_options.date_to
        data_url = f"{self.config.authentication.api_base_url}?data"

        if dataset == DatasetEnum.xexport:
            granularity = self.config.sync_options.granularity
            num_nodes = len(self.config.sync_options.nodes)
            chunks = list(
                self._generate_date_chunks(date_from, date_to, granularity, num_nodes)
            )
            total_chunks = len(chunks)

            logging.info(
                "Fetching %d node(s), date range %s to %s, %d chunk(s), granularity '%s'",
                num_nodes,
                date_from,
                date_to,
                total_chunks,
                granularity.value,
            )

            return asyncio.run(
                self._fetch_and_write_chunks(chunks, key, data_url, csv_writer)
            )
        return 0



================================================
FILE: src/component.py
================================================
import csv
import logging
import os
import re
from dataclasses import dataclass
from datetime import datetime, timedelta

from keboola.component.base import ComponentBase
from keboola.component.exceptions import UserException

from configuration import (
    Configuration,
    GranularityEnum,
    DATASET_UNIQUE_FIELDS,
    DATASET_OUTPUT_FIELDS,
)
from api_client import EnergisClient


@dataclass
class FileMetadata:
    """Encapsulates output file information."""

    table_name: str
    file_name: str
    file_path: str


class Component(ComponentBase):
    def __init__(self):
        super().__init__()
        self.output_dir = None
        self.client = None
        self.config = None

    def run(self):
        """Main execution code."""
        last_processed_date = self._get_last_processed_date()
        self.config = Configuration(
            last_processed_date=last_processed_date, **self.configuration.parameters
        )
        self.client = EnergisClient(self.config)
        self.output_dir = os.path.join(self.configuration.data_dir, "out", "tables")
        os.makedirs(self.output_dir, exist_ok=True)
        file_metadata = self._build_file_metadata()
        file_created = self._fetch_and_save_to_csv(file_metadata)
        if file_created:
            self._create_manifest(file_metadata)
            self._save_state()
        logging.info("Data processing completed!")

    def _get_last_processed_date(self) -> str | None:
        """Returns the last processed date from state file (adjusted by -1 day)."""
        try:
            state = self.get_state_file()
        except Exception:
            logging.warning("Failed to read state file. Starting fresh.")
            return None
        last_processed_date = state.get("last_processed_date")
        if last_processed_date:
            try:
                last_date = datetime.strptime(last_processed_date, "%Y-%m-%d").date()
                adjusted_date = last_date - timedelta(days=1)
                return str(adjusted_date)
            except ValueError:
                logging.warning(
                    "Invalid date format in state file: %s", last_processed_date
                )
        return None

    def _build_file_metadata(self) -> FileMetadata:
        """Generates file metadata containing name and full path."""
        granularity = self._granularity_to_filename(
            self.config.sync_options.granularity
        )
        table_name = (
            f"energis_{self.config.sync_options.dataset.value}_{granularity}_data"
        )
        file_name = f"{table_name}.csv"
        file_path = os.path.join(self.output_dir, file_name)
        return FileMetadata(table_name, file_name, file_path)

    @staticmethod
    def _granularity_to_filename(granularity: GranularityEnum) -> str:
        """Returns a descriptive filename component based on the GranularityEnum value."""
        return re.sub(r"([A-Z])", r"_\1", granularity.value).lower()

    def _fetch_and_save_to_csv(self, file_metadata: FileMetadata) -> bool:
        """Fetches data and saves directly to CSV. Returns True if data was written."""
        fieldnames = DATASET_OUTPUT_FIELDS.get(self.config.sync_options.dataset, [])
        try:
            with open(
                file_metadata.file_path, mode="w", newline="", encoding="utf-8"
            ) as csv_file:
                writer = csv.DictWriter(csv_file, fieldnames=fieldnames)
                writer.writeheader()
                row_count = self.client.fetch_data(writer)
            if row_count == 0:
                logging.info("No data found")
                return False
            logging.info(
                "Data successfully saved to %s (%d rows)",
                file_metadata.file_path,
                row_count,
            )
            return True
        except Exception as e:
            logging.error("Failed to fetch/save data to CSV: %s", str(e))
            raise

    def _create_manifest(self, file_metadata: FileMetadata) -> None:
        """Creates a Keboola manifest file for the output table."""
        primary_keys = DATASET_UNIQUE_FIELDS.get(self.config.sync_options.dataset, [])
        output_table = self.create_out_table_definition(
            file_metadata.file_name,
            incremental=True,
            primary_key=primary_keys,
            destination=f"out.c-data.{file_metadata.table_name}",
        )
        self.write_manifest(output_table)
        logging.info("Manifest created for %s", file_metadata.file_name)

    def _save_state(self) -> None:
        """Saves the last processed date to state file."""
        try:
            self.write_state_file(
                {"last_processed_date": self.config.sync_options.date_to}
            )
            logging.info(
                "Saved last processed date: %s", self.config.sync_options.date_to
            )
        except Exception as e:
            logging.warning("Failed to save state file: %s", str(e))


"""
        Main entrypoint
"""
if __name__ == "__main__":
    try:
        comp = Component()
        comp.execute_action()
    except UserException as exc:
        logging.exception(exc)
        exit(1)
    except Exception as exc:
        logging.exception(exc)
        exit(2)



================================================
FILE: src/configuration.py
================================================
import logging
from datetime import date
from enum import Enum

from pydantic import BaseModel, Field, ValidationError, field_validator
from keboola.component.exceptions import UserException


class EnvironmentEnum(str, Enum):
    dev = "dev"
    prod = "prod"


ENVIRONMENT_URLS = {
    EnvironmentEnum.dev: "https://webenergis.eu/test/1.wsc/soap.r",
    EnvironmentEnum.prod: "https://bilance.c-energy.cz/cgi-bin/1.wsc/soap.r",
}


class DatasetEnum(str, Enum):
    xexport = "xexport"


DATASET_UNIQUE_FIELDS = {DatasetEnum.xexport: ["uzel", "cas"]}

DATASET_OUTPUT_FIELDS = {DatasetEnum.xexport: ["uzel", "hodnota", "cas"]}


class GranularityEnum(str, Enum):
    year = "year"
    quarterYear = "quarterYear"
    month = "month"
    day = "day"
    hour = "hour"
    quarterHour = "quarterHour"
    minute = "minute"


class Authentication(BaseModel):
    username: str
    password: str = Field(alias="#password")
    environment: EnvironmentEnum = Field(
        default=EnvironmentEnum.prod,
        description="Choose 'dev' for testing or 'prod' for production.",
    )

    @field_validator("username", "password")
    def must_not_be_empty(cls, value: str, info) -> str:
        if not value.strip():
            raise ValueError(f"Field '{info.field_name}' cannot be empty")
        return value

    @property
    def credentials(self) -> tuple[str, str]:
        return self.username, self.password

    @property
    def api_base_url(self) -> str:
        """Returns the full API base URL based on the selected environment."""
        return ENVIRONMENT_URLS[self.environment]


class SyncOptions(BaseModel):
    dataset: DatasetEnum = Field(
        default=DatasetEnum.xexport, description="Source dataset for data extraction"
    )
    nodes: list[int] = Field(
        default=[], description="List of nodes to fetch, e.g. [7090001]"
    )
    date_from: str = Field(
        default="2020-01-01",
        description="Date from which to fetch data, default '2020-01-01'",
    )
    date_to: str | None = Field(
        default=None, description="Date to which to fetch data."
    )
    granularity: GranularityEnum = Field(
        default=GranularityEnum.day,
        description="Granularity of fetched data, default 'day'",
    )
    reload_full_data: bool = Field(
        default=False,
        description="When enabled, retrieves the complete dataset from 'date_from', bypassing incremental loading",
    )

    @field_validator("nodes")
    def must_not_be_empty(cls, values: list[int], info) -> list[int]:
        if len(values) == 0:
            raise ValueError(f"Field '{info.field_name}' cannot be empty")
        return values

    @field_validator("granularity")
    def validate_granularity(cls, value: GranularityEnum) -> GranularityEnum:
        if value not in GranularityEnum:
            allowed_values = "', '".join([e.value for e in GranularityEnum])
            raise ValueError(
                f"Invalid value '{value}' for 'granularity'. Must be one of {allowed_values}"
            )
        return value

    @property
    def resolved_date_to(self) -> str:
        """Ensures date_to is always a string."""
        return self.date_to if self.date_to else str(date.today())


class Configuration(BaseModel):
    authentication: Authentication
    sync_options: SyncOptions
    debug: bool = False

    def __init__(self, last_processed_date: str | None = None, **data):
        try:
            super().__init__(**data)

            if last_processed_date and not self.sync_options.reload_full_data:
                self.sync_options.date_from = last_processed_date

            if not self.sync_options.date_to:
                self.sync_options.date_to = self.sync_options.resolved_date_to

            logging.info("Using date_from: %s", self.sync_options.date_from)
            logging.info("Using date_to: %s", self.sync_options.date_to)
            logging.info("Using granularity: %s", self.sync_options.granularity.value)
        except ValidationError as e:
            error_messages = [f"{err['loc'][0]}: {err['msg']}" for err in e.errors()]
            raise UserException(f"Validation Error: {', '.join(error_messages)}")

        if self.debug:
            logging.debug("Component will run in Debug mode")



================================================
FILE: tests/__init__.py
================================================
import sys
import os

sys.path.append(os.path.dirname(os.path.realpath(__file__)) + "/../src")



================================================
FILE: tests/test_api_client.py
================================================
import pytest
from unittest.mock import Mock, patch

from api_client import EnergisClient, GRANULARITY_META
from configuration import Configuration, DatasetEnum, GranularityEnum


@pytest.fixture
def mock_config():
    """Provides a mock Configuration object."""
    mock_config = Mock(spec=Configuration)

    mock_auth = Mock()
    mock_auth.credentials = ("testuser", "testpassword")
    mock_auth.api_base_url = "https://fake-api.com"
    mock_auth.username = "testuser"

    mock_config.authentication = mock_auth

    mock_sync_options = Mock()
    mock_sync_options.dataset = DatasetEnum.xexport
    mock_sync_options.nodes = [7090001]
    mock_sync_options.date_from = "2025-01-01"
    mock_sync_options.date_to = "2025-01-31"
    mock_sync_options.granularity = GranularityEnum.day
    mock_sync_options.resolved_date_to = "2025-01-31"

    mock_config.sync_options = mock_sync_options
    mock_config.debug = False

    return mock_config


@pytest.fixture
def mock_auth_client():
    """Mocks httpx.Client for authentication."""
    mock_client = Mock()
    return mock_client


@pytest.fixture
def client(mock_config, mock_auth_client):
    """Creates an EnergisClient instance with mocked auth client."""
    client = EnergisClient(mock_config)
    client.auth_client = mock_auth_client
    return client


def create_mock_response(status_code, content):
    """Creates a mock HTTP response with given status code and content."""
    response = Mock()
    response.status_code = status_code
    response.content = content.encode("utf-8")
    response.text = content
    return response


def test_authenticate_success(client, mock_auth_client):
    """Tests successful authentication."""
    xml_response = """<response><key>test-api-key</key></response>"""
    mock_auth_client.post.return_value = create_mock_response(200, xml_response)

    auth_key = client.authenticate()

    assert auth_key == "test-api-key"
    mock_auth_client.post.assert_called_once()


def test_authenticate_failure(client, mock_auth_client):
    """Tests authentication failure with HTTP error."""
    mock_auth_client.post.return_value = create_mock_response(
        401, "<error>Unauthorized</error>"
    )

    with pytest.raises(Exception, match="Authentication failed: 401"):
        client.authenticate()


def test_authenticate_retry_on_already_logged_in(client, mock_auth_client):
    """Tests authentication retry logic when user is already logged in."""
    xml_response = """<faultstring>Uživatel již v systému přihlášen</faultstring>"""
    mock_auth_client.post.return_value = create_mock_response(500, xml_response)

    with patch("time.sleep", return_value=None) as mock_sleep:
        with pytest.raises(Exception, match="Maximum retries reached"):
            client.authenticate()

        assert mock_auth_client.post.call_count == client.max_retries
        mock_sleep.assert_called_with(client.retry_delay)


def test_parse_xexport_response_success(client, mock_config):
    """Tests _parse_xexport_response with valid SOAP response."""
    mock_config.sync_options.granularity = GranularityEnum.day

    xml_response = """
    <response>
        <responseData>
            <uzel>7090001</uzel>
            <hodnota>123.45</hodnota>
            <cas>06.03.2025</cas>
        </responseData>
    </response>
    """

    results = client._parse_xexport_response(xml_response.encode("utf-8"))

    assert len(results) == 1
    assert results[0] == {"uzel": "7090001", "hodnota": "123.45", "cas": "2025-03-06"}


def test_parse_xexport_response_hour_granularity(client, mock_config):
    """Tests _parse_xexport_response with hour granularity."""
    mock_config.sync_options.granularity = GranularityEnum.hour

    xml_response = """
    <response>
        <responseData>
            <uzel>7090001</uzel>
            <hodnota>123.45</hodnota>
            <cas>06.03.2025 08-09</cas>
        </responseData>
    </response>
    """

    results = client._parse_xexport_response(xml_response.encode("utf-8"))

    assert len(results) == 1
    assert results[0]["cas"] == "2025-03-06 08:00"


def test_parse_xexport_response_empty(client, mock_config):
    """Tests _parse_xexport_response with no data rows."""
    mock_config.sync_options.granularity = GranularityEnum.day

    xml_response = "<response></response>"

    results = client._parse_xexport_response(xml_response.encode("utf-8"))

    assert len(results) == 0


def test_parse_xexport_response_multiple_rows(client, mock_config):
    """Tests _parse_xexport_response with multiple data rows."""
    mock_config.sync_options.granularity = GranularityEnum.day

    xml_response = """
    <response>
        <responseData>
            <uzel>7090001</uzel>
            <hodnota>100.00</hodnota>
            <cas>01.03.2025</cas>
        </responseData>
        <responseData>
            <uzel>7090002</uzel>
            <hodnota>200.00</hodnota>
            <cas>02.03.2025</cas>
        </responseData>
    </response>
    """

    results = client._parse_xexport_response(xml_response.encode("utf-8"))

    assert len(results) == 2
    assert results[0]["uzel"] == "7090001"
    assert results[1]["uzel"] == "7090002"


def test_convert_date_to_mmddyyyyhhmm():
    """Tests correct conversion of date format."""
    assert EnergisClient.convert_date_to_mmddyyyyhhmm("2025-03-06") == "030620250000"


def test_granularity_to_short_code():
    """Tests mapping of granularity enum to short codes."""
    assert EnergisClient.granularity_to_short_code(GranularityEnum.year) == "r"
    assert EnergisClient.granularity_to_short_code(GranularityEnum.minute) == "t"
    assert EnergisClient.granularity_to_short_code(GranularityEnum.quarterHour) == "c"


def test_granularity_meta_complete_coverage():
    """Ensures all GranularityEnum values have metadata in GRANULARITY_META."""
    for granularity in GranularityEnum:
        assert granularity in GRANULARITY_META, f"Missing metadata for {granularity}"
        meta = GRANULARITY_META[granularity]
        assert isinstance(meta.short_code, str) and len(meta.short_code) == 1
        assert isinstance(meta.points_per_day, int) and meta.points_per_day > 0


class TestFormatDatetime:
    """Tests for format_datetime static method."""

    def test_year_passthrough(self):
        """Year granularity returns value unchanged."""
        assert EnergisClient.format_datetime("2025", GranularityEnum.year) == "2025"

    def test_quarter_year_roman_numerals(self):
        """QuarterYear converts roman numerals to Q1-Q4 format."""
        assert (
            EnergisClient.format_datetime("I/2025", GranularityEnum.quarterYear)
            == "Q1/2025"
        )
        assert (
            EnergisClient.format_datetime("II/2025", GranularityEnum.quarterYear)
            == "Q2/2025"
        )
        assert (
            EnergisClient.format_datetime("III/2025", GranularityEnum.quarterYear)
            == "Q3/2025"
        )
        assert (
            EnergisClient.format_datetime("IV/2025", GranularityEnum.quarterYear)
            == "Q4/2025"
        )

    def test_quarter_year_unknown_quarter(self):
        """QuarterYear with unknown quarter token passes through unchanged."""
        assert (
            EnergisClient.format_datetime("V/2025", GranularityEnum.quarterYear)
            == "V/2025"
        )

    def test_month_passthrough(self):
        """Month granularity returns value unchanged."""
        assert (
            EnergisClient.format_datetime("01/2025", GranularityEnum.month) == "01/2025"
        )

    def test_day_format_conversion(self):
        """Day converts DD.MM.YYYY to YYYY-MM-DD."""
        assert (
            EnergisClient.format_datetime("06.03.2025", GranularityEnum.day)
            == "2025-03-06"
        )
        assert (
            EnergisClient.format_datetime("31.12.2024", GranularityEnum.day)
            == "2024-12-31"
        )

    def test_hour_without_minutes(self):
        """Hour granularity with hour range (no minutes) adds :00."""
        assert (
            EnergisClient.format_datetime("06.03.2025 08-09", GranularityEnum.hour)
            == "2025-03-06 08:00"
        )
        assert (
            EnergisClient.format_datetime("06.03.2025 23-00", GranularityEnum.hour)
            == "2025-03-06 23:00"
        )

    def test_quarter_hour_with_minutes(self):
        """QuarterHour granularity with time range preserves minutes."""
        assert (
            EnergisClient.format_datetime(
                "06.03.2025 08:15-08:30", GranularityEnum.quarterHour
            )
            == "2025-03-06 08:15"
        )
        assert (
            EnergisClient.format_datetime(
                "06.03.2025 23:45-00:00", GranularityEnum.quarterHour
            )
            == "2025-03-06 23:45"
        )

    def test_minute_with_minutes(self):
        """Minute granularity with time range preserves minutes."""
        assert (
            EnergisClient.format_datetime(
                "06.03.2025 08:01-08:02", GranularityEnum.minute
            )
            == "2025-03-06 08:01"
        )

    def test_day_invalid_date_raises(self):
        """Day granularity with invalid date raises ValueError."""
        with pytest.raises(ValueError):
            EnergisClient.format_datetime("31.02.2025", GranularityEnum.day)

    def test_hour_missing_time_part_raises(self):
        """Hour granularity without time part raises ValueError."""
        with pytest.raises(ValueError):
            EnergisClient.format_datetime("06.03.2025", GranularityEnum.hour)



================================================
FILE: tests/test_configuration.py
================================================
import pytest
import logging
from datetime import date
from configuration import (
    Configuration,
    Authentication,
    SyncOptions,
    GranularityEnum,
    DatasetEnum,
    EnvironmentEnum,
)


@pytest.fixture
def valid_auth():
    return Authentication(
        username="testuser",
        **{"#password": "securepassword"},
        environment=EnvironmentEnum.prod,
    )


@pytest.fixture
def valid_sync_options():
    """Returns a valid SyncOptions instance."""
    return SyncOptions(
        dataset=DatasetEnum.xexport,
        nodes=[12345],
        date_from="2025-01-01",
        date_to="2025-01-31",
        granularity=GranularityEnum.day,
    )


def test_authentication_properties(valid_auth):
    """Tests the computed properties of Authentication."""
    assert valid_auth.credentials == ("testuser", "securepassword")
    assert valid_auth.api_base_url == "https://bilance.c-energy.cz/cgi-bin/1.wsc/soap.r"


def test_authentication_validation():
    with pytest.raises(ValueError, match="Field 'username' cannot be empty"):
        Authentication(username="", **{"#password": "securepassword"})

    with pytest.raises(
        ValueError, match="Value error, Field 'password' cannot be empty"
    ):
        Authentication(username="testuser", **{"#password": ""})


def test_sync_options_validation():
    """Tests that SyncOptions enforces correct values."""
    with pytest.raises(ValueError, match="Field 'nodes' cannot be empty"):
        SyncOptions(
            dataset=DatasetEnum.xexport,
            nodes=[],
            date_from="2025-01-01",
            date_to="2025-01-31",
            granularity=GranularityEnum.day,
        )

    with pytest.raises(
        ValueError,
        match="Input should be 'year', 'quarterYear', 'month', 'day', 'hour', 'quarterHour' or 'minute'",
    ):
        SyncOptions(
            dataset=DatasetEnum.xexport,
            nodes=[12345],
            date_from="2025-01-01",
            date_to="2025-01-31",
            granularity="invalid",
        )


def test_sync_options_resolved_date_to(valid_sync_options):
    """Tests that resolved_date_to returns the correct value."""
    assert valid_sync_options.resolved_date_to == "2025-01-31"

    sync_options_without_date_to = SyncOptions(
        dataset=DatasetEnum.xexport,
        nodes=[12345],
        date_from="2025-01-01",
        date_to=None,
        granularity=GranularityEnum.day,
    )
    assert sync_options_without_date_to.resolved_date_to == str(date.today())


def test_configuration_initialization(valid_auth, valid_sync_options, caplog):
    """Tests Configuration initialization and state handling."""
    with caplog.at_level(logging.INFO):
        config = Configuration(
            last_processed_date="2025-01-01",
            authentication=valid_auth,
            sync_options=valid_sync_options,
        )

    assert config.sync_options.date_from == "2025-01-01"
    assert config.sync_options.date_to == "2025-01-31"

    assert "Using date_from: 2025-01-01" in caplog.text
    assert f"Using date_to: {config.sync_options.date_to}" in caplog.text
    assert f"Using granularity: {config.sync_options.granularity.value}" in caplog.text


def test_configuration_validation_error():
    """Tests that Configuration raises validation errors when required fields are missing."""
    with pytest.raises(ValueError, match="Field 'username' cannot be empty"):
        Configuration(
            last_processed_date=None,
            authentication=Authentication(username="", password="password"),
            sync_options=SyncOptions(
                dataset=DatasetEnum.xexport,
                nodes=[12345],
                date_from="2025-01-01",
                date_to="2025-01-31",
                granularity=GranularityEnum.day,
            ),
        )



================================================
FILE: .github/workflows/push.yml
================================================
name: Keboola Component Build & Deploy Pipeline
on:
  push:  # skip the workflow on the main branch without tags
    branches-ignore:
      - main
    tags:
      - "*"

concurrency: ci-${{ github.ref }}  # to avoid tag collisions in the ECR
env:
  # repository variables:
  KBC_DEVELOPERPORTAL_APP: "keboola.ex-energis"
  KBC_DEVELOPERPORTAL_VENDOR: "keboola"
  DOCKERHUB_USER: ${{ secrets.DOCKERHUB_USER }}
  KBC_DEVELOPERPORTAL_USERNAME: ${{ vars.KBC_DEVELOPERPORTAL_USERNAME }}

  # repository secrets:
  DOCKERHUB_TOKEN: ${{ secrets.DOCKERHUB_TOKEN }}
  KBC_DEVELOPERPORTAL_PASSWORD: ${{ secrets.KBC_DEVELOPERPORTAL_PASSWORD }}

  # (Optional) Test KBC project: https://connection.keboola.com/admin/projects/0000
  KBC_TEST_PROJECT_CONFIGS: "" # space separated list of config ids
  KBC_STORAGE_TOKEN: ${{ secrets.KBC_STORAGE_TOKEN }} # required for running KBC tests

jobs:
  push_event_info:
    name: Push Event Info
    runs-on: ubuntu-latest
    outputs:
      app_image_tag: ${{ steps.tag.outputs.app_image_tag }}
      is_semantic_tag: ${{ steps.tag.outputs.is_semantic_tag }}
      is_default_branch: ${{ steps.default_branch.outputs.is_default_branch }}
      is_deploy_ready: ${{ steps.deploy_ready.outputs.is_deploy_ready }}
    steps:
      - name: Checkout Repository
        uses: actions/checkout@v4

      - name: Fetch all branches from remote repository
        run: git fetch --prune --unshallow --tags -f

      - name: Get current branch name
        id: current_branch
        run: |
          if [[ ${{ github.ref }} != "refs/tags/"* ]]; then
            branch_name=${{ github.ref_name }}
            echo "branch_name=$branch_name" | tee -a $GITHUB_OUTPUT
          else
            raw=$(git branch -r --contains ${{ github.ref }})
            branch="$(echo ${raw/*origin\//} | tr -d '\n')"
            echo "branch_name=$branch" | tee -a $GITHUB_OUTPUT
          fi

      - name: Is current branch the default branch
        id: default_branch
        run: |
          echo "default_branch='${{ github.event.repository.default_branch }}'"
          if [ "${{ github.event.repository.default_branch }}" = "${{ steps.current_branch.outputs.branch_name }}" ]; then
             echo "is_default_branch=true" | tee -a $GITHUB_OUTPUT
          else
             echo "is_default_branch=false" | tee -a $GITHUB_OUTPUT
          fi

      - name: Set image tag
        id: tag
        run: |
          TAG="${GITHUB_REF##*/}"
          IS_SEMANTIC_TAG=$(echo "$TAG" | grep -q '^v\?[0-9]\+\.[0-9]\+\.[0-9]\+$' && echo true || echo false)
          echo "is_semantic_tag=$IS_SEMANTIC_TAG" | tee -a $GITHUB_OUTPUT
          echo "app_image_tag=$TAG" | tee -a $GITHUB_OUTPUT

      - name: Deploy-Ready check
        id: deploy_ready
        run: |
          if [[ "${{ github.ref }}" == refs/tags/* \
            && "${{ steps.tag.outputs.is_semantic_tag }}" == "true" ]]; then
              echo "is_deploy_ready=true" | tee -a $GITHUB_OUTPUT
          else
              echo "is_deploy_ready=false" | tee -a $GITHUB_OUTPUT
          fi

  build:
    name: Docker Image Build
    runs-on: ubuntu-latest
    needs:
      - push_event_info
    env:
      DOCKERHUB_TOKEN: ${{ secrets.DOCKERHUB_TOKEN }}
    steps:
      - name: Checkout Repository
        uses: actions/checkout@v4

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: Build and push
        uses: docker/build-push-action@v5
        with:
          context: .
          file: ./Dockerfile
          tags: ${{ env.KBC_DEVELOPERPORTAL_APP }}:latest
          outputs: type=docker,dest=/tmp/${{ env.KBC_DEVELOPERPORTAL_APP }}.tar

      - name: Upload artifact
        uses: actions/upload-artifact@v4
        with:
          name: ${{ env.KBC_DEVELOPERPORTAL_APP }}
          path: /tmp/${{ env.KBC_DEVELOPERPORTAL_APP }}.tar

  tests:
    name: Run Tests
    runs-on: ubuntu-latest
    needs:
      - push_event_info
      - build
    steps:
      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: Download artifact
        uses: actions/download-artifact@v4
        with:
          name: ${{ env.KBC_DEVELOPERPORTAL_APP }}
          path: /tmp

      - name: Load Image & Run Tests
        run: |
          docker load --input /tmp/${{ env.KBC_DEVELOPERPORTAL_APP }}.tar
          docker image ls -a
          docker run ${{ env.KBC_DEVELOPERPORTAL_APP }}:latest flake8 . --config=flake8.cfg
          echo "Running unit-tests..."
          docker run ${{ env.KBC_DEVELOPERPORTAL_APP }}:latest python -m pytest tests/

  tests-kbc:
    name: Run KBC Tests
    needs:
      - push_event_info
      - build
    runs-on: ubuntu-latest
    steps:
      - name: Set up environment variables
        run: |
          echo "KBC_TEST_PROJECT_CONFIGS=${KBC_TEST_PROJECT_CONFIGS}" >> $GITHUB_ENV
          echo "KBC_STORAGE_TOKEN=${{ secrets.KBC_STORAGE_TOKEN }}" >> $GITHUB_ENV

      - name: Run KBC test jobs
        if: env.KBC_TEST_PROJECT_CONFIGS != '' && env.KBC_STORAGE_TOKEN != ''
        uses: keboola/action-run-configs-parallel@master
        with:
          token: ${{ secrets.KBC_STORAGE_TOKEN }}
          componentId: ${{ env.KBC_DEVELOPERPORTAL_APP }}
          tag: ${{ needs.push_event_info.outputs.app_image_tag }}
          configs: ${{ env.KBC_TEST_PROJECT_CONFIGS }}

  push:
    name: Docker Image Push
    runs-on: ubuntu-latest
    needs:
      - push_event_info
      - tests
      - tests-kbc
    env:
      DOCKERHUB_TOKEN: ${{ secrets.DOCKERHUB_TOKEN }}
    steps:
      - name: Checkout Repository
        uses: actions/checkout@v4

      - name: Download artifact
        uses: actions/download-artifact@v4
        with:
          name: ${{ env.KBC_DEVELOPERPORTAL_APP }}
          path: /tmp

      - name: Load Image & Run Tests
        run: |
          docker load --input /tmp/${{ env.KBC_DEVELOPERPORTAL_APP }}.tar
          docker image ls -a

      - name: Docker login
        if: env.DOCKERHUB_TOKEN
        run: docker login --username "${{ env.DOCKERHUB_USER }}" --password "${{ env.DOCKERHUB_TOKEN }}"

      - name: Push image to ECR
        uses: keboola/action-push-to-ecr@master
        with:
          vendor: ${{ env.KBC_DEVELOPERPORTAL_VENDOR }}
          app_id: ${{ env.KBC_DEVELOPERPORTAL_APP }}
          username: ${{ env.KBC_DEVELOPERPORTAL_USERNAME }}
          password: ${{ secrets.KBC_DEVELOPERPORTAL_PASSWORD }}
          tag: ${{ needs.push_event_info.outputs.app_image_tag }}
          push_latest: ${{ needs.push_event_info.outputs.is_deploy_ready }}
          source_image: ${{ env.KBC_DEVELOPERPORTAL_APP }}

  deploy:
    name: Deploy to KBC
    env:
      KBC_DEVELOPERPORTAL_PASSWORD: ${{ secrets.KBC_DEVELOPERPORTAL_PASSWORD }}
    needs:
      - push_event_info
      - build
      - push
    if: needs.push_event_info.outputs.is_deploy_ready == 'true'
    runs-on: ubuntu-latest
    steps:
      - name: Set Developer Portal Tag
        uses: keboola/action-set-tag-developer-portal@master
        with:
          vendor: ${{ env.KBC_DEVELOPERPORTAL_VENDOR }}
          app_id: ${{ env.KBC_DEVELOPERPORTAL_APP }}
          username: ${{ env.KBC_DEVELOPERPORTAL_USERNAME }}
          password: ${{ secrets.KBC_DEVELOPERPORTAL_PASSWORD }}
          tag: ${{ needs.push_event_info.outputs.app_image_tag }}

  update_developer_portal_properties:
    name: Developer Portal Properties Update
    env:
      KBC_DEVELOPERPORTAL_PASSWORD: ${{ secrets.KBC_DEVELOPERPORTAL_PASSWORD }}
    needs:
      - push_event_info
      - build
      - push
    runs-on: ubuntu-latest
    if: needs.push_event_info.outputs.is_deploy_ready == 'true'
    steps:
      - name: Checkout Repository
        uses: actions/checkout@v4

      - name: Update developer portal properties
        run: |
          chmod +x scripts/developer_portal/*.sh
          scripts/developer_portal/update_properties.sh


