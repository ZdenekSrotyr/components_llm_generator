Directory structure:
└── keboola-component-odoo-extractor/
    ├── README.md
    ├── deploy.sh
    ├── docker-compose.yml
    ├── Dockerfile
    ├── LICENSE.md
    ├── pyproject.toml
    ├── uv.lock
    ├── .flake8
    ├── .pre-commit-config.yaml
    ├── component_config/
    │   ├── actions.md
    │   ├── component_long_description.md
    │   ├── component_short_description.md
    │   ├── configRowSchema.json
    │   ├── configSchema.json
    │   ├── configuration_description.md
    │   ├── documentationUrl.md
    │   ├── licenseUrl.md
    │   ├── logger
    │   ├── loggerConfiguration.json
    │   ├── sourceCodeUrl.md
    │   └── sample-config/
    │       ├── config.json
    │       └── in/
    │           ├── state.json
    │           ├── files/
    │           │   └── order1.xml
    │           └── tables/
    │               ├── test.csv
    │               └── test.csv.manifest
    ├── scripts/
    │   ├── build_n_test.sh
    │   └── developer_portal/
    │       ├── fn_actions_md_update.sh
    │       └── update_properties.sh
    ├── src/
    │   ├── component.py
    │   ├── configuration.py
    │   └── clients/
    │       ├── json2_client.py
    │       └── xmlrpc_client.py
    ├── tests/
    │   ├── __init__.py
    │   └── test_component.py
    └── .github/
        └── workflows/
            └── push.yml

================================================
FILE: README.md
================================================
# Odoo Extractor

Extract data from Odoo ERP systems using XML-RPC or JSON-2 protocols with dynamic model/field discovery and modern Python 3.13 implementation.

## Features

### Core Capabilities
- ✅ **Dual Protocol Support** - Choose between XML-RPC (all versions) or JSON-2 (Odoo 19+)
- ✅ **Dynamic Model Discovery** - Browse and select from hundreds of Odoo models via UI
- ✅ **Field Discovery** - Automatically load field definitions for selected models
- ✅ **Database Discovery** - Auto-discover available databases on Odoo instance
- ✅ **Test Connection** - Validate credentials before running extractions
- ✅ **Configuration Rows** - Modern Keboola pattern: one row per model
- ✅ **Incremental Loading** - Cursor-based state tracking for efficient updates
- ✅ **Smart Relationship Handling** - Automatically splits many2many/one2many into normalized tables

### Technical Highlights
- ✅ **Modern Type Hints** - Python 3.13 with `list[str]`, `dict[str, Any]`, `int | None`
- ✅ **Sync Actions** - Dynamic UI with testConnection, listDatabases, listModels, listFields
- ✅ **Cursor-Based Pagination** - Efficient `id > cursor_id` pagination with configurable page size
- ✅ **Client Abstraction** - Separate XmlRpcClient and Json2Client implementations
- ✅ **Code Quality** - Ruff formatted, type-checked, dataclass-driven architecture

## Configuration

### Configuration Rows Pattern

This component uses **configuration rows** - the modern Keboola architecture where:
- Each configuration row = one Odoo model extraction
- Component runs once per row (independent executions)
- Each row has its own state (incremental tracking)
- Add multiple rows to extract multiple models

**Benefits:**
- ✅ Isolated state per model (no conflicts)
- ✅ Independent execution (parallel processing)
- ✅ Easy to add/remove models (just add/delete rows)
- ✅ Clear separation of concerns

### Global Configuration

Set up your Odoo connection once (shared across all rows):

**Connection Parameters:**
- `odoo_url` - Odoo instance URL (e.g., `https://demo.odoo.com`)
- `database` - Database name (use **List Databases** button to discover)
- `username` - User email/login (optional for JSON-2 protocol)
- `#api_key` - API key or password (encrypted field)
- `api_protocol` - Protocol to use:
  - `xmlrpc` - XML-RPC (Odoo 8.0-19.0, will be removed in future versions)
  - `json2` - JSON-2 (Odoo 19.0+, recommended)

**UI Features:**
- **Test Connection** button - Validates credentials and protocol availability
- **List Databases** button - Auto-discovers available databases on the instance

### Row Configuration (Per Model)

Each configuration row defines extraction for ONE Odoo model:

**Required Parameters:**
- `model` - Odoo model name (e.g., `res.partner`, `sale.order`)
- `output_table` - Output table name (e.g., `customers`, `sales_orders`)

**Optional Parameters:**
- `fields` - Field list to extract (empty = extract all fields)
- `domain` - Odoo domain filter (e.g., `[["state", "=", "sale"]]`)
- `incremental` - Enable incremental loading (default: `false`)
- `page_size` - Records per page for pagination (default: `1000`)
- `primary_key` - Primary key columns (default: `["id"]`)

**UI Features:**
- **Model Dropdown** - Select from 100+ models (autoloaded via sync action)
- **Fields Multi-Select** - Choose fields to extract (autoloaded based on model)
- Shows field labels, types, and technical names

## API Protocol Comparison

### XML-RPC (Legacy)
- ✅ **Compatibility:** Odoo 8.0-19.0
- ✅ **Stability:** Battle-tested, widely used
- ✅ **Username required:** Must provide username
- ⚠️ **Performance:** Verbose XML format
- ⚠️ **Deprecated:** Will be removed in future Odoo versions

### JSON-2 (Recommended - Odoo 19+)
- ✅ **Performance:** Native JSON, more efficient than XML-RPC
- ✅ **Cleaner API:** Smaller payloads, simpler authentication
- ✅ **No username needed:** API key is sufficient
- ⚠️ **Compatibility:** Odoo 19.0+ only

**Recommendation:** Use JSON-2 if you're on Odoo 19+ (recommended), otherwise XML-RPC for older versions.

## Example Configuration

### Global Config (Connection)
```json
{
  "parameters": {
    "odoo_url": "https://demo.odoo.com",
    "database": "demo",
    "username": "admin",
    "#api_key": "admin",
    "api_protocol": "xmlrpc"
  }
}
```

### Configuration Row #1 (Partners - Full Extract)
```json
{
  "parameters": {
    "model": "res.partner",
    "output_table": "customers",
    "fields": ["id", "name", "email", "phone", "country_id", "child_ids"],
    "incremental": false,
    "page_size": 1000,
    "primary_key": ["id"]
  }
}
```

### Configuration Row #2 (Sales Orders - Incremental)
```json
{
  "parameters": {
    "model": "sale.order",
    "output_table": "sales_orders",
    "domain": [["state", "=", "sale"]],
    "incremental": true,
    "page_size": 500,
    "primary_key": ["id"]
  }
}
```

## Supported Models

Extract from any Odoo model:

- **Contacts**: `res.partner`, `res.users`, `res.company`
- **Sales**: `sale.order`, `sale.order.line`
- **Invoicing**: `account.move`, `account.move.line`
- **Inventory**: `product.product`, `product.template`, `stock.move`
- **CRM**: `crm.lead`, `crm.stage`
- **HR**: `hr.employee`, `hr.department`
- And many more!

Use the **List Models** button in the UI to see all available models for your Odoo instance.

## Handling Relational Fields

The extractor automatically handles Odoo's relational data structures by creating properly normalized tables:

### many2one Fields (Flattened in Main Table)

**Example:** `country_id: [233, "United States"]`

Flattened into the main table as two columns:

```csv
id,name,country_id_id,country_id_name
15,Azure Interior,233,United States
```

### many2many & one2many Fields (Auto-Split into Separate Tables)

**Example:** Partner with categories and child contacts

**Input record:**
```json
{
  "id": 15,
  "name": "Azure Interior",
  "category_id": [5],
  "child_ids": [27, 34, 28]
}
```

**Output: 3 separate tables** (normalized structure)

**`customers.csv`** (main table):
```csv
id,name
15,Azure Interior
```

**`customers__category_id.csv`** (relationship table):
```csv
partner_id,category_id
15,5
```

**Primary Key:** `["partner_id", "category_id"]` (composite)

**`customers__child_ids.csv`** (relationship table):
```csv
partner_id,child_id
15,27
15,34
15,28
```

**Primary Key:** `["partner_id", "child_id"]` (composite)

### Bridge Table Incremental Support

Bridge tables (relationship tables) now support incremental mode:

- ✅ **Incremental mode matches main table** - If main table uses incremental, so do bridge tables
- ✅ **Composite primary keys** - Prevents duplicate relationships in storage
- ✅ **Automatic creation** - No configuration needed
- ⚠️ **Known trade-off:** Deleted relationships remain until full reload (accepted limitation)

**Example:** If `customers` uses `incremental: true`, then `customers__child_ids` also uses incremental mode with composite PK `["partner_id", "child_id"]`.

### Why Auto-Split?

✅ **Proper relational structure** - Industry-standard data modeling
✅ **Easy SQL joins** - `JOIN customers__category_id ON id = partner_id`
✅ **BI tool friendly** - Works seamlessly with Tableau, PowerBI, Looker
✅ **No data loss** - Preserves all relationship information
✅ **Scalable** - Handles large many2many datasets efficiently

### Field Type Summary

| Odoo Field Type | Storage Strategy | Example Output |
|-----------------|------------------|----------------|
| **Scalar** (text, number, date) | Main table column | `email: "user@example.com"` |
| **many2one** | Flattened in main table | `country_id_id: 233`<br>`country_id_name: "United States"` |
| **many2many** | Separate bridge table with composite PK | `customers__category_id.csv` |
| **one2many** | Separate bridge table with composite PK | `customers__child_ids.csv` |
| **False** values | Converted to NULL | `phone: NULL` |

## Schema Metadata Files

The extractor automatically generates **metadata files** for each model to help you understand field types, relationships, and build SQL joins between tables.

### What Are Metadata Files?

For each extracted model, a metadata file is created with the naming pattern `metadata__{table_name}.csv`. These files document:

- **Field names** and their Odoo types (char, integer, many2one, many2many, etc.)
- **Relationship targets** (which model a field relates to)
- **Table locations** (main table vs. relationship tables)
- **Join columns** (for building SQL joins)

Metadata files are created even if no records were extracted, so you always have schema documentation.

### Metadata File Format

**Columns:**
- `field_name` - The field name in Odoo
- `field_type` - Odoo field type (char, integer, many2one, many2many, one2many, etc.)
- `target_model` - For relationship fields, the target Odoo model
- `location` - Which CSV file contains this field
- `source_column` - Column name to use in JOIN ON clause (if applicable)
- `target_column` - Target column name in relationship table (if applicable)

### Example: `metadata__customers.csv`

```csv
field_name,field_type,target_model,location,source_column,target_column
id,integer,,customers.csv,,
name,char,,customers.csv,,
email,char,,customers.csv,,
country_id,many2one,res.country,customers.csv,country_id_id,
country_id_id,integer,,customers.csv,,
country_id_name,char,,customers.csv,,
category_id,many2many,res.partner.category,customers__category_id.csv,partner_id,category_id
child_ids,one2many,res.partner,customers__child_ids.csv,partner_id,child_id
```

### Using Metadata for SQL Joins

The metadata file shows you exactly how to join tables:

**Example 1: Join partner with country (many2one)**
```sql
SELECT 
  p.id,
  p.name,
  p.country_id_id,
  c.name AS country_name
FROM customers p
LEFT JOIN res_country c 
  ON p.country_id_id = c.id
```

**Example 2: Join partner with categories (many2many)**
```sql
SELECT 
  p.id,
  p.name,
  cat.name AS category_name
FROM customers p
JOIN customers__category_id rel 
  ON p.id = rel.partner_id
JOIN res_partner_category cat 
  ON rel.category_id = cat.id
```

**Example 3: Find partners with child contacts (one2many)**
```sql
SELECT 
  parent.name AS parent_name,
  child.name AS child_name
FROM customers parent
JOIN customers__child_ids rel 
  ON parent.id = rel.partner_id
JOIN customers child 
  ON rel.child_id = child.id
```

### Reading Metadata in Your Transformation

The metadata file columns tell you everything you need:

- **Scalar fields** (`field_type` = char, integer, date, etc.)
  - Located in main table
  - Empty `source_column` and `target_column`
  
- **many2one fields** (flattened)
  - Original field row shows `target_model` and `source_column` for joining
  - Two additional rows for `{field}_id` and `{field}_name` columns
  
- **many2many/one2many fields** (normalized)
  - `location` shows relationship table name
  - `source_column` = foreign key to main table (e.g., `partner_id`)
  - `target_column` = foreign key to related records (e.g., `category_id`)

### Metadata Files Are Always Created

- ✅ Created for every extraction, even if no records found
- ✅ Documents the complete schema based on Odoo field metadata
- ✅ Includes only fields you selected (if using field picker)
- ✅ Includes all fields if no field selection (extract all)
- ✅ Prefixed with `metadata__` for easy identification

## Incremental Loading

Enable incremental loading to efficiently extract only new records since the last run.

### How It Works

1. **Cursor-Based Pagination** - Uses `id > cursor_id` domain filter (not offset-based)
2. **State Tracking** - Stores last processed ID after each successful run
3. **Automatic Resume** - Next run continues from last processed ID
4. **Per-Row State** - Each configuration row tracks its own state independently
5. **Full Load Override** - Switching from incremental to full load starts fresh

### State Structure

Each configuration row maintains its own state file:

```json
{
  "last_id": 1234,
  "last_run": "2026-01-27T10:30:00Z",
  "metadata": {
    "model": "res.partner",
    "incremental": true,
    "domain": [["active", "=", true]],
    "fields": ["id", "name", "email"],
    "page_size": 1000
  }
}
```

**State Fields:**
- `last_id` - Last successfully processed record ID (cursor position)
- `last_run` - ISO timestamp of last successful extraction
- `metadata` - Configuration snapshot for validation (detects domain/field changes)

### Cursor-Based Pagination

The component uses efficient cursor-based pagination:

```python
# Page 1: Extract records 1-1000
domain: [["id", ">", 0]]

# Page 2: Extract records 1001-2000
domain: [["id", ">", 1000]]

# Page 3: Extract records 2001-3000
domain: [["id", ">", 2000]]
```

**Benefits:**
- ✅ Constant query performance (no OFFSET overhead)
- ✅ Works with incremental mode (adds to existing domain)
- ✅ Handles large datasets efficiently
- ✅ Configurable page size (default: 1000)

### Incremental Mode Validation

The component validates state consistency:

- ✅ **Domain change detection** - Warns if domain filter changed
- ✅ **Field change detection** - Warns if field selection changed
- ✅ **Model validation** - Ensures state matches current configuration
- ⚠️ **State invalidation** - Changing domain/fields may require full reload

### Empty Table Handling

When no records are extracted:

- ✅ **No CSV files written** - Prevents unnecessary storage operations
- ✅ **Metadata still created** - Schema documentation always available
- ✅ **State still updated** - Tracks last_run timestamp
- ✅ **Logs warning** - Clearly indicates no data found

## Development

### Run Locally

```bash
# Set up environment
export KBC_DATADIR=/path/to/data/dir

# Run component
python src/component.py
```

### Docker

```bash
# Build
docker build -t odoo-extractor .

# Run
docker run -v $(pwd)/data:/data odoo-extractor
```

### Code Quality

This component follows Keboola code quality standards:

```bash
# Format code
uvx ruff format .

# Check linting
uvx ruff check --fix .
```

**Quality Features:**
- ✅ Modern Python 3.13 type hints (`list[str]`, `dict[str, Any]`, `int | None`)
- ✅ No deprecated typing imports (`typing.List`, `typing.Dict`, `typing.Optional`)
- ✅ `@staticmethod` decorators on pure functions
- ✅ `@sync_action` decorators for UI actions
- ✅ Dataclass-driven architecture (`BridgeTableMetadata`, `SplitTablesResult`)
- ✅ Ruff formatted and linted
- ✅ Clean orchestrator pattern in `run()` method

## Architecture

### Core Modules

**`clients/xmlrpc_client.py`** - XML-RPC protocol client (Odoo 8.0-19.0, legacy)
  - `authenticate()` - Odoo authentication via common service
  - `search_read()` - Extract data with domain filtering
  - `get_fields()` - Get field definitions for a model
  - `list_models()` - Discover available models
  - `list_databases()` - Discover available databases
  - `test_connection()` - Validate credentials

**`clients/json2_client.py`** - JSON-2 protocol client (Odoo 19+, high performance)
  - Same interface as XmlRpcClient
  - More efficient than XML-RPC (native JSON)
  - No username required (API key only)
  - Native JSON payloads

**`configuration.py`** - Pydantic models for validation
  - `Parameters` - Global connection parameters
  - `RowConfiguration` - Per-row extraction configuration
  - URL validation, field validation, encrypted #api_key support

**`component.py`** - Main component with extraction logic
  - `run()` - Clean orchestrator (load state → extract → write state)
  - `_extract_data()` - Per-model extraction with cursor-based pagination
  - `_split_records()` - Smart relational field handling (returns `SplitTablesResult`)
  - `_write_csv()` - CSV generation with proper escaping
  - `_write_metadata()` - Schema documentation generation
  - **Sync Actions:**
    - `test_connection_action()` - Test credentials (@sync_action)
    - `list_databases_action()` - Load databases for dropdown (@sync_action)
    - `list_models_action()` - Load models for dropdown (@sync_action)
    - `list_fields_action()` - Load fields for multi-select (@sync_action)

### Patterns Used

- **Configuration Rows Pattern**: One row = one model (modern Keboola standard)
- **Client Abstraction**: Protocol-agnostic interface (XmlRpcClient + Json2Client)
- **Orchestrator Pattern**: `run()` delegates to well-named methods
- **Cursor-Based Pagination**: `id > cursor_id` for efficient large dataset handling
- **Load-Once/Write-Once**: State loaded at start, written at end
- **Sync Actions**: Dynamic UI with @sync_action decorator
- **Type Safety**: Full type hints throughout (Python 3.13)
- **Dataclass Architecture**: `BridgeTableMetadata`, `SplitTablesResult` for type-safe structures

## Tested Against

- **Odoo Versions**: 18.0, 19.0
- **Python Version**: 3.13
- **Protocols**: XML-RPC (legacy), JSON-2 (Odoo 19+)
- **Test Records**: 40+ partners, 20+ relationship records
- **Incremental Runs**: Verified across multiple runs with state persistence

## License

MIT License

## Author

Keboola



================================================
FILE: deploy.sh
================================================
#!/bin/sh
set -e

env

# compatibility with travis and bitbucket
if [ ! -z ${BITBUCKET_TAG} ]
then
	echo "assigning bitbucket tag"
	export TAG="$BITBUCKET_TAG"
elif [ ! -z ${TRAVIS_TAG} ]
then
	echo "assigning travis tag"
	export TAG="$TRAVIS_TAG"
elif [ ! -z ${GITHUB_TAG} ]
then
	echo "assigning github tag"
	export TAG="$GITHUB_TAG"
else
	echo No Tag is set!
	exit 1
fi

echo "Tag is '${TAG}'"

#check if deployment is triggered only in master
if [ ${BITBUCKET_BRANCH} != "master" ]; then
               echo Deploy on tagged commit can be only executed in master!
               exit 1
fi

# Obtain the component repository and log in
echo "Obtain the component repository and log in"
docker pull quay.io/keboola/developer-portal-cli-v2:latest
export REPOSITORY=`docker run --rm  \
    -e KBC_DEVELOPERPORTAL_USERNAME \
    -e KBC_DEVELOPERPORTAL_PASSWORD \
    quay.io/keboola/developer-portal-cli-v2:latest \
    ecr:get-repository ${KBC_DEVELOPERPORTAL_VENDOR} ${KBC_DEVELOPERPORTAL_APP}`

echo "Set credentials"
eval $(docker run --rm \
    -e KBC_DEVELOPERPORTAL_USERNAME \
    -e KBC_DEVELOPERPORTAL_PASSWORD \
    quay.io/keboola/developer-portal-cli-v2:latest \
    ecr:get-login ${KBC_DEVELOPERPORTAL_VENDOR} ${KBC_DEVELOPERPORTAL_APP})

# Push to the repository
echo "Push to the repository"
docker tag ${APP_IMAGE}:latest ${REPOSITORY}:${TAG}
docker tag ${APP_IMAGE}:latest ${REPOSITORY}:latest
docker push ${REPOSITORY}:${TAG}
docker push ${REPOSITORY}:latest

# Update the tag in Keboola Developer Portal -> Deploy to KBC
if echo ${TAG} | grep -c '^v\?[0-9]\+\.[0-9]\+\.[0-9]\+$'
then
    docker run --rm \
        -e KBC_DEVELOPERPORTAL_USERNAME \
        -e KBC_DEVELOPERPORTAL_PASSWORD \
        quay.io/keboola/developer-portal-cli-v2:latest \
        update-app-repository ${KBC_DEVELOPERPORTAL_VENDOR} ${KBC_DEVELOPERPORTAL_APP} ${TAG} ecr ${REPOSITORY}
else
    echo "Skipping deployment to KBC, tag ${TAG} is not allowed."
fi



================================================
FILE: docker-compose.yml
================================================
services:
  # for development purposes
  dev:
    build: .
    volumes:
        - ./:/code
        - ./data:/data
    environment:
      - KBC_DATADIR=./data
  test:
    # Use to run flake8 and unittests checks
    build: .
    volumes:
      - ./:/code
      - ./data:/data
    environment:
      - KBC_DATADIR=./data
    command:
      - /bin/sh
      - /code/scripts/build_n_test.sh



================================================
FILE: Dockerfile
================================================
FROM python:3.13-slim
COPY --from=ghcr.io/astral-sh/uv:latest /uv /uvx /bin/

# uncomment the following line should you have any troubles installing certain packages which require C/C++ extensions
# to be compiled during installation, eg. numpy, psycopg2, …
# RUN apt-get update && apt-get install -y build-essential

WORKDIR /code/

COPY pyproject.toml .
COPY uv.lock .

ENV UV_PROJECT_ENVIRONMENT="/usr/local/"
RUN uv sync --all-groups --frozen

COPY src/ src
COPY tests/ tests
COPY scripts/ scripts
COPY .flake8 .
COPY deploy.sh .

CMD ["python", "-u", "src/component.py"]



================================================
FILE: LICENSE.md
================================================
The MIT License (MIT)

Copyright (c) 2018 Keboola DS, http://keboola.com

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files, to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is furnished
to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
THE SOFTWARE.


================================================
FILE: pyproject.toml
================================================
[project]
name = "odoo-extractor"
dynamic = ["version"]
readme = "README.md"
requires-python = "~=3.13.0"
dependencies = [
    "freezegun>=1.5.1",
    "keboola-component>=1.6.10",
    "keboola-http-client>=1.0.1",
    "keboola-utils>=1.1.0",
    "mock>=5.2.0",
    "pydantic>=2.11.3",
]

[dependency-groups]
dev = [
    "flake8>=7.2.0",
    "pre-commit>=4.5.0",
    "ruff>=0.11.5",
]

[tool.ruff]
line-length = 120



================================================
FILE: uv.lock
================================================
version = 1
revision = 3
requires-python = "==3.13.*"

[[package]]
name = "aiolimiter"
version = "1.2.1"
source = { registry = "https://pypi.org/simple" }
sdist = { url = "https://files.pythonhosted.org/packages/f1/23/b52debf471f7a1e42e362d959a3982bdcb4fe13a5d46e63d28868807a79c/aiolimiter-1.2.1.tar.gz", hash = "sha256:e02a37ea1a855d9e832252a105420ad4d15011505512a1a1d814647451b5cca9", size = 7185, upload-time = "2024-12-08T15:31:51.496Z" }
wheels = [
    { url = "https://files.pythonhosted.org/packages/f3/ba/df6e8e1045aebc4778d19b8a3a9bc1808adb1619ba94ca354d9ba17d86c3/aiolimiter-1.2.1-py3-none-any.whl", hash = "sha256:d3f249e9059a20badcb56b61601a83556133655c11d1eb3dd3e04ff069e5f3c7", size = 6711, upload-time = "2024-12-08T15:31:49.874Z" },
]

[[package]]
name = "annotated-types"
version = "0.7.0"
source = { registry = "https://pypi.org/simple" }
sdist = { url = "https://files.pythonhosted.org/packages/ee/67/531ea369ba64dcff5ec9c3402f9f51bf748cec26dde048a2f973a4eea7f5/annotated_types-0.7.0.tar.gz", hash = "sha256:aff07c09a53a08bc8cfccb9c85b05f1aa9a2a6f23728d790723543408344ce89", size = 16081, upload-time = "2024-05-20T21:33:25.928Z" }
wheels = [
    { url = "https://files.pythonhosted.org/packages/78/b6/6307fbef88d9b5ee7421e68d78a9f162e0da4900bc5f5793f6d3d0e34fb8/annotated_types-0.7.0-py3-none-any.whl", hash = "sha256:1f02e8b43a8fbbc3f3e0d4f0f4bfc8131bcb4eebe8849b8e5c773f3a1c582a53", size = 13643, upload-time = "2024-05-20T21:33:24.1Z" },
]

[[package]]
name = "anyio"
version = "4.12.1"
source = { registry = "https://pypi.org/simple" }
dependencies = [
    { name = "idna" },
]
sdist = { url = "https://files.pythonhosted.org/packages/96/f0/5eb65b2bb0d09ac6776f2eb54adee6abe8228ea05b20a5ad0e4945de8aac/anyio-4.12.1.tar.gz", hash = "sha256:41cfcc3a4c85d3f05c932da7c26d0201ac36f72abd4435ba90d0464a3ffed703", size = 228685, upload-time = "2026-01-06T11:45:21.246Z" }
wheels = [
    { url = "https://files.pythonhosted.org/packages/38/0e/27be9fdef66e72d64c0cdc3cc2823101b80585f8119b5c112c2e8f5f7dab/anyio-4.12.1-py3-none-any.whl", hash = "sha256:d405828884fc140aa80a3c667b8beed277f1dfedec42ba031bd6ac3db606ab6c", size = 113592, upload-time = "2026-01-06T11:45:19.497Z" },
]

[[package]]
name = "certifi"
version = "2026.1.4"
source = { registry = "https://pypi.org/simple" }
sdist = { url = "https://files.pythonhosted.org/packages/e0/2d/a891ca51311197f6ad14a7ef42e2399f36cf2f9bd44752b3dc4eab60fdc5/certifi-2026.1.4.tar.gz", hash = "sha256:ac726dd470482006e014ad384921ed6438c457018f4b3d204aea4281258b2120", size = 154268, upload-time = "2026-01-04T02:42:41.825Z" }
wheels = [
    { url = "https://files.pythonhosted.org/packages/e6/ad/3cc14f097111b4de0040c83a525973216457bbeeb63739ef1ed275c1c021/certifi-2026.1.4-py3-none-any.whl", hash = "sha256:9943707519e4add1115f44c2bc244f782c0249876bf51b6599fee1ffbedd685c", size = 152900, upload-time = "2026-01-04T02:42:40.15Z" },
]

[[package]]
name = "cfgv"
version = "3.5.0"
source = { registry = "https://pypi.org/simple" }
sdist = { url = "https://files.pythonhosted.org/packages/4e/b5/721b8799b04bf9afe054a3899c6cf4e880fcf8563cc71c15610242490a0c/cfgv-3.5.0.tar.gz", hash = "sha256:d5b1034354820651caa73ede66a6294d6e95c1b00acc5e9b098e917404669132", size = 7334, upload-time = "2025-11-19T20:55:51.612Z" }
wheels = [
    { url = "https://files.pythonhosted.org/packages/db/3c/33bac158f8ab7f89b2e59426d5fe2e4f63f7ed25df84c036890172b412b5/cfgv-3.5.0-py2.py3-none-any.whl", hash = "sha256:a8dc6b26ad22ff227d2634a65cb388215ce6cc96bbcc5cfde7641ae87e8dacc0", size = 7445, upload-time = "2025-11-19T20:55:50.744Z" },
]

[[package]]
name = "charset-normalizer"
version = "3.4.4"
source = { registry = "https://pypi.org/simple" }
sdist = { url = "https://files.pythonhosted.org/packages/13/69/33ddede1939fdd074bce5434295f38fae7136463422fe4fd3e0e89b98062/charset_normalizer-3.4.4.tar.gz", hash = "sha256:94537985111c35f28720e43603b8e7b43a6ecfb2ce1d3058bbe955b73404e21a", size = 129418, upload-time = "2025-10-14T04:42:32.879Z" }
wheels = [
    { url = "https://files.pythonhosted.org/packages/97/45/4b3a1239bbacd321068ea6e7ac28875b03ab8bc0aa0966452db17cd36714/charset_normalizer-3.4.4-cp313-cp313-macosx_10_13_universal2.whl", hash = "sha256:e1f185f86a6f3403aa2420e815904c67b2f9ebc443f045edd0de921108345794", size = 208091, upload-time = "2025-10-14T04:41:13.346Z" },
    { url = "https://files.pythonhosted.org/packages/7d/62/73a6d7450829655a35bb88a88fca7d736f9882a27eacdca2c6d505b57e2e/charset_normalizer-3.4.4-cp313-cp313-manylinux2014_aarch64.manylinux_2_17_aarch64.manylinux_2_28_aarch64.whl", hash = "sha256:6b39f987ae8ccdf0d2642338faf2abb1862340facc796048b604ef14919e55ed", size = 147936, upload-time = "2025-10-14T04:41:14.461Z" },
    { url = "https://files.pythonhosted.org/packages/89/c5/adb8c8b3d6625bef6d88b251bbb0d95f8205831b987631ab0c8bb5d937c2/charset_normalizer-3.4.4-cp313-cp313-manylinux2014_armv7l.manylinux_2_17_armv7l.manylinux_2_31_armv7l.whl", hash = "sha256:3162d5d8ce1bb98dd51af660f2121c55d0fa541b46dff7bb9b9f86ea1d87de72", size = 144180, upload-time = "2025-10-14T04:41:15.588Z" },
    { url = "https://files.pythonhosted.org/packages/91/ed/9706e4070682d1cc219050b6048bfd293ccf67b3d4f5a4f39207453d4b99/charset_normalizer-3.4.4-cp313-cp313-manylinux2014_ppc64le.manylinux_2_17_ppc64le.manylinux_2_28_ppc64le.whl", hash = "sha256:81d5eb2a312700f4ecaa977a8235b634ce853200e828fbadf3a9c50bab278328", size = 161346, upload-time = "2025-10-14T04:41:16.738Z" },
    { url = "https://files.pythonhosted.org/packages/d5/0d/031f0d95e4972901a2f6f09ef055751805ff541511dc1252ba3ca1f80cf5/charset_normalizer-3.4.4-cp313-cp313-manylinux2014_s390x.manylinux_2_17_s390x.manylinux_2_28_s390x.whl", hash = "sha256:5bd2293095d766545ec1a8f612559f6b40abc0eb18bb2f5d1171872d34036ede", size = 158874, upload-time = "2025-10-14T04:41:17.923Z" },
    { url = "https://files.pythonhosted.org/packages/f5/83/6ab5883f57c9c801ce5e5677242328aa45592be8a00644310a008d04f922/charset_normalizer-3.4.4-cp313-cp313-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl", hash = "sha256:a8a8b89589086a25749f471e6a900d3f662d1d3b6e2e59dcecf787b1cc3a1894", size = 153076, upload-time = "2025-10-14T04:41:19.106Z" },
    { url = "https://files.pythonhosted.org/packages/75/1e/5ff781ddf5260e387d6419959ee89ef13878229732732ee73cdae01800f2/charset_normalizer-3.4.4-cp313-cp313-manylinux_2_31_riscv64.manylinux_2_39_riscv64.whl", hash = "sha256:bc7637e2f80d8530ee4a78e878bce464f70087ce73cf7c1caf142416923b98f1", size = 150601, upload-time = "2025-10-14T04:41:20.245Z" },
    { url = "https://files.pythonhosted.org/packages/d7/57/71be810965493d3510a6ca79b90c19e48696fb1ff964da319334b12677f0/charset_normalizer-3.4.4-cp313-cp313-musllinux_1_2_aarch64.whl", hash = "sha256:f8bf04158c6b607d747e93949aa60618b61312fe647a6369f88ce2ff16043490", size = 150376, upload-time = "2025-10-14T04:41:21.398Z" },
    { url = "https://files.pythonhosted.org/packages/e5/d5/c3d057a78c181d007014feb7e9f2e65905a6c4ef182c0ddf0de2924edd65/charset_normalizer-3.4.4-cp313-cp313-musllinux_1_2_armv7l.whl", hash = "sha256:554af85e960429cf30784dd47447d5125aaa3b99a6f0683589dbd27e2f45da44", size = 144825, upload-time = "2025-10-14T04:41:22.583Z" },
    { url = "https://files.pythonhosted.org/packages/e6/8c/d0406294828d4976f275ffbe66f00266c4b3136b7506941d87c00cab5272/charset_normalizer-3.4.4-cp313-cp313-musllinux_1_2_ppc64le.whl", hash = "sha256:74018750915ee7ad843a774364e13a3db91682f26142baddf775342c3f5b1133", size = 162583, upload-time = "2025-10-14T04:41:23.754Z" },
    { url = "https://files.pythonhosted.org/packages/d7/24/e2aa1f18c8f15c4c0e932d9287b8609dd30ad56dbe41d926bd846e22fb8d/charset_normalizer-3.4.4-cp313-cp313-musllinux_1_2_riscv64.whl", hash = "sha256:c0463276121fdee9c49b98908b3a89c39be45d86d1dbaa22957e38f6321d4ce3", size = 150366, upload-time = "2025-10-14T04:41:25.27Z" },
    { url = "https://files.pythonhosted.org/packages/e4/5b/1e6160c7739aad1e2df054300cc618b06bf784a7a164b0f238360721ab86/charset_normalizer-3.4.4-cp313-cp313-musllinux_1_2_s390x.whl", hash = "sha256:362d61fd13843997c1c446760ef36f240cf81d3ebf74ac62652aebaf7838561e", size = 160300, upload-time = "2025-10-14T04:41:26.725Z" },
    { url = "https://files.pythonhosted.org/packages/7a/10/f882167cd207fbdd743e55534d5d9620e095089d176d55cb22d5322f2afd/charset_normalizer-3.4.4-cp313-cp313-musllinux_1_2_x86_64.whl", hash = "sha256:9a26f18905b8dd5d685d6d07b0cdf98a79f3c7a918906af7cc143ea2e164c8bc", size = 154465, upload-time = "2025-10-14T04:41:28.322Z" },
    { url = "https://files.pythonhosted.org/packages/89/66/c7a9e1b7429be72123441bfdbaf2bc13faab3f90b933f664db506dea5915/charset_normalizer-3.4.4-cp313-cp313-win32.whl", hash = "sha256:9b35f4c90079ff2e2edc5b26c0c77925e5d2d255c42c74fdb70fb49b172726ac", size = 99404, upload-time = "2025-10-14T04:41:29.95Z" },
    { url = "https://files.pythonhosted.org/packages/c4/26/b9924fa27db384bdcd97ab83b4f0a8058d96ad9626ead570674d5e737d90/charset_normalizer-3.4.4-cp313-cp313-win_amd64.whl", hash = "sha256:b435cba5f4f750aa6c0a0d92c541fb79f69a387c91e61f1795227e4ed9cece14", size = 107092, upload-time = "2025-10-14T04:41:31.188Z" },
    { url = "https://files.pythonhosted.org/packages/af/8f/3ed4bfa0c0c72a7ca17f0380cd9e4dd842b09f664e780c13cff1dcf2ef1b/charset_normalizer-3.4.4-cp313-cp313-win_arm64.whl", hash = "sha256:542d2cee80be6f80247095cc36c418f7bddd14f4a6de45af91dfad36d817bba2", size = 100408, upload-time = "2025-10-14T04:41:32.624Z" },
    { url = "https://files.pythonhosted.org/packages/0a/4c/925909008ed5a988ccbb72dcc897407e5d6d3bd72410d69e051fc0c14647/charset_normalizer-3.4.4-py3-none-any.whl", hash = "sha256:7a32c560861a02ff789ad905a2fe94e3f840803362c84fecf1851cb4cf3dc37f", size = 53402, upload-time = "2025-10-14T04:42:31.76Z" },
]

[[package]]
name = "dateparser"
version = "1.2.2"
source = { registry = "https://pypi.org/simple" }
dependencies = [
    { name = "python-dateutil" },
    { name = "pytz" },
    { name = "regex" },
    { name = "tzlocal" },
]
sdist = { url = "https://files.pythonhosted.org/packages/a9/30/064144f0df1749e7bb5faaa7f52b007d7c2d08ec08fed8411aba87207f68/dateparser-1.2.2.tar.gz", hash = "sha256:986316f17cb8cdc23ea8ce563027c5ef12fc725b6fb1d137c14ca08777c5ecf7", size = 329840, upload-time = "2025-06-26T09:29:23.211Z" }
wheels = [
    { url = "https://files.pythonhosted.org/packages/87/22/f020c047ae1346613db9322638186468238bcfa8849b4668a22b97faad65/dateparser-1.2.2-py3-none-any.whl", hash = "sha256:5a5d7211a09013499867547023a2a0c91d5a27d15dd4dbcea676ea9fe66f2482", size = 315453, upload-time = "2025-06-26T09:29:21.412Z" },
]

[[package]]
name = "deprecated"
version = "1.3.1"
source = { registry = "https://pypi.org/simple" }
dependencies = [
    { name = "wrapt" },
]
sdist = { url = "https://files.pythonhosted.org/packages/49/85/12f0a49a7c4ffb70572b6c2ef13c90c88fd190debda93b23f026b25f9634/deprecated-1.3.1.tar.gz", hash = "sha256:b1b50e0ff0c1fddaa5708a2c6b0a6588bb09b892825ab2b214ac9ea9d92a5223", size = 2932523, upload-time = "2025-10-30T08:19:02.757Z" }
wheels = [
    { url = "https://files.pythonhosted.org/packages/84/d0/205d54408c08b13550c733c4b85429e7ead111c7f0014309637425520a9a/deprecated-1.3.1-py2.py3-none-any.whl", hash = "sha256:597bfef186b6f60181535a29fbe44865ce137a5079f295b479886c82729d5f3f", size = 11298, upload-time = "2025-10-30T08:19:00.758Z" },
]

[[package]]
name = "distlib"
version = "0.4.0"
source = { registry = "https://pypi.org/simple" }
sdist = { url = "https://files.pythonhosted.org/packages/96/8e/709914eb2b5749865801041647dc7f4e6d00b549cfe88b65ca192995f07c/distlib-0.4.0.tar.gz", hash = "sha256:feec40075be03a04501a973d81f633735b4b69f98b05450592310c0f401a4e0d", size = 614605, upload-time = "2025-07-17T16:52:00.465Z" }
wheels = [
    { url = "https://files.pythonhosted.org/packages/33/6b/e0547afaf41bf2c42e52430072fa5658766e3d65bd4b03a563d1b6336f57/distlib-0.4.0-py2.py3-none-any.whl", hash = "sha256:9659f7d87e46584a30b5780e43ac7a2143098441670ff0a49d5f9034c54a6c16", size = 469047, upload-time = "2025-07-17T16:51:58.613Z" },
]

[[package]]
name = "filelock"
version = "3.20.3"
source = { registry = "https://pypi.org/simple" }
sdist = { url = "https://files.pythonhosted.org/packages/1d/65/ce7f1b70157833bf3cb851b556a37d4547ceafc158aa9b34b36782f23696/filelock-3.20.3.tar.gz", hash = "sha256:18c57ee915c7ec61cff0ecf7f0f869936c7c30191bb0cf406f1341778d0834e1", size = 19485, upload-time = "2026-01-09T17:55:05.421Z" }
wheels = [
    { url = "https://files.pythonhosted.org/packages/b5/36/7fb70f04bf00bc646cd5bb45aa9eddb15e19437a28b8fb2b4a5249fac770/filelock-3.20.3-py3-none-any.whl", hash = "sha256:4b0dda527ee31078689fc205ec4f1c1bf7d56cf88b6dc9426c4f230e46c2dce1", size = 16701, upload-time = "2026-01-09T17:55:04.334Z" },
]

[[package]]
name = "flake8"
version = "7.3.0"
source = { registry = "https://pypi.org/simple" }
dependencies = [
    { name = "mccabe" },
    { name = "pycodestyle" },
    { name = "pyflakes" },
]
sdist = { url = "https://files.pythonhosted.org/packages/9b/af/fbfe3c4b5a657d79e5c47a2827a362f9e1b763336a52f926126aa6dc7123/flake8-7.3.0.tar.gz", hash = "sha256:fe044858146b9fc69b551a4b490d69cf960fcb78ad1edcb84e7fbb1b4a8e3872", size = 48326, upload-time = "2025-06-20T19:31:35.838Z" }
wheels = [
    { url = "https://files.pythonhosted.org/packages/9f/56/13ab06b4f93ca7cac71078fbe37fcea175d3216f31f85c3168a6bbd0bb9a/flake8-7.3.0-py2.py3-none-any.whl", hash = "sha256:b9696257b9ce8beb888cdbe31cf885c90d31928fe202be0889a7cdafad32f01e", size = 57922, upload-time = "2025-06-20T19:31:34.425Z" },
]

[[package]]
name = "freezegun"
version = "1.5.5"
source = { registry = "https://pypi.org/simple" }
dependencies = [
    { name = "python-dateutil" },
]
sdist = { url = "https://files.pythonhosted.org/packages/95/dd/23e2f4e357f8fd3bdff613c1fe4466d21bfb00a6177f238079b17f7b1c84/freezegun-1.5.5.tar.gz", hash = "sha256:ac7742a6cc6c25a2c35e9292dfd554b897b517d2dec26891a2e8debf205cb94a", size = 35914, upload-time = "2025-08-09T10:39:08.338Z" }
wheels = [
    { url = "https://files.pythonhosted.org/packages/5e/2e/b41d8a1a917d6581fc27a35d05561037b048e47df50f27f8ac9c7e27a710/freezegun-1.5.5-py3-none-any.whl", hash = "sha256:cd557f4a75cf074e84bc374249b9dd491eaeacd61376b9eb3c423282211619d2", size = 19266, upload-time = "2025-08-09T10:39:06.636Z" },
]

[[package]]
name = "h11"
version = "0.16.0"
source = { registry = "https://pypi.org/simple" }
sdist = { url = "https://files.pythonhosted.org/packages/01/ee/02a2c011bdab74c6fb3c75474d40b3052059d95df7e73351460c8588d963/h11-0.16.0.tar.gz", hash = "sha256:4e35b956cf45792e4caa5885e69fba00bdbc6ffafbfa020300e549b208ee5ff1", size = 101250, upload-time = "2025-04-24T03:35:25.427Z" }
wheels = [
    { url = "https://files.pythonhosted.org/packages/04/4b/29cac41a4d98d144bf5f6d33995617b185d14b22401f75ca86f384e87ff1/h11-0.16.0-py3-none-any.whl", hash = "sha256:63cf8bbe7522de3bf65932fda1d9c2772064ffb3dae62d55932da54b31cb6c86", size = 37515, upload-time = "2025-04-24T03:35:24.344Z" },
]

[[package]]
name = "httpcore"
version = "1.0.9"
source = { registry = "https://pypi.org/simple" }
dependencies = [
    { name = "certifi" },
    { name = "h11" },
]
sdist = { url = "https://files.pythonhosted.org/packages/06/94/82699a10bca87a5556c9c59b5963f2d039dbd239f25bc2a63907a05a14cb/httpcore-1.0.9.tar.gz", hash = "sha256:6e34463af53fd2ab5d807f399a9b45ea31c3dfa2276f15a2c3f00afff6e176e8", size = 85484, upload-time = "2025-04-24T22:06:22.219Z" }
wheels = [
    { url = "https://files.pythonhosted.org/packages/7e/f5/f66802a942d491edb555dd61e3a9961140fd64c90bce1eafd741609d334d/httpcore-1.0.9-py3-none-any.whl", hash = "sha256:2d400746a40668fc9dec9810239072b40b4484b640a8c38fd654a024c7a1bf55", size = 78784, upload-time = "2025-04-24T22:06:20.566Z" },
]

[[package]]
name = "httpx"
version = "0.28.1"
source = { registry = "https://pypi.org/simple" }
dependencies = [
    { name = "anyio" },
    { name = "certifi" },
    { name = "httpcore" },
    { name = "idna" },
]
sdist = { url = "https://files.pythonhosted.org/packages/b1/df/48c586a5fe32a0f01324ee087459e112ebb7224f646c0b5023f5e79e9956/httpx-0.28.1.tar.gz", hash = "sha256:75e98c5f16b0f35b567856f597f06ff2270a374470a5c2392242528e3e3e42fc", size = 141406, upload-time = "2024-12-06T15:37:23.222Z" }
wheels = [
    { url = "https://files.pythonhosted.org/packages/2a/39/e50c7c3a983047577ee07d2a9e53faf5a69493943ec3f6a384bdc792deb2/httpx-0.28.1-py3-none-any.whl", hash = "sha256:d909fcccc110f8c7faf814ca82a9a4d816bc5a6dbfea25d6591d6985b8ba59ad", size = 73517, upload-time = "2024-12-06T15:37:21.509Z" },
]

[[package]]
name = "identify"
version = "2.6.16"
source = { registry = "https://pypi.org/simple" }
sdist = { url = "https://files.pythonhosted.org/packages/5b/8d/e8b97e6bd3fb6fb271346f7981362f1e04d6a7463abd0de79e1fda17c067/identify-2.6.16.tar.gz", hash = "sha256:846857203b5511bbe94d5a352a48ef2359532bc8f6727b5544077a0dcfb24980", size = 99360, upload-time = "2026-01-12T18:58:58.201Z" }
wheels = [
    { url = "https://files.pythonhosted.org/packages/b8/58/40fbbcefeda82364720eba5cf2270f98496bdfa19ea75b4cccae79c698e6/identify-2.6.16-py2.py3-none-any.whl", hash = "sha256:391ee4d77741d994189522896270b787aed8670389bfd60f326d677d64a6dfb0", size = 99202, upload-time = "2026-01-12T18:58:56.627Z" },
]

[[package]]
name = "idna"
version = "3.11"
source = { registry = "https://pypi.org/simple" }
sdist = { url = "https://files.pythonhosted.org/packages/6f/6d/0703ccc57f3a7233505399edb88de3cbd678da106337b9fcde432b65ed60/idna-3.11.tar.gz", hash = "sha256:795dafcc9c04ed0c1fb032c2aa73654d8e8c5023a7df64a53f39190ada629902", size = 194582, upload-time = "2025-10-12T14:55:20.501Z" }
wheels = [
    { url = "https://files.pythonhosted.org/packages/0e/61/66938bbb5fc52dbdf84594873d5b51fb1f7c7794e9c0f5bd885f30bc507b/idna-3.11-py3-none-any.whl", hash = "sha256:771a87f49d9defaf64091e6e6fe9c18d4833f140bd19464795bc32d966ca37ea", size = 71008, upload-time = "2025-10-12T14:55:18.883Z" },
]

[[package]]
name = "keboola-component"
version = "1.6.13"
source = { registry = "https://pypi.org/simple" }
dependencies = [
    { name = "deprecated" },
    { name = "pygelf" },
    { name = "pytz" },
]
sdist = { url = "https://files.pythonhosted.org/packages/91/e9/80a83c04bccaad7f5d7b6e8b9c0305085db2bd22838f7323f57aaaefd2f4/keboola.component-1.6.13.tar.gz", hash = "sha256:11b072da1cab39233ff798217a876cdacf17f446decdb89735f295ca20662874", size = 59550, upload-time = "2025-09-15T14:00:47.874Z" }
wheels = [
    { url = "https://files.pythonhosted.org/packages/a4/35/f4dab3d75a155260b90c72bb37d03a9bfd24dc18f52ccea2d61e587dbef6/keboola.component-1.6.13-py3-none-any.whl", hash = "sha256:eceda4c2d083b3857d6eb98e30d7bfe48a48ed0f8567e6898218cee4d9391318", size = 44151, upload-time = "2025-09-15T14:00:46.291Z" },
]

[[package]]
name = "keboola-http-client"
version = "1.2.0"
source = { registry = "https://pypi.org/simple" }
dependencies = [
    { name = "aiolimiter" },
    { name = "httpx" },
    { name = "requests" },
]
sdist = { url = "https://files.pythonhosted.org/packages/0f/b9/8e43e2b7c1f2667a9bc40b96a0098dcdd5d77b8d937fa1312ebd99ad9561/keboola_http_client-1.2.0.tar.gz", hash = "sha256:b3a3bcdc096ab84cff19ffa65d2ee303032c73d2d8d8b8aa93a82fb5ba6da484", size = 18369, upload-time = "2025-11-19T13:19:39.454Z" }
wheels = [
    { url = "https://files.pythonhosted.org/packages/09/7d/1d2b64896f9fff44de82783194a0def1e683dbfe7a8491db6d88d9a403c9/keboola_http_client-1.2.0-py3-none-any.whl", hash = "sha256:de80f5866d4d0aafc3a67492dc3e2d31d6c7e53f79406d7130620c952a4da493", size = 12632, upload-time = "2025-11-19T13:19:38.003Z" },
]

[[package]]
name = "keboola-utils"
version = "1.1.0"
source = { registry = "https://pypi.org/simple" }
dependencies = [
    { name = "dateparser" },
    { name = "pytz" },
]
sdist = { url = "https://files.pythonhosted.org/packages/a7/b8/ccfddc2eb510f7a6ab878ab8a6249a23494194780a436676da6c2f5d23c7/keboola.utils-1.1.0.tar.gz", hash = "sha256:e943dbda932d945bcd5edd51283eea8f7035249c9dac769d3e96d2f507b52f60", size = 9830, upload-time = "2021-04-09T11:11:49.828Z" }
wheels = [
    { url = "https://files.pythonhosted.org/packages/f9/f4/6697a0c2ff512baa7b84413972e51d5449a0a145f68dc750f05a8b1da39d/keboola.utils-1.1.0-py3-none-any.whl", hash = "sha256:8c73faa4a81f371a2eecd8465b08a51b3f7608969dd91d38d5b3bcfad7ef0da5", size = 10131, upload-time = "2021-04-09T11:11:48.826Z" },
]

[[package]]
name = "mccabe"
version = "0.7.0"
source = { registry = "https://pypi.org/simple" }
sdist = { url = "https://files.pythonhosted.org/packages/e7/ff/0ffefdcac38932a54d2b5eed4e0ba8a408f215002cd178ad1df0f2806ff8/mccabe-0.7.0.tar.gz", hash = "sha256:348e0240c33b60bbdf4e523192ef919f28cb2c3d7d5c7794f74009290f236325", size = 9658, upload-time = "2022-01-24T01:14:51.113Z" }
wheels = [
    { url = "https://files.pythonhosted.org/packages/27/1a/1f68f9ba0c207934b35b86a8ca3aad8395a3d6dd7921c0686e23853ff5a9/mccabe-0.7.0-py2.py3-none-any.whl", hash = "sha256:6c2d30ab6be0e4a46919781807b4f0d834ebdd6c6e3dca0bda5a15f863427b6e", size = 7350, upload-time = "2022-01-24T01:14:49.62Z" },
]

[[package]]
name = "mock"
version = "5.2.0"
source = { registry = "https://pypi.org/simple" }
sdist = { url = "https://files.pythonhosted.org/packages/07/8c/14c2ae915e5f9dca5a22edd68b35be94400719ccfa068a03e0fb63d0f6f6/mock-5.2.0.tar.gz", hash = "sha256:4e460e818629b4b173f32d08bf30d3af8123afbb8e04bb5707a1fd4799e503f0", size = 92796, upload-time = "2025-03-03T12:31:42.911Z" }
wheels = [
    { url = "https://files.pythonhosted.org/packages/bd/d9/617e6af809bf3a1d468e0d58c3997b1dc219a9a9202e650d30c2fc85d481/mock-5.2.0-py3-none-any.whl", hash = "sha256:7ba87f72ca0e915175596069dbbcc7c75af7b5e9b9bc107ad6349ede0819982f", size = 31617, upload-time = "2025-03-03T12:31:41.518Z" },
]

[[package]]
name = "nodeenv"
version = "1.10.0"
source = { registry = "https://pypi.org/simple" }
sdist = { url = "https://files.pythonhosted.org/packages/24/bf/d1bda4f6168e0b2e9e5958945e01910052158313224ada5ce1fb2e1113b8/nodeenv-1.10.0.tar.gz", hash = "sha256:996c191ad80897d076bdfba80a41994c2b47c68e224c542b48feba42ba00f8bb", size = 55611, upload-time = "2025-12-20T14:08:54.006Z" }
wheels = [
    { url = "https://files.pythonhosted.org/packages/88/b2/d0896bdcdc8d28a7fc5717c305f1a861c26e18c05047949fb371034d98bd/nodeenv-1.10.0-py2.py3-none-any.whl", hash = "sha256:5bb13e3eed2923615535339b3c620e76779af4cb4c6a90deccc9e36b274d3827", size = 23438, upload-time = "2025-12-20T14:08:52.782Z" },
]

[[package]]
name = "odoo-extractor"
source = { virtual = "." }
dependencies = [
    { name = "freezegun" },
    { name = "keboola-component" },
    { name = "keboola-http-client" },
    { name = "keboola-utils" },
    { name = "mock" },
    { name = "pydantic" },
]

[package.dev-dependencies]
dev = [
    { name = "flake8" },
    { name = "pre-commit" },
    { name = "ruff" },
]

[package.metadata]
requires-dist = [
    { name = "freezegun", specifier = ">=1.5.1" },
    { name = "keboola-component", specifier = ">=1.6.10" },
    { name = "keboola-http-client", specifier = ">=1.0.1" },
    { name = "keboola-utils", specifier = ">=1.1.0" },
    { name = "mock", specifier = ">=5.2.0" },
    { name = "pydantic", specifier = ">=2.11.3" },
]

[package.metadata.requires-dev]
dev = [
    { name = "flake8", specifier = ">=7.2.0" },
    { name = "pre-commit", specifier = ">=4.5.0" },
    { name = "ruff", specifier = ">=0.11.5" },
]

[[package]]
name = "platformdirs"
version = "4.5.1"
source = { registry = "https://pypi.org/simple" }
sdist = { url = "https://files.pythonhosted.org/packages/cf/86/0248f086a84f01b37aaec0fa567b397df1a119f73c16f6c7a9aac73ea309/platformdirs-4.5.1.tar.gz", hash = "sha256:61d5cdcc6065745cdd94f0f878977f8de9437be93de97c1c12f853c9c0cdcbda", size = 21715, upload-time = "2025-12-05T13:52:58.638Z" }
wheels = [
    { url = "https://files.pythonhosted.org/packages/cb/28/3bfe2fa5a7b9c46fe7e13c97bda14c895fb10fa2ebf1d0abb90e0cea7ee1/platformdirs-4.5.1-py3-none-any.whl", hash = "sha256:d03afa3963c806a9bed9d5125c8f4cb2fdaf74a55ab60e5d59b3fde758104d31", size = 18731, upload-time = "2025-12-05T13:52:56.823Z" },
]

[[package]]
name = "pre-commit"
version = "4.5.1"
source = { registry = "https://pypi.org/simple" }
dependencies = [
    { name = "cfgv" },
    { name = "identify" },
    { name = "nodeenv" },
    { name = "pyyaml" },
    { name = "virtualenv" },
]
sdist = { url = "https://files.pythonhosted.org/packages/40/f1/6d86a29246dfd2e9b6237f0b5823717f60cad94d47ddc26afa916d21f525/pre_commit-4.5.1.tar.gz", hash = "sha256:eb545fcff725875197837263e977ea257a402056661f09dae08e4b149b030a61", size = 198232, upload-time = "2025-12-16T21:14:33.552Z" }
wheels = [
    { url = "https://files.pythonhosted.org/packages/5d/19/fd3ef348460c80af7bb4669ea7926651d1f95c23ff2df18b9d24bab4f3fa/pre_commit-4.5.1-py2.py3-none-any.whl", hash = "sha256:3b3afd891e97337708c1674210f8eba659b52a38ea5f822ff142d10786221f77", size = 226437, upload-time = "2025-12-16T21:14:32.409Z" },
]

[[package]]
name = "pycodestyle"
version = "2.14.0"
source = { registry = "https://pypi.org/simple" }
sdist = { url = "https://files.pythonhosted.org/packages/11/e0/abfd2a0d2efe47670df87f3e3a0e2edda42f055053c85361f19c0e2c1ca8/pycodestyle-2.14.0.tar.gz", hash = "sha256:c4b5b517d278089ff9d0abdec919cd97262a3367449ea1c8b49b91529167b783", size = 39472, upload-time = "2025-06-20T18:49:48.75Z" }
wheels = [
    { url = "https://files.pythonhosted.org/packages/d7/27/a58ddaf8c588a3ef080db9d0b7e0b97215cee3a45df74f3a94dbbf5c893a/pycodestyle-2.14.0-py2.py3-none-any.whl", hash = "sha256:dd6bf7cb4ee77f8e016f9c8e74a35ddd9f67e1d5fd4184d86c3b98e07099f42d", size = 31594, upload-time = "2025-06-20T18:49:47.491Z" },
]

[[package]]
name = "pydantic"
version = "2.12.5"
source = { registry = "https://pypi.org/simple" }
dependencies = [
    { name = "annotated-types" },
    { name = "pydantic-core" },
    { name = "typing-extensions" },
    { name = "typing-inspection" },
]
sdist = { url = "https://files.pythonhosted.org/packages/69/44/36f1a6e523abc58ae5f928898e4aca2e0ea509b5aa6f6f392a5d882be928/pydantic-2.12.5.tar.gz", hash = "sha256:4d351024c75c0f085a9febbb665ce8c0c6ec5d30e903bdb6394b7ede26aebb49", size = 821591, upload-time = "2025-11-26T15:11:46.471Z" }
wheels = [
    { url = "https://files.pythonhosted.org/packages/5a/87/b70ad306ebb6f9b585f114d0ac2137d792b48be34d732d60e597c2f8465a/pydantic-2.12.5-py3-none-any.whl", hash = "sha256:e561593fccf61e8a20fc46dfc2dfe075b8be7d0188df33f221ad1f0139180f9d", size = 463580, upload-time = "2025-11-26T15:11:44.605Z" },
]

[[package]]
name = "pydantic-core"
version = "2.41.5"
source = { registry = "https://pypi.org/simple" }
dependencies = [
    { name = "typing-extensions" },
]
sdist = { url = "https://files.pythonhosted.org/packages/71/70/23b021c950c2addd24ec408e9ab05d59b035b39d97cdc1130e1bce647bb6/pydantic_core-2.41.5.tar.gz", hash = "sha256:08daa51ea16ad373ffd5e7606252cc32f07bc72b28284b6bc9c6df804816476e", size = 460952, upload-time = "2025-11-04T13:43:49.098Z" }
wheels = [
    { url = "https://files.pythonhosted.org/packages/87/06/8806241ff1f70d9939f9af039c6c35f2360cf16e93c2ca76f184e76b1564/pydantic_core-2.41.5-cp313-cp313-macosx_10_12_x86_64.whl", hash = "sha256:941103c9be18ac8daf7b7adca8228f8ed6bb7a1849020f643b3a14d15b1924d9", size = 2120403, upload-time = "2025-11-04T13:40:25.248Z" },
    { url = "https://files.pythonhosted.org/packages/94/02/abfa0e0bda67faa65fef1c84971c7e45928e108fe24333c81f3bfe35d5f5/pydantic_core-2.41.5-cp313-cp313-macosx_11_0_arm64.whl", hash = "sha256:112e305c3314f40c93998e567879e887a3160bb8689ef3d2c04b6cc62c33ac34", size = 1896206, upload-time = "2025-11-04T13:40:27.099Z" },
    { url = "https://files.pythonhosted.org/packages/15/df/a4c740c0943e93e6500f9eb23f4ca7ec9bf71b19e608ae5b579678c8d02f/pydantic_core-2.41.5-cp313-cp313-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:0cbaad15cb0c90aa221d43c00e77bb33c93e8d36e0bf74760cd00e732d10a6a0", size = 1919307, upload-time = "2025-11-04T13:40:29.806Z" },
    { url = "https://files.pythonhosted.org/packages/9a/e3/6324802931ae1d123528988e0e86587c2072ac2e5394b4bc2bc34b61ff6e/pydantic_core-2.41.5-cp313-cp313-manylinux_2_17_armv7l.manylinux2014_armv7l.whl", hash = "sha256:03ca43e12fab6023fc79d28ca6b39b05f794ad08ec2feccc59a339b02f2b3d33", size = 2063258, upload-time = "2025-11-04T13:40:33.544Z" },
    { url = "https://files.pythonhosted.org/packages/c9/d4/2230d7151d4957dd79c3044ea26346c148c98fbf0ee6ebd41056f2d62ab5/pydantic_core-2.41.5-cp313-cp313-manylinux_2_17_ppc64le.manylinux2014_ppc64le.whl", hash = "sha256:dc799088c08fa04e43144b164feb0c13f9a0bc40503f8df3e9fde58a3c0c101e", size = 2214917, upload-time = "2025-11-04T13:40:35.479Z" },
    { url = "https://files.pythonhosted.org/packages/e6/9f/eaac5df17a3672fef0081b6c1bb0b82b33ee89aa5cec0d7b05f52fd4a1fa/pydantic_core-2.41.5-cp313-cp313-manylinux_2_17_s390x.manylinux2014_s390x.whl", hash = "sha256:97aeba56665b4c3235a0e52b2c2f5ae9cd071b8a8310ad27bddb3f7fb30e9aa2", size = 2332186, upload-time = "2025-11-04T13:40:37.436Z" },
    { url = "https://files.pythonhosted.org/packages/cf/4e/35a80cae583a37cf15604b44240e45c05e04e86f9cfd766623149297e971/pydantic_core-2.41.5-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:406bf18d345822d6c21366031003612b9c77b3e29ffdb0f612367352aab7d586", size = 2073164, upload-time = "2025-11-04T13:40:40.289Z" },
    { url = "https://files.pythonhosted.org/packages/bf/e3/f6e262673c6140dd3305d144d032f7bd5f7497d3871c1428521f19f9efa2/pydantic_core-2.41.5-cp313-cp313-manylinux_2_5_i686.manylinux1_i686.whl", hash = "sha256:b93590ae81f7010dbe380cdeab6f515902ebcbefe0b9327cc4804d74e93ae69d", size = 2179146, upload-time = "2025-11-04T13:40:42.809Z" },
    { url = "https://files.pythonhosted.org/packages/75/c7/20bd7fc05f0c6ea2056a4565c6f36f8968c0924f19b7d97bbfea55780e73/pydantic_core-2.41.5-cp313-cp313-musllinux_1_1_aarch64.whl", hash = "sha256:01a3d0ab748ee531f4ea6c3e48ad9dac84ddba4b0d82291f87248f2f9de8d740", size = 2137788, upload-time = "2025-11-04T13:40:44.752Z" },
    { url = "https://files.pythonhosted.org/packages/3a/8d/34318ef985c45196e004bc46c6eab2eda437e744c124ef0dbe1ff2c9d06b/pydantic_core-2.41.5-cp313-cp313-musllinux_1_1_armv7l.whl", hash = "sha256:6561e94ba9dacc9c61bce40e2d6bdc3bfaa0259d3ff36ace3b1e6901936d2e3e", size = 2340133, upload-time = "2025-11-04T13:40:46.66Z" },
    { url = "https://files.pythonhosted.org/packages/9c/59/013626bf8c78a5a5d9350d12e7697d3d4de951a75565496abd40ccd46bee/pydantic_core-2.41.5-cp313-cp313-musllinux_1_1_x86_64.whl", hash = "sha256:915c3d10f81bec3a74fbd4faebe8391013ba61e5a1a8d48c4455b923bdda7858", size = 2324852, upload-time = "2025-11-04T13:40:48.575Z" },
    { url = "https://files.pythonhosted.org/packages/1a/d9/c248c103856f807ef70c18a4f986693a46a8ffe1602e5d361485da502d20/pydantic_core-2.41.5-cp313-cp313-win32.whl", hash = "sha256:650ae77860b45cfa6e2cdafc42618ceafab3a2d9a3811fcfbd3bbf8ac3c40d36", size = 1994679, upload-time = "2025-11-04T13:40:50.619Z" },
    { url = "https://files.pythonhosted.org/packages/9e/8b/341991b158ddab181cff136acd2552c9f35bd30380422a639c0671e99a91/pydantic_core-2.41.5-cp313-cp313-win_amd64.whl", hash = "sha256:79ec52ec461e99e13791ec6508c722742ad745571f234ea6255bed38c6480f11", size = 2019766, upload-time = "2025-11-04T13:40:52.631Z" },
    { url = "https://files.pythonhosted.org/packages/73/7d/f2f9db34af103bea3e09735bb40b021788a5e834c81eedb541991badf8f5/pydantic_core-2.41.5-cp313-cp313-win_arm64.whl", hash = "sha256:3f84d5c1b4ab906093bdc1ff10484838aca54ef08de4afa9de0f5f14d69639cd", size = 1981005, upload-time = "2025-11-04T13:40:54.734Z" },
]

[[package]]
name = "pyflakes"
version = "3.4.0"
source = { registry = "https://pypi.org/simple" }
sdist = { url = "https://files.pythonhosted.org/packages/45/dc/fd034dc20b4b264b3d015808458391acbf9df40b1e54750ef175d39180b1/pyflakes-3.4.0.tar.gz", hash = "sha256:b24f96fafb7d2ab0ec5075b7350b3d2d2218eab42003821c06344973d3ea2f58", size = 64669, upload-time = "2025-06-20T18:45:27.834Z" }
wheels = [
    { url = "https://files.pythonhosted.org/packages/c2/2f/81d580a0fb83baeb066698975cb14a618bdbed7720678566f1b046a95fe8/pyflakes-3.4.0-py2.py3-none-any.whl", hash = "sha256:f742a7dbd0d9cb9ea41e9a24a918996e8170c799fa528688d40dd582c8265f4f", size = 63551, upload-time = "2025-06-20T18:45:26.937Z" },
]

[[package]]
name = "pygelf"
version = "0.4.3"
source = { registry = "https://pypi.org/simple" }
sdist = { url = "https://files.pythonhosted.org/packages/49/91/ac1605bb40092ae41fbb833ee55447f72e19ce5459efa6bd3beecc67e971/pygelf-0.4.3.tar.gz", hash = "sha256:8ed972563be3c8f168483f01dbf522b6bc697959c97a3f4881324b3f79638911", size = 11017, upload-time = "2025-06-14T19:21:19.832Z" }
wheels = [
    { url = "https://files.pythonhosted.org/packages/d4/ee/ebac3de919431912e0be380fafd01059a091a489f6b5d7896c2a04548895/pygelf-0.4.3-py3-none-any.whl", hash = "sha256:0876c99a77f9f021834982c9808205b3239fabf5886788d701f31b495b65c8ae", size = 8750, upload-time = "2025-06-14T19:21:16.953Z" },
]

[[package]]
name = "python-dateutil"
version = "2.9.0.post0"
source = { registry = "https://pypi.org/simple" }
dependencies = [
    { name = "six" },
]
sdist = { url = "https://files.pythonhosted.org/packages/66/c0/0c8b6ad9f17a802ee498c46e004a0eb49bc148f2fd230864601a86dcf6db/python-dateutil-2.9.0.post0.tar.gz", hash = "sha256:37dd54208da7e1cd875388217d5e00ebd4179249f90fb72437e91a35459a0ad3", size = 342432, upload-time = "2024-03-01T18:36:20.211Z" }
wheels = [
    { url = "https://files.pythonhosted.org/packages/ec/57/56b9bcc3c9c6a792fcbaf139543cee77261f3651ca9da0c93f5c1221264b/python_dateutil-2.9.0.post0-py2.py3-none-any.whl", hash = "sha256:a8b2bc7bffae282281c8140a97d3aa9c14da0b136dfe83f850eea9a5f7470427", size = 229892, upload-time = "2024-03-01T18:36:18.57Z" },
]

[[package]]
name = "pytz"
version = "2025.2"
source = { registry = "https://pypi.org/simple" }
sdist = { url = "https://files.pythonhosted.org/packages/f8/bf/abbd3cdfb8fbc7fb3d4d38d320f2441b1e7cbe29be4f23797b4a2b5d8aac/pytz-2025.2.tar.gz", hash = "sha256:360b9e3dbb49a209c21ad61809c7fb453643e048b38924c765813546746e81c3", size = 320884, upload-time = "2025-03-25T02:25:00.538Z" }
wheels = [
    { url = "https://files.pythonhosted.org/packages/81/c4/34e93fe5f5429d7570ec1fa436f1986fb1f00c3e0f43a589fe2bbcd22c3f/pytz-2025.2-py2.py3-none-any.whl", hash = "sha256:5ddf76296dd8c44c26eb8f4b6f35488f3ccbf6fbbd7adee0b7262d43f0ec2f00", size = 509225, upload-time = "2025-03-25T02:24:58.468Z" },
]

[[package]]
name = "pyyaml"
version = "6.0.3"
source = { registry = "https://pypi.org/simple" }
sdist = { url = "https://files.pythonhosted.org/packages/05/8e/961c0007c59b8dd7729d542c61a4d537767a59645b82a0b521206e1e25c2/pyyaml-6.0.3.tar.gz", hash = "sha256:d76623373421df22fb4cf8817020cbb7ef15c725b9d5e45f17e189bfc384190f", size = 130960, upload-time = "2025-09-25T21:33:16.546Z" }
wheels = [
    { url = "https://files.pythonhosted.org/packages/d1/11/0fd08f8192109f7169db964b5707a2f1e8b745d4e239b784a5a1dd80d1db/pyyaml-6.0.3-cp313-cp313-macosx_10_13_x86_64.whl", hash = "sha256:8da9669d359f02c0b91ccc01cac4a67f16afec0dac22c2ad09f46bee0697eba8", size = 181669, upload-time = "2025-09-25T21:32:23.673Z" },
    { url = "https://files.pythonhosted.org/packages/b1/16/95309993f1d3748cd644e02e38b75d50cbc0d9561d21f390a76242ce073f/pyyaml-6.0.3-cp313-cp313-macosx_11_0_arm64.whl", hash = "sha256:2283a07e2c21a2aa78d9c4442724ec1eb15f5e42a723b99cb3d822d48f5f7ad1", size = 173252, upload-time = "2025-09-25T21:32:25.149Z" },
    { url = "https://files.pythonhosted.org/packages/50/31/b20f376d3f810b9b2371e72ef5adb33879b25edb7a6d072cb7ca0c486398/pyyaml-6.0.3-cp313-cp313-manylinux2014_aarch64.manylinux_2_17_aarch64.manylinux_2_28_aarch64.whl", hash = "sha256:ee2922902c45ae8ccada2c5b501ab86c36525b883eff4255313a253a3160861c", size = 767081, upload-time = "2025-09-25T21:32:26.575Z" },
    { url = "https://files.pythonhosted.org/packages/49/1e/a55ca81e949270d5d4432fbbd19dfea5321eda7c41a849d443dc92fd1ff7/pyyaml-6.0.3-cp313-cp313-manylinux2014_s390x.manylinux_2_17_s390x.manylinux_2_28_s390x.whl", hash = "sha256:a33284e20b78bd4a18c8c2282d549d10bc8408a2a7ff57653c0cf0b9be0afce5", size = 841159, upload-time = "2025-09-25T21:32:27.727Z" },
    { url = "https://files.pythonhosted.org/packages/74/27/e5b8f34d02d9995b80abcef563ea1f8b56d20134d8f4e5e81733b1feceb2/pyyaml-6.0.3-cp313-cp313-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl", hash = "sha256:0f29edc409a6392443abf94b9cf89ce99889a1dd5376d94316ae5145dfedd5d6", size = 801626, upload-time = "2025-09-25T21:32:28.878Z" },
    { url = "https://files.pythonhosted.org/packages/f9/11/ba845c23988798f40e52ba45f34849aa8a1f2d4af4b798588010792ebad6/pyyaml-6.0.3-cp313-cp313-musllinux_1_2_aarch64.whl", hash = "sha256:f7057c9a337546edc7973c0d3ba84ddcdf0daa14533c2065749c9075001090e6", size = 753613, upload-time = "2025-09-25T21:32:30.178Z" },
    { url = "https://files.pythonhosted.org/packages/3d/e0/7966e1a7bfc0a45bf0a7fb6b98ea03fc9b8d84fa7f2229e9659680b69ee3/pyyaml-6.0.3-cp313-cp313-musllinux_1_2_x86_64.whl", hash = "sha256:eda16858a3cab07b80edaf74336ece1f986ba330fdb8ee0d6c0d68fe82bc96be", size = 794115, upload-time = "2025-09-25T21:32:31.353Z" },
    { url = "https://files.pythonhosted.org/packages/de/94/980b50a6531b3019e45ddeada0626d45fa85cbe22300844a7983285bed3b/pyyaml-6.0.3-cp313-cp313-win32.whl", hash = "sha256:d0eae10f8159e8fdad514efdc92d74fd8d682c933a6dd088030f3834bc8e6b26", size = 137427, upload-time = "2025-09-25T21:32:32.58Z" },
    { url = "https://files.pythonhosted.org/packages/97/c9/39d5b874e8b28845e4ec2202b5da735d0199dbe5b8fb85f91398814a9a46/pyyaml-6.0.3-cp313-cp313-win_amd64.whl", hash = "sha256:79005a0d97d5ddabfeeea4cf676af11e647e41d81c9a7722a193022accdb6b7c", size = 154090, upload-time = "2025-09-25T21:32:33.659Z" },
    { url = "https://files.pythonhosted.org/packages/73/e8/2bdf3ca2090f68bb3d75b44da7bbc71843b19c9f2b9cb9b0f4ab7a5a4329/pyyaml-6.0.3-cp313-cp313-win_arm64.whl", hash = "sha256:5498cd1645aa724a7c71c8f378eb29ebe23da2fc0d7a08071d89469bf1d2defb", size = 140246, upload-time = "2025-09-25T21:32:34.663Z" },
]

[[package]]
name = "regex"
version = "2026.1.15"
source = { registry = "https://pypi.org/simple" }
sdist = { url = "https://files.pythonhosted.org/packages/0b/86/07d5056945f9ec4590b518171c4254a5925832eb727b56d3c38a7476f316/regex-2026.1.15.tar.gz", hash = "sha256:164759aa25575cbc0651bef59a0b18353e54300d79ace8084c818ad8ac72b7d5", size = 414811, upload-time = "2026-01-14T23:18:02.775Z" }
wheels = [
    { url = "https://files.pythonhosted.org/packages/f8/2e/6870bb16e982669b674cce3ee9ff2d1d46ab80528ee6bcc20fb2292efb60/regex-2026.1.15-cp313-cp313-macosx_10_13_universal2.whl", hash = "sha256:e69d0deeb977ffe7ed3d2e4439360089f9c3f217ada608f0f88ebd67afb6385e", size = 489164, upload-time = "2026-01-14T23:15:13.962Z" },
    { url = "https://files.pythonhosted.org/packages/dc/67/9774542e203849b0286badf67199970a44ebdb0cc5fb739f06e47ada72f8/regex-2026.1.15-cp313-cp313-macosx_10_13_x86_64.whl", hash = "sha256:3601ffb5375de85a16f407854d11cca8fe3f5febbe3ac78fb2866bb220c74d10", size = 291218, upload-time = "2026-01-14T23:15:15.647Z" },
    { url = "https://files.pythonhosted.org/packages/b2/87/b0cda79f22b8dee05f774922a214da109f9a4c0eca5da2c9d72d77ea062c/regex-2026.1.15-cp313-cp313-macosx_11_0_arm64.whl", hash = "sha256:4c5ef43b5c2d4114eb8ea424bb8c9cec01d5d17f242af88b2448f5ee81caadbc", size = 288895, upload-time = "2026-01-14T23:15:17.788Z" },
    { url = "https://files.pythonhosted.org/packages/3b/6a/0041f0a2170d32be01ab981d6346c83a8934277d82c780d60b127331f264/regex-2026.1.15-cp313-cp313-manylinux2014_aarch64.manylinux_2_17_aarch64.manylinux_2_28_aarch64.whl", hash = "sha256:968c14d4f03e10b2fd960f1d5168c1f0ac969381d3c1fcc973bc45fb06346599", size = 798680, upload-time = "2026-01-14T23:15:19.342Z" },
    { url = "https://files.pythonhosted.org/packages/58/de/30e1cfcdbe3e891324aa7568b7c968771f82190df5524fabc1138cb2d45a/regex-2026.1.15-cp313-cp313-manylinux2014_ppc64le.manylinux_2_17_ppc64le.manylinux_2_28_ppc64le.whl", hash = "sha256:56a5595d0f892f214609c9f76b41b7428bed439d98dc961efafdd1354d42baae", size = 864210, upload-time = "2026-01-14T23:15:22.005Z" },
    { url = "https://files.pythonhosted.org/packages/64/44/4db2f5c5ca0ccd40ff052ae7b1e9731352fcdad946c2b812285a7505ca75/regex-2026.1.15-cp313-cp313-manylinux2014_s390x.manylinux_2_17_s390x.manylinux_2_28_s390x.whl", hash = "sha256:0bf650f26087363434c4e560011f8e4e738f6f3e029b85d4904c50135b86cfa5", size = 912358, upload-time = "2026-01-14T23:15:24.569Z" },
    { url = "https://files.pythonhosted.org/packages/79/b6/e6a5665d43a7c42467138c8a2549be432bad22cbd206f5ec87162de74bd7/regex-2026.1.15-cp313-cp313-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl", hash = "sha256:18388a62989c72ac24de75f1449d0fb0b04dfccd0a1a7c1c43af5eb503d890f6", size = 803583, upload-time = "2026-01-14T23:15:26.526Z" },
    { url = "https://files.pythonhosted.org/packages/e7/53/7cd478222169d85d74d7437e74750005e993f52f335f7c04ff7adfda3310/regex-2026.1.15-cp313-cp313-manylinux_2_31_riscv64.manylinux_2_39_riscv64.whl", hash = "sha256:6d220a2517f5893f55daac983bfa9fe998a7dbcaee4f5d27a88500f8b7873788", size = 775782, upload-time = "2026-01-14T23:15:29.352Z" },
    { url = "https://files.pythonhosted.org/packages/ca/b5/75f9a9ee4b03a7c009fe60500fe550b45df94f0955ca29af16333ef557c5/regex-2026.1.15-cp313-cp313-musllinux_1_2_aarch64.whl", hash = "sha256:c9c08c2fbc6120e70abff5d7f28ffb4d969e14294fb2143b4b5c7d20e46d1714", size = 787978, upload-time = "2026-01-14T23:15:31.295Z" },
    { url = "https://files.pythonhosted.org/packages/72/b3/79821c826245bbe9ccbb54f6eadb7879c722fd3e0248c17bfc90bf54e123/regex-2026.1.15-cp313-cp313-musllinux_1_2_ppc64le.whl", hash = "sha256:7ef7d5d4bd49ec7364315167a4134a015f61e8266c6d446fc116a9ac4456e10d", size = 858550, upload-time = "2026-01-14T23:15:33.558Z" },
    { url = "https://files.pythonhosted.org/packages/4a/85/2ab5f77a1c465745bfbfcb3ad63178a58337ae8d5274315e2cc623a822fa/regex-2026.1.15-cp313-cp313-musllinux_1_2_riscv64.whl", hash = "sha256:6e42844ad64194fa08d5ccb75fe6a459b9b08e6d7296bd704460168d58a388f3", size = 763747, upload-time = "2026-01-14T23:15:35.206Z" },
    { url = "https://files.pythonhosted.org/packages/6d/84/c27df502d4bfe2873a3e3a7cf1bdb2b9cc10284d1a44797cf38bed790470/regex-2026.1.15-cp313-cp313-musllinux_1_2_s390x.whl", hash = "sha256:cfecdaa4b19f9ca534746eb3b55a5195d5c95b88cac32a205e981ec0a22b7d31", size = 850615, upload-time = "2026-01-14T23:15:37.523Z" },
    { url = "https://files.pythonhosted.org/packages/7d/b7/658a9782fb253680aa8ecb5ccbb51f69e088ed48142c46d9f0c99b46c575/regex-2026.1.15-cp313-cp313-musllinux_1_2_x86_64.whl", hash = "sha256:08df9722d9b87834a3d701f3fca570b2be115654dbfd30179f30ab2f39d606d3", size = 789951, upload-time = "2026-01-14T23:15:39.582Z" },
    { url = "https://files.pythonhosted.org/packages/fc/2a/5928af114441e059f15b2f63e188bd00c6529b3051c974ade7444b85fcda/regex-2026.1.15-cp313-cp313-win32.whl", hash = "sha256:d426616dae0967ca225ab12c22274eb816558f2f99ccb4a1d52ca92e8baf180f", size = 266275, upload-time = "2026-01-14T23:15:42.108Z" },
    { url = "https://files.pythonhosted.org/packages/4f/16/5bfbb89e435897bff28cf0352a992ca719d9e55ebf8b629203c96b6ce4f7/regex-2026.1.15-cp313-cp313-win_amd64.whl", hash = "sha256:febd38857b09867d3ed3f4f1af7d241c5c50362e25ef43034995b77a50df494e", size = 277145, upload-time = "2026-01-14T23:15:44.244Z" },
    { url = "https://files.pythonhosted.org/packages/56/c1/a09ff7392ef4233296e821aec5f78c51be5e91ffde0d163059e50fd75835/regex-2026.1.15-cp313-cp313-win_arm64.whl", hash = "sha256:8e32f7896f83774f91499d239e24cebfadbc07639c1494bb7213983842348337", size = 270411, upload-time = "2026-01-14T23:15:45.858Z" },
    { url = "https://files.pythonhosted.org/packages/3c/38/0cfd5a78e5c6db00e6782fdae70458f89850ce95baa5e8694ab91d89744f/regex-2026.1.15-cp313-cp313t-macosx_10_13_universal2.whl", hash = "sha256:ec94c04149b6a7b8120f9f44565722c7ae31b7a6d2275569d2eefa76b83da3be", size = 492068, upload-time = "2026-01-14T23:15:47.616Z" },
    { url = "https://files.pythonhosted.org/packages/50/72/6c86acff16cb7c959c4355826bbf06aad670682d07c8f3998d9ef4fee7cd/regex-2026.1.15-cp313-cp313t-macosx_10_13_x86_64.whl", hash = "sha256:40c86d8046915bb9aeb15d3f3f15b6fd500b8ea4485b30e1bbc799dab3fe29f8", size = 292756, upload-time = "2026-01-14T23:15:49.307Z" },
    { url = "https://files.pythonhosted.org/packages/4e/58/df7fb69eadfe76526ddfce28abdc0af09ffe65f20c2c90932e89d705153f/regex-2026.1.15-cp313-cp313t-macosx_11_0_arm64.whl", hash = "sha256:726ea4e727aba21643205edad8f2187ec682d3305d790f73b7a51c7587b64bdd", size = 291114, upload-time = "2026-01-14T23:15:51.484Z" },
    { url = "https://files.pythonhosted.org/packages/ed/6c/a4011cd1cf96b90d2cdc7e156f91efbd26531e822a7fbb82a43c1016678e/regex-2026.1.15-cp313-cp313t-manylinux2014_aarch64.manylinux_2_17_aarch64.manylinux_2_28_aarch64.whl", hash = "sha256:1cb740d044aff31898804e7bf1181cc72c03d11dfd19932b9911ffc19a79070a", size = 807524, upload-time = "2026-01-14T23:15:53.102Z" },
    { url = "https://files.pythonhosted.org/packages/1d/25/a53ffb73183f69c3e9f4355c4922b76d2840aee160af6af5fac229b6201d/regex-2026.1.15-cp313-cp313t-manylinux2014_ppc64le.manylinux_2_17_ppc64le.manylinux_2_28_ppc64le.whl", hash = "sha256:05d75a668e9ea16f832390d22131fe1e8acc8389a694c8febc3e340b0f810b93", size = 873455, upload-time = "2026-01-14T23:15:54.956Z" },
    { url = "https://files.pythonhosted.org/packages/66/0b/8b47fc2e8f97d9b4a851736f3890a5f786443aa8901061c55f24c955f45b/regex-2026.1.15-cp313-cp313t-manylinux2014_s390x.manylinux_2_17_s390x.manylinux_2_28_s390x.whl", hash = "sha256:d991483606f3dbec93287b9f35596f41aa2e92b7c2ebbb935b63f409e243c9af", size = 915007, upload-time = "2026-01-14T23:15:57.041Z" },
    { url = "https://files.pythonhosted.org/packages/c2/fa/97de0d681e6d26fabe71968dbee06dd52819e9a22fdce5dac7256c31ed84/regex-2026.1.15-cp313-cp313t-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl", hash = "sha256:194312a14819d3e44628a44ed6fea6898fdbecb0550089d84c403475138d0a09", size = 812794, upload-time = "2026-01-14T23:15:58.916Z" },
    { url = "https://files.pythonhosted.org/packages/22/38/e752f94e860d429654aa2b1c51880bff8dfe8f084268258adf9151cf1f53/regex-2026.1.15-cp313-cp313t-manylinux_2_31_riscv64.manylinux_2_39_riscv64.whl", hash = "sha256:fe2fda4110a3d0bc163c2e0664be44657431440722c5c5315c65155cab92f9e5", size = 781159, upload-time = "2026-01-14T23:16:00.817Z" },
    { url = "https://files.pythonhosted.org/packages/e9/a7/d739ffaef33c378fc888302a018d7f81080393d96c476b058b8c64fd2b0d/regex-2026.1.15-cp313-cp313t-musllinux_1_2_aarch64.whl", hash = "sha256:124dc36c85d34ef2d9164da41a53c1c8c122cfb1f6e1ec377a1f27ee81deb794", size = 795558, upload-time = "2026-01-14T23:16:03.267Z" },
    { url = "https://files.pythonhosted.org/packages/3e/c4/542876f9a0ac576100fc73e9c75b779f5c31e3527576cfc9cb3009dcc58a/regex-2026.1.15-cp313-cp313t-musllinux_1_2_ppc64le.whl", hash = "sha256:a1774cd1981cd212506a23a14dba7fdeaee259f5deba2df6229966d9911e767a", size = 868427, upload-time = "2026-01-14T23:16:05.646Z" },
    { url = "https://files.pythonhosted.org/packages/fc/0f/d5655bea5b22069e32ae85a947aa564912f23758e112cdb74212848a1a1b/regex-2026.1.15-cp313-cp313t-musllinux_1_2_riscv64.whl", hash = "sha256:b5f7d8d2867152cdb625e72a530d2ccb48a3d199159144cbdd63870882fb6f80", size = 769939, upload-time = "2026-01-14T23:16:07.542Z" },
    { url = "https://files.pythonhosted.org/packages/20/06/7e18a4fa9d326daeda46d471a44ef94201c46eaa26dbbb780b5d92cbfdda/regex-2026.1.15-cp313-cp313t-musllinux_1_2_s390x.whl", hash = "sha256:492534a0ab925d1db998defc3c302dae3616a2fc3fe2e08db1472348f096ddf2", size = 854753, upload-time = "2026-01-14T23:16:10.395Z" },
    { url = "https://files.pythonhosted.org/packages/3b/67/dc8946ef3965e166f558ef3b47f492bc364e96a265eb4a2bb3ca765c8e46/regex-2026.1.15-cp313-cp313t-musllinux_1_2_x86_64.whl", hash = "sha256:c661fc820cfb33e166bf2450d3dadbda47c8d8981898adb9b6fe24e5e582ba60", size = 799559, upload-time = "2026-01-14T23:16:12.347Z" },
    { url = "https://files.pythonhosted.org/packages/a5/61/1bba81ff6d50c86c65d9fd84ce9699dd106438ee4cdb105bf60374ee8412/regex-2026.1.15-cp313-cp313t-win32.whl", hash = "sha256:99ad739c3686085e614bf77a508e26954ff1b8f14da0e3765ff7abbf7799f952", size = 268879, upload-time = "2026-01-14T23:16:14.049Z" },
    { url = "https://files.pythonhosted.org/packages/e9/5e/cef7d4c5fb0ea3ac5c775fd37db5747f7378b29526cc83f572198924ff47/regex-2026.1.15-cp313-cp313t-win_amd64.whl", hash = "sha256:32655d17905e7ff8ba5c764c43cb124e34a9245e45b83c22e81041e1071aee10", size = 280317, upload-time = "2026-01-14T23:16:15.718Z" },
    { url = "https://files.pythonhosted.org/packages/b4/52/4317f7a5988544e34ab57b4bde0f04944c4786128c933fb09825924d3e82/regex-2026.1.15-cp313-cp313t-win_arm64.whl", hash = "sha256:b2a13dd6a95e95a489ca242319d18fc02e07ceb28fa9ad146385194d95b3c829", size = 271551, upload-time = "2026-01-14T23:16:17.533Z" },
]

[[package]]
name = "requests"
version = "2.32.5"
source = { registry = "https://pypi.org/simple" }
dependencies = [
    { name = "certifi" },
    { name = "charset-normalizer" },
    { name = "idna" },
    { name = "urllib3" },
]
sdist = { url = "https://files.pythonhosted.org/packages/c9/74/b3ff8e6c8446842c3f5c837e9c3dfcfe2018ea6ecef224c710c85ef728f4/requests-2.32.5.tar.gz", hash = "sha256:dbba0bac56e100853db0ea71b82b4dfd5fe2bf6d3754a8893c3af500cec7d7cf", size = 134517, upload-time = "2025-08-18T20:46:02.573Z" }
wheels = [
    { url = "https://files.pythonhosted.org/packages/1e/db/4254e3eabe8020b458f1a747140d32277ec7a271daf1d235b70dc0b4e6e3/requests-2.32.5-py3-none-any.whl", hash = "sha256:2462f94637a34fd532264295e186976db0f5d453d1cdd31473c85a6a161affb6", size = 64738, upload-time = "2025-08-18T20:46:00.542Z" },
]

[[package]]
name = "ruff"
version = "0.14.12"
source = { registry = "https://pypi.org/simple" }
sdist = { url = "https://files.pythonhosted.org/packages/85/81/5fd87d61352fb0f86b4436f278fe19b3770a8b73d42e8b3405d28df6b759/ruff-0.14.12.tar.gz", hash = "sha256:276b0821947f2afff8ee6da282bade96459d2e29f5a203eef04eb7b7a85b119f", size = 6055422, upload-time = "2026-01-15T16:22:12.371Z" }
wheels = [
    { url = "https://files.pythonhosted.org/packages/e4/de/58c5e3b4e6be8d0e007856128be59688cd4025a5345693dd169d61df8eb2/ruff-0.14.12-py3-none-linux_armv6l.whl", hash = "sha256:59434a99f0af57111f62cd77e86b4d4896a2c72bb90cc039d1ac501b151b798b", size = 13046871, upload-time = "2026-01-15T16:21:53.033Z" },
    { url = "https://files.pythonhosted.org/packages/dd/b3/d9710419b6aed406a41c7eb215d604a55d2137f2a60e24d0939dae081b1b/ruff-0.14.12-py3-none-macosx_10_12_x86_64.whl", hash = "sha256:a5912e8270c6b9ed28ae50b993032d195046293fefa56127a8dffbaa5e5bfc04", size = 13433477, upload-time = "2026-01-15T16:21:40.401Z" },
    { url = "https://files.pythonhosted.org/packages/da/4f/25cfc2c4b9fa22c90038bdd966e8e3aea92826790e5350f537f7b3f84609/ruff-0.14.12-py3-none-macosx_11_0_arm64.whl", hash = "sha256:5f59c587a413c9bd3259ec2d006853671f823ac4b4f974653bbcc84c180271de", size = 12356766, upload-time = "2026-01-15T16:21:42.853Z" },
    { url = "https://files.pythonhosted.org/packages/dd/5d/8da8aaca205ad94c87848e5f67b2cd014c022a76ea485ef9f1004ebc5118/ruff-0.14.12-py3-none-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:bd31832569b06c75fdbf6f5f63a3458b7038d97f6e908b6e08fd02d00c20a3ae", size = 12771650, upload-time = "2026-01-15T16:22:00.387Z" },
    { url = "https://files.pythonhosted.org/packages/78/cc/75bc23144392ed21cd3413baf2476b9cd48eb056d87080530a1fe748108e/ruff-0.14.12-py3-none-manylinux_2_17_armv7l.manylinux2014_armv7l.whl", hash = "sha256:cc1ba7b0d74d14b75c3a9d7e7ca01040bd126bd6bde2cffe3c31c1defe649ec6", size = 12820601, upload-time = "2026-01-15T16:21:55.76Z" },
    { url = "https://files.pythonhosted.org/packages/fb/1b/66d03158d2c477da458d9ea22feed4d40609d596dd6fa10bf158039ce8f8/ruff-0.14.12-py3-none-manylinux_2_17_i686.manylinux2014_i686.whl", hash = "sha256:c1a90feecc2e44c01737d9d879ba6fc84b5626a7bd31e81991443198596ebe22", size = 13671644, upload-time = "2026-01-15T16:22:17.561Z" },
    { url = "https://files.pythonhosted.org/packages/22/df/0fa8920f4f1ca00d48a6f9b0b2310c426f4fcc943967af2d2723f7476d04/ruff-0.14.12-py3-none-manylinux_2_17_ppc64.manylinux2014_ppc64.whl", hash = "sha256:b4c3478b459b71940f49d4dac1f91efa3852bb566368ad9f94dae2c257b6e63e", size = 15147221, upload-time = "2026-01-15T16:21:32.998Z" },
    { url = "https://files.pythonhosted.org/packages/54/9a/64365c7be12c51100f4159d15a8b818e4ffdb6aa592080932aa954a59cbd/ruff-0.14.12-py3-none-manylinux_2_17_ppc64le.manylinux2014_ppc64le.whl", hash = "sha256:c14202522c2887e6644308827e72a6a0561fa965854e42ef14b325fa617c2634", size = 14709017, upload-time = "2026-01-15T16:22:02.69Z" },
    { url = "https://files.pythonhosted.org/packages/a7/58/2696c48a5ac88e9716a25048895f450772ce2f3e4cb37d67efc1e11da884/ruff-0.14.12-py3-none-manylinux_2_17_s390x.manylinux2014_s390x.whl", hash = "sha256:2e15471064058c5f22ad17aec4cab3920f71bf6b2dd8e1c8cfb05e8e9ee6d9d6", size = 14133819, upload-time = "2026-01-15T16:21:58.031Z" },
    { url = "https://files.pythonhosted.org/packages/74/81/ce6aea2dcb40cba3d865f4fda5b5058ddc7786002d5f8413e6bc542ed665/ruff-0.14.12-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:697c2e00f00cb1027b91fc8930e276bed580b2976a3e4aca50eae2b3db291f92", size = 13849027, upload-time = "2026-01-15T16:21:50.801Z" },
    { url = "https://files.pythonhosted.org/packages/db/42/402928ed9a377f15abea9331bc77315f1c83ecffa6477251cb435df674bb/ruff-0.14.12-py3-none-manylinux_2_31_riscv64.whl", hash = "sha256:0864023ac5b2c90af354372529926b4fce4980bff828b722bedf115a0677131b", size = 14030353, upload-time = "2026-01-15T16:22:04.835Z" },
    { url = "https://files.pythonhosted.org/packages/02/1a/bc4ee626929034fa1f0d97f03edf334bfdc947cc2609baed7529a4adb352/ruff-0.14.12-py3-none-musllinux_1_2_aarch64.whl", hash = "sha256:6372d9e07c0e61342582b29ba825c0712930c08ee72312d1764abfe761de2806", size = 12666546, upload-time = "2026-01-15T16:22:07.392Z" },
    { url = "https://files.pythonhosted.org/packages/f2/3f/e00efbf5ecf9279b06fcc26821178c46d89b402facdf9b7974b2a76f1da0/ruff-0.14.12-py3-none-musllinux_1_2_armv7l.whl", hash = "sha256:c59c4941400a86c60219fd1457012e6da23a92590755ab4ed1ae25bbe4aab948", size = 12802512, upload-time = "2026-01-15T16:21:48.13Z" },
    { url = "https://files.pythonhosted.org/packages/6f/05/610b462fc211eb877457ee08062af50c56d924849038ec1e6005d6e50791/ruff-0.14.12-py3-none-musllinux_1_2_i686.whl", hash = "sha256:65ce54567c42e3a6d2548b49b8e4e87148eaf455ad76d7a20f83c902bc7cc5e4", size = 13205003, upload-time = "2026-01-15T16:21:37.904Z" },
    { url = "https://files.pythonhosted.org/packages/43/87/68fb2335cf969f3b5a7808265e6998cc735bce9a8efc57f6a3c1c167b3bb/ruff-0.14.12-py3-none-musllinux_1_2_x86_64.whl", hash = "sha256:28255d5a1828bc1da67c8c5a2cea5c83de6f0b6185eef46f4fc12957396fb169", size = 13925981, upload-time = "2026-01-15T16:21:45.453Z" },
    { url = "https://files.pythonhosted.org/packages/cc/a7/2f02a56b457c7cf568778fbbc2302ce6aa00bd20f9dd6149329a376a6964/ruff-0.14.12-py3-none-win32.whl", hash = "sha256:a111f79ba789257177fe5971eea061c8545af3c0cab3529fa00155f6621c68da", size = 12897262, upload-time = "2026-01-15T16:22:15Z" },
    { url = "https://files.pythonhosted.org/packages/8b/fd/86c2309a254b4e0982b3423504614d9f05b077961167a31bdb5b533be8a9/ruff-0.14.12-py3-none-win_amd64.whl", hash = "sha256:8da366e9942b26ac1fb0df43264a3550655160b9536cdb66a2b070a22b6e5d6a", size = 14105034, upload-time = "2026-01-15T16:22:10.139Z" },
    { url = "https://files.pythonhosted.org/packages/5c/0a/8f0d458479113587b1dfd3fabedfd3f1df4653801273993b1f4dc31a935f/ruff-0.14.12-py3-none-win_arm64.whl", hash = "sha256:f0672b72872dc204580d2d3f8bdc4e922c88a0f93e2a3fb799ca085797a5a7c4", size = 13064991, upload-time = "2026-01-15T16:21:35.436Z" },
]

[[package]]
name = "six"
version = "1.17.0"
source = { registry = "https://pypi.org/simple" }
sdist = { url = "https://files.pythonhosted.org/packages/94/e7/b2c673351809dca68a0e064b6af791aa332cf192da575fd474ed7d6f16a2/six-1.17.0.tar.gz", hash = "sha256:ff70335d468e7eb6ec65b95b99d3a2836546063f63acc5171de367e834932a81", size = 34031, upload-time = "2024-12-04T17:35:28.174Z" }
wheels = [
    { url = "https://files.pythonhosted.org/packages/b7/ce/149a00dd41f10bc29e5921b496af8b574d8413afcd5e30dfa0ed46c2cc5e/six-1.17.0-py2.py3-none-any.whl", hash = "sha256:4721f391ed90541fddacab5acf947aa0d3dc7d27b2e1e8eda2be8970586c3274", size = 11050, upload-time = "2024-12-04T17:35:26.475Z" },
]

[[package]]
name = "typing-extensions"
version = "4.15.0"
source = { registry = "https://pypi.org/simple" }
sdist = { url = "https://files.pythonhosted.org/packages/72/94/1a15dd82efb362ac84269196e94cf00f187f7ed21c242792a923cdb1c61f/typing_extensions-4.15.0.tar.gz", hash = "sha256:0cea48d173cc12fa28ecabc3b837ea3cf6f38c6d1136f85cbaaf598984861466", size = 109391, upload-time = "2025-08-25T13:49:26.313Z" }
wheels = [
    { url = "https://files.pythonhosted.org/packages/18/67/36e9267722cc04a6b9f15c7f3441c2363321a3ea07da7ae0c0707beb2a9c/typing_extensions-4.15.0-py3-none-any.whl", hash = "sha256:f0fa19c6845758ab08074a0cfa8b7aecb71c999ca73d62883bc25cc018c4e548", size = 44614, upload-time = "2025-08-25T13:49:24.86Z" },
]

[[package]]
name = "typing-inspection"
version = "0.4.2"
source = { registry = "https://pypi.org/simple" }
dependencies = [
    { name = "typing-extensions" },
]
sdist = { url = "https://files.pythonhosted.org/packages/55/e3/70399cb7dd41c10ac53367ae42139cf4b1ca5f36bb3dc6c9d33acdb43655/typing_inspection-0.4.2.tar.gz", hash = "sha256:ba561c48a67c5958007083d386c3295464928b01faa735ab8547c5692e87f464", size = 75949, upload-time = "2025-10-01T02:14:41.687Z" }
wheels = [
    { url = "https://files.pythonhosted.org/packages/dc/9b/47798a6c91d8bdb567fe2698fe81e0c6b7cb7ef4d13da4114b41d239f65d/typing_inspection-0.4.2-py3-none-any.whl", hash = "sha256:4ed1cacbdc298c220f1bd249ed5287caa16f34d44ef4e9c3d0cbad5b521545e7", size = 14611, upload-time = "2025-10-01T02:14:40.154Z" },
]

[[package]]
name = "tzdata"
version = "2025.3"
source = { registry = "https://pypi.org/simple" }
sdist = { url = "https://files.pythonhosted.org/packages/5e/a7/c202b344c5ca7daf398f3b8a477eeb205cf3b6f32e7ec3a6bac0629ca975/tzdata-2025.3.tar.gz", hash = "sha256:de39c2ca5dc7b0344f2eba86f49d614019d29f060fc4ebc8a417896a620b56a7", size = 196772, upload-time = "2025-12-13T17:45:35.667Z" }
wheels = [
    { url = "https://files.pythonhosted.org/packages/c7/b0/003792df09decd6849a5e39c28b513c06e84436a54440380862b5aeff25d/tzdata-2025.3-py2.py3-none-any.whl", hash = "sha256:06a47e5700f3081aab02b2e513160914ff0694bce9947d6b76ebd6bf57cfc5d1", size = 348521, upload-time = "2025-12-13T17:45:33.889Z" },
]

[[package]]
name = "tzlocal"
version = "5.3.1"
source = { registry = "https://pypi.org/simple" }
dependencies = [
    { name = "tzdata", marker = "sys_platform == 'win32'" },
]
sdist = { url = "https://files.pythonhosted.org/packages/8b/2e/c14812d3d4d9cd1773c6be938f89e5735a1f11a9f184ac3639b93cef35d5/tzlocal-5.3.1.tar.gz", hash = "sha256:cceffc7edecefea1f595541dbd6e990cb1ea3d19bf01b2809f362a03dd7921fd", size = 30761, upload-time = "2025-03-05T21:17:41.549Z" }
wheels = [
    { url = "https://files.pythonhosted.org/packages/c2/14/e2a54fabd4f08cd7af1c07030603c3356b74da07f7cc056e600436edfa17/tzlocal-5.3.1-py3-none-any.whl", hash = "sha256:eb1a66c3ef5847adf7a834f1be0800581b683b5608e74f86ecbcef8ab91bb85d", size = 18026, upload-time = "2025-03-05T21:17:39.857Z" },
]

[[package]]
name = "urllib3"
version = "2.6.3"
source = { registry = "https://pypi.org/simple" }
sdist = { url = "https://files.pythonhosted.org/packages/c7/24/5f1b3bdffd70275f6661c76461e25f024d5a38a46f04aaca912426a2b1d3/urllib3-2.6.3.tar.gz", hash = "sha256:1b62b6884944a57dbe321509ab94fd4d3b307075e0c2eae991ac71ee15ad38ed", size = 435556, upload-time = "2026-01-07T16:24:43.925Z" }
wheels = [
    { url = "https://files.pythonhosted.org/packages/39/08/aaaad47bc4e9dc8c725e68f9d04865dbcb2052843ff09c97b08904852d84/urllib3-2.6.3-py3-none-any.whl", hash = "sha256:bf272323e553dfb2e87d9bfd225ca7b0f467b919d7bbd355436d3fd37cb0acd4", size = 131584, upload-time = "2026-01-07T16:24:42.685Z" },
]

[[package]]
name = "virtualenv"
version = "20.36.1"
source = { registry = "https://pypi.org/simple" }
dependencies = [
    { name = "distlib" },
    { name = "filelock" },
    { name = "platformdirs" },
]
sdist = { url = "https://files.pythonhosted.org/packages/aa/a3/4d310fa5f00863544e1d0f4de93bddec248499ccf97d4791bc3122c9d4f3/virtualenv-20.36.1.tar.gz", hash = "sha256:8befb5c81842c641f8ee658481e42641c68b5eab3521d8e092d18320902466ba", size = 6032239, upload-time = "2026-01-09T18:21:01.296Z" }
wheels = [
    { url = "https://files.pythonhosted.org/packages/6a/2a/dc2228b2888f51192c7dc766106cd475f1b768c10caaf9727659726f7391/virtualenv-20.36.1-py3-none-any.whl", hash = "sha256:575a8d6b124ef88f6f51d56d656132389f961062a9177016a50e4f507bbcc19f", size = 6008258, upload-time = "2026-01-09T18:20:59.425Z" },
]

[[package]]
name = "wrapt"
version = "2.0.1"
source = { registry = "https://pypi.org/simple" }
sdist = { url = "https://files.pythonhosted.org/packages/49/2a/6de8a50cb435b7f42c46126cf1a54b2aab81784e74c8595c8e025e8f36d3/wrapt-2.0.1.tar.gz", hash = "sha256:9c9c635e78497cacb81e84f8b11b23e0aacac7a136e73b8e5b2109a1d9fc468f", size = 82040, upload-time = "2025-11-07T00:45:33.312Z" }
wheels = [
    { url = "https://files.pythonhosted.org/packages/ad/fe/41af4c46b5e498c90fc87981ab2972fbd9f0bccda597adb99d3d3441b94b/wrapt-2.0.1-cp313-cp313-macosx_10_13_universal2.whl", hash = "sha256:47b0f8bafe90f7736151f61482c583c86b0693d80f075a58701dd1549b0010a9", size = 78132, upload-time = "2025-11-07T00:44:04.628Z" },
    { url = "https://files.pythonhosted.org/packages/1c/92/d68895a984a5ebbbfb175512b0c0aad872354a4a2484fbd5552e9f275316/wrapt-2.0.1-cp313-cp313-macosx_10_13_x86_64.whl", hash = "sha256:cbeb0971e13b4bd81d34169ed57a6dda017328d1a22b62fda45e1d21dd06148f", size = 61211, upload-time = "2025-11-07T00:44:05.626Z" },
    { url = "https://files.pythonhosted.org/packages/e8/26/ba83dc5ae7cf5aa2b02364a3d9cf74374b86169906a1f3ade9a2d03cf21c/wrapt-2.0.1-cp313-cp313-macosx_11_0_arm64.whl", hash = "sha256:eb7cffe572ad0a141a7886a1d2efa5bef0bf7fe021deeea76b3ab334d2c38218", size = 61689, upload-time = "2025-11-07T00:44:06.719Z" },
    { url = "https://files.pythonhosted.org/packages/cf/67/d7a7c276d874e5d26738c22444d466a3a64ed541f6ef35f740dbd865bab4/wrapt-2.0.1-cp313-cp313-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl", hash = "sha256:c8d60527d1ecfc131426b10d93ab5d53e08a09c5fa0175f6b21b3252080c70a9", size = 121502, upload-time = "2025-11-07T00:44:09.557Z" },
    { url = "https://files.pythonhosted.org/packages/0f/6b/806dbf6dd9579556aab22fc92908a876636e250f063f71548a8660382184/wrapt-2.0.1-cp313-cp313-manylinux2014_aarch64.manylinux_2_17_aarch64.manylinux_2_28_aarch64.whl", hash = "sha256:c654eafb01afac55246053d67a4b9a984a3567c3808bb7df2f8de1c1caba2e1c", size = 123110, upload-time = "2025-11-07T00:44:10.64Z" },
    { url = "https://files.pythonhosted.org/packages/e5/08/cdbb965fbe4c02c5233d185d070cabed2ecc1f1e47662854f95d77613f57/wrapt-2.0.1-cp313-cp313-manylinux_2_31_riscv64.manylinux_2_39_riscv64.whl", hash = "sha256:98d873ed6c8b4ee2418f7afce666751854d6d03e3c0ec2a399bb039cd2ae89db", size = 117434, upload-time = "2025-11-07T00:44:08.138Z" },
    { url = "https://files.pythonhosted.org/packages/2d/d1/6aae2ce39db4cb5216302fa2e9577ad74424dfbe315bd6669725569e048c/wrapt-2.0.1-cp313-cp313-musllinux_1_2_aarch64.whl", hash = "sha256:c9e850f5b7fc67af856ff054c71690d54fa940c3ef74209ad9f935b4f66a0233", size = 121533, upload-time = "2025-11-07T00:44:12.142Z" },
    { url = "https://files.pythonhosted.org/packages/79/35/565abf57559fbe0a9155c29879ff43ce8bd28d2ca61033a3a3dd67b70794/wrapt-2.0.1-cp313-cp313-musllinux_1_2_riscv64.whl", hash = "sha256:e505629359cb5f751e16e30cf3f91a1d3ddb4552480c205947da415d597f7ac2", size = 116324, upload-time = "2025-11-07T00:44:13.28Z" },
    { url = "https://files.pythonhosted.org/packages/e1/e0/53ff5e76587822ee33e560ad55876d858e384158272cd9947abdd4ad42ca/wrapt-2.0.1-cp313-cp313-musllinux_1_2_x86_64.whl", hash = "sha256:2879af909312d0baf35f08edeea918ee3af7ab57c37fe47cb6a373c9f2749c7b", size = 120627, upload-time = "2025-11-07T00:44:14.431Z" },
    { url = "https://files.pythonhosted.org/packages/7c/7b/38df30fd629fbd7612c407643c63e80e1c60bcc982e30ceeae163a9800e7/wrapt-2.0.1-cp313-cp313-win32.whl", hash = "sha256:d67956c676be5a24102c7407a71f4126d30de2a569a1c7871c9f3cabc94225d7", size = 58252, upload-time = "2025-11-07T00:44:17.814Z" },
    { url = "https://files.pythonhosted.org/packages/85/64/d3954e836ea67c4d3ad5285e5c8fd9d362fd0a189a2db622df457b0f4f6a/wrapt-2.0.1-cp313-cp313-win_amd64.whl", hash = "sha256:9ca66b38dd642bf90c59b6738af8070747b610115a39af2498535f62b5cdc1c3", size = 60500, upload-time = "2025-11-07T00:44:15.561Z" },
    { url = "https://files.pythonhosted.org/packages/89/4e/3c8b99ac93527cfab7f116089db120fef16aac96e5f6cdb724ddf286086d/wrapt-2.0.1-cp313-cp313-win_arm64.whl", hash = "sha256:5a4939eae35db6b6cec8e7aa0e833dcca0acad8231672c26c2a9ab7a0f8ac9c8", size = 58993, upload-time = "2025-11-07T00:44:16.65Z" },
    { url = "https://files.pythonhosted.org/packages/f9/f4/eff2b7d711cae20d220780b9300faa05558660afb93f2ff5db61fe725b9a/wrapt-2.0.1-cp313-cp313t-macosx_10_13_universal2.whl", hash = "sha256:a52f93d95c8d38fed0669da2ebdb0b0376e895d84596a976c15a9eb45e3eccb3", size = 82028, upload-time = "2025-11-07T00:44:18.944Z" },
    { url = "https://files.pythonhosted.org/packages/0c/67/cb945563f66fd0f61a999339460d950f4735c69f18f0a87ca586319b1778/wrapt-2.0.1-cp313-cp313t-macosx_10_13_x86_64.whl", hash = "sha256:4e54bbf554ee29fcceee24fa41c4d091398b911da6e7f5d7bffda963c9aed2e1", size = 62949, upload-time = "2025-11-07T00:44:20.074Z" },
    { url = "https://files.pythonhosted.org/packages/ec/ca/f63e177f0bbe1e5cf5e8d9b74a286537cd709724384ff20860f8f6065904/wrapt-2.0.1-cp313-cp313t-macosx_11_0_arm64.whl", hash = "sha256:908f8c6c71557f4deaa280f55d0728c3bca0960e8c3dd5ceeeafb3c19942719d", size = 63681, upload-time = "2025-11-07T00:44:21.345Z" },
    { url = "https://files.pythonhosted.org/packages/39/a1/1b88fcd21fd835dca48b556daef750952e917a2794fa20c025489e2e1f0f/wrapt-2.0.1-cp313-cp313t-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl", hash = "sha256:e2f84e9af2060e3904a32cea9bb6db23ce3f91cfd90c6b426757cf7cc01c45c7", size = 152696, upload-time = "2025-11-07T00:44:24.318Z" },
    { url = "https://files.pythonhosted.org/packages/62/1c/d9185500c1960d9f5f77b9c0b890b7fc62282b53af7ad1b6bd779157f714/wrapt-2.0.1-cp313-cp313t-manylinux2014_aarch64.manylinux_2_17_aarch64.manylinux_2_28_aarch64.whl", hash = "sha256:e3612dc06b436968dfb9142c62e5dfa9eb5924f91120b3c8ff501ad878f90eb3", size = 158859, upload-time = "2025-11-07T00:44:25.494Z" },
    { url = "https://files.pythonhosted.org/packages/91/60/5d796ed0f481ec003220c7878a1d6894652efe089853a208ea0838c13086/wrapt-2.0.1-cp313-cp313t-manylinux_2_31_riscv64.manylinux_2_39_riscv64.whl", hash = "sha256:6d2d947d266d99a1477cd005b23cbd09465276e302515e122df56bb9511aca1b", size = 146068, upload-time = "2025-11-07T00:44:22.81Z" },
    { url = "https://files.pythonhosted.org/packages/04/f8/75282dd72f102ddbfba137e1e15ecba47b40acff32c08ae97edbf53f469e/wrapt-2.0.1-cp313-cp313t-musllinux_1_2_aarch64.whl", hash = "sha256:7d539241e87b650cbc4c3ac9f32c8d1ac8a54e510f6dca3f6ab60dcfd48c9b10", size = 155724, upload-time = "2025-11-07T00:44:26.634Z" },
    { url = "https://files.pythonhosted.org/packages/5a/27/fe39c51d1b344caebb4a6a9372157bdb8d25b194b3561b52c8ffc40ac7d1/wrapt-2.0.1-cp313-cp313t-musllinux_1_2_riscv64.whl", hash = "sha256:4811e15d88ee62dbf5c77f2c3ff3932b1e3ac92323ba3912f51fc4016ce81ecf", size = 144413, upload-time = "2025-11-07T00:44:27.939Z" },
    { url = "https://files.pythonhosted.org/packages/83/2b/9f6b643fe39d4505c7bf926d7c2595b7cb4b607c8c6b500e56c6b36ac238/wrapt-2.0.1-cp313-cp313t-musllinux_1_2_x86_64.whl", hash = "sha256:c1c91405fcf1d501fa5d55df21e58ea49e6b879ae829f1039faaf7e5e509b41e", size = 150325, upload-time = "2025-11-07T00:44:29.29Z" },
    { url = "https://files.pythonhosted.org/packages/bb/b6/20ffcf2558596a7f58a2e69c89597128781f0b88e124bf5a4cadc05b8139/wrapt-2.0.1-cp313-cp313t-win32.whl", hash = "sha256:e76e3f91f864e89db8b8d2a8311d57df93f01ad6bb1e9b9976d1f2e83e18315c", size = 59943, upload-time = "2025-11-07T00:44:33.211Z" },
    { url = "https://files.pythonhosted.org/packages/87/6a/0e56111cbb3320151eed5d3821ee1373be13e05b376ea0870711f18810c3/wrapt-2.0.1-cp313-cp313t-win_amd64.whl", hash = "sha256:83ce30937f0ba0d28818807b303a412440c4b63e39d3d8fc036a94764b728c92", size = 63240, upload-time = "2025-11-07T00:44:30.935Z" },
    { url = "https://files.pythonhosted.org/packages/1d/54/5ab4c53ea1f7f7e5c3e7c1095db92932cc32fd62359d285486d00c2884c3/wrapt-2.0.1-cp313-cp313t-win_arm64.whl", hash = "sha256:4b55cacc57e1dc2d0991dbe74c6419ffd415fb66474a02335cb10efd1aa3f84f", size = 60416, upload-time = "2025-11-07T00:44:32.002Z" },
    { url = "https://files.pythonhosted.org/packages/15/d1/b51471c11592ff9c012bd3e2f7334a6ff2f42a7aed2caffcf0bdddc9cb89/wrapt-2.0.1-py3-none-any.whl", hash = "sha256:4d2ce1bf1a48c5277d7969259232b57645aae5686dba1eaeade39442277afbca", size = 44046, upload-time = "2025-11-07T00:45:32.116Z" },
]



================================================
FILE: .flake8
================================================
[flake8]
exclude =
    __pycache__,
    .git,
    .venv,
    venv
ignore = E203,W503
max-line-length = 120



================================================
FILE: .pre-commit-config.yaml
================================================
repos:
  - repo: local
    hooks:
      - id: ruff-format-check
        name: ruff format check
        entry: uv run ruff format --check
        language: system
        types: [python]
        pass_filenames: false

      - id: ruff-check
        name: ruff check
        entry: uv run ruff check --extend-select PLR6301
        language: system
        types: [python]
        pass_filenames: false

      - id: ruff-isort-check
        name: ruff isort check
        entry: uv run ruff check --select I
        language: system
        types: [python]
        pass_filenames: false

      - id: flake8
        name: flake8
        entry: uv run flake8
        language: system
        types: [python]
        pass_filenames: false

      - id: unittest
        name: unittest
        entry: uv run python -m unittest discover
        language: system
        types: [python]
        pass_filenames: false



================================================
FILE: component_config/actions.md
================================================
["testConnection","listModels","listFields"]



================================================
FILE: component_config/component_long_description.md
================================================
# Odoo Extractor

Extract data from Odoo ERP systems via XML-RPC or JSON-2 API with intelligent model/field discovery and incremental loading.

## Key Features

### Dynamic UI Experience
- **Test Connection** - Validate Odoo credentials before running extractions
- **Model Discovery** - Browse and select from 146+ Odoo models automatically
- **Field Discovery** - Load field definitions dynamically based on selected model
- **No Manual Entry** - All models and fields discovered from your Odoo instance

### Powerful Data Extraction
- **Multiple Endpoints** - Configure multiple models in a single extraction
- **Incremental Loading** - ID-based state tracking for efficient updates
- **Auto-Flattening** - Handles Odoo many2one and many2many relationships
- **Flexible Filtering** - Use Odoo domain filters for targeted extraction

### Production-Ready
- **State Management** - Reliable tracking across all endpoints with nested structure
- **Modern Python 3.13** - Full type safety with modern type hints
- **Quality Standards** - Ruff formatted, lint-free, proper error handling
- **Well-Tested** - Verified against Odoo 19.0 with 40+ test records

## Common Use Cases

- **Customer Data**: Extract contacts, companies, addresses from `res.partner`
- **Sales Orders**: Pull sales data from `sale.order` and `sale.order.line`
- **Invoicing**: Extract invoices from `account.move` and `account.move.line`
- **Product Catalogs**: Get products from `product.product` and `product.template`
- **Inventory**: Track stock movements via `stock.move`
- **CRM**: Extract leads and opportunities from `crm.lead`
- **Custom Modules**: Access any custom Odoo model

## How It Works

1. **Connect**: Enter your Odoo URL, database, and credentials
2. **Test**: Click "Test Connection" to validate access
3. **Select Models**: Choose models from the dynamic dropdown (146+ available)
4. **Pick Fields**: Select specific fields or extract all
5. **Configure**: Set incremental loading, limits, and sort order
6. **Extract**: Run extraction and get clean CSV output

## Technical Highlights

- **Sync Actions**: Real-time model and field loading via Keboola sync actions
- **Nested State**: Clean state structure with `state["endpoints"][table]["last_id"]`
- **Type Safety**: Full Python 3.13 type hints throughout
- **API Discovery**: Uses `ir.model` and `fields_get()` for metadata
- **Error Handling**: Clear UserException messages for all failure scenarios

Perfect for integrating Odoo data into your data warehouse or analytics platform!



================================================
FILE: component_config/component_short_description.md
================================================
Extract data from Odoo ERP via XML-RPC or JSON-2 with dynamic model/field selection and incremental loading



================================================
FILE: component_config/configRowSchema.json
================================================
{
  "type": "object",
  "title": "Odoo Model Extraction",
  "required": [
    "model"
  ],
  "properties": {
    "model": {
      "type": "string",
      "title": "Odoo Model",
      "description": "Odoo model name (e.g., res.partner, sale.order)",
      "propertyOrder": 10,
      "enum": [],
      "options": {
        "async": {
          "action": "listModels",
          "label": "Load Models"
        }
      }
    },
    "fields": {
      "type": "array",
      "format": "select",
      "title": "Fields to Extract",
      "description": "Select specific fields to extract, or leave empty to extract all available fields",
      "propertyOrder": 20,
      "enum": [],
      "items": {
        "type": "string"
      },
      "uniqueItems": true,
      "options": {
        "async": {
          "action": "listFields",
          "label": "Load Fields",
          "watchFor": [
            "model"
          ]
        },
        "tags": true,
        "creatable": true
      }
    },
    "domain": {
      "type": "string",
      "format": "textarea",
      "title": "Domain Filter (Optional)",
      "description": "Odoo domain filter as JSON array, e.g. [[\"is_company\", \"=\", true]]",
      "propertyOrder": 30
    },
    "incremental": {
      "type": "boolean",
      "format": "checkbox",
      "title": "Incremental Loading",
      "description": "Extract only new records since last run (based on ID field)",
      "default": false,
      "propertyOrder": 40
    },
    "page_size": {
      "type": "integer",
      "title": "Page Size",
      "description": "Number of records to fetch per page",
      "default": 1000,
      "minimum": 100,
      "maximum": 10000,
      "propertyOrder": 50
    }
  }
}



================================================
FILE: component_config/configSchema.json
================================================
{
  "type": "object",
  "title": "Odoo Extractor Configuration",
  "required": [
    "odoo_url"
  ],
  "properties": {
    "odoo_url": {
      "type": "string",
      "title": "Odoo URL",
      "description": "Your Odoo instance URL (e.g., https://mycompany.odoo.com or http://localhost:8069)",
      "propertyOrder": 10
    },
    "database": {
      "type": "string",
      "title": "Database Name",
      "description": "Odoo database name",
      "propertyOrder": 20,
      "enum": [],
      "options": {
        "async": {
          "action": "listDatabases",
          "label": "Load Databases"
        }
      }
    },
    "api_protocol": {
      "type": "string",
      "format": "radio",
      "title": "API Protocol",
      "enum": [
        "json2",
        "xmlrpc"
      ],
      "default": "xmlrpc",
      "propertyOrder": 25,
      "options": {
        "enum_titles": [
          "JSON-2",
          "XML-RPC"
        ],
        "tooltip": "Select JSON-2 for Odoo 19+ (recommended). XML-RPC is deprecated in Odoo 19 and will be removed in Odoo 20, but works with all older versions."
      }
    },
    "username": {
      "type": "string",
      "title": "Username",
      "description": "Required for XML-RPC",
      "propertyOrder": 30,
      "options": {
        "dependencies": {
          "api_protocol": "xmlrpc"
        }
      }
    },
    "#api_key": {
      "type": "string",
      "format": "password",
      "title": "API Key",
      "description": "Generate in user preferences",
      "propertyOrder": 40
    },
    "test_connection": {
      "type": "button",
      "format": "test-connection",
      "propertyOrder": 50,
      "options": {
        "async": {
          "action": "testConnection",
          "label": "Test Connection"
        }
      }
    }
  }
}


================================================
FILE: component_config/configuration_description.md
================================================
[Empty file]


================================================
FILE: component_config/documentationUrl.md
================================================
https://github.com/keboola/component-odoo-extractor/blob/master/README.md



================================================
FILE: component_config/licenseUrl.md
================================================
https://github.com/keboola/component-odoo-extractor/blob/master/LICENSE.md



================================================
FILE: component_config/logger
================================================
gelf


================================================
FILE: component_config/loggerConfiguration.json
================================================
{
  "verbosity": {
    "100": "normal",
    "200": "normal",
    "250": "normal",
    "300": "verbose",
    "400": "verbose",
    "500": "camouflage",
    "550": "camouflage",
    "600": "camouflage"
  },
  "gelf_server_type": "tcp"
}


================================================
FILE: component_config/sourceCodeUrl.md
================================================
https://github.com/keboola/component-odoo-extractor



================================================
FILE: component_config/sample-config/config.json
================================================
{
  "storage": {
    "input": {
      "files": [],
      "tables": [
        {
          "source": "in.c-test.test",
          "destination": "test.csv",
          "limit": 50,
          "columns": [],
          "where_values": [],
          "where_operator": "eq"
        }
      ]
    },
    "output": {
      "files": [],
      "tables": []
    }
  },
  "parameters": {
    "#api_token": "DEMO",
    "print_hello": true,
    "period_from": "yesterday",
    "endpoints": [
      "deals",
      "companies"
    ],
    "company_properties": "",
    "deal_properties": "",
    "debug": true
  },
  "image_parameters": {
    "syrup_url": "https://syrup.keboola.com/"
  },
  "authorization": {
    "oauth_api": {
      "id": "OAUTH_API_ID",
      "credentials": {
        "id": "main",
        "authorizedFor": "Myself",
        "creator": {
          "id": "1234",
          "description": "me@keboola.com"
        },
        "created": "2016-01-31 00:13:30",
        "#data": "{\"refresh_token\":\"MCWBkfdK9m5YK*Oqahwm6XN6elMAEwcH5kYcK8Ku!bpiOgSDZN9MQIzunpMsh6LyKH0i!7OcwwwajuxPfvm2PrrWYSs*HerDr2ZSJ39pqHJcvwUNIvHdtcgFFr3Em*yhn3GKBwM2p9UrjtgdAriSDny5YgUYGuI3gYJY1ypD*wBaAOzzeeXZx6CdgjruJ7gboTAngbWk3CzO9rORIwXAAlGUH6ZgBQJL3AwkYVMRFV4BvIvDAMF*0DcGDyrcyYDw9X3vYn*Wy!OqgrenKCGowdJk0C0136SUv4PJI383y76UMim6Q7KGDj7Lf!K2N2FDbxsz2iZKZTBr2vHx8pEC1oBc$\"}",
        "oauthVersion": "2.0",
        "appKey": "000000004C184A49",
        "#appSecret": "vBAYak49pVK1zghHAgDH4tCSCNlT-CiN"
      }
    }
  }
}



================================================
FILE: component_config/sample-config/in/state.json
================================================
{"data_delta": "10222018"}


================================================
FILE: component_config/sample-config/in/files/order1.xml
================================================
<?xml version='1.0' ?>
<root_el>
    <orders>
        <order>
            <id>1</id>
            <date>2018-01-01</date>
            <cust_name>David</cust_name>	
            <order-item>
                <price currency="CZK">100</price>
                <item>Umbrella</item>
            </order-item>
            <order-item>
                <price currency="CZK">200</price>
                <item>Rain Coat</item>
            </order-item>
        </order>
    </orders>
</root_el>


================================================
FILE: component_config/sample-config/in/tables/test.csv
================================================
"Type","Campaign_Name","Status","Start_Date","End_Date","Location","Eventbrite_link"
"Event","How to become data driven startup","Complete","2015-10-13","2015-10-13","United Kingdom","https://www.eventbrite.co.uk/e/how-to-become-data-driven-startup-registration-18711425377"
"Event","How to become data driven startup","Complete","2015-11-04","2015-11-04","United Kingdom","https://www.eventbrite.co.uk/e/how-to-become-data-driven-startup-registration-18711426380"
"Event","How to become data driven startup","Complete","2015-10-13","2015-10-13","United Kingdom","https://www.eventbrite.co.uk/e/how-to-become-data-driven-startup-registration-18711425377"
"Event","How to become data driven startup","Complete","2015-11-04","2015-11-04","United Kingdom","https://www.eventbrite.co.uk/e/how-to-become-data-driven-startup-registration-18711426380"
"Event","DATAGIRLS PRESENT: HOW TO BECOME DATA-DRIVEN","Complete","2016-01-14","2016-01-14","United Kingdom","https://www.eventbrite.co.uk/e/datagirls-present-how-to-become-data-driven-tickets-20152992142"
"Event","DATAGIRLS PRESENT: HOW TO BECOME DATA-DRIVEN","Complete","2016-02-25","2016-02-25","United Kingdom","https://www.eventbrite.co.uk/e/datagirls-present-how-to-become-data-driven-tickets-20967439175"
"Event","Data Tools for Startups","Complete","2016-03-17","2016-03-17","United Kingdom","https://www.eventbrite.co.uk/e/data-tools-for-startups-tickets-21257426535"
"Event","Data Festival London 2016","Complete","2016-06-24","2016-06-26","United Kingdom","https://www.eventbrite.co.uk/e/data-festival-london-2016-tickets-25192608771"
"Event","Becoming data driven in the high street fashion","Complete","2016-10-12","2016-10-12","United Kingdom","https://www.eventbrite.co.uk/e/becoming-data-driven-in-the-high-street-fashion-tickets-27481268213"
"Event","The Data Foundry present: DATAGIRLS Weekend","Complete","2016-10-14","2016-10-16","United Kingdom","https://www.eventbrite.co.uk/e/the-data-foundry-present-datagirls-weekend-tickets-27350069795"
"Event","[NLP] How to analyse text data for knowledge discovery","Complete","2017-04-10","2017-04-10","United Kingdom","https://www.eventbrite.co.uk/e/nlp-how-to-analyse-text-data-for-knowledge-discovery-tickets-32320274812"
"Event","Keboola DataBrunch - Amazon Go a ako s ním v maloobchode “bojovať”","Complete","2017-03-09","2017-03-09","Slovakia","https://www.eventbrite.co.uk/e/keboola-databrunch-amazon-go-a-ako-s-nim-v-maloobchode-bojovat-tickets-31827553068"
"Event","Keboola DataBrunch - Amazon Go a jak s nim v maloobchodě “bojovat”","Complete","2017-03-29","2017-03-29","Czech Republic","https://www.eventbrite.co.uk/e/keboola-databrunch-amazon-go-a-jak-s-nim-v-maloobchode-bojovat-tickets-32182393405"
"Event","The Data Foundry present: DATAGIRLS Weekend","Complete","2016-10-14","2016-10-16","United Kingdom","https://www.eventbrite.co.uk/e/the-data-foundry-present-datagirls-weekend-tickets-27350069795"
"Event","[NLP] How to analyse text data for knowledge discovery","Complete","2017-04-10","2017-04-10","United Kingdom","https://www.eventbrite.co.uk/e/nlp-how-to-analyse-text-data-for-knowledge-discovery-tickets-32320274812"
"Event","Keboola Data Brunch - KPIs and AmazonGo, budoucnost retailu? ","Complete","2017-06-27","2017-06-27","Czech Republic","https://www.eventbrite.co.uk/e/keboola-data-brunch-kpis-amazongo-budoucnost-retailu-tickets-35257195220"
"Event","Learn how to #DoMoreWithData with DataGirls","Complete","2017-10-01","2017-10-01","United Kingdom","https://www.eventbrite.co.uk/e/learn-how-to-domorewithdata-with-datagirls-tickets-36777944823"
"Event","Are You Using Data to Understand Your Customers? ","Complete","2018-02-27","2018-02-27","United Kingdom","https://www.eventbrite.co.uk/e/are-you-using-data-to-understand-your-customers-tickets-42000160611"
"Event","Conversion Rate Optimisation in Travel Industry","Complete","2018-01-30","2018-01-30","United Kingdom","https://www.eventbrite.co.uk/e/conversion-rate-optimisation-in-travel-industry-tickets-38951076719"
"Event","Learn how to #DoMoreWithData with DataGirls","Complete","2017-10-01","2017-10-01","United Kingdom","https://www.eventbrite.co.uk/e/learn-how-to-domorewithdata-with-datagirls-tickets-36777944823"
"Event","Are You Using Data to Understand Your Customers? ","Complete","2018-02-27","2018-02-27","United Kingdom","https://www.eventbrite.co.uk/e/are-you-using-data-to-understand-your-customers-tickets-42000160611"



================================================
FILE: component_config/sample-config/in/tables/test.csv.manifest
================================================
{
    "id": "in.c-test.test",
    "uri": "https:\/\/connection.keboola.com\/v2\/storage\/tables\/in.c-test.test",
    "name": "test",
    "primary_key": [],
    "indexed_columns": [],
    "created": "2018-03-02T15:36:50+0100",
    "last_change_date": "2018-03-02T15:36:54+0100",
    "last_import_date": "2018-03-02T15:36:54+0100",
    "rows_count": 0,
    "data_size_bytes": 0,
    "is_alias": false,
    "attributes": [],
    "columns": [
        "Type",
        "Campaign_Name",
        "Status",
        "Start_Date",
        "End_Date",
        "Location",
        "Eventbrite_link"
    ],
    "metadata": [
        {
            "id": "18271581",
            "key": "KBC.createdBy.component.id",
            "value": "transformation",
            "provider": "system",
            "timestamp": "2018-03-02T15:37:02+0100"
        },
        {
            "id": "18271582",
            "key": "KBC.createdBy.configuration.id",
            "value": "361585608",
            "provider": "system",
            "timestamp": "2018-03-02T15:37:02+0100"
        },
        {
            "id": "18271583",
            "key": "KBC.createdBy.configurationRow.id",
            "value": "361585762",
            "provider": "system",
            "timestamp": "2018-03-02T15:37:02+0100"
        },
        {
            "id": "18271584",
            "key": "KBC.lastUpdatedBy.component.id",
            "value": "transformation",
            "provider": "system",
            "timestamp": "2018-03-02T15:37:02+0100"
        },
        {
            "id": "18271585",
            "key": "KBC.lastUpdatedBy.configuration.id",
            "value": "361585608",
            "provider": "system",
            "timestamp": "2018-03-02T15:37:02+0100"
        },
        {
            "id": "18271586",
            "key": "KBC.lastUpdatedBy.configurationRow.id",
            "value": "361585762",
            "provider": "system",
            "timestamp": "2018-03-02T15:37:02+0100"
        }
    ],
    "column_metadata": {
        "Type": [],
        "Campaign_Name": [],
        "Status": [],
        "Start_Date": [],
        "End_Date": [],
        "Location": [],
        "Eventbrite_link": []
    }
}


================================================
FILE: scripts/build_n_test.sh
================================================
#!/bin/sh
set -e

flake8
python -m unittest discover



================================================
FILE: scripts/developer_portal/fn_actions_md_update.sh
================================================
#!/bin/bash

# Set the path to the Python script file
PYTHON_FILE="src/component.py"
# Set the path to the Markdown file containing actions
MD_FILE="component_config/actions.md"

# Get all occurrences of lines containing @sync_action('XXX') from the .py file
SYNC_ACTIONS=$(grep -o -E "@sync_action\(['\"][^'\"]*['\"]\)" "$PYTHON_FILE" | sed "s/@sync_action(\(['\"]\)\([^'\"]*\)\(['\"]\))/\2/" | sort | uniq)

# Check if any sync actions were found
if [ -n "$SYNC_ACTIONS" ]; then
    # Iterate over each occurrence of @sync_action('XXX')
    for sync_action in $SYNC_ACTIONS; do
        EXISTING_ACTIONS+=("$sync_action")
    done

    # Convert the array to JSON format
    JSON_ACTIONS=$(printf '"%s",' "${EXISTING_ACTIONS[@]}")
    JSON_ACTIONS="[${JSON_ACTIONS%,}]"

    # Update the content of the actions.md file
    echo "$JSON_ACTIONS" > "$MD_FILE"
else
    echo "No sync actions found. Not creating the file."
fi


================================================
FILE: scripts/developer_portal/update_properties.sh
================================================
#!/usr/bin/env bash

set -e

# Check if the KBC_DEVELOPERPORTAL_APP environment variable is set
if [ -z "$KBC_DEVELOPERPORTAL_APP" ]; then
    echo "Error: KBC_DEVELOPERPORTAL_APP environment variable is not set."
    exit 1
fi

# Pull the latest version of the developer portal CLI Docker image
docker pull quay.io/keboola/developer-portal-cli-v2:latest

# Function to update a property for the given app ID
update_property() {
    local app_id="$1"
    local prop_name="$2"
    local file_path="$3"

    if [ ! -f "$file_path" ]; then
        echo "File '$file_path' not found. Skipping update for property '$prop_name' of application '$app_id'."
        return
    fi

    # shellcheck disable=SC2155
    local value=$(<"$file_path")

    echo "Updating $prop_name for $app_id"
    echo "$value"

    if [ -n "$value" ]; then
        docker run --rm \
            -e KBC_DEVELOPERPORTAL_USERNAME \
            -e KBC_DEVELOPERPORTAL_PASSWORD \
            quay.io/keboola/developer-portal-cli-v2:latest \
            update-app-property "$KBC_DEVELOPERPORTAL_VENDOR" "$app_id" "$prop_name" --value="$value"
        echo "Property $prop_name updated successfully for $app_id"
    else
        echo "$prop_name is empty for $app_id, skipping..."
    fi
}

app_id="$KBC_DEVELOPERPORTAL_APP"

update_property "$app_id" "isDeployReady" "component_config/isDeployReady.md"
update_property "$app_id" "longDescription" "component_config/component_long_description.md"
update_property "$app_id" "configurationSchema" "component_config/configSchema.json"
update_property "$app_id" "configurationRowSchema" "component_config/configRowSchema.json"
update_property "$app_id" "configurationDescription" "component_config/configuration_description.md"
update_property "$app_id" "shortDescription" "component_config/component_short_description.md"
update_property "$app_id" "logger" "component_config/logger"
update_property "$app_id" "loggerConfiguration" "component_config/loggerConfiguration.json"
update_property "$app_id" "licenseUrl" "component_config/licenseUrl.md"
update_property "$app_id" "documentationUrl" "component_config/documentationUrl.md"
update_property "$app_id" "sourceCodeUrl" "component_config/sourceCodeUrl.md"
update_property "$app_id" "uiOptions" "component_config/uiOptions.md"

# Update the actions.md file
source "$(dirname "$0")/fn_actions_md_update.sh"
# update_property actions
update_property "$app_id" "actions" "component_config/actions.md"


================================================
FILE: src/component.py
================================================
"""
Odoo Extractor Component

Extracts data from Odoo ERP via XML-RPC API.
Uses modern Python 3.9+ type hints and clean orchestrator pattern.
"""

import csv
import logging
from dataclasses import asdict, dataclass, fields
from datetime import datetime, timezone
from pathlib import Path
from typing import Any

from keboola.component.base import ComponentBase, sync_action
from keboola.component.exceptions import UserException
from keboola.component.sync_actions import SelectElement

from clients.json2_client import Json2Client
from clients.xmlrpc_client import XmlRpcClient
from configuration import Configuration

PROTOCOL_JSON2 = "json2"
PROTOCOL_XMLRPC = "xmlrpc"
DISPLAY_JSON2 = "JSON-2"
DISPLAY_XMLRPC = "XML-RPC"


@dataclass
class MetadataRow:
    """Schema metadata row for documenting field types and relationships."""

    field_name: str
    field_type: str
    target_model: str
    location: str
    source_column: str
    target_column: str


@dataclass
class BridgeTableMetadata:
    """
    Metadata for a many2many/one2many relationship bridge table.

    Bridge tables store relationships between records (e.g., partner → children).
    Each relationship becomes a row with composite primary key.
    """

    table_name: str
    records: list[dict[str, Any]]
    primary_key: list[str]


@dataclass
class SplitTablesResult:
    """
    Result of splitting Odoo records into main table and bridge tables.

    Main table contains scalar fields and flattened many2one relationships.
    Bridge tables contain many2many/one2many relationships as separate records.
    """

    main_records: list[dict[str, Any]]
    bridge_tables: dict[str, BridgeTableMetadata]


class Component(ComponentBase):
    """
    Odoo Extractor Component.

    Connects to Odoo via XML-RPC and extracts data from configured models.
    Follows clean orchestrator pattern with delegated methods.
    """

    def __init__(self) -> None:
        """Initialize component."""
        super().__init__()
        self.state: dict[str, Any] = {}
        self.config = Configuration(**self.configuration.parameters)
        self.client = self._initialize_client(self.config)

    def run(self) -> None:
        """Main extraction logic."""
        if not self.config.model:
            raise UserException("No model configured")

        self._validate_config_for_run()
        self._test_connection()

        self.state = self.get_state_file()
        self._validate_state()
        self._extract_with_paging()

        if self.state:
            self.write_state_file(self.state)

        logging.info("Extraction completed successfully")

    def _initialize_client(self, params: Configuration) -> XmlRpcClient | Json2Client:
        """
        Initialize and return appropriate Odoo client based on api_protocol config.

        Args:
            params: Configuration object

        Returns:
            Initialized XmlRpcClient or Json2Client based on api_protocol setting
        """
        ClientClass = Json2Client if params.api_protocol == PROTOCOL_JSON2 else XmlRpcClient

        return ClientClass(
            url=params.odoo_url,
            database=params.database,
            username=params.username,
            api_key=params.api_key,
        )

    def _validate_config_for_run(self) -> None:
        """Validate configuration before data extraction."""
        errors = []

        if not self.config.database:
            errors.append("Database name is required")

        if not self.config.api_key:
            errors.append("API key is required")

        if self.config.api_protocol == PROTOCOL_XMLRPC and not self.config.username:
            errors.append("Username is required for XML-RPC")

        if not self.config.model:
            errors.append("Model name is required")

        if errors:
            raise UserException(f"Configuration incomplete: {'; '.join(errors)}")

    def _validate_state(self) -> None:
        """Validate model and domain haven't changed since last run."""
        if not self.state:
            logging.info("No previous state found - first run")
            return

        stored_model = self.state.get("model")
        if stored_model and stored_model != self.config.model:
            raise UserException(
                f"Model changed from '{stored_model}' to '{self.config.model}'. "
                "Clear the component state to extract a different model."
            )

        stored_domain = self.state.get("domain", "")
        current_domain = self.config.domain or ""
        if stored_domain != current_domain:
            raise UserException(
                "Domain filter changed since last run. Clear the component state to continue with new filter."
            )

        last_run = self.state.get("last_run", {})
        if last_run:
            logging.info(
                f"Previous run: {last_run.get('timestamp', 'unknown')} - {last_run.get('records_fetched', 0)} records"
            )

    def _test_connection(self) -> None:
        """Test Odoo connection and authentication."""
        if self.client:
            logging.info("Testing Odoo connection...")
            self.client.test_connection()

    def _extract_with_paging(self) -> None:
        """Extract data with cursor-based pagination."""
        logging.info(f"Extracting {self.config.model} -> {self.config.table_name}")

        # Check if we're switching from incremental to full load
        state_last_id = self.state.get("last_id", 0)
        if not self.config.incremental and state_last_id > 0:
            logging.warning(f"Full load mode with existing state (last_id={state_last_id}). Starting fresh extraction.")

        # Initialize cursor from state (incremental) or 0 (full load)
        cursor_id = state_last_id if self.config.incremental else 0

        # Build initial domain with cursor
        domain = self.config.get_domain()
        if cursor_id > 0:
            domain.append(("id", ">", cursor_id))
            logging.info(f"Incremental mode: resuming from ID {cursor_id}")

        table = self.create_out_table_definition(
            name=self.config.table_name,
            incremental=self.config.incremental,
            primary_key=["id"],
        )

        page_num = 1
        total_records = 0
        all_relationship_metadata: dict[str, BridgeTableMetadata] = {}

        # Cursor-based paging loop
        while True:
            logging.info(f"Fetching page {page_num} (cursor: id > {cursor_id}, limit: {self.config.page_size})")

            records = self.client.search_read(
                model=self.config.model,
                domain=domain,
                fields=self.config.fields,
                limit=self.config.page_size,
                order="id asc",
            )

            if not records:
                logging.info("No more records to fetch")
                break

            result = self._split_records(records, self.config.model, self.config.table_name)

            # Write main table (append after first page)
            mode = "a" if page_num > 1 else "w"
            self._write_csv(Path(table.full_path), result.main_records, mode=mode)

            # Accumulate relationship records
            for rel_table_name, rel_data in result.bridge_tables.items():
                if rel_table_name not in all_relationship_metadata:
                    all_relationship_metadata[rel_table_name] = BridgeTableMetadata(
                        table_name=rel_table_name,
                        records=[],
                        primary_key=rel_data.primary_key,
                    )
                all_relationship_metadata[rel_table_name].records.extend(rel_data.records)

            # Update cursor for next page
            max_id = max(r.get("id", 0) for r in records if isinstance(r.get("id"), int))
            cursor_id = max_id

            # Update domain with new cursor
            domain = [d for d in domain if d[0] != "id"]
            domain.append(("id", ">", cursor_id))

            total_records += len(records)
            page_num += 1

            if len(records) < self.config.page_size:
                break

        # Write manifests and relationship tables
        if total_records > 0:
            self.write_manifest(table)

        for rel_table_name, rel_data in all_relationship_metadata.items():
            if rel_data.records:
                rel_table = self.create_out_table_definition(
                    name=rel_data.table_name,
                    incremental=self.config.incremental,
                    primary_key=rel_data.primary_key,
                )
                self._write_csv(Path(rel_table.full_path), rel_data.records)
                self.write_manifest(rel_table)
                logging.info(f"Wrote {len(rel_data.records)} relationship records to {rel_data.table_name}")

        # Write metadata
        if total_records > 0:
            main_table_fields = []
            if Path(table.full_path).exists():
                with open(Path(table.full_path), "r", encoding="utf-8") as f:
                    reader = csv.DictReader(f)
                    main_table_fields = list(reader.fieldnames or [])

            # Extract just the table names with records for metadata
            relationship_tables_with_records = {name: data.records for name, data in all_relationship_metadata.items()}

            self._write_metadata_file(
                self.config.model,
                self.config.table_name,
                main_table_fields,
                relationship_tables_with_records,
            )

        logging.info(f"Wrote {total_records} total records to {self.config.table_name}")

        # Get Odoo version for debugging
        odoo_version = "unknown"
        try:
            odoo_version = self.client.get_version()
        except Exception:
            pass

        # Build comprehensive state
        self.state = {
            "model": self.config.model,
            "domain": self.config.domain or "",
            "last_id": cursor_id if self.config.incremental else 0,
            "last_run": {
                "timestamp": datetime.now(timezone.utc).isoformat(),
                "records_fetched": total_records,
                "incremental": self.config.incremental,
                "odoo_version": odoo_version,
                "page_size": self.config.page_size,
            },
        }

    @staticmethod
    def _split_records(
        records: list[dict[str, Any]],
        model_name: str,
        table_name: str,
    ) -> SplitTablesResult:
        """
        Split records into main table and bridge tables.

        Handles different Odoo field types:
        - many2one: [id, name] → flattened to field_id, field_name in main table
        - many2many/one2many: [id1, id2, ...] → separate bridge table
        - scalar: kept as-is in main table

        Args:
            records: Raw Odoo records
            model_name: Odoo model name (e.g., 'res.partner')
            table_name: Base table name (e.g., 'res_partner.csv')

        Returns:
            SplitTablesResult containing:
            - main_records: Main table records (many2one flattened, scalars preserved)
            - bridge_tables: Dict of table name → BridgeTableMetadata with:
                - table_name: Bridge table name
                - records: List of relationship records
                - primary_key: Composite primary key fields

        Example:
            Input: [{"id": 15, "name": "Azure", "category_id": [5], "child_ids": [27,34]}]
            Output:
                SplitTablesResult(
                    main_records=[{"id": 15, "name": "Azure"}],
                    bridge_tables={
                        "res_partner__category_id.csv": BridgeTableMetadata(
                            table_name="res_partner__category_id.csv",
                            records=[{"partner_id": 15, "category_id": 5}],
                            primary_key=["partner_id", "category_id"]
                        ),
                        "res_partner__child_ids.csv": BridgeTableMetadata(
                            table_name="res_partner__child_ids.csv",
                            records=[
                                {"partner_id": 15, "child_id": 27},
                                {"partner_id": 15, "child_id": 34}
                            ],
                            primary_key=["partner_id", "child_id"]
                        )
                    }
                )
        """
        main_records = []
        relationship_metadata: dict[str, BridgeTableMetadata] = {}

        # Extract foreign key name from model (e.g., 'res.partner' → 'partner_id')
        # Use the last part of the model name
        fk_name = model_name.split(".")[-1] + "_id"

        # Base name for relationship tables (remove .csv extension if present)
        base_name = table_name.replace(".csv", "")

        for record in records:
            main_record: dict[str, Any] = {}
            record_id = record.get("id")

            for key, value in record.items():
                if isinstance(value, (list, tuple)) and len(value) == 2 and isinstance(value[0], int):
                    # many2one field: [id, name] → flatten to main table
                    main_record[f"{key}_id"] = value[0]
                    main_record[f"{key}_name"] = value[1]

                elif isinstance(value, list) and value and all(isinstance(v, int) for v in value):
                    # many2many or one2many: [id1, id2, ...] → split to relationship table
                    rel_table_name = f"{base_name}__{key}.csv"

                    # Determine relationship field name (remove trailing _ids if present)
                    rel_field_name = key.rstrip("s") if key.endswith("_ids") else key
                    if not rel_field_name.endswith("_id"):
                        rel_field_name = key.replace("_ids", "_id")

                    # Initialize metadata structure for this relationship table
                    if rel_table_name not in relationship_metadata:
                        relationship_metadata[rel_table_name] = BridgeTableMetadata(
                            table_name=rel_table_name,
                            records=[],
                            primary_key=[fk_name, rel_field_name],
                        )

                    # Create relationship records
                    for rel_id in value:
                        relationship_metadata[rel_table_name].records.append(
                            {fk_name: record_id, rel_field_name: rel_id}
                        )
                    # Don't include this field in main record

                elif isinstance(value, list):
                    # Empty list or non-integer list → skip
                    # Don't add to main table or relationship table
                    pass

                elif value is False:
                    # Odoo uses False for null values
                    main_record[key] = None

                else:
                    # Regular scalar field
                    main_record[key] = value

            main_records.append(main_record)

        return SplitTablesResult(
            main_records=main_records,
            bridge_tables=relationship_metadata,
        )

    @staticmethod
    def _write_csv(file_path: Path, records: list[dict[str, Any]], mode: str = "w") -> None:
        """Write records to CSV file."""
        if not records:
            return

        file_exists = file_path.exists() and file_path.stat().st_size > 0
        write_header = not file_exists or mode == "w"

        fieldnames = list(records[0].keys())

        if mode == "a" and file_exists:
            with open(file_path, mode="r", encoding="utf-8") as f:
                reader = csv.DictReader(f)
                existing_fieldnames = list(reader.fieldnames or [])
                fieldnames = existing_fieldnames + [f for f in fieldnames if f not in existing_fieldnames]
        else:
            all_keys: set[str] = set()
            for record in records:
                all_keys.update(record.keys())
            for key in all_keys:
                if key not in fieldnames:
                    fieldnames.append(key)

        with open(file_path, mode=mode, encoding="utf-8", newline="") as f:
            writer = csv.DictWriter(f, fieldnames=fieldnames, extrasaction="ignore")
            if write_header:
                writer.writeheader()
            writer.writerows(records)

    def _write_metadata_file(
        self,
        model_name: str,
        table_name: str,
        main_table_fields: list[str],
        relationship_tables: dict[str, list[dict[str, Any]]],
    ) -> None:
        """Write metadata CSV file describing field types and relationships."""
        if not self.client:
            raise UserException("Odoo client not initialized")

        all_fields = self.client.get_model_fields(model_name)

        if main_table_fields:
            fields_to_document = main_table_fields
        elif self.config.fields:
            fields_to_document = self.config.fields
        else:
            fields_to_document = list(all_fields.keys())

        # Build metadata rows
        metadata_rows: list[MetadataRow] = []

        # Process each field
        for field_name in fields_to_document:
            # Skip flattened many2one fields (_id, _name suffixes) - we'll handle them separately
            if field_name.endswith("_id") or field_name.endswith("_name"):
                # Check if this is a flattened many2one field
                original_field = field_name.rsplit("_", 1)[0]
                if original_field in all_fields and all_fields[original_field].get("type") == "many2one":
                    # This is a flattened field, skip it here
                    continue

            field_meta = all_fields.get(field_name, {})
            field_type = field_meta.get("type", "")
            relation = field_meta.get("relation", "")

            if field_type == "many2one":
                # Many2one: Create 3 rows (original + _id + _name flattened columns)
                base_table = table_name if table_name.endswith(".csv") else f"{table_name}.csv"
                metadata_rows.append(
                    MetadataRow(
                        field_name,
                        field_type,
                        relation,
                        base_table,
                        f"{field_name}_id",
                        "",
                    )
                )
                metadata_rows.append(MetadataRow(f"{field_name}_id", "integer", "", base_table, "", ""))
                metadata_rows.append(MetadataRow(f"{field_name}_name", "char", "", base_table, "", ""))

            elif field_type in ("many2many", "one2many"):
                # Many2many/one2many: Check if relationship table exists
                rel_table_name = f"{table_name}__{field_name}.csv"
                if rel_table_name in relationship_tables:
                    # Determine relationship column name
                    rel_field_name = field_name.rstrip("s") if field_name.endswith("_ids") else field_name
                    if not rel_field_name.endswith("_id"):
                        rel_field_name = field_name.replace("_ids", "_id")

                    # Determine source FK name
                    fk_name = model_name.split(".")[-1] + "_id"

                    metadata_rows.append(
                        MetadataRow(
                            field_name,
                            field_type,
                            relation,
                            rel_table_name,
                            fk_name,
                            rel_field_name,
                        )
                    )

            else:
                # Scalar field
                base_table = table_name if table_name.endswith(".csv") else f"{table_name}.csv"
                metadata_rows.append(MetadataRow(field_name, field_type, "", base_table, "", ""))

        # Create table definition for metadata file
        metadata_table = self.create_out_table_definition(
            name=f"metadata__{table_name}",
            incremental=False,
            primary_key=[],
        )

        # Write metadata CSV
        fieldnames = [field.name for field in fields(MetadataRow)]

        with open(metadata_table.full_path, mode="w", encoding="utf-8", newline="") as f:
            writer = csv.DictWriter(f, fieldnames=fieldnames)
            writer.writeheader()
            writer.writerows([asdict(row) for row in metadata_rows])

        # Write manifest for metadata file
        self.write_manifest(metadata_table)

        logging.info(f"Wrote metadata file: metadata__{table_name}.csv ({len(metadata_rows)} fields)")

    # === Helper Methods ===

    def _extract_short_error(self, exception: Exception) -> str:
        """Extract concise error message from exception."""
        error_str = str(exception)

        # Map common errors to short forms
        if "Invalid apikey" in error_str or "Invalid API key" in error_str:
            return "invalid API key"
        elif "401" in error_str:
            return "invalid API key"
        elif "403" in error_str or "forbidden" in error_str.lower():
            return "access forbidden"
        elif "404" in error_str:
            return "endpoint not found"
        elif "invalid credentials" in error_str.lower():
            return "invalid credentials"
        elif "authentication failed" in error_str.lower():
            # Extract the specific reason if present
            parts = error_str.split(":")
            if len(parts) > 1:
                return parts[-1].strip()[:50]
            return error_str[:50]
        else:
            # Keep it short, max 50 chars
            return error_str[:50] + "..." if len(error_str) > 50 else error_str

    # === Sync Actions (UI buttons) ===

    @sync_action("testConnection")
    def test_connection_action(self) -> dict[str, str]:
        """
        Test connection showing:
        1. Odoo version
        2. Protocol availability (✓/✗ for both JSON-2 and XML-RPC)
        3. Authentication status for selected protocol only
        4. Model count if authentication succeeds

        Message format:
        "Odoo {version}. Supports: JSON-2 {✓/✗}, XML-RPC {✓/✗}. Authenticated using {protocol}, {N} models"

        Returns:
            Success/error response for UI
        """
        try:
            # All validation happens in Configuration __init__
            # Just extract the values we need
            odoo_url = self.config.odoo_url
            database = self.config.database
            username = self.config.username
            api_key = self.config.api_key
            selected_protocol = self.config.api_protocol

            # Step 1: Check protocol availability (no auth required)
            protocols_available = {}
            odoo_version = None

            # Initialize clients
            xmlrpc_client = XmlRpcClient(odoo_url, database, username, api_key)
            json2_client = Json2Client(odoo_url, database, username, api_key)

            # Check XML-RPC availability
            try:
                version = xmlrpc_client.get_version()
                protocols_available[DISPLAY_XMLRPC] = True
                odoo_version = version
            except Exception as e:
                protocols_available[DISPLAY_XMLRPC] = False
                logging.debug(f"XML-RPC availability check failed: {e}")

            # Check JSON-2 availability
            try:
                version = json2_client.get_version()
                protocols_available[DISPLAY_JSON2] = True
                if not odoo_version:
                    odoo_version = version
            except Exception as e:
                protocols_available[DISPLAY_JSON2] = False
                logging.debug(f"JSON-2 availability check failed: {e}")

            # Fail if no version detected from any protocol
            if not odoo_version:
                raise UserException("Cannot connect to Odoo instance at this URL")

            # Step 2: Build "Supports" section
            supports_parts = []
            for protocol in [DISPLAY_JSON2, DISPLAY_XMLRPC]:
                symbol = "✓" if protocols_available.get(protocol, False) else "✗"
                supports_parts.append(f"{protocol} {symbol}")
            supports_str = ", ".join(supports_parts)

            # Step 3: Test authentication for selected protocol only
            selected_client = None
            auth_message = ""

            if selected_protocol == PROTOCOL_JSON2:
                if not protocols_available[DISPLAY_JSON2]:
                    return {
                        "status": "error",
                        "message": (
                            f"Odoo {odoo_version}. Supports: {supports_str}. "
                            f"{DISPLAY_JSON2} not available on this instance"
                        ),
                    }
                try:
                    json2_client.test_connection()
                    selected_client = json2_client
                    auth_message = f"Authenticated using {DISPLAY_JSON2}"
                except Exception as e:
                    short_error = self._extract_short_error(e)
                    return {
                        "status": "error",
                        "message": (
                            f"Odoo {odoo_version}. Supports: {supports_str}. "
                            f"Authentication failed using {DISPLAY_JSON2} ({short_error})"
                        ),
                    }
            else:  # xmlrpc (default)
                if not protocols_available[DISPLAY_XMLRPC]:
                    return {
                        "status": "error",
                        "message": (
                            f"Odoo {odoo_version}. Supports: {supports_str}. "
                            f"{DISPLAY_XMLRPC} not available on this instance"
                        ),
                    }
                try:
                    xmlrpc_client.test_connection()
                    selected_client = xmlrpc_client
                    auth_message = f"Authenticated using {DISPLAY_XMLRPC}"
                except Exception as e:
                    short_error = self._extract_short_error(e)
                    return {
                        "status": "error",
                        "message": (
                            f"Odoo {odoo_version}. Supports: {supports_str}. "
                            f"Authentication failed using {DISPLAY_XMLRPC} ({short_error})"
                        ),
                    }

            # Step 4: Get model count
            model_suffix = ""
            try:
                models = selected_client.list_models()
                model_suffix = f", {len(models)} models"
            except Exception as e:
                logging.warning(f"Could not fetch model count: {e}")

            # Step 5: Build final success message
            message = f"Odoo {odoo_version}. Supports: {supports_str}. {auth_message}{model_suffix}"

            return {"status": "success", "message": message}

        except UserException as e:
            raise e
        except Exception as e:
            raise UserException(f"Connection test failed: {str(e)}")

    @sync_action("listModels")
    def list_models_action(self) -> list[SelectElement]:
        """
        List available Odoo models - sync action for model dropdown.

        Returns:
            Dropdown data with model names
        """
        try:
            models = self.client.list_models()

            models_sorted = sorted(models, key=lambda m: m["model"])

            dropdown_data = [
                SelectElement(
                    value=model["model"],
                    label=f"{model['model']} - {model['name']}",
                )
                for model in models_sorted
            ]

            return dropdown_data

        except UserException as e:
            raise e
        except Exception as e:
            raise UserException(f"Failed to load models: {str(e)}")

    @sync_action("listFields")
    def list_fields_action(self) -> list[SelectElement]:
        """List fields for selected model."""
        try:
            model = self.config.model
            if not model:
                raise UserException("Please select a model first")

            fields_dict = self.client.get_model_fields(model)

            dropdown_data = []
            for field_name, field_info in fields_dict.items():
                if field_name == "_unknown":
                    continue

                field_label = field_info.get("string", field_name)
                field_type = field_info.get("type", "unknown")
                dropdown_data.append(
                    SelectElement(
                        value=field_name,
                        label=f"{field_label} ({field_name}) - {field_type}",
                    )
                )

            return dropdown_data

        except UserException as e:
            raise e
        except Exception as e:
            raise UserException(f"Failed to load fields: {str(e)}")

    @sync_action("listDatabases")
    def list_databases_action(self) -> list[SelectElement]:
        """
        List available databases on the Odoo instance.

        For odoo.com instances, database listing is blocked for security.
        This method detects odoo.com and suggests the database name from the URL.

        Returns:
            Dropdown data with database names

        Raises:
            UserException: If listing databases fails
        """
        try:
            odoo_url = self.config.odoo_url
            is_odoo_com = ".odoo.com" in odoo_url.lower()

            if is_odoo_com:
                from urllib.parse import urlparse

                parsed = urlparse(odoo_url)
                hostname = parsed.hostname or ""
                subdomain = hostname.replace(".odoo.com", "").replace(".dev", "").replace(".saas", "")

                if subdomain:
                    logging.info(f"Detected odoo.com instance - suggesting database name from subdomain: {subdomain}")
                    return [SelectElement(value=subdomain)]
                else:
                    raise UserException(
                        "This is an Odoo.com instance. Database listing is blocked for security. "
                        "Please enter the database name manually (usually matches your subdomain)."
                    )

            if self.config.api_protocol == PROTOCOL_JSON2:
                client = Json2Client(odoo_url, "", None, "")
                databases = client.list_databases()
            else:
                client = XmlRpcClient(odoo_url, "", "", "")
                databases = client.list_databases()

            logging.info(f"Found {len(databases)} database(s): {databases}")

            # Convert to dropdown format
            dropdown_data = [SelectElement(value=db) for db in databases]
            return dropdown_data

        except UserException as e:
            if "Access Denied" in str(e) and ".odoo.com" in self.config.odoo_url.lower():
                raise UserException(
                    "Database listing is blocked on Odoo.com instances. "
                    "Please enter the database name manually (it usually matches your subdomain)."
                )
            raise e
        except Exception as e:
            raise UserException(f"Failed to list databases: {str(e)}")


if __name__ == "__main__":
    try:
        comp = Component()
        comp.execute_action()
    except UserException as exc:
        logging.exception(exc)
        exit(1)
    except Exception as exc:
        logging.exception(exc)
        exit(2)



================================================
FILE: src/configuration.py
================================================
"""
Configuration schema for Odoo Extractor.

Uses Pydantic for validation with modern Python 3.9+ type hints.
"""

import json
from typing import Any

from keboola.component.exceptions import UserException
from pydantic import BaseModel, Field, ValidationError, field_validator

PROTOCOL_XMLRPC = "xmlrpc"


class Configuration(BaseModel):
    """Configuration for Odoo Extractor - supports both connection and extraction settings."""

    odoo_url: str = Field(description="Odoo instance URL")
    database: str = Field(default="", description="Database name")
    username: str | None = Field(default=None, description="Username/email")
    api_key: str = Field(default="", alias="#api_key", description="API key")
    api_protocol: str = Field(default=PROTOCOL_XMLRPC, description="API protocol: xmlrpc or json2")

    model: str = Field(default="", description="Odoo model name")
    fields: list[str] | None = Field(default=None, description="Fields to extract")
    domain: str | None = Field(default=None, description="Odoo domain filter as JSON string")
    incremental: bool = Field(default=False, description="Enable incremental loading")
    page_size: int = Field(default=1000, description="Number of records per page")

    def __init__(self, **data: Any) -> None:
        try:
            super().__init__(**data)
        except ValidationError as e:
            error_messages = []
            for err in e.errors():
                if err["loc"]:
                    error_messages.append(f"{err['loc'][0]}: {err['msg']}")
                else:
                    error_messages.append(err["msg"])
            raise UserException(f"Configuration validation error: {', '.join(error_messages)}")

    @field_validator("odoo_url")
    @classmethod
    def validate_url(cls, v: str) -> str:
        if not v.startswith(("http://", "https://")):
            raise ValueError("Odoo URL must start with http:// or https://")
        return v.rstrip("/")

    @property
    def table_name(self) -> str:
        if self.model:
            return f"{self.model.replace('.', '_')}.csv"
        return ""

    def get_domain(self) -> list[Any]:
        if not self.domain:
            return []
        try:
            return json.loads(self.domain)
        except json.JSONDecodeError:
            raise UserException(f"Invalid domain JSON: {self.domain}")

    class Config:
        populate_by_name = True



================================================
FILE: src/clients/json2_client.py
================================================
"""
Odoo JSON-2 API Client

Handles authentication and data extraction from Odoo ERP via JSON-2 API.
Compatible with Odoo v19+.
"""

import logging
from typing import Any

from keboola.component.exceptions import UserException
from keboola.http_client import HttpClient


class Json2Client:
    """Client for interacting with Odoo JSON-2 API (Odoo 19+)."""

    def __init__(self, url: str, database: str, username: str | None, api_key: str) -> None:
        """
        Initialize Odoo JSON-2 client.

        Args:
            url: Odoo instance URL (e.g., https://mycompany.odoo.com)
            database: Database name
            username: User email/login (not used in JSON-2 auth)
            api_key: API key (bearer token)
        """
        self.url: str = url.rstrip("/")
        self.database: str = database
        self.username: str | None = username  # Not used in JSON-2 auth
        self.api_key: str = api_key

        # Prepare default headers
        default_header = {
            "Content-Type": "application/json; charset=utf-8",
            "User-Agent": "keboola-odoo-extractor/1.0",
        }

        # Add database header if specified
        if self.database:
            default_header["X-Odoo-Database"] = self.database

        # Initialize HTTP client
        self.http_client = HttpClient(
            base_url=f"{url.rstrip('/')}/json/2",
            auth_header={"Authorization": f"bearer {api_key}"},
            default_http_header=default_header,
        )

        logging.info(f"Initialized Odoo JSON-2 client for {self.url}")

    def get_version(self) -> str:
        """
        Get Odoo version (no authentication required).

        Returns:
            Version string (e.g., "19.0", "20.0")

        Raises:
            UserException: If version check fails
        """
        try:
            version_info = self.http_client.get(
                endpoint_path=f"{self.url}/web/version",
                is_absolute_path=True,
                timeout=10,
            )
            version = version_info.get("version", "unknown")

            logging.info(f"Detected Odoo version: {version} via JSON-2")
            return version

        except Exception as e:
            # Check if it's an HTTP error
            if hasattr(e, "response") and hasattr(e.response, "status_code"):
                if e.response.status_code == 404:
                    raise UserException("JSON-2 version check failed: HTTP 404 - /web/version endpoint not found")
                else:
                    raise UserException(f"JSON-2 version check failed: HTTP {e.response.status_code}")
            raise UserException(f"JSON-2 version check failed: {str(e)}")

    def test_connection(self) -> dict[str, str]:
        """
        Test connection and authentication.

        Returns:
            Dict with version and protocol info

        Raises:
            UserException: If connection fails
        """
        if not self.api_key:
            raise UserException("API key is required for JSON-2 authentication")

        try:
            version = self.get_version()

            _ = self.http_client.post(
                endpoint_path="res.users/search_read",
                json={"domain": [], "limit": 1, "fields": ["id"]},
                timeout=10,
            )

            # If we got here, authentication worked
            logging.info("JSON-2 authentication successful")
            return {"version": version, "protocol": "JSON-2"}

        except Exception as e:
            if hasattr(e, "response") and hasattr(e.response, "status_code"):
                if e.response.status_code == 401:
                    raise UserException("JSON-2 authentication failed (HTTP 401): Invalid API key")
                elif e.response.status_code == 403:
                    raise UserException("JSON-2 authentication failed (HTTP 403): Access forbidden")
                elif e.response.status_code == 404:
                    raise UserException("JSON-2 API not available (HTTP 404) - Odoo instance may be older than v19")
                else:
                    raise UserException(f"JSON-2 connection failed: HTTP {e.response.status_code}")
            if isinstance(e, UserException):
                raise e
            raise UserException(f"JSON-2 connection failed: {str(e)}")

    def list_models(self) -> list[dict[str, str]]:
        """
        List available Odoo models.

        Returns:
            List of model dictionaries with 'model' and 'name' keys

        Raises:
            UserException: If listing models fails
        """
        try:
            models = self.http_client.post(
                endpoint_path="ir.model/search_read",
                json={
                    "domain": [
                        (
                            "transient",
                            "=",
                            False,
                        ),  # Filter out wizards/temporary models
                        ("model", "!=", "_unknown"),  # Filter out placeholder model
                    ],
                    "fields": ["model", "name"],
                },
                timeout=30,
            )
            logging.info(f"Retrieved {len(models)} models via JSON-2")
            return models

        except Exception as e:
            if hasattr(e, "response") and hasattr(e.response, "status_code"):
                if e.response.status_code == 401:
                    raise UserException("JSON-2 authentication failed (HTTP 401): Invalid API key")
                elif e.response.status_code == 403:
                    raise UserException("JSON-2 access forbidden (HTTP 403): User lacks permission to list models")
                elif e.response.status_code == 404:
                    raise UserException("JSON-2 API not available (HTTP 404)")
                else:
                    raise UserException(f"JSON-2 failed to list models (HTTP {e.response.status_code})")
            if isinstance(e, UserException):
                raise e
            raise UserException(f"JSON-2 failed to list models: {str(e)}")

    def get_model_fields(self, model: str) -> dict[str, dict[str, Any]]:
        """
        Get field definitions for an Odoo model.

        Args:
            model: Odoo model name (e.g., 'res.partner')

        Returns:
            Dictionary of field definitions with field metadata

        Raises:
            UserException: If getting fields fails
        """
        try:
            fields = self.http_client.post(
                endpoint_path=f"{model}/fields_get",
                json={
                    "attributes": [
                        "string",
                        "type",
                        "help",
                        "required",
                        "relation",
                        "relation_field",
                    ]
                },
                timeout=30,
            )

            if not isinstance(fields, dict):
                raise UserException(f"Unexpected response type from Odoo: {type(fields)}")

            logging.info(f"Retrieved {len(fields)} fields for {model} via JSON-2")
            return fields

        except Exception as e:
            if hasattr(e, "response") and hasattr(e.response, "status_code"):
                if e.response.status_code == 401:
                    raise UserException("JSON-2 authentication failed (HTTP 401): Invalid API key")
                elif e.response.status_code == 403:
                    raise UserException(f"JSON-2 access forbidden (HTTP 403): User lacks permission to access {model}")
                elif e.response.status_code == 404:
                    raise UserException(f"JSON-2 model not found (HTTP 404): {model} does not exist or API unavailable")
                else:
                    raise UserException(f"JSON-2 failed to get fields for {model} (HTTP {e.response.status_code})")
            if isinstance(e, UserException):
                raise e
            raise UserException(f"JSON-2 failed to get fields for {model}: {str(e)}")

    def search_read(
        self,
        model: str,
        domain: list[Any] | None = None,
        fields: list[str] | None = None,
        limit: int | None = None,
        offset: int = 0,
        order: str | None = None,
    ) -> list[dict[str, Any]]:
        """
        Search and read records from Odoo model.

        Args:
            model: Odoo model name (e.g., 'res.partner', 'sale.order')
            domain: Search domain filter
            fields: List of fields to retrieve
            limit: Maximum number of records
            offset: Number of records to skip
            order: Sort order

        Returns:
            List of records as dictionaries

        Raises:
            UserException: If API call fails
        """
        try:
            # Build request payload
            payload = {
                "domain": domain or [],
                "fields": fields or [],
                "offset": offset,
            }

            if limit:
                payload["limit"] = limit
            if order:
                payload["order"] = order

            # Make API call
            records = self.http_client.post(endpoint_path=f"{model}/search_read", json=payload, timeout=30)

            # Validate response
            if not isinstance(records, list):
                raise UserException(f"Unexpected response type from Odoo: {type(records)}")

            logging.info(f"Retrieved {len(records)} records from {model} via JSON-2")
            return records

        except Exception as e:
            # Check if it's an HTTP error
            if hasattr(e, "response") and hasattr(e.response, "status_code"):
                if e.response.status_code == 401:
                    raise UserException("JSON-2 authentication failed (HTTP 401): Invalid API key")
                elif e.response.status_code == 403:
                    raise UserException(f"JSON-2 access forbidden (HTTP 403): User lacks permission to access {model}")
                elif e.response.status_code == 404:
                    raise UserException(f"JSON-2 model not found (HTTP 404): {model} does not exist or API unavailable")
                else:
                    raise UserException(f"JSON-2 failed to fetch data from {model} (HTTP {e.response.status_code})")
            if isinstance(e, UserException):
                raise e
            raise UserException(f"JSON-2 failed to fetch data from {model}: {str(e)}")

    def list_databases(self) -> list[str]:
        """
        List available databases on the Odoo instance.

        Uses JSON-RPC endpoint (not JSON-2) as database listing doesn't require authentication.

        Returns:
            List of database names

        Raises:
            UserException: If listing databases fails
        """
        try:
            response = self.http_client.post(
                endpoint_path=f"{self.url}/web/database/list",
                is_absolute_path=True,
                json={"jsonrpc": "2.0", "method": "call", "params": {}, "id": 1},
                timeout=10,
            )

            if isinstance(response, dict) and "result" in response:
                databases = response["result"]
                if not isinstance(databases, list):
                    raise UserException(f"Unexpected database list format: {type(databases)}")
                logging.info(f"Retrieved {len(databases)} database(s) via JSON-RPC")
                return databases
            else:
                raise UserException("Unexpected response format from database list")

        except Exception as e:
            if isinstance(e, UserException):
                raise e
            raise UserException(f"Failed to list databases: {str(e)}")



================================================
FILE: src/clients/xmlrpc_client.py
================================================
"""
Odoo XML-RPC API Client

Handles authentication and data extraction from Odoo ERP via XML-RPC.
"""

import logging
import xmlrpc.client
from typing import Any

from keboola.component.exceptions import UserException


class XmlRpcClient:
    """Client for interacting with Odoo XML-RPC API."""

    def __init__(self, url: str, database: str, username: str | None, api_key: str) -> None:
        """
        Initialize Odoo client.

        Args:
            url: Odoo instance URL (e.g., https://mycompany.odoo.com)
            database: Database name
            username: User email/login
            api_key: API key or password
        """
        self.url: str = url.rstrip("/")
        self.database: str = database
        self.username: str | None = username
        self.api_key: str = api_key
        self.uid: int | None = None

        # Initialize XML-RPC endpoints
        self.common: xmlrpc.client.ServerProxy = xmlrpc.client.ServerProxy(f"{self.url}/xmlrpc/2/common")
        self.models: xmlrpc.client.ServerProxy = xmlrpc.client.ServerProxy(f"{self.url}/xmlrpc/2/object")
        self.db: xmlrpc.client.ServerProxy = xmlrpc.client.ServerProxy(f"{self.url}/xmlrpc/2/db")

        logging.info(f"Initialized Odoo client for {self.url}")

    def authenticate(self) -> int:
        """
        Authenticate with Odoo and get user ID.

        Returns:
            User ID

        Raises:
            UserException: If authentication fails
        """
        try:
            uid = self.common.authenticate(self.database, self.username, self.api_key, {})

            if not uid or not isinstance(uid, int):
                raise UserException("Authentication failed. Please check your credentials.")

            self.uid = uid
            logging.info(f"Successfully authenticated as user ID: {self.uid}")
            return self.uid

        except xmlrpc.client.Fault as e:
            raise UserException(f"Odoo authentication error: {e.faultString}")
        except Exception as e:
            raise UserException(f"Failed to connect to Odoo: {str(e)}")

    def search_read(
        self,
        model: str,
        domain: list[Any] | None = None,
        fields: list[str] | None = None,
        limit: int | None = None,
        offset: int = 0,
        order: str | None = None,
    ) -> list[dict[str, Any]]:
        """
        Search and read records from Odoo model.

        Args:
            model: Odoo model name (e.g., 'res.partner', 'sale.order')
            domain: Search domain filter
            fields: List of fields to retrieve
            limit: Maximum number of records
            offset: Number of records to skip
            order: Sort order

        Returns:
            List of records as dictionaries

        Raises:
            UserException: If API call fails
        """
        if not self.uid:
            self.authenticate()

        domain = domain or []

        try:
            kwargs: dict[str, Any] = {
                "fields": fields or [],
                "offset": offset,
            }

            if limit:
                kwargs["limit"] = limit
            if order:
                kwargs["order"] = order

            result = self.models.execute_kw(
                self.database,
                self.uid,
                self.api_key,
                model,
                "search_read",
                [domain],
                kwargs,
            )

            # Ensure we got a list back
            if not isinstance(result, list):
                raise UserException(f"Unexpected response type from Odoo: {type(result)}")

            records: list[dict[str, Any]] = result
            logging.info(f"Retrieved {len(records)} records from {model}")
            return records

        except xmlrpc.client.Fault as e:
            raise UserException(f"Odoo API error: {e.faultString}")
        except Exception as e:
            raise UserException(f"Failed to fetch data from {model}: {str(e)}")

    def get_model_fields(self, model: str) -> dict[str, dict[str, Any]]:
        """
        Get field definitions for an Odoo model.

        Args:
            model: Odoo model name

        Returns:
            Dictionary of field definitions

        Raises:
            UserException: If API call fails
        """
        if not self.uid:
            self.authenticate()

        try:
            result = self.models.execute_kw(
                self.database,
                self.uid,
                self.api_key,
                model,
                "fields_get",
                [],
                {
                    "attributes": [
                        "string",
                        "type",
                        "help",
                        "required",
                        "relation",
                        "relation_field",
                    ]
                },
            )

            if not isinstance(result, dict):
                raise UserException(f"Unexpected response type from Odoo: {type(result)}")

            fields: dict[str, dict[str, Any]] = result
            logging.info(f"Retrieved field definitions for {model}")
            return fields

        except xmlrpc.client.Fault as e:
            raise UserException(f"Odoo API error: {e.faultString}")
        except Exception as e:
            raise UserException(f"Failed to get fields for {model}: {str(e)}")

    def list_models(self) -> list[dict[str, Any]]:
        """
        List all available Odoo models.

        Returns:
            List of model dictionaries with 'model' and 'name' keys

        Raises:
            UserException: If API call fails
        """
        if not self.uid:
            self.authenticate()

        try:
            result = self.models.execute_kw(
                self.database,
                self.uid,
                self.api_key,
                "ir.model",
                "search_read",
                [
                    [
                        (
                            "transient",
                            "=",
                            False,
                        ),  # Filter out wizards/temporary models
                        ("model", "!=", "_unknown"),  # Filter out placeholder model
                    ]
                ],
                {"fields": ["model", "name"], "order": "name asc"},
            )

            if not isinstance(result, list):
                raise UserException(f"Unexpected response type from Odoo: {type(result)}")

            models: list[dict[str, Any]] = result
            logging.info(f"Retrieved {len(models)} Odoo models")
            return models

        except xmlrpc.client.Fault as e:
            raise UserException(f"Odoo API error: {e.faultString}")
        except Exception as e:
            raise UserException(f"Failed to list models: {str(e)}")

    def get_version(self) -> str:
        """
        Get Odoo version (no authentication required).

        Returns:
            Version string (e.g., "18.0", "19.0")

        Raises:
            UserException: If version check fails
        """
        try:
            version_info = self.common.version()

            if isinstance(version_info, dict):
                version = version_info.get("server_version", "unknown")
            else:
                version = "unknown"

            logging.info(f"Detected Odoo version: {version} via XML-RPC")
            return version

        except xmlrpc.client.Fault as e:
            raise UserException(f"XML-RPC version check failed: {e.faultString}")
        except Exception as e:
            raise UserException(f"XML-RPC version check failed: {str(e)}")

    def test_connection(self) -> dict[str, str]:
        """
        Test connection and authentication.

        Returns:
            Dict with version and protocol info

        Raises:
            UserException: If connection fails
        """
        if not self.database:
            raise UserException("Database name is required")

        if not self.username:
            raise UserException("Username is required for XML-RPC authentication")

        if not self.api_key:
            raise UserException("API key is required")

        try:
            version = self.get_version()
            self.authenticate()

            return {"version": version, "protocol": "XML-RPC"}

        except UserException as e:
            raise e
        except Exception as e:
            raise UserException(f"XML-RPC connection failed: {str(e)}")

    def list_databases(self) -> list[str]:
        """
        List available databases on the Odoo instance.

        Returns:
            List of database names

        Raises:
            UserException: If listing databases fails
        """
        try:
            databases = self.db.list()

            if not isinstance(databases, list):
                raise UserException(f"Unexpected response type from Odoo: {type(databases)}")

            logging.info(f"Retrieved {len(databases)} database(s) via XML-RPC")
            return databases

        except xmlrpc.client.Fault as e:
            raise UserException(f"XML-RPC error listing databases: {e.faultString}")
        except Exception as e:
            raise UserException(f"Failed to list databases: {str(e)}")



================================================
FILE: tests/__init__.py
================================================
import sys
from pathlib import Path

sys.path.append(str((Path(__file__).resolve().parent.parent / "src")))



================================================
FILE: tests/test_component.py
================================================
"""
Tests for Odoo Extractor Component.

Uses modern Python 3.9+ type hints and proper mocking.
"""

import unittest
from typing import Any
from unittest.mock import MagicMock, Mock, patch

from clients.xmlrpc_client import XmlRpcClient
from component import Component
from configuration import Configuration


class TestConfiguration(unittest.TestCase):
    """Test configuration validation."""

    def test_valid_config(self) -> None:
        """Test valid configuration."""
        config = Configuration(
            odoo_url="https://demo.odoo.com",
            database="demo",
            username="admin",
            api_key="test123",
            model="res.partner",
        )
        self.assertEqual(config.odoo_url, "https://demo.odoo.com")
        self.assertEqual(config.model, "res.partner")
        self.assertEqual(config.table_name, "res_partner.csv")

    def test_url_validation_invalid(self) -> None:
        """Test URL validation rejects invalid URLs."""
        with self.assertRaises(Exception):
            Configuration(
                odoo_url="invalid-url",
                database="demo",
                username="admin",
                api_key="test",
                model="res.partner",
            )

    def test_trailing_slash_removed(self) -> None:
        """Test trailing slash is removed from URL."""
        config = Configuration(
            odoo_url="https://demo.odoo.com/",
            database="demo",
            username="admin",
            api_key="test",
            model="res.partner",
        )
        self.assertEqual(config.odoo_url, "https://demo.odoo.com")


class TestXmlRpcClient(unittest.TestCase):
    """Test Odoo client."""

    @patch("clients.xmlrpc_client.xmlrpc.client.ServerProxy")
    def test_authentication_success(self, mock_server: Mock) -> None:
        """Test successful authentication."""
        mock_common = MagicMock()
        mock_common.authenticate.return_value = 123
        mock_server.return_value = mock_common

        client = XmlRpcClient(
            url="https://demo.odoo.com",
            database="demo",
            username="admin",
            api_key="test",
        )
        client.common = mock_common

        uid = client.authenticate()
        self.assertEqual(uid, 123)

    @patch("clients.xmlrpc_client.xmlrpc.client.ServerProxy")
    def test_search_read(self, mock_server: Mock) -> None:
        """Test search_read method."""
        mock_models = MagicMock()
        mock_models.execute_kw.return_value = [{"id": 1, "name": "Test Partner"}]

        client = XmlRpcClient(
            url="https://demo.odoo.com",
            database="demo",
            username="admin",
            api_key="test",
        )
        client.models = mock_models
        client.uid = 123

        records = client.search_read(model="res.partner", fields=["id", "name"])

        self.assertEqual(len(records), 1)
        self.assertEqual(records[0]["name"], "Test Partner")


class TestComponent(unittest.TestCase):
    """Test component logic."""

    def test_split_records_many2one(self) -> None:
        """Test many2one fields are flattened in main table."""
        records: list[dict[str, Any]] = [
            {
                "id": 1,
                "name": "Test",
                "country_id": [21, "United States"],
            }
        ]

        result = Component._split_records(records, "res.partner", "res_partner.csv")

        self.assertEqual(len(result.main_records), 1)
        self.assertEqual(result.main_records[0]["id"], 1)
        self.assertEqual(result.main_records[0]["country_id_id"], 21)
        self.assertEqual(result.main_records[0]["country_id_name"], "United States")
        self.assertEqual(len(result.bridge_tables), 0)  # No relationship tables for many2one

    def test_split_records_many2many(self) -> None:
        """Test many2many fields are split into relationship tables."""
        records: list[dict[str, Any]] = [{"id": 1, "name": "Test", "tag_ids": [5, 9, 12]}]

        result = Component._split_records(records, "res.partner", "res_partner.csv")

        # Main table should not have tag_ids
        self.assertEqual(len(result.main_records), 1)
        self.assertEqual(result.main_records[0]["id"], 1)
        self.assertEqual(result.main_records[0]["name"], "Test")
        self.assertNotIn("tag_ids", result.main_records[0])

        # Relationship table should have 3 records
        self.assertIn("res_partner__tag_ids.csv", result.bridge_tables)
        rel_metadata = result.bridge_tables
        rel_data = rel_metadata["res_partner__tag_ids.csv"]
        self.assertEqual(rel_data.primary_key, ["partner_id", "tag_id"])
        self.assertEqual(rel_data.table_name, "res_partner__tag_ids.csv")
        self.assertEqual(len(rel_data.records), 3)
        self.assertEqual(rel_data.records[0], {"partner_id": 1, "tag_id": 5})
        self.assertEqual(rel_data.records[1], {"partner_id": 1, "tag_id": 9})
        self.assertEqual(rel_data.records[2], {"partner_id": 1, "tag_id": 12})

    def test_split_records_false_values(self) -> None:
        """Test False values converted to None."""
        records: list[dict[str, Any]] = [{"id": 1, "email": False}]

        result = Component._split_records(records, "res.partner", "res_partner.csv")

        self.assertEqual(len(result.main_records), 1)
        self.assertIsNone(result.main_records[0]["email"])
        self.assertEqual(len(result.bridge_tables), 0)

    def test_split_records_empty_relationships(self) -> None:
        """Test empty relationship lists don't create tables."""
        records: list[dict[str, Any]] = [{"id": 1, "tag_ids": []}]

        result = Component._split_records(records, "res.partner", "res_partner.csv")

        self.assertEqual(len(result.main_records), 1)
        self.assertEqual(len(result.bridge_tables), 0)  # No tables for empty lists

    def test_split_records_multiple_relationships(self) -> None:
        """Test multiple relationship fields create separate tables."""
        records: list[dict[str, Any]] = [
            {
                "id": 15,
                "name": "Azure",
                "category_id": [5],
                "child_ids": [27, 34, 28],
            }
        ]

        result = Component._split_records(records, "res.partner", "res_partner.csv")

        # Main table
        self.assertEqual(len(result.main_records), 1)
        self.assertEqual(result.main_records[0]["id"], 15)

        # Two relationship tables
        self.assertEqual(len(result.bridge_tables), 2)
        self.assertIn("res_partner__category_id.csv", result.bridge_tables)
        self.assertIn("res_partner__child_ids.csv", result.bridge_tables)
        rel_metadata = result.bridge_tables

        # category_id has 1 record and correct primary key
        category_data = rel_metadata["res_partner__category_id.csv"]
        self.assertEqual(category_data.primary_key, ["partner_id", "category_id"])
        self.assertEqual(category_data.table_name, "res_partner__category_id.csv")
        self.assertEqual(len(category_data.records), 1)

        # child_ids has 3 records and correct primary key
        child_data = rel_metadata["res_partner__child_ids.csv"]
        self.assertEqual(child_data.primary_key, ["partner_id", "child_id"])
        self.assertEqual(child_data.table_name, "res_partner__child_ids.csv")
        self.assertEqual(len(child_data.records), 3)


class TestMetadataGeneration(unittest.TestCase):
    """Test metadata file generation."""

    @patch("builtins.open", new_callable=lambda: MagicMock())
    @patch("component.Component._write_csv")
    @patch("component.Component.write_manifest")
    @patch("component.Component.create_out_table_definition")
    def test_metadata_file_created(
        self,
        mock_table_def: Mock,
        mock_manifest: Mock,
        mock_write_csv: Mock,
        mock_open: Mock,
    ) -> None:
        """Test that metadata file is created during extraction."""
        # Mock the client's field metadata
        mock_client = MagicMock()
        mock_client.get_model_fields.return_value = {
            "id": {"type": "integer", "string": "ID"},
            "name": {"type": "char", "string": "Name"},
            "country_id": {
                "type": "many2one",
                "string": "Country",
                "relation": "res.country",
            },
            "category_id": {
                "type": "many2many",
                "string": "Tags",
                "relation": "res.partner.category",
            },
        }
        mock_client.search_read.return_value = [
            {
                "id": 1,
                "name": "Test Partner",
                "country_id": [233, "United States"],
                "category_id": [5],
            }
        ]

        # Create component with mocked client
        with patch("component.Component._initialize_client", return_value=mock_client):
            with patch("component.Component.__init__") as mock_init:
                mock_init.return_value = None
                comp = Component()
                comp.client = mock_client
                comp.state = {}

            # Mock the tables_out_path property
            with patch.object(
                type(comp),
                "tables_out_path",
                new_callable=lambda: property(lambda self: "/tmp/test_out"),
            ):
                # Mock table definition - return different paths for different tables
                def create_mock_table(name, **kwargs):
                    mock_table = MagicMock()
                    mock_table.full_path = f"/tmp/test_out/{name}.csv"
                    return mock_table

                mock_table_def.side_effect = create_mock_table

                # Set config
                comp.config = Configuration(
                    odoo_url="https://demo.odoo.com",
                    database="demo",
                    username="admin",
                    api_key="test123",
                    model="res.partner",
                    fields=["id", "name", "country_id", "category_id"],
                )

                # Run extraction
                comp._extract_with_paging()

                # Verify metadata file was opened for writing
                metadata_calls = [call for call in mock_open.call_args_list if "metadata__" in str(call)]
                self.assertTrue(len(metadata_calls) > 0, "Metadata file should be created")


if __name__ == "__main__":
    unittest.main()



================================================
FILE: .github/workflows/push.yml
================================================
name: Keboola Component Build & Deploy Pipeline
on:
  push:  # skip the workflow on the main branch without tags
    branches-ignore:
      - main
    tags:
      - "*"

concurrency: ci-${{ github.ref }}  # to avoid tag collisions in the ECR
env:
  # repository variables:
  KBC_DEVELOPERPORTAL_APP: keboola.ex-odoo
  KBC_DEVELOPERPORTAL_VENDOR: keboola
  DOCKERHUB_USER: ${{ secrets.DOCKERHUB_USER }}
  KBC_DEVELOPERPORTAL_USERNAME: ${{ vars.KBC_DEVELOPERPORTAL_USERNAME }}

  # repository secrets:
  DOCKERHUB_TOKEN: ${{ secrets.DOCKERHUB_TOKEN }}  # recommended for pushing to ECR
  KBC_DEVELOPERPORTAL_PASSWORD: ${{ secrets.KBC_DEVELOPERPORTAL_PASSWORD }}

  # (optional) test KBC project: https://connection.keboola.com/admin/projects/0000
  KBC_TEST_PROJECT_CONFIGS: ""  # space separated list of config ids
  KBC_STORAGE_TOKEN: ${{ secrets.KBC_STORAGE_TOKEN }}  # required for running KBC tests

jobs:
  push_event_info:
    name: Push Event Info
    runs-on: ubuntu-latest
    outputs:
      app_image_tag: ${{ steps.tag.outputs.app_image_tag }}
      is_semantic_tag: ${{ steps.tag.outputs.is_semantic_tag }}
      is_default_branch: ${{ steps.default_branch.outputs.is_default_branch }}
      is_deploy_ready: ${{ steps.deploy_ready.outputs.is_deploy_ready }}
    steps:
      - name: Checkout Repository
        uses: actions/checkout@v4

      - name: Fetch all branches from remote repository
        run: git fetch --prune --unshallow --tags -f

      - name: Get current branch name
        id: current_branch
        run: |
          if [[ ${{ github.ref }} != "refs/tags/"* ]]; then
            branch_name=${{ github.ref_name }}
            echo "branch_name=$branch_name" | tee -a $GITHUB_OUTPUT
          else
            raw=$(git branch -r --contains ${{ github.ref }})
            branch="$(echo ${raw/*origin\//} | tr -d '\n')"
            echo "branch_name=$branch" | tee -a $GITHUB_OUTPUT
          fi

      - name: Is current branch the default branch
        id: default_branch
        run: |
          echo "default_branch='${{ github.event.repository.default_branch }}'"
          if [ "${{ github.event.repository.default_branch }}" = "${{ steps.current_branch.outputs.branch_name }}" ]; then
             echo "is_default_branch=true" | tee -a $GITHUB_OUTPUT
          else
             echo "is_default_branch=false" | tee -a $GITHUB_OUTPUT
          fi

      - name: Set image tag
        id: tag
        run: |
          TAG="${GITHUB_REF##*/}"
          IS_SEMANTIC_TAG=$(echo "$TAG" | grep -q '^v\?[0-9]\+\.[0-9]\+\.[0-9]\+$' && echo true || echo false)
          echo "is_semantic_tag=$IS_SEMANTIC_TAG" | tee -a $GITHUB_OUTPUT
          echo "app_image_tag=$TAG" | tee -a $GITHUB_OUTPUT

      - name: Deploy-Ready check
        id: deploy_ready
        run: |
          if [[ "${{ steps.default_branch.outputs.is_default_branch }}" == "true" \
            && "${{ github.ref }}" == refs/tags/* \
            && "${{ steps.tag.outputs.is_semantic_tag }}" == "true" ]]; then
              echo "is_deploy_ready=true" | tee -a $GITHUB_OUTPUT
          else
              echo "is_deploy_ready=false" | tee -a $GITHUB_OUTPUT
          fi

  build:
    name: Docker Image Build
    runs-on: ubuntu-latest
    needs:
      - push_event_info
    env:
      DOCKERHUB_TOKEN: ${{ secrets.DOCKERHUB_TOKEN }}
    steps:
      - name: Checkout Repository
        uses: actions/checkout@v4

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: Build and push
        uses: docker/build-push-action@v5
        with:
          context: .
          file: ./Dockerfile
          tags: ${{ env.KBC_DEVELOPERPORTAL_APP }}:latest
          outputs: type=docker,dest=/tmp/${{ env.KBC_DEVELOPERPORTAL_APP }}.tar

      - name: Upload artifact
        uses: actions/upload-artifact@v4
        with:
          name: ${{ env.KBC_DEVELOPERPORTAL_APP }}
          path: /tmp/${{ env.KBC_DEVELOPERPORTAL_APP }}.tar

  tests:
    name: Run Tests
    runs-on: ubuntu-latest
    needs:
      - push_event_info
      - build
    steps:
      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: Download artifact
        uses: actions/download-artifact@v4
        with:
          name: ${{ env.KBC_DEVELOPERPORTAL_APP }}
          path: /tmp

      - name: Load Image & Run Tests
        run: |
          docker load --input /tmp/${{ env.KBC_DEVELOPERPORTAL_APP }}.tar
          docker image ls -a
          docker run ${{ env.KBC_DEVELOPERPORTAL_APP }}:latest flake8 .
          echo "Running unit-tests..."
          docker run ${{ env.KBC_DEVELOPERPORTAL_APP }}:latest python -m unittest discover

  tests-kbc:
    name: Run KBC Tests
    needs:
      - push_event_info
      - build
    runs-on: ubuntu-latest
    steps:
      - name: Set up environment variables
        run: |
          echo "KBC_TEST_PROJECT_CONFIGS=${KBC_TEST_PROJECT_CONFIGS}" >> $GITHUB_ENV
          echo "KBC_STORAGE_TOKEN=${{ secrets.KBC_STORAGE_TOKEN }}" >> $GITHUB_ENV

      - name: Run KBC test jobs
        if: env.KBC_TEST_PROJECT_CONFIGS != '' && env.KBC_STORAGE_TOKEN != ''
        uses: keboola/action-run-configs-parallel@master
        with:
          token: ${{ secrets.KBC_STORAGE_TOKEN }}
          componentId: ${{ env.KBC_DEVELOPERPORTAL_APP }}
          tag: ${{ needs.push_event_info.outputs.app_image_tag }}
          configs: ${{ env.KBC_TEST_PROJECT_CONFIGS }}

  push:
    name: Docker Image Push
    runs-on: ubuntu-latest
    needs:
      - push_event_info
      - tests
      - tests-kbc
    env:
      DOCKERHUB_TOKEN: ${{ secrets.DOCKERHUB_TOKEN }}
    steps:
      - name: Checkout Repository
        uses: actions/checkout@v4

      - name: Download artifact
        uses: actions/download-artifact@v4
        with:
          name: ${{ env.KBC_DEVELOPERPORTAL_APP }}
          path: /tmp

      - name: Load Image & Run Tests
        run: |
          docker load --input /tmp/${{ env.KBC_DEVELOPERPORTAL_APP }}.tar
          docker image ls -a

      - name: Docker login
        if: env.DOCKERHUB_TOKEN
        run: docker login --username "${{ env.DOCKERHUB_USER }}" --password "${{ env.DOCKERHUB_TOKEN }}"

      - name: Push image to ECR
        uses: keboola/action-push-to-ecr@master
        with:
          vendor: ${{ env.KBC_DEVELOPERPORTAL_VENDOR }}
          app_id: ${{ env.KBC_DEVELOPERPORTAL_APP }}
          username: ${{ env.KBC_DEVELOPERPORTAL_USERNAME }}
          password: ${{ secrets.KBC_DEVELOPERPORTAL_PASSWORD }}
          tag: ${{ needs.push_event_info.outputs.app_image_tag }}
          push_latest: ${{ needs.push_event_info.outputs.is_deploy_ready }}
          source_image: ${{ env.KBC_DEVELOPERPORTAL_APP }}

  deploy:
    name: Deploy to KBC
    env:
      KBC_DEVELOPERPORTAL_PASSWORD: ${{ secrets.KBC_DEVELOPERPORTAL_PASSWORD }}
    needs:
      - push_event_info
      - build
      - push
    if: needs.push_event_info.outputs.is_deploy_ready == 'true'
    runs-on: ubuntu-latest
    steps:
      - name: Set Developer Portal Tag
        uses: keboola/action-set-tag-developer-portal@master
        with:
          vendor: ${{ env.KBC_DEVELOPERPORTAL_VENDOR }}
          app_id: ${{ env.KBC_DEVELOPERPORTAL_APP }}
          username: ${{ env.KBC_DEVELOPERPORTAL_USERNAME }}
          password: ${{ secrets.KBC_DEVELOPERPORTAL_PASSWORD }}
          tag: ${{ needs.push_event_info.outputs.app_image_tag }}

  update_developer_portal_properties:
    name: Developer Portal Properties Update
    env:
      KBC_DEVELOPERPORTAL_PASSWORD: ${{ secrets.KBC_DEVELOPERPORTAL_PASSWORD }}
    needs:
      - push_event_info
      - build
      - push
    runs-on: ubuntu-latest
    if: needs.push_event_info.outputs.is_deploy_ready == 'true'
    steps:
      - name: Checkout Repository
        uses: actions/checkout@v4

      - name: Update developer portal properties
        run: |
          chmod +x scripts/developer_portal/*.sh
          scripts/developer_portal/update_properties.sh


