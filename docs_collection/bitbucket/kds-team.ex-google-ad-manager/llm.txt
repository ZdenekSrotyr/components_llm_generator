Directory structure:
└── kds_consulting_team-kds-team.ex-google-ad-manager/
    ├── README.md
    ├── bitbucket-pipelines.yml
    ├── change_log.md
    ├── deploy.sh
    ├── docker-compose.yml
    ├── Dockerfile
    ├── flake8.cfg
    ├── LICENSE.md
    ├── requirements.txt
    ├── .travis.yml
    ├── component_config/
    │   ├── component_long_description.md
    │   ├── component_short_description.md
    │   ├── configRowSchema.json
    │   ├── configSchema.json
    │   ├── configuration_description.md
    │   ├── logger
    │   ├── loggerConfiguration.json
    │   └── sample-config/
    │       ├── config.json
    │       └── in/
    │           ├── state.json
    │           ├── files/
    │           │   └── order1.xml
    │           └── tables/
    │               ├── test.csv
    │               └── test.csv.manifest
    ├── scripts/
    │   ├── build_n_run.ps1
    │   ├── build_n_test.sh
    │   ├── run.bat
    │   ├── run_kbc_tests.ps1
    │   └── update_dev_portal_properties.sh
    ├── src/
    │   ├── component.py
    │   └── google_ad_manager/
    │       ├── __init__.py
    │       └── client.py
    └── tests/
        ├── __init__.py
        └── test_component.py

================================================
FILE: README.md
================================================
# Google Ad Manager Report extractor

This extractor allows you to download specified reports from your Google Ad Manager account. The component uses the 202105 version of the API.

**Table of contents:**  
  
[TOC]

## Authentication
To authenticate the component you must create a Google Service Account and link it to the Google Ad Manager account in the API settings.
From the Google Service Account JSON key you will be able to get the private key and the Token URI.
   
- Token URI (token_uri) - [REQ] uri specified in the service account json key
- Private key (#private_key) - [REQ] specified in the service account json key, copy and paste the entire key (Key must be written in one row, each new line must be delimited by \n character) 
- Service Account Email (client_email) - [REQ]
- Network code (network_code) [REQ] - You'll find this in the URL when you are logged into your network. For example, in the URL https://admanager.google.com/1234#home, 1234 is your network code.

## Report parameters
It is recommended to first create a report on the Google Ad Manager report page to first
test if all dimension and metric combinations are available for the given report type, as
well as the date ranges matching the dimensions (eg. WEEK dimension must have one or more week sun-sat, 
if a date range of mon-fri is given it will result in an error).

Once you create a valid report on the Google Ad Manager report page you can go to the 
[api docs](https://developers.google.com/ad-manager/api/reference/v202105/ReportService.ReportQuery#dimensions)
to find the proper names of the dimensions and metrics for the API.
Eg. CTR in the Ad exchange report type is AD_EXCHANGE_CTR in the API. 

- Output name (report_name) - [REQ] name of output eg. historical_report_ads_weekly will be saved as this in storage
- API version (api_version) - [REQ] API version for the component to use, see [deprecation schedule](https://developers.google.com/ad-manager/api/deprecation)
- Report settings (report_settings) [REQ]
  - Dimensios (dimensions) - [REQ] should be written comma separated (no quotation marks) eg. DIMENSION1, DIMENSION2 ... etc.
  - Dimension attributes (dimension_attributes) - [OPT] should be written comma separated (no quotation marks) eg. DIMENSION_ATTR1, DIMENSION_ATTR2 ... etc.
  - Metrics (metrics) - [REQ] should be written comma separated (no quotation marks) eg. METRIC1, METRIC2 ... etc.
  - Report type (report_type) - [REQ] type of report to download
  - Ad Unit view (ad_unit_view) [OPT] - Ad unit view describes how data is fetched about ad units, Default TOP_LEVEL: 
    - TOP_LEVEL : Only the top level ad units. Metrics include events for their descendants that are not filtered out.
    - FLAT : All the ad units. Metrics do not include events for the descendants.
    - HIERARCHICAL : Use the ad unit hierarchy. There will be as many ad unit columns as levels of ad units in the generated report
  - Report Currency (report_currency) [OPT] - The currency for revenue metrics. Defaults to the network currency if left null. The supported currency codes can be found in [this Help Center article](https://support.google.com/admanager/answer/6019533).
- Date settings (date_settings) [REQ]
  - Date range (date_range) - [REQ] Type of date range
  - Last week (sun-sat) used for WEEK dimension
  - Last month (from first day of the previous month to last day of the previous month)
  - Custom - must then specify date from and to (3 days ago to 1 day ago) (1 march 2021 to 23 march 2021)
    - Date to (date_to) - [OPT] 4 days ago, yeserday, August 14, 2020 EST (it uses [dateparser](https://pypi.org/project/dateparser/))
  - Date from (date_from) - [OPT]


================================================
FILE: bitbucket-pipelines.yml
================================================
options:
  docker: true

pipelines:
  default:
    - step:
        caches:
          - docker
        script:
          - export APP_IMAGE=keboola-component
          - docker build . --tag=$APP_IMAGE
          - docker images
          - docker -v
          - docker run $APP_IMAGE flake8 /code/ --config=/code/flake8.cfg
          - echo "Running unit-tests..."
          - docker run $APP_IMAGE python -m unittest discover
          # push test image to ecr - uncomment for testing before deployment
          - export TEST_TAG=${BITBUCKET_BRANCH//\//-}
          - echo "Pushing test image to repo. [tag=${TEST_TAG}]"
          - export REPOSITORY=`docker run --rm -e KBC_DEVELOPERPORTAL_USERNAME -e KBC_DEVELOPERPORTAL_PASSWORD -e KBC_DEVELOPERPORTAL_URL quay.io/keboola/developer-portal-cli-v2:latest ecr:get-repository $KBC_DEVELOPERPORTAL_VENDOR $KBC_DEVELOPERPORTAL_APP`
          - docker tag $APP_IMAGE:latest $REPOSITORY:$TEST_TAG
          - eval $(docker run --rm -e KBC_DEVELOPERPORTAL_USERNAME -e KBC_DEVELOPERPORTAL_PASSWORD -e KBC_DEVELOPERPORTAL_URL quay.io/keboola/developer-portal-cli-v2:latest ecr:get-login $KBC_DEVELOPERPORTAL_VENDOR $KBC_DEVELOPERPORTAL_APP)
          - docker push $REPOSITORY:$TEST_TAG


  branches:
    master:
      - step:
          caches:
            - docker
          script:
            - export APP_IMAGE=keboola-component
            - docker build . --tag=$APP_IMAGE
            - docker images
            - docker -v
            - docker run $APP_IMAGE flake8 /code/ --config=/code/flake8.cfg
            - echo "Running unit-tests..."
            - docker run $APP_IMAGE python -m unittest discover
            # push test image to ecr - uncomment for testing before deployment
            - export TEST_TAG=${BITBUCKET_BRANCH//\//-}
            - echo "Pushing test image to repo. [tag=${TEST_TAG}]"
            - export REPOSITORY=`docker run --rm -e KBC_DEVELOPERPORTAL_USERNAME -e KBC_DEVELOPERPORTAL_PASSWORD -e KBC_DEVELOPERPORTAL_URL quay.io/keboola/developer-portal-cli-v2:latest ecr:get-repository $KBC_DEVELOPERPORTAL_VENDOR $KBC_DEVELOPERPORTAL_APP`
            - docker tag $APP_IMAGE:latest $REPOSITORY:$TEST_TAG
            - eval $(docker run --rm -e KBC_DEVELOPERPORTAL_USERNAME -e KBC_DEVELOPERPORTAL_PASSWORD -e KBC_DEVELOPERPORTAL_URL quay.io/keboola/developer-portal-cli-v2:latest ecr:get-login $KBC_DEVELOPERPORTAL_VENDOR $KBC_DEVELOPERPORTAL_APP)
            - docker push $REPOSITORY:$TEST_TAG
            - chmod +x ./scripts/update_dev_portal_properties.sh
            - ./scripts/update_dev_portal_properties.sh
  tags:
    '*':
      - step:
          deployment: production
          script:
            - export APP_IMAGE=keboola-component
            - docker build . --tag=$APP_IMAGE
            - docker images
            - docker run $APP_IMAGE flake8 /code/ --config=/code/flake8.cfg
            - echo "Running unit-tests..."
            - docker run $APP_IMAGE python -m unittest discover
            - echo "Preparing KBC test image"
            - docker pull quay.io/keboola/developer-portal-cli-v2:latest
            # push test image to ECR - uncomment when initialised
            # - export REPOSITORY=`docker run --rm -e KBC_DEVELOPERPORTAL_USERNAME -e KBC_DEVELOPERPORTAL_PASSWORD -e KBC_DEVELOPERPORTAL_URL quay.io/keboola/developer-portal-cli-v2:latest ecr:get-repository $KBC_DEVELOPERPORTAL_VENDOR $KBC_DEVELOPERPORTAL_APP`
            # - docker tag $APP_IMAGE:latest $REPOSITORY:test
            # - eval $(docker run --rm -e KBC_DEVELOPERPORTAL_USERNAME -e KBC_DEVELOPERPORTAL_PASSWORD -e KBC_DEVELOPERPORTAL_URL quay.io/keboola/developer-portal-cli-v2:latest ecr:get-login $KBC_DEVELOPERPORTAL_VENDOR $KBC_DEVELOPERPORTAL_APP)
            # - docker push $REPOSITORY:test
            # - docker run --rm -e KBC_STORAGE_TOKEN quay.io/keboola/syrup-cli:latest run-job $KBC_DEVELOPERPORTAL_APP $BASE_KBC_CONFIG test
            # - docker run --rm -e KBC_STORAGE_TOKEN quay.io/keboola/syrup-cli:latest run-job $KBC_DEVELOPERPORTAL_APP $KBC_CONFIG_1 test
            - chmod +x ./scripts/update_dev_portal_properties.sh
            - chmod +x ./deploy.sh
            - ./scripts/update_dev_portal_properties.sh
            - ./deploy.sh


================================================
FILE: change_log.md
================================================
**0.1.1**

- fix requirements
- add src folder to path for tests

**0.1.0**

- src folder structure
- remove dependency on handler lib - import the code directly to enable modifications until its released

**0.0.2**

- add dependency to base lib
- basic tests

**0.0.1**

- add utils scripts
- move kbc tests directly to pipelines file
- use uptodate base docker image
- add changelog



================================================
FILE: deploy.sh
================================================
#!/bin/sh
set -e

env

# compatibility with travis and bitbucket
if [ ! -z ${BITBUCKET_TAG} ]
then
	echo "asigning bitbucket tag"
	export TAG="$BITBUCKET_TAG"
elif [ ! -z ${TRAVIS_TAG} ]
then
	echo "asigning travis tag"
	export TAG="$TRAVIS_TAG"
else
	echo No Tag is set!
	exit 1
fi

echo "Tag is '${TAG}'"

#check if deployment is triggered only in master
if [ ${BITBUCKET_BRANCH} != "master" ]; then
               echo Deploy on tagged commit can be only executed in master!
               exit 1
fi

# Obtain the component repository and log in
echo "Obtain the component repository and log in"
docker pull quay.io/keboola/developer-portal-cli-v2:latest
export REPOSITORY=`docker run --rm  \
    -e KBC_DEVELOPERPORTAL_USERNAME \
    -e KBC_DEVELOPERPORTAL_PASSWORD \
    quay.io/keboola/developer-portal-cli-v2:latest \
    ecr:get-repository ${KBC_DEVELOPERPORTAL_VENDOR} ${KBC_DEVELOPERPORTAL_APP}`

echo "Set credentials"
eval $(docker run --rm \
    -e KBC_DEVELOPERPORTAL_USERNAME \
    -e KBC_DEVELOPERPORTAL_PASSWORD \
    quay.io/keboola/developer-portal-cli-v2:latest \
    ecr:get-login ${KBC_DEVELOPERPORTAL_VENDOR} ${KBC_DEVELOPERPORTAL_APP})

# Push to the repository
echo "Push to the repository"
docker tag ${APP_IMAGE}:latest ${REPOSITORY}:${TAG}
docker tag ${APP_IMAGE}:latest ${REPOSITORY}:latest
docker push ${REPOSITORY}:${TAG}
docker push ${REPOSITORY}:latest

# Update the tag in Keboola Developer Portal -> Deploy to KBC
if echo ${TAG} | grep -c '^v\?[0-9]\+\.[0-9]\+\.[0-9]\+$'
then
    docker run --rm \
        -e KBC_DEVELOPERPORTAL_USERNAME \
        -e KBC_DEVELOPERPORTAL_PASSWORD \
        quay.io/keboola/developer-portal-cli-v2:latest \
        update-app-repository ${KBC_DEVELOPERPORTAL_VENDOR} ${KBC_DEVELOPERPORTAL_APP} ${TAG} ecr ${REPOSITORY}
else
    echo "Skipping deployment to KBC, tag ${TAG} is not allowed."
fi



================================================
FILE: docker-compose.yml
================================================
version: "2"
services:
  # for development purposes
  dev:
    build: .
    volumes:
        - ./:/code
        - ./data:/data
    environment:
      - KBC_DATADIR=./data
  test:
    # Use to run flake8 and unittests checks
    build: .
    volumes:
      - ./:/code
      - ./data:/data
    environment:
      - KBC_DATADIR=./data
    command:
      - /bin/sh
      - /code/scripts/build_n_test.sh


================================================
FILE: Dockerfile
================================================
FROM python:3.8.6-slim
ENV PYTHONIOENCODING utf-8

COPY /src /code/src/
COPY /tests /code/tests/
COPY /scripts /code/scripts/
COPY requirements.txt /code/requirements.txt
COPY flake8.cfg /code/flake8.cfg
COPY deploy.sh /code/deploy.sh

# install gcc to be able to build packages - e.g. required by regex, dateparser, also required for pandas
RUN apt-get update && apt-get install -y build-essential

RUN pip install flake8

RUN pip install -r /code/requirements.txt

WORKDIR /code/


CMD ["python", "-u", "/code/src/component.py"]



================================================
FILE: flake8.cfg
================================================
[flake8]
exclude =
    .git,
    __pycache__,
    tests,
    example
    venv
max-line-length = 120

# F812: list comprehension redefines ...
# H101: Use TODO(NAME)
# H202: assertRaises Exception too broad
# H233: Python 3.x incompatible use of print operator
# H301: one import per line
# H306: imports not in alphabetical order (time, os)
# H401: docstring should not start with a space
# H403: multi line docstrings should end on a new line
# H404: multi line docstring should start without a leading new line
# H405: multi line docstring summary not separated with an empty line
# H501: Do not use self.__dict__ for string formatting



================================================
FILE: LICENSE.md
================================================
The MIT License (MIT)

Copyright (c) 2018 Keboola DS, http://keboola.com

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files, to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is furnished
to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
THE SOFTWARE.


================================================
FILE: requirements.txt
================================================
keboola.component==1.1.0
keboola.utils
keboola.http-client
mock
freezegun
googleads
retry==0.9.2
dateparser


================================================
FILE: .travis.yml
================================================
sudo: false

services:
  - docker

jobs:
  include:
    - stage: tests
      script:
        - docker run $APP_IMAGE flake8 /code/ --config=/code/flake8.cfg
        - docker run $APP_IMAGE python -m unittest discover
      # push test image to ECR - uncomment for testing before deployment
      #  - docker pull quay.io/keboola/developer-portal-cli-v2:latest
      #  - export REPOSITORY=`docker run --rm -e KBC_DEVELOPERPORTAL_USERNAME -e KBC_DEVELOPERPORTAL_PASSWORD -e KBC_DEVELOPERPORTAL_URL quay.io/keboola/developer-portal-cli-v2:latest ecr:get-repository $KBC_DEVELOPERPORTAL_VENDOR $KBC_DEVELOPERPORTAL_APP`
      #  - docker tag $APP_IMAGE:latest $REPOSITORY:test
      #  - eval $(docker run --rm -e KBC_DEVELOPERPORTAL_USERNAME -e KBC_DEVELOPERPORTAL_PASSWORD -e KBC_DEVELOPERPORTAL_URL quay.io/keboola/developer-portal-cli-v2:latest ecr:get-login $KBC_DEVELOPERPORTAL_VENDOR $KBC_DEVELOPERPORTAL_APP)
      #  - docker push $REPOSITORY:test
      #  - docker pull quay.io/keboola/syrup-cli:latest
    - stage: deploy_dev_portal
      if: branch = master
      script: "./scripts/update_dev_portal_properties.sh"

before_script:
  - export APP_IMAGE=keboola-component
  - docker -v
  - docker build -t $APP_IMAGE .
  - chmod +x ./scripts/update_dev_portal_properties.sh
  - chmod +x ./deploy.sh

after_success:
  - docker images

deploy:
  provider: script
  skip_cleanup: true
  script: ./deploy.sh
  on:
    tags: true
    branch: master



================================================
FILE: component_config/component_long_description.md
================================================
This component allows you to download reports from the Google Ad Manager API, you can select various report types and metrics based on your needs.


================================================
FILE: component_config/component_short_description.md
================================================
Google Ad Manager is an ad management platform for large publishers who have significant direct sales.


================================================
FILE: component_config/configRowSchema.json
================================================
{
  "title": "Report Configuration",
  "type": "object",
  "required": [
    "report_name"
  ],
  "properties": {
    "report_name": {
      "title": "Output Name",
      "type": "string",
      "description": "Name of output table of the report eg. historical_report",
      "propertyOrder": 10
    },
    "api_version": {
      "title": "API version",
      "type": "string",
      "enum": [
            "v202408",
            "v202405",
            "v202402",
            "v202311"
          ],
      "default": "v202408",
      "description": "Google Ad Manager API version. More info in <a href='https://developers.google.com/ad-manager/api/rel_notes'>Google docs</a>",
      "propertyOrder": 15
    },
    "report_settings": {
      "type": "object",
      "title": "Report settings",
      "required": [
        "metrics",
        "dimensions",
        "ad_unit_view"
      ],
      "propertyOrder": 20,
      "properties": {
        "dimensions": {
          "title": "Dimensions",
          "type": "string",
          "description": "List of dimensions to use for the report, find supported dimensions for specific report types in the documentation",
          "propertyOrder": 40
        },
        "dimension_attributes": {
          "title": "Dimension Attributes",
          "type": "string",
          "description": "List of dimensions attributes to use for the report, find supported dimension attributes for specific report types in the documentation",
          "propertyOrder": 50
        },
        "metrics": {
          "title": "Metrics",
          "type": "string",
          "description": "List of metrics to use for the report, find supported metrics for specific report types in the documentation",
          "propertyOrder": 60
        },
        "ad_unit_view": {
          "title": "Ad unit view",
          "type": "string",
          "enum": [
            "FLAT",
            "TOP_LEVEL",
            "HIERARCHICAL"
          ],
          "description": "Ad unit view describes how data is fetched about ad units, data can be fetched for all ad units with Flat, only top level ad units with Top level, or Hierarchically",
          "default": "Object",
          "propertyOrder": 80
        },
        "report_currency": {
          "title": "Report Currency",
          "type": "string",
          "description": "The currency for revenue metrics. Defaults to the network currency if left null. The supported currency codes can be found in <a href='https://support.google.com/admanager/answer/6019533'>this Help Center article.</a>"
        },
        "include_zero_impressions": {
          "title": "Include zero impressions",
          "type": "boolean",
          "format" : "checkbox",
          "description": "If your report supports this, you can download data of ads with zero impressions",
          "default": false,
          "propertyOrder": 100
        }
      }
    },
    "date_settings": {
      "type": "object",
      "title": "Date range",
      "propertyOrder": 100,
      "required": [
        "date_range"
      ],
      "properties": {
        "date_range": {
          "title": "Dynamic date range",
          "type": "string",
          "enum": [
            "Last week (sun-sat)",
            "Next week",
            "Last month",
            "Next month",
            "Next_day",
            "Yesterday",
            "Reach lifetime",
            "Custom"
          ],
          "propertyOrder": 110
        },
        "date_from": {
          "title": "Date from",
          "type": "string",
          "options": {
            "dependencies": {
              "date_range": "Custom"
            }
          },
          "description": "Start date of the report eg. 3 days ago",
          "propertyOrder": 120
        },
        "date_to": {
          "title": "Date to",
          "type": "string",
          "options": {
            "dependencies": {
              "date_range": "Custom"
            }
          },
          "description": "End date of the report eg. 1 day ago",
          "propertyOrder": 130
        }
      }
    }
  }
}


================================================
FILE: component_config/configSchema.json
================================================
{
  "type": "object",
  "title": "Google Ad Manager Authentication",
  "required": [
    "client_email",
    "#private_key",
    "token_uri",
    "network_code"
  ],
  "properties": {
    "client_email": {
      "title": "Client email",
      "type": "string",
      "propertyOrder": 1
    },
    "#private_key": {
      "title": "Private Key",
      "type": "string",
      "description": "Credentials - private key in plain text (will be encrypted by Keboola). Key must be written in one row, each new line must be delimited by \\n character",
      "propertyOrder": 2
    },
    "token_uri": {
      "title": "Token URI",
      "type": "string",
      "default": "https://oauth2.googleapis.com/token",
      "description": "Authentication token uri : https://oauth2.googleapis.com/token if not specified otherwise",
      "propertyOrder": 3
    },
    "network_code": {
      "title": "Network Code",
      "type": "string",
      "description": "You'll find this in the URL when you are logged into your network. For example, in the URL https://admanager.google.com/1234#home, 1234 is your network code.",
      "propertyOrder": 4
    }
  }
}



================================================
FILE: component_config/configuration_description.md
================================================



================================================
FILE: component_config/logger
================================================
gelf


================================================
FILE: component_config/loggerConfiguration.json
================================================
{
  "verbosity": {
    "100": "normal",
    "200": "normal",
    "250": "normal",
    "300": "verbose",
    "400": "verbose",
    "500": "camouflage",
    "550": "camouflage",
    "600": "camouflage"
  },
  "gelf_server_type": "tcp"
}


================================================
FILE: component_config/sample-config/config.json
================================================
{
  "storage": {
    "input": {
      "files": [],
      "tables": [
        {
          "source": "in.c-test.test",
          "destination": "test.csv",
          "limit": 50,
          "columns": [],
          "where_values": [],
          "where_operator": "eq"
        }
      ]
    },
    "output": {
      "files": [],
      "tables": []
    }
  },
  "parameters": {
    "#api_token": "demo",
    "period_from": "yesterday",
    "endpoints": [
      "deals",
      "companies"
    ],
    "company_properties": "",
    "deal_properties": "",
    "debug": true
  },
  "image_parameters": {
    "syrup_url": "https://syrup.keboola.com/"
  },
  "authorization": {
    "oauth_api": {
      "id": "OAUTH_API_ID",
      "credentials": {
        "id": "main",
        "authorizedFor": "Myself",
        "creator": {
          "id": "1234",
          "description": "me@keboola.com"
        },
        "created": "2016-01-31 00:13:30",
        "#data": "{\"refresh_token\":\"MCWBkfdK9m5YK*Oqahwm6XN6elMAEwcH5kYcK8Ku!bpiOgSDZN9MQIzunpMsh6LyKH0i!7OcwwwajuxPfvm2PrrWYSs*HerDr2ZSJ39pqHJcvwUNIvHdtcgFFr3Em*yhn3GKBwM2p9UrjtgdAriSDny5YgUYGuI3gYJY1ypD*wBaAOzzeeXZx6CdgjruJ7gboTAngbWk3CzO9rORIwXAAlGUH6ZgBQJL3AwkYVMRFV4BvIvDAMF*0DcGDyrcyYDw9X3vYn*Wy!OqgrenKCGowdJk0C0136SUv4PJI383y76UMim6Q7KGDj7Lf!K2N2FDbxsz2iZKZTBr2vHx8pEC1oBc$\"}",
        "oauthVersion": "2.0",
        "appKey": "000000004C184A49",
        "#appSecret": "vBAYak49pVK1zghHAgDH4tCSCNlT-CiN"
      }
    }
  }
}



================================================
FILE: component_config/sample-config/in/state.json
================================================
{"data_delta": "10222018"}


================================================
FILE: component_config/sample-config/in/files/order1.xml
================================================
<?xml version='1.0' ?>
<root_el>
    <orders>
        <order>
            <id>1</id>
            <date>2018-01-01</date>
            <cust_name>David</cust_name>	
            <order-item>
                <price currency="CZK">100</price>
                <item>Umbrella</item>
            </order-item>
            <order-item>
                <price currency="CZK">200</price>
                <item>Rain Coat</item>
            </order-item>
        </order>
    </orders>
</root_el>


================================================
FILE: component_config/sample-config/in/tables/test.csv
================================================
"Type","Campaign_Name","Status","Start_Date","End_Date","Location","Eventbrite_link"
"Event","How to become data driven startup","Complete","2015-10-13","2015-10-13","United Kingdom","https://www.eventbrite.co.uk/e/how-to-become-data-driven-startup-registration-18711425377"
"Event","How to become data driven startup","Complete","2015-11-04","2015-11-04","United Kingdom","https://www.eventbrite.co.uk/e/how-to-become-data-driven-startup-registration-18711426380"
"Event","How to become data driven startup","Complete","2015-10-13","2015-10-13","United Kingdom","https://www.eventbrite.co.uk/e/how-to-become-data-driven-startup-registration-18711425377"
"Event","How to become data driven startup","Complete","2015-11-04","2015-11-04","United Kingdom","https://www.eventbrite.co.uk/e/how-to-become-data-driven-startup-registration-18711426380"
"Event","DATAGIRLS PRESENT: HOW TO BECOME DATA-DRIVEN","Complete","2016-01-14","2016-01-14","United Kingdom","https://www.eventbrite.co.uk/e/datagirls-present-how-to-become-data-driven-tickets-20152992142"
"Event","DATAGIRLS PRESENT: HOW TO BECOME DATA-DRIVEN","Complete","2016-02-25","2016-02-25","United Kingdom","https://www.eventbrite.co.uk/e/datagirls-present-how-to-become-data-driven-tickets-20967439175"
"Event","Data Tools for Startups","Complete","2016-03-17","2016-03-17","United Kingdom","https://www.eventbrite.co.uk/e/data-tools-for-startups-tickets-21257426535"
"Event","Data Festival London 2016","Complete","2016-06-24","2016-06-26","United Kingdom","https://www.eventbrite.co.uk/e/data-festival-london-2016-tickets-25192608771"
"Event","Becoming data driven in the high street fashion","Complete","2016-10-12","2016-10-12","United Kingdom","https://www.eventbrite.co.uk/e/becoming-data-driven-in-the-high-street-fashion-tickets-27481268213"
"Event","The Data Foundry present: DATAGIRLS Weekend","Complete","2016-10-14","2016-10-16","United Kingdom","https://www.eventbrite.co.uk/e/the-data-foundry-present-datagirls-weekend-tickets-27350069795"
"Event","[NLP] How to analyse text data for knowledge discovery","Complete","2017-04-10","2017-04-10","United Kingdom","https://www.eventbrite.co.uk/e/nlp-how-to-analyse-text-data-for-knowledge-discovery-tickets-32320274812"
"Event","Keboola DataBrunch - Amazon Go a ako s ním v maloobchode “bojovať”","Complete","2017-03-09","2017-03-09","Slovakia","https://www.eventbrite.co.uk/e/keboola-databrunch-amazon-go-a-ako-s-nim-v-maloobchode-bojovat-tickets-31827553068"
"Event","Keboola DataBrunch - Amazon Go a jak s nim v maloobchodě “bojovat”","Complete","2017-03-29","2017-03-29","Czech Republic","https://www.eventbrite.co.uk/e/keboola-databrunch-amazon-go-a-jak-s-nim-v-maloobchode-bojovat-tickets-32182393405"
"Event","The Data Foundry present: DATAGIRLS Weekend","Complete","2016-10-14","2016-10-16","United Kingdom","https://www.eventbrite.co.uk/e/the-data-foundry-present-datagirls-weekend-tickets-27350069795"
"Event","[NLP] How to analyse text data for knowledge discovery","Complete","2017-04-10","2017-04-10","United Kingdom","https://www.eventbrite.co.uk/e/nlp-how-to-analyse-text-data-for-knowledge-discovery-tickets-32320274812"
"Event","Keboola Data Brunch - KPIs and AmazonGo, budoucnost retailu? ","Complete","2017-06-27","2017-06-27","Czech Republic","https://www.eventbrite.co.uk/e/keboola-data-brunch-kpis-amazongo-budoucnost-retailu-tickets-35257195220"
"Event","Learn how to #DoMoreWithData with DataGirls","Complete","2017-10-01","2017-10-01","United Kingdom","https://www.eventbrite.co.uk/e/learn-how-to-domorewithdata-with-datagirls-tickets-36777944823"
"Event","Are You Using Data to Understand Your Customers? ","Complete","2018-02-27","2018-02-27","United Kingdom","https://www.eventbrite.co.uk/e/are-you-using-data-to-understand-your-customers-tickets-42000160611"
"Event","Conversion Rate Optimisation in Travel Industry","Complete","2018-01-30","2018-01-30","United Kingdom","https://www.eventbrite.co.uk/e/conversion-rate-optimisation-in-travel-industry-tickets-38951076719"
"Event","Learn how to #DoMoreWithData with DataGirls","Complete","2017-10-01","2017-10-01","United Kingdom","https://www.eventbrite.co.uk/e/learn-how-to-domorewithdata-with-datagirls-tickets-36777944823"
"Event","Are You Using Data to Understand Your Customers? ","Complete","2018-02-27","2018-02-27","United Kingdom","https://www.eventbrite.co.uk/e/are-you-using-data-to-understand-your-customers-tickets-42000160611"



================================================
FILE: component_config/sample-config/in/tables/test.csv.manifest
================================================
{
    "id": "in.c-test.test",
    "uri": "https:\/\/connection.keboola.com\/v2\/storage\/tables\/in.c-test.test",
    "name": "test",
    "primary_key": [],
    "indexed_columns": [],
    "created": "2018-03-02T15:36:50+0100",
    "last_change_date": "2018-03-02T15:36:54+0100",
    "last_import_date": "2018-03-02T15:36:54+0100",
    "rows_count": 0,
    "data_size_bytes": 0,
    "is_alias": false,
    "attributes": [],
    "columns": [
        "Type",
        "Campaign_Name",
        "Status",
        "Start_Date",
        "End_Date",
        "Location",
        "Eventbrite_link"
    ],
    "metadata": [
        {
            "id": "18271581",
            "key": "KBC.createdBy.component.id",
            "value": "transformation",
            "provider": "system",
            "timestamp": "2018-03-02T15:37:02+0100"
        },
        {
            "id": "18271582",
            "key": "KBC.createdBy.configuration.id",
            "value": "361585608",
            "provider": "system",
            "timestamp": "2018-03-02T15:37:02+0100"
        },
        {
            "id": "18271583",
            "key": "KBC.createdBy.configurationRow.id",
            "value": "361585762",
            "provider": "system",
            "timestamp": "2018-03-02T15:37:02+0100"
        },
        {
            "id": "18271584",
            "key": "KBC.lastUpdatedBy.component.id",
            "value": "transformation",
            "provider": "system",
            "timestamp": "2018-03-02T15:37:02+0100"
        },
        {
            "id": "18271585",
            "key": "KBC.lastUpdatedBy.configuration.id",
            "value": "361585608",
            "provider": "system",
            "timestamp": "2018-03-02T15:37:02+0100"
        },
        {
            "id": "18271586",
            "key": "KBC.lastUpdatedBy.configurationRow.id",
            "value": "361585762",
            "provider": "system",
            "timestamp": "2018-03-02T15:37:02+0100"
        }
    ],
    "column_metadata": {
        "Type": [],
        "Campaign_Name": [],
        "Status": [],
        "Start_Date": [],
        "End_Date": [],
        "Location": [],
        "Eventbrite_link": []
    }
}


================================================
FILE: scripts/build_n_run.ps1
================================================
echo Building component...
$COMP_TAG = Read-Host -Prompt 'Input Docker tag name:'
docker build -rm -t $COMP_TAG ../

echo Running component...
Write-host "Would you like to use default data folder? (../data)" -ForegroundColor Yellow 
    $Readhost = Read-Host " ( y / n ) " 
    Switch ($ReadHost) 
     { 
       Y {Write-host "Yes use: " (join-path (Split-Path -Path (Get-Location).Path) "data"); $DATA_PATH = (join-path (Split-Path -Path (Get-Location).Path) "data") } 
       N {Write-Host "No, I'll specify myself"; $DATA_PATH = Read-Host -Prompt 'Input data folder path:'} 
       Default {Write-Host "Default, run app"; docker run -v $DATA_PATH`:/data -e KBC_DATADIR=/data $COMP_TAG} 
     } 

Write-host "Would you like to execute the container to Bash, skipping the execution?" -ForegroundColor Yellow 
    $Readhost = Read-Host " ( y / n ) " 
    Switch ($ReadHost) 
     { 
       Y {Write-host "Yes, get me to the bash"; docker run -ti -v $DATA_PATH`:/data --entrypoint=//bin//bash $COMP_TAG} 
       N {Write-Host "No, execute the app normally"; 
		    echo $DATA_PATH
			docker run -v $DATA_PATH`:/data -e KBC_DATADIR=/data $COMP_TAG
	   } 
       Default {Write-Host "Default, run app"; docker run -v $DATA_PATH`:/data -e KBC_DATADIR=/data $COMP_TAG} 
     } 





================================================
FILE: scripts/build_n_test.sh
================================================
#!/bin/sh
set -e

flake8 --config=flake8.cfg
python -m unittest discover


================================================
FILE: scripts/run.bat
================================================
@echo off

echo Running component...
docker run -v %cd%:/data -e KBC_DATADIR=/data comp-tag


================================================
FILE: scripts/run_kbc_tests.ps1
================================================
echo "Preparing KBC test image"
# set env vars
$KBC_DEVELOPERPORTAL_USERNAME  = Read-Host -Prompt 'Input your service account user name'
$KBC_DEVELOPERPORTAL_PASSWORD  = Read-Host -Prompt 'Input your service account pass'
$KBC_DEVELOPERPORTAL_VENDOR = 'esnerda'
$KBC_DEVELOPERPORTAL_APP = 'esnerda.ex-gusto-export'
$BASE_KBC_CONFIG = '455568423'
$KBC_STORAGE_TOKEN = Read-Host -Prompt 'Input your storage token'


#build app
$APP_IMAGE='keboola-comp-test'
docker build ..\ --tag=$APP_IMAGE
docker images
docker -v
#docker run $APP_IMAGE flake8 --config=./deployment/flake8.cfg
echo "Running unit-tests..."
docker run $APP_IMAGE python -m unittest discover

docker pull quay.io/keboola/developer-portal-cli-v2:latest
$REPOSITORY= docker run --rm -e KBC_DEVELOPERPORTAL_USERNAME=$KBC_DEVELOPERPORTAL_USERNAME -e KBC_DEVELOPERPORTAL_PASSWORD=$KBC_DEVELOPERPORTAL_PASSWORD quay.io/keboola/developer-portal-cli-v2:latest ecr:get-repository $KBC_DEVELOPERPORTAL_VENDOR $KBC_DEVELOPERPORTAL_APP

docker tag $APP_IMAGE`:latest $REPOSITORY`:test

echo 'running login'
$(docker run --rm -e KBC_DEVELOPERPORTAL_USERNAME=$KBC_DEVELOPERPORTAL_USERNAME -e KBC_DEVELOPERPORTAL_PASSWORD=$KBC_DEVELOPERPORTAL_PASSWORD -e KBC_DEVELOPERPORTAL_URL quay.io/keboola/developer-portal-cli-v2:latest ecr:get-login $KBC_DEVELOPERPORTAL_VENDOR $KBC_DEVELOPERPORTAL_APP)

echo 'pushing test image'
docker push $REPOSITORY`:test

echo 'running test config in KBC'
docker run --rm -e KBC_STORAGE_TOKEN=$KBC_STORAGE_TOKEN quay.io/keboola/syrup-cli:latest run-job $KBC_DEVELOPERPORTAL_APP $BASE_KBC_CONFIG test



================================================
FILE: scripts/update_dev_portal_properties.sh
================================================
#!/usr/bin/env bash

set -e
# Obtain the component repository and log in
docker pull quay.io/keboola/developer-portal-cli-v2:latest


# Update properties in Keboola Developer Portal
echo "Updating long description"
value=`cat component_config/component_long_description.md`
echo "$value"
if [ ! -z "$value" ]
then
    docker run --rm \
            -e KBC_DEVELOPERPORTAL_USERNAME \
            -e KBC_DEVELOPERPORTAL_PASSWORD \
            quay.io/keboola/developer-portal-cli-v2:latest \
            update-app-property ${KBC_DEVELOPERPORTAL_VENDOR} ${KBC_DEVELOPERPORTAL_APP} longDescription --value="$value"
else
    echo "longDescription is empty!"
    exit 1
fi

echo "Updating config schema"
value=`cat component_config/configSchema.json`
echo "$value"
if [ ! -z "$value" ]
then
    docker run --rm \
            -e KBC_DEVELOPERPORTAL_USERNAME \
            -e KBC_DEVELOPERPORTAL_PASSWORD \
            quay.io/keboola/developer-portal-cli-v2:latest \
            update-app-property ${KBC_DEVELOPERPORTAL_VENDOR} ${KBC_DEVELOPERPORTAL_APP} configurationSchema --value="$value"
else
    echo "configurationSchema is empty!"
fi

echo "Updating row config schema"
value=`cat component_config/configRowSchema.json`
echo "$value"
if [ ! -z "$value" ]
then
    docker run --rm \
            -e KBC_DEVELOPERPORTAL_USERNAME \
            -e KBC_DEVELOPERPORTAL_PASSWORD \
            quay.io/keboola/developer-portal-cli-v2:latest \
            update-app-property ${KBC_DEVELOPERPORTAL_VENDOR} ${KBC_DEVELOPERPORTAL_APP} configurationRowSchema --value="$value"
else
    echo "configurationRowSchema is empty!"
fi


echo "Updating config description"

value=`cat component_config/configuration_description.md`
echo "$value"
if [ ! -z "$value" ]
then
    docker run --rm \
            -e KBC_DEVELOPERPORTAL_USERNAME \
            -e KBC_DEVELOPERPORTAL_PASSWORD \
            quay.io/keboola/developer-portal-cli-v2:latest \
            update-app-property ${KBC_DEVELOPERPORTAL_VENDOR} ${KBC_DEVELOPERPORTAL_APP} configurationDescription --value="$value"
else
    echo "configurationDescription is empty!"
fi


echo "Updating short description"

value=`cat component_config/component_short_description.md`
echo "$value"
if [ ! -z "$value" ]
then
    docker run --rm \
            -e KBC_DEVELOPERPORTAL_USERNAME \
            -e KBC_DEVELOPERPORTAL_PASSWORD \
            quay.io/keboola/developer-portal-cli-v2:latest \
            update-app-property ${KBC_DEVELOPERPORTAL_VENDOR} ${KBC_DEVELOPERPORTAL_APP} shortDescription --value="$value"
else
    echo "shortDescription is empty!"
fi

echo "Updating logger settings"

value=`cat component_config/logger`
echo "$value"
if [ ! -z "$value" ]
then
    docker run --rm \
            -e KBC_DEVELOPERPORTAL_USERNAME \
            -e KBC_DEVELOPERPORTAL_PASSWORD \
            quay.io/keboola/developer-portal-cli-v2:latest \
            update-app-property ${KBC_DEVELOPERPORTAL_VENDOR} ${KBC_DEVELOPERPORTAL_APP} logger --value="$value"
else
    echo "logger type is empty!"
fi

echo "Updating logger configuration"
value=`cat component_config/loggerConfiguration.json`
echo "$value"
if [ ! -z "$value" ]
then
    docker run --rm \
            -e KBC_DEVELOPERPORTAL_USERNAME \
            -e KBC_DEVELOPERPORTAL_PASSWORD \
            quay.io/keboola/developer-portal-cli-v2:latest \
            update-app-property ${KBC_DEVELOPERPORTAL_VENDOR} ${KBC_DEVELOPERPORTAL_APP} loggerConfiguration --value="$value"
else
    echo "loggerConfiguration is empty!"
fi


================================================
FILE: src/component.py
================================================
import logging
import dateparser
import os
import re
from datetime import date
from datetime import timedelta
from typing import List

from google_ad_manager import GoogleAdManagerClient, GoogleAdManagerClientException
from keboola.utils.header_normalizer import get_normalizer, NormalizerStrategy
from keboola.component.base import ComponentBase, UserException
from googleads import errors as google_errors
from google.auth import exceptions

KEY_API_VERSION = "api_version"
KEY_CLIENT_EMAIL = "client_email"
KEY_PRIVATE_KEY = "#private_key"
KEY_TOKEN_URI = "token_uri"
KEY_NETWORK_CODE = "network_code"
KEY_REPORT_SETTINGS = "report_settings"
KEY_REPORT_NAME = "report_name"
KEY_METRICS = "metrics"
KEY_DIMENSIONS = "dimensions"
KEY_DIMENSION_ATTRIBUTES = "dimension_attributes"
KEY_DATE_RANGE_SETTINGS = "date_settings"
KEY_DATE_FROM = "date_from"
KEY_DATE_TO = "date_to"
KEY_DATE_RANGE = "date_range"
KEY_REPORT_CURRENCY = "report_currency"
KEY_AD_UNIT_VIEW = "ad_unit_view"

REQUIRED_PARAMETERS = [KEY_CLIENT_EMAIL, KEY_PRIVATE_KEY, KEY_TOKEN_URI, KEY_NETWORK_CODE, KEY_REPORT_SETTINGS,
                       KEY_REPORT_NAME, KEY_DATE_RANGE_SETTINGS]
REQUIRED_IMAGE_PARS = []

SUPPORTED_VERSIONS = ["v202408", "v202405", "v202402", "v202311"]


class Component(ComponentBase):
    def __init__(self):
        super().__init__(required_parameters=REQUIRED_PARAMETERS,
                         required_image_parameters=REQUIRED_IMAGE_PARS)

    def run(self):
        params = self.configuration.parameters

        client_email = params.get(KEY_CLIENT_EMAIL)
        private_key = params.get(KEY_PRIVATE_KEY).replace("\\n", '\n')
        token_uri = params.get(KEY_TOKEN_URI)
        network_code = params.get(KEY_NETWORK_CODE)
        report_name = params.get(KEY_REPORT_NAME)
        report_name = "".join([self._normalize_report_name(report_name), ".csv"])
        report_settings = params.get(KEY_REPORT_SETTINGS)
        metrics = self._parse_input_string_to_list(report_settings.get(KEY_METRICS))
        dimensions = self._parse_input_string_to_list(report_settings.get(KEY_DIMENSIONS))
        dimension_attributes = self._parse_input_string_to_list(report_settings.get(KEY_DIMENSION_ATTRIBUTES))
        report_currency = report_settings.get(KEY_REPORT_CURRENCY, None)
        ad_unit_view = report_settings.get(KEY_AD_UNIT_VIEW)
        date_settings = params.get(KEY_DATE_RANGE_SETTINGS, {})
        date_from = date_settings.get(KEY_DATE_FROM)
        date_to = date_settings.get(KEY_DATE_TO)
        date_range = date_settings.get(KEY_DATE_RANGE)

        if (api_version := params.get(KEY_API_VERSION)) is not None:
            if api_version not in SUPPORTED_VERSIONS:
                raise UserException(f"Unsupported API version: {api_version}, please use "
                                    f"one of: {SUPPORTED_VERSIONS} and save the configuration again")

        date_from, date_to, dynamic_date = self._get_date_range(date_from, date_to, date_range)

        try:
            client = GoogleAdManagerClient(client_email, private_key, token_uri, network_code, api_version)
        except ValueError as client_error:
            raise UserException(client_error) from client_error
        except exceptions.RefreshError as login_error:
            raise UserException(login_error) from login_error
        except GoogleAdManagerClientException as client_error:
            raise UserException(client_error) from client_error

        report_query = client.get_report_query(dimensions, metrics,
                                               dimension_attributes=dimension_attributes, date_from=date_from,
                                               date_to=date_to, dynamic_date=dynamic_date, currency=report_currency,
                                               ad_unit_view=ad_unit_view)
        try:
            result_file = client.fetch_report_result(report_query)
        except google_errors.GoogleAdsServerFault as google_error:
            raise UserException(google_error) from google_error
        except GoogleAdManagerClientException as client_error:
            raise UserException(client_error) from client_error

        filesize = os.path.getsize(result_file.name)
        if filesize == 0:
            raise UserException("No data found")

        table = self.create_out_table_definition(report_name, incremental=False)
        columns = self._write_results_get_columns(result_file.name, table.full_path)
        columns = self._normalize_column_names(columns)
        table.columns = columns

        self.write_tabledef_manifest(table)

    @staticmethod
    def _normalize_column_names(output_columns: List) -> List:
        header_normalizer = get_normalizer(strategy=NormalizerStrategy.DEFAULT, forbidden_sub="_")
        return header_normalizer.normalize_header(output_columns)

    @staticmethod
    def _write_results_get_columns(in_table_path: str, out_table_path: str) -> List:
        """Processes binary file to utf-8 and returns columns"""
        columns = []
        with open(out_table_path, mode='wt', encoding='utf-8') as new_file:
            with open(in_table_path, mode='rb') as original_file:
                for i, line in enumerate(original_file):
                    if i == 0:
                        columns = line.decode().strip().split(",")
                        # Do not write header to CSV file
                        continue
                    new_file.write(line.decode())
        return columns

    @staticmethod
    def _parse_input_string_to_list(input_string: str) -> List:
        input_string = re.sub(r"[^a-zA-Z0-9_,]", '', input_string)
        input_list = input_string.split(",")
        return [word.strip() for word in input_list]

    @staticmethod
    def _get_last_week_dates() -> (date, date):
        today = date.today()
        offset = (today.weekday() - 5) % 7
        last_week_saturday = today - timedelta(days=offset)
        last_week_sunday = last_week_saturday - timedelta(days=6)
        return last_week_sunday, last_week_saturday

    @staticmethod
    def _get_last_month_dates() -> (date, date):
        last_day_of_prev_month = date.today().replace(day=1) - timedelta(days=1)
        start_day_of_prev_month = date.today().replace(day=1) - timedelta(days=last_day_of_prev_month.day)
        return start_day_of_prev_month, last_day_of_prev_month

    def _get_date_range(self, date_from: str, date_to: str, date_range: str) -> (date, date, str):
        dynamic_date = ""
        if date_range == "Last week (sun-sat)":
            date_from, date_to = self._get_last_week_dates()
        elif date_range == "Last month":
            date_from, date_to = self._get_last_month_dates()
        elif date_range == "Custom":
            try:
                date_from = dateparser.parse(date_from).date()
                date_to = dateparser.parse(date_to).date()
            except (AttributeError, TypeError) as err:
                raise UserException("Failed to parse custom date") from err
        elif date_range == "Next week":
            dynamic_date = "NEXT_WEEK"
        elif date_range == "Next month":
            dynamic_date = "NEXT_MONTH"
        elif date_range == "Reach lifetime":
            dynamic_date = "REACH_LIFETIME"
        elif date_range == "Next day":
            dynamic_date = "NEXT_DAY"
        elif date_range == "Yesterday":
            dynamic_date = "YESTERDAY"
        else:
            logging.info("No date range specified")
        return date_from, date_to, dynamic_date

    @staticmethod
    def _normalize_report_name(report_name: str) -> str:
        header_normalizer = get_normalizer(strategy=NormalizerStrategy.DEFAULT, forbidden_sub="_")
        return header_normalizer.normalize_header([report_name])[0]


if __name__ == "__main__":
    try:
        comp = Component()
        comp.run()
    except UserException as exc:
        logging.exception(exc)
        exit(1)
    except Exception as exc:
        logging.exception(exc)
        exit(2)



================================================
FILE: src/google_ad_manager/__init__.py
================================================
from .client import GoogleAdManagerClient, GoogleAdManagerClientException  # noqa



================================================
FILE: src/google_ad_manager/client.py
================================================
import logging

import googleads.errors
import yaml
import json
import tempfile
from retry import retry
from typing import List
from datetime import date
from googleads import ad_manager
from googleads import errors
from googleads.common import ZeepServiceProxy


class GoogleAdManagerClientException(Exception):
    pass


class GoogleAdManagerClient:

    def __init__(self, client_email, private_key, token_uri, network_code, api_version):
        logging.info(f"Using version of Google Ad Manager API: {api_version}")

        private_key_file = self.get_private_key_file(private_key, client_email, token_uri)

        self.api_version = api_version
        self.client = self.get_client(network_code, private_key_file)
        self.report_downloader = self.client.GetDataDownloader(version=self.api_version)

    @staticmethod
    def get_client(network_code: str, private_key_file: str) -> ad_manager.AdManagerClient:
        try:
            client = ad_manager.AdManagerClient.LoadFromString(yaml.dump({
                "ad_manager": {
                    "application_name": "kds-team.ex-google-ad-manager",
                    "network_code": network_code,
                    "path_to_private_key_file": private_key_file
                }
            }))
        except ValueError as e:
            raise GoogleAdManagerClientException(f"{e} Please, check format of your private key. "
                                                 f"New lines must be delimited by \\n character.") from e

        client.cache = ZeepServiceProxy.NO_CACHE
        return client

    @staticmethod
    def get_private_key_file(private_key: str, client_email: str, token_uri: str) -> str:
        file_path = "/tmp/private_key.json"
        with open(file_path, 'w') as outfile:
            json.dump({
                "private_key": private_key,
                "client_email": client_email,
                "token_uri": token_uri
            }, outfile)
        return file_path

    def get_report_query(self, dimensions: List, metrics: List, dimension_attributes: List = None,
                         ad_unit_view: str = "", currency: str = "", date_from: date = "", date_to: date = "",
                         dynamic_date: str = "", include_zero_impressions: bool = False) -> dict:

        report_query = {
            'dimensions': dimensions,
            'columns': metrics
        }

        if currency:
            report_query['reportCurrency'] = currency

        if dynamic_date:
            report_query["dateRangeType"] = dynamic_date
        elif date_from and date_to:
            report_query['dateRangeType'] = "CUSTOM_DATE"
            report_query['startDate'] = date_from
            report_query['endDate'] = date_to

        if dimension_attributes:
            report_query['dimensionAttributes'] = dimension_attributes

        if ad_unit_view:
            report_query['adUnitView'] = ad_unit_view

        if include_zero_impressions:
            report_query['include_zero_impressions'] = True

        logging.info(f"Running query : {report_query}")
        return report_query

    @retry(errors.GoogleAdsServerFault, tries=5, delay=30)
    def fetch_report_result(self, report_query: dict) -> tempfile.NamedTemporaryFile:
        report_file = tempfile.NamedTemporaryFile(suffix='.csv', delete=False)
        report_job = {'reportQuery': report_query}
        report_job_id = self.create_report(report_job)

        try:
            self.report_downloader.DownloadReportToFile(
                report_job_id=report_job_id,
                export_format='CSV_DUMP',
                outfile=report_file,
                use_gzip_compression=False)
        except errors.GoogleAdsServerFault as e:
            raise errors.GoogleAdsServerFault(f"Google Server Error occured : {e}") from e

        report_file.close()

        return report_file

    def create_report(self, report_job: dict):
        """Create report via API"""
        try:
            return self.report_downloader.WaitForReport(report_job)
        except errors.AdManagerReportError as e:
            raise GoogleAdManagerClientException(f'Failed to generate report. Error: {e}') from e
        except KeyError as e:
            raise GoogleAdManagerClientException(f"Failed to generate report. Please check used dimensions, "
                                                 f"metrics and used api version, Error: {e}") from e
        except googleads.errors.GoogleAdsServerFault as e:
            raise GoogleAdManagerClientException(f"Failed to generate report. Please check used dimensions, "
                                                 f"metrics and used api version, Error: {e}") from e
        except googleads.errors.GoogleAdsValueError() as e:
            raise GoogleAdManagerClientException(f"Failed to generate report. Selected API version is probably "
                                                 f"deprecated. Error: {e} from e")



================================================
FILE: tests/__init__.py
================================================
import sys
import os
sys.path.append(os.path.dirname(os.path.realpath(__file__)) + "/../src")


================================================
FILE: tests/test_component.py
================================================
'''
Created on 12. 11. 2018

@author: esner
'''
import unittest
import mock
import os
from freezegun import freeze_time

from component import Component


class TestComponent(unittest.TestCase):

    # set global time to 2010-10-10 - affects functions like datetime.now()
    @freeze_time("2010-10-10")
    # set KBC_DATADIR env to non-existing dir
    @mock.patch.dict(os.environ, {'KBC_DATADIR': './non-existing-dir'})
    def test_run_no_cfg_fails(self):
        with self.assertRaises(ValueError):
            comp = Component()
            comp.run()


if __name__ == "__main__":
    # import sys;sys.argv = ['', 'Test.testName']
    unittest.main()


