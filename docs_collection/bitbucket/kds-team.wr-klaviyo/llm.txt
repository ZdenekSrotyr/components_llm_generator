Directory structure:
└── kds_consulting_team-kds-team.wr-klaviyo/
    ├── README.md
    ├── bitbucket-pipelines.yml
    ├── change_log.md
    ├── deploy.sh
    ├── docker-compose.yml
    ├── Dockerfile
    ├── flake8.cfg
    ├── LICENSE.md
    ├── requirements.txt
    ├── component_config/
    │   ├── component_long_description.md
    │   ├── component_short_description.md
    │   ├── configSchema.json
    │   ├── configuration_description.md
    │   ├── stack_parameters.json
    │   └── sample-config/
    │       ├── config.json
    │       └── in/
    │           ├── state.json
    │           ├── files/
    │           │   └── order1.xml
    │           └── tables/
    │               ├── test.csv
    │               └── test.csv.manifest
    ├── scripts/
    │   ├── build_n_run.ps1
    │   ├── build_n_test.sh
    │   ├── run.bat
    │   ├── run_kbc_tests.ps1
    │   └── update_dev_portal_properties.sh
    ├── src/
    │   ├── component.py
    │   └── klaviyo.py
    └── tests/
        ├── __init__.py
        └── test_component.py

================================================
FILE: README.md
================================================
# Klaviyo Writer

Creating/Updating customer profiles, and mangaing list memeberships and subscriptions on the [Klaviyo email marketing platform](https://www.klaviyo.com/?utm_source=google&utm_campaign=Branded-Klaviyo-Search&utm_term=klaviyo&utm_medium=paid&match=e&gclid=CjwKCAiA-f78BRBbEiwATKRRBA6z61AGOOHNWVxlT1MQsxdYa28smyXg03o7QSWQ-KUqohg_8Y8--BoCg_EQAvD_BwE)

## Klaviyo API Documentation
[Klaviyo API](https://www.klaviyo.com/docs)

## Configurations
The Klaviyo writer will be using the tables configured in the input mapping for the requests. Each row in the table will be constructed as one request. Each column in the table will be construct as a JSON formatted key value pair with the column name as the property name while the column value as the property value. Any `empty` property value for that perspective column will `NOT` be included in the requests. 

## Parameters

1. API Token
    - Your Klaviyo Account API Token
    - To Fetch your API Token:
      1. Log into your Klaviyo platform
      2. Your profile name (top right)
      3. Account
      4. Settings
      5. API Keys
      6. Create API Key (if required)

2. Endpoint
    1. [Update Profile Attributes](https://www.klaviyo.com/docs/api/people)
        - Add or update one or more attirbutes ofr a person based on Person ID
        - If a property already exists, it will be updated
        - If a property is not set for that record, it will be created
        - To add a new profile into the Profile Pool, the profile will need to be added be using **Subscribe Profiles to List** or **Add Profiles to List**
        - Required column in input mapping
            1. id
        - Any properties not listed belong will be submitted as a custom property
            1. email
            2. first_name
            3. last_name
            4. phone_number
            5. title
            6. organization
            7. city
            8. region
            9. zip
            10. image

    2. [Subscribe Profiles to List](https://www.klaviyo.com/docs/api/v2/lists#post-subscribe)
        - Subscribe or re-subscribe profiles to a list
        - Request `must` contain `one of` properties below:
            1. email
            2. phone_number
        - If you are a GDPR compliant business, you will need to include `$consent`
            - Supported `$consent` value
                1. email
                2. web
                3. sms
                4. directmail
                5. mobile
            - If the cell value for `$consent` is none of the above, the respective consent column and value will be submitted as a custom property

    3. [Add Profiles to List](https://www.klaviyo.com/docs/api/v2/lists#post-members)
        - Add profiles to a list
        - This endpoint is functionally equivalent to adding profiles to a list via a CSV upload and will immediately add profiles to the list
        - Request `must` contain `one of` properties below:
            1. email
            2. phone_number


================================================
FILE: bitbucket-pipelines.yml
================================================
options:
  docker: true

pipelines:
  default:
    - step:
        script:
          - export APP_IMAGE=$APP_IMAGE
          - docker build . --tag=$APP_IMAGE
          - docker images
          - docker -v
          - docker run $APP_IMAGE flake8 /code/ --config=/code/flake8.cfg
          - echo "Running unit-tests..."
          - docker run $APP_IMAGE python -m unittest discover
          # push test image to ecr - uncomment for testing before deployment
#          - echo 'Pushing test image to repo. [tag=test]'
#          - export REPOSITORY=`docker run --rm -e KBC_DEVELOPERPORTAL_USERNAME -e KBC_DEVELOPERPORTAL_PASSWORD -e KBC_DEVELOPERPORTAL_URL quay.io/keboola/developer-portal-cli-v2:latest ecr:get-repository $KBC_DEVELOPERPORTAL_VENDOR $KBC_DEVELOPERPORTAL_APP`
#          - docker tag $APP_IMAGE:latest $REPOSITORY:test
#          - eval $(docker run --rm -e KBC_DEVELOPERPORTAL_USERNAME -e KBC_DEVELOPERPORTAL_PASSWORD -e KBC_DEVELOPERPORTAL_URL quay.io/keboola/developer-portal-cli-v2:latest ecr:get-login $KBC_DEVELOPERPORTAL_VENDOR $KBC_DEVELOPERPORTAL_APP)
#          - docker push $REPOSITORY:test

  branches:
    master:
      - step:
          script:
            - export APP_IMAGE=$APP_IMAGE
            - docker build . --tag=$APP_IMAGE
            - docker images
            - docker -v
            - docker run $APP_IMAGE flake8 /code/ --config=/code/flake8.cfg
            - echo "Running unit-tests..."
            - docker run $APP_IMAGE python -m unittest discover
            # push test image to ecr - uncomment for testing before deployment
#            - echo 'Pushing test image to repo. [tag=test]'
#            - export REPOSITORY=`docker run --rm -e KBC_DEVELOPERPORTAL_USERNAME -e KBC_DEVELOPERPORTAL_PASSWORD -e KBC_DEVELOPERPORTAL_URL quay.io/keboola/developer-portal-cli-v2:latest ecr:get-repository $KBC_DEVELOPERPORTAL_VENDOR $KBC_DEVELOPERPORTAL_APP`
#            - docker tag $APP_IMAGE:latest $REPOSITORY:test
#            - eval $(docker run --rm -e KBC_DEVELOPERPORTAL_USERNAME -e KBC_DEVELOPERPORTAL_PASSWORD -e KBC_DEVELOPERPORTAL_URL quay.io/keboola/developer-portal-cli-v2:latest ecr:get-login $KBC_DEVELOPERPORTAL_VENDOR $KBC_DEVELOPERPORTAL_APP)
#            - docker push $REPOSITORY:test
            - ./scripts/update_dev_portal_properties.sh
  tags:
    '*':
      - step:
          deployment: production
          script:
            - export APP_IMAGE=$APP_IMAGE
            - docker build . --tag=$APP_IMAGE
            - docker images
            - docker run $APP_IMAGE flake8 /code/ --config=/code/flake8.cfg
            - echo "Running unit-tests..."
            - docker run $APP_IMAGE python -m unittest discover
            - echo "Preparing KBC test image"
            - docker pull quay.io/keboola/developer-portal-cli-v2:latest
            # push test image to ECR - uncomment when initialised
            # - export REPOSITORY=`docker run --rm -e KBC_DEVELOPERPORTAL_USERNAME -e KBC_DEVELOPERPORTAL_PASSWORD -e KBC_DEVELOPERPORTAL_URL quay.io/keboola/developer-portal-cli-v2:latest ecr:get-repository $KBC_DEVELOPERPORTAL_VENDOR $KBC_DEVELOPERPORTAL_APP`
            # - docker tag $APP_IMAGE:latest $REPOSITORY:test
            # - eval $(docker run --rm -e KBC_DEVELOPERPORTAL_USERNAME -e KBC_DEVELOPERPORTAL_PASSWORD -e KBC_DEVELOPERPORTAL_URL quay.io/keboola/developer-portal-cli-v2:latest ecr:get-login $KBC_DEVELOPERPORTAL_VENDOR $KBC_DEVELOPERPORTAL_APP)
            # - docker push $REPOSITORY:test
            # - docker run --rm -e KBC_STORAGE_TOKEN quay.io/keboola/syrup-cli:latest run-job $KBC_DEVELOPERPORTAL_APP $BASE_KBC_CONFIG test
            # - docker run --rm -e KBC_STORAGE_TOKEN quay.io/keboola/syrup-cli:latest run-job $KBC_DEVELOPERPORTAL_APP $KBC_CONFIG_1 test
            - ./scripts/update_dev_portal_properties.sh
            - ./deploy.sh


================================================
FILE: change_log.md
================================================
**0.1.1**

- fix requirements
- add src folder to path for tests

**0.1.0**

- src folder structure
- remove dependency on handler lib - import the code directly to enable modifications until its released

**0.0.2**

- add dependency to base lib
- basic tests

**0.0.1**

- add utils scripts
- move kbc tests directly to pipelines file
- use uptodate base docker image
- add changelog



================================================
FILE: deploy.sh
================================================
#!/bin/sh
set -e

#check if deployment is triggered only in master
if [ $BITBUCKET_BRANCH != "master" ]; then
               echo Deploy on tagged commit can be only executed in master!
               exit 1
fi

# Obtain the component repository and log in
docker pull quay.io/keboola/developer-portal-cli-v2:latest
export REPOSITORY=`docker run --rm  \
    -e KBC_DEVELOPERPORTAL_USERNAME \
    -e KBC_DEVELOPERPORTAL_PASSWORD \
    quay.io/keboola/developer-portal-cli-v2:latest \
    ecr:get-repository ${KBC_DEVELOPERPORTAL_VENDOR} ${KBC_DEVELOPERPORTAL_APP}`

eval $(docker run --rm \
    -e KBC_DEVELOPERPORTAL_USERNAME \
    -e KBC_DEVELOPERPORTAL_PASSWORD \
    quay.io/keboola/developer-portal-cli-v2:latest \
    ecr:get-login ${KBC_DEVELOPERPORTAL_VENDOR} ${KBC_DEVELOPERPORTAL_APP})

# Push to the repository
docker tag ${APP_IMAGE}:latest ${REPOSITORY}:${BITBUCKET_TAG}
docker tag ${APP_IMAGE}:latest ${REPOSITORY}:latest
docker push ${REPOSITORY}:${BITBUCKET_TAG}
docker push ${REPOSITORY}:latest

# Update the tag in Keboola Developer Portal -> Deploy to KBC
if echo ${BITBUCKET_TAG} | grep -c '^v\?[0-9]\+\.[0-9]\+\.[0-9]\+$'
then
    docker run --rm \
        -e KBC_DEVELOPERPORTAL_USERNAME \
        -e KBC_DEVELOPERPORTAL_PASSWORD \
        quay.io/keboola/developer-portal-cli-v2:latest \
        update-app-repository ${KBC_DEVELOPERPORTAL_VENDOR} ${KBC_DEVELOPERPORTAL_APP} ${BITBUCKET_TAG} ecr ${REPOSITORY}
else
    echo "Skipping deployment to KBC, tag ${BITBUCKET_TAG} is not allowed."
fi



================================================
FILE: docker-compose.yml
================================================
version: "2"
services:
  # for development purposes
  dev:
    build: .
    volumes:
        - ./:/code
        - ./data:/data
    environment:
      - KBC_DATADIR=./data
  test:
    # Use to run flake8 and unittests checks
    build: .
    volumes:
      - ./:/code
      - ./data:/data
    environment:
      - KBC_DATADIR=./data
    command:
      - /bin/sh
      - /code/scripts/build_n_test.sh


================================================
FILE: Dockerfile
================================================
FROM python:3.7.2-slim
ENV PYTHONIOENCODING utf-8

COPY . /code/

# install gcc to be able to build packages - e.g. required by regex, dateparser, also required for pandas
RUN apt-get update && apt-get install -y build-essential

RUN pip install --upgrade pip

RUN pip install flake8

RUN pip install -r /code/requirements.txt

WORKDIR /code/


CMD ["python", "-u", "/code/src/component.py"]



================================================
FILE: flake8.cfg
================================================
[flake8]
exclude =
    .git,
    __pycache__,
    tests
max-line-length = 120

# F812: list comprehension redefines ...
# H101: Use TODO(NAME)
# H202: assertRaises Exception too broad
# H233: Python 3.x incompatible use of print operator
# H301: one import per line
# H306: imports not in alphabetical order (time, os)
# H401: docstring should not start with a space
# H403: multi line docstrings should end on a new line
# H404: multi line docstring should start without a leading new line
# H405: multi line docstring summary not separated with an empty line
# H501: Do not use self.__dict__ for string formatting



================================================
FILE: LICENSE.md
================================================
Copyright (c) 2018 Keboola DS

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files, to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is furnished
to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
THE SOFTWARE.


================================================
FILE: requirements.txt
================================================
https://bitbucket.org/kds_consulting_team/keboola-python-util-lib/get/0.2.10.zip#egg=kbc
logging_gelf==0.0.18
mock
freezegun
pandas


================================================
FILE: component_config/component_long_description.md
================================================
Creating/Updating customer profiles, and mangaing list memeberships and subscriptions on the [Klaviyo email marketing platform](https://www.klaviyo.com/?utm_source=google&utm_campaign=Branded-Klaviyo-Search&utm_term=klaviyo&utm_medium=paid&match=e&gclid=CjwKCAiA-f78BRBbEiwATKRRBA6z61AGOOHNWVxlT1MQsxdYa28smyXg03o7QSWQ-KUqohg_8Y8--BoCg_EQAvD_BwE)

## Klaviyo API Documentation
[Klaviyo API](https://www.klaviyo.com/docs)

## Configurations
The Klaviyo writer will be using the tables configured in the input mapping for the requests. Each row in the table will be constructed as one request. Each column in the table will be construct as a JSON formatted key value pair with the column name as the property name while the column value as the property value. Any `empty` property value for that perspective column will `NOT` be included in the requests. 

## Parameters

1. API Token
    - Your Klaviyo Account API Token
    - To Fetch your API Token:
      1. Log into your Klaviyo platform
      2. Your profile name (top right)
      3. Account
      4. Settings
      5. API Keys
      6. Create API Key (if required)

2. Endpoint
    1. [Update Profile Attributes](https://www.klaviyo.com/docs/api/people)
        - Add or update one or more attirbutes ofr a person based on Person ID
        - If a property already exists, it will be updated
        - If a property is not set for that record, it will be created
        - To add a new profile into the Profile Pool, the profile will need to be added be using **Subscribe Profiles to List** or **Add Profiles to List**
        - Required column in input mapping
            1. id
        - Any properties not listed belong will be submitted as a custom property
            1. email
            2. first_name
            3. last_name
            4. phone_number
            5. title
            6. organization
            7. city
            8. region
            9. zip
            10. image

    2. [Subscribe Profiles to List](https://www.klaviyo.com/docs/api/v2/lists#post-subscribe)
        - Subscribe or re-subscribe profiles to a list
        - Request `must` contain `one of` properties below:
            1. email
            2. phone_number
        - If you are a GDPR compliant business, you will need to include `$consent`
            - Supported `$consent` value
                1. email
                2. web
                3. sms
                4. directmail
                5. mobile
            - If the cell value for `$consent` is none of the above, the respective consent column and value will be submitted as a custom property

    3. [Add Profiles to List](https://www.klaviyo.com/docs/api/v2/lists#post-members)
        - Add profiles to a list
        - This endpoint is functionally equivalent to adding profiles to a list via a CSV upload and will immediately add profiles to the list
        - Request `must` contain `one of` properties below:
            1. email
            2. phone_number


================================================
FILE: component_config/component_short_description.md
================================================
Managing customer resources for Klaviyo platform


================================================
FILE: component_config/configSchema.json
================================================
{
    "type": "object",
    "title": "extractor configuration",
    "required": [
        "#api_token",
        "endpoint",
        "list_id"
    ],
    "properties": {
        "#api_token": {
            "type": "string",
            "title": "API token",
            "format": "password",
            "propertyOrder": 100
        },
        "endpoint": {
            "type": "string",
            "title": "Endpoint",
            "propertyOrder": 200,
            "enum": [
                "add_update_profile",
                "subscribe_profiles_to_list",
                "add_profiles_to_list"
            ],
            "options": {
                "enum_titles": [
                    "Update Profile Attributes",
                    "Subscribe Profiles to List",
                    "Add Profiles to List"
                ]
            }
        },
        "list_id": {
            "type": "string",
            "title": "List ID",
            "propertyOrder": 300,
            "description": "Required when Endpoint [Subscribe Profiles to List] or [Add Profiles to List] is selected."
        }
    }
}


================================================
FILE: component_config/configuration_description.md
================================================
## Parameters

1. API Token
    - Your Klaviyo Account API Token
    - To Fetch your API Token:
      1. Log into your Klaviyo platform
      2. Your profile name (top right)
      3. Account
      4. Settings
      5. API Keys
      6. Create API Key (if required)

2. Endpoint
    1. [Update Profile Attributes](https://www.klaviyo.com/docs/api/people)
        - Add or update one or more attirbutes ofr a person based on Person ID
        - If a property already exists, it will be updated
        - If a property is not set for that record, it will be created
        - To add a new profile into the Profile Pool, the profile will need to be added be using **Subscribe Profiles to List** or **Add Profiles to List**
        - Required column in input mapping
            1. id
        - Any properties not listed belong will be submitted as a custom property
            1. email
            2. first_name
            3. last_name
            4. phone_number
            5. title
            6. organization
            7. city
            8. region
            9. zip
            10. image

    2. [Subscribe Profiles to List](https://www.klaviyo.com/docs/api/v2/lists#post-subscribe)
        - Subscribe or re-subscribe profiles to a list
        - Request `must` contain `one of` properties below:
            1. email
            2. phone_number
        - If you are a GDPR compliant business, you will need to include `$consent`
            - Supported `$consent` value
                1. email
                2. web
                3. sms
                4. directmail
                5. mobile
            - If the cell value for `$consent` is none of the above, the respective consent column and value will be submitted as a custom property

    3. [Add Profiles to List](https://www.klaviyo.com/docs/api/v2/lists#post-members)
        - Add profiles to a list
        - This endpoint is functionally equivalent to adding profiles to a list via a CSV upload and will immediately add profiles to the list
        - Request `must` contain `one of` properties below:
            1. email
            2. phone_number


================================================
FILE: component_config/stack_parameters.json
================================================
{}


================================================
FILE: component_config/sample-config/config.json
================================================
{
  "storage": {
    "input": {
      "files": [],
      "tables": [
        {
          "source": "in.c-test.test",
          "destination": "test.csv",
          "limit": 50,
          "columns": [],
          "where_values": [],
          "where_operator": "eq"
        }
      ]
    },
    "output": {
      "files": [],
      "tables": []
    }
  },
  "parameters": {
    "#api_token": "demo",
    "period_from": "yesterday",
    "endpoints": [
      "deals",
      "companies"
    ],
    "company_properties": "",
    "deal_properties": "",
    "debug": true
  },
  "image_parameters": {
    "syrup_url": "https://syrup.keboola.com/"
  },
  "authorization": {
    "oauth_api": {
      "id": "OAUTH_API_ID",
      "credentials": {
        "id": "main",
        "authorizedFor": "Myself",
        "creator": {
          "id": "1234",
          "description": "me@keboola.com"
        },
        "created": "2016-01-31 00:13:30",
        "#data": "{\"refresh_token\":\"MCWBkfdK9m5YK*Oqahwm6XN6elMAEwcH5kYcK8Ku!bpiOgSDZN9MQIzunpMsh6LyKH0i!7OcwwwajuxPfvm2PrrWYSs*HerDr2ZSJ39pqHJcvwUNIvHdtcgFFr3Em*yhn3GKBwM2p9UrjtgdAriSDny5YgUYGuI3gYJY1ypD*wBaAOzzeeXZx6CdgjruJ7gboTAngbWk3CzO9rORIwXAAlGUH6ZgBQJL3AwkYVMRFV4BvIvDAMF*0DcGDyrcyYDw9X3vYn*Wy!OqgrenKCGowdJk0C0136SUv4PJI383y76UMim6Q7KGDj7Lf!K2N2FDbxsz2iZKZTBr2vHx8pEC1oBc$\"}",
        "oauthVersion": "2.0",
        "appKey": "000000004C184A49",
        "#appSecret": "vBAYak49pVK1zghHAgDH4tCSCNlT-CiN"
      }
    }
  }
}



================================================
FILE: component_config/sample-config/in/state.json
================================================
{"data_delta": "10222018"}


================================================
FILE: component_config/sample-config/in/files/order1.xml
================================================
<?xml version='1.0' ?>
<root_el>
    <orders>
        <order>
            <id>1</id>
            <date>2018-01-01</date>
            <cust_name>David</cust_name>	
            <order-item>
                <price currency="CZK">100</price>
                <item>Umbrella</item>
            </order-item>
            <order-item>
                <price currency="CZK">200</price>
                <item>Rain Coat</item>
            </order-item>
        </order>
    </orders>
</root_el>


================================================
FILE: component_config/sample-config/in/tables/test.csv
================================================
"Type","Campaign_Name","Status","Start_Date","End_Date","Location","Eventbrite_link"
"Event","How to become data driven startup","Complete","2015-10-13","2015-10-13","United Kingdom","https://www.eventbrite.co.uk/e/how-to-become-data-driven-startup-registration-18711425377"
"Event","How to become data driven startup","Complete","2015-11-04","2015-11-04","United Kingdom","https://www.eventbrite.co.uk/e/how-to-become-data-driven-startup-registration-18711426380"
"Event","How to become data driven startup","Complete","2015-10-13","2015-10-13","United Kingdom","https://www.eventbrite.co.uk/e/how-to-become-data-driven-startup-registration-18711425377"
"Event","How to become data driven startup","Complete","2015-11-04","2015-11-04","United Kingdom","https://www.eventbrite.co.uk/e/how-to-become-data-driven-startup-registration-18711426380"
"Event","DATAGIRLS PRESENT: HOW TO BECOME DATA-DRIVEN","Complete","2016-01-14","2016-01-14","United Kingdom","https://www.eventbrite.co.uk/e/datagirls-present-how-to-become-data-driven-tickets-20152992142"
"Event","DATAGIRLS PRESENT: HOW TO BECOME DATA-DRIVEN","Complete","2016-02-25","2016-02-25","United Kingdom","https://www.eventbrite.co.uk/e/datagirls-present-how-to-become-data-driven-tickets-20967439175"
"Event","Data Tools for Startups","Complete","2016-03-17","2016-03-17","United Kingdom","https://www.eventbrite.co.uk/e/data-tools-for-startups-tickets-21257426535"
"Event","Data Festival London 2016","Complete","2016-06-24","2016-06-26","United Kingdom","https://www.eventbrite.co.uk/e/data-festival-london-2016-tickets-25192608771"
"Event","Becoming data driven in the high street fashion","Complete","2016-10-12","2016-10-12","United Kingdom","https://www.eventbrite.co.uk/e/becoming-data-driven-in-the-high-street-fashion-tickets-27481268213"
"Event","The Data Foundry present: DATAGIRLS Weekend","Complete","2016-10-14","2016-10-16","United Kingdom","https://www.eventbrite.co.uk/e/the-data-foundry-present-datagirls-weekend-tickets-27350069795"
"Event","[NLP] How to analyse text data for knowledge discovery","Complete","2017-04-10","2017-04-10","United Kingdom","https://www.eventbrite.co.uk/e/nlp-how-to-analyse-text-data-for-knowledge-discovery-tickets-32320274812"
"Event","Keboola DataBrunch - Amazon Go a ako s ním v maloobchode “bojovať”","Complete","2017-03-09","2017-03-09","Slovakia","https://www.eventbrite.co.uk/e/keboola-databrunch-amazon-go-a-ako-s-nim-v-maloobchode-bojovat-tickets-31827553068"
"Event","Keboola DataBrunch - Amazon Go a jak s nim v maloobchodě “bojovat”","Complete","2017-03-29","2017-03-29","Czech Republic","https://www.eventbrite.co.uk/e/keboola-databrunch-amazon-go-a-jak-s-nim-v-maloobchode-bojovat-tickets-32182393405"
"Event","The Data Foundry present: DATAGIRLS Weekend","Complete","2016-10-14","2016-10-16","United Kingdom","https://www.eventbrite.co.uk/e/the-data-foundry-present-datagirls-weekend-tickets-27350069795"
"Event","[NLP] How to analyse text data for knowledge discovery","Complete","2017-04-10","2017-04-10","United Kingdom","https://www.eventbrite.co.uk/e/nlp-how-to-analyse-text-data-for-knowledge-discovery-tickets-32320274812"
"Event","Keboola Data Brunch - KPIs and AmazonGo, budoucnost retailu? ","Complete","2017-06-27","2017-06-27","Czech Republic","https://www.eventbrite.co.uk/e/keboola-data-brunch-kpis-amazongo-budoucnost-retailu-tickets-35257195220"
"Event","Learn how to #DoMoreWithData with DataGirls","Complete","2017-10-01","2017-10-01","United Kingdom","https://www.eventbrite.co.uk/e/learn-how-to-domorewithdata-with-datagirls-tickets-36777944823"
"Event","Are You Using Data to Understand Your Customers? ","Complete","2018-02-27","2018-02-27","United Kingdom","https://www.eventbrite.co.uk/e/are-you-using-data-to-understand-your-customers-tickets-42000160611"
"Event","Conversion Rate Optimisation in Travel Industry","Complete","2018-01-30","2018-01-30","United Kingdom","https://www.eventbrite.co.uk/e/conversion-rate-optimisation-in-travel-industry-tickets-38951076719"
"Event","Learn how to #DoMoreWithData with DataGirls","Complete","2017-10-01","2017-10-01","United Kingdom","https://www.eventbrite.co.uk/e/learn-how-to-domorewithdata-with-datagirls-tickets-36777944823"
"Event","Are You Using Data to Understand Your Customers? ","Complete","2018-02-27","2018-02-27","United Kingdom","https://www.eventbrite.co.uk/e/are-you-using-data-to-understand-your-customers-tickets-42000160611"



================================================
FILE: component_config/sample-config/in/tables/test.csv.manifest
================================================
{
    "id": "in.c-test.test",
    "uri": "https:\/\/connection.keboola.com\/v2\/storage\/tables\/in.c-test.test",
    "name": "test",
    "primary_key": [],
    "indexed_columns": [],
    "created": "2018-03-02T15:36:50+0100",
    "last_change_date": "2018-03-02T15:36:54+0100",
    "last_import_date": "2018-03-02T15:36:54+0100",
    "rows_count": 0,
    "data_size_bytes": 0,
    "is_alias": false,
    "attributes": [],
    "columns": [
        "Type",
        "Campaign_Name",
        "Status",
        "Start_Date",
        "End_Date",
        "Location",
        "Eventbrite_link"
    ],
    "metadata": [
        {
            "id": "18271581",
            "key": "KBC.createdBy.component.id",
            "value": "transformation",
            "provider": "system",
            "timestamp": "2018-03-02T15:37:02+0100"
        },
        {
            "id": "18271582",
            "key": "KBC.createdBy.configuration.id",
            "value": "361585608",
            "provider": "system",
            "timestamp": "2018-03-02T15:37:02+0100"
        },
        {
            "id": "18271583",
            "key": "KBC.createdBy.configurationRow.id",
            "value": "361585762",
            "provider": "system",
            "timestamp": "2018-03-02T15:37:02+0100"
        },
        {
            "id": "18271584",
            "key": "KBC.lastUpdatedBy.component.id",
            "value": "transformation",
            "provider": "system",
            "timestamp": "2018-03-02T15:37:02+0100"
        },
        {
            "id": "18271585",
            "key": "KBC.lastUpdatedBy.configuration.id",
            "value": "361585608",
            "provider": "system",
            "timestamp": "2018-03-02T15:37:02+0100"
        },
        {
            "id": "18271586",
            "key": "KBC.lastUpdatedBy.configurationRow.id",
            "value": "361585762",
            "provider": "system",
            "timestamp": "2018-03-02T15:37:02+0100"
        }
    ],
    "column_metadata": {
        "Type": [],
        "Campaign_Name": [],
        "Status": [],
        "Start_Date": [],
        "End_Date": [],
        "Location": [],
        "Eventbrite_link": []
    }
}


================================================
FILE: scripts/build_n_run.ps1
================================================
echo Building component...
$COMP_TAG = Read-Host -Prompt 'Input Docker tag name:'
docker build -rm -t $COMP_TAG ../

echo Running component...
Write-host "Would you like to use default data folder? (../data)" -ForegroundColor Yellow 
    $Readhost = Read-Host " ( y / n ) " 
    Switch ($ReadHost) 
     { 
       Y {Write-host "Yes use: " (join-path (Split-Path -Path (Get-Location).Path) "data"); $DATA_PATH = (join-path (Split-Path -Path (Get-Location).Path) "data") } 
       N {Write-Host "No, I'll specify myself"; $DATA_PATH = Read-Host -Prompt 'Input data folder path:'} 
       Default {Write-Host "Default, run app"; docker run -v $DATA_PATH`:/data -e KBC_DATADIR=/data $COMP_TAG} 
     } 

Write-host "Would you like to execute the container to Bash, skipping the execution?" -ForegroundColor Yellow 
    $Readhost = Read-Host " ( y / n ) " 
    Switch ($ReadHost) 
     { 
       Y {Write-host "Yes, get me to the bash"; docker run -ti -v $DATA_PATH`:/data --entrypoint=//bin//bash $COMP_TAG} 
       N {Write-Host "No, execute the app normally"; 
		    echo $DATA_PATH
			docker run -v $DATA_PATH`:/data -e KBC_DATADIR=/data $COMP_TAG
	   } 
       Default {Write-Host "Default, run app"; docker run -v $DATA_PATH`:/data -e KBC_DATADIR=/data $COMP_TAG} 
     } 





================================================
FILE: scripts/build_n_test.sh
================================================
#!/bin/sh
set -e

flake8 --config=flake8.cfg
python -m unittest discover


================================================
FILE: scripts/run.bat
================================================
@echo off

echo Running component...
docker run -v %cd%:/data -e KBC_DATADIR=/data comp-tag


================================================
FILE: scripts/run_kbc_tests.ps1
================================================
echo "Preparing KBC test image"
# set env vars
$KBC_DEVELOPERPORTAL_USERNAME  = Read-Host -Prompt 'Input your service account user name'
$KBC_DEVELOPERPORTAL_PASSWORD  = Read-Host -Prompt 'Input your service account pass'
$KBC_DEVELOPERPORTAL_VENDOR = 'esnerda'
$KBC_DEVELOPERPORTAL_APP = 'esnerda.ex-gusto-export'
$BASE_KBC_CONFIG = '455568423'
$KBC_STORAGE_TOKEN = Read-Host -Prompt 'Input your storage token'


#build app
$APP_IMAGE='keboola-comp-test'
docker build ..\ --tag=$APP_IMAGE
docker images
docker -v
#docker run $APP_IMAGE flake8 --config=./deployment/flake8.cfg
echo "Running unit-tests..."
docker run $APP_IMAGE python -m unittest discover

docker pull quay.io/keboola/developer-portal-cli-v2:latest
$REPOSITORY= docker run --rm -e KBC_DEVELOPERPORTAL_USERNAME=$KBC_DEVELOPERPORTAL_USERNAME -e KBC_DEVELOPERPORTAL_PASSWORD=$KBC_DEVELOPERPORTAL_PASSWORD quay.io/keboola/developer-portal-cli-v2:latest ecr:get-repository $KBC_DEVELOPERPORTAL_VENDOR $KBC_DEVELOPERPORTAL_APP

docker tag $APP_IMAGE`:latest $REPOSITORY`:test

echo 'running login'
$(docker run --rm -e KBC_DEVELOPERPORTAL_USERNAME=$KBC_DEVELOPERPORTAL_USERNAME -e KBC_DEVELOPERPORTAL_PASSWORD=$KBC_DEVELOPERPORTAL_PASSWORD -e KBC_DEVELOPERPORTAL_URL quay.io/keboola/developer-portal-cli-v2:latest ecr:get-login $KBC_DEVELOPERPORTAL_VENDOR $KBC_DEVELOPERPORTAL_APP)

echo 'pushing test image'
docker push $REPOSITORY`:test

echo 'running test config in KBC'
docker run --rm -e KBC_STORAGE_TOKEN=$KBC_STORAGE_TOKEN quay.io/keboola/syrup-cli:latest run-job $KBC_DEVELOPERPORTAL_APP $BASE_KBC_CONFIG test



================================================
FILE: scripts/update_dev_portal_properties.sh
================================================
#!/usr/bin/env bash

set -e
# Obtain the component repository and log in
docker pull quay.io/keboola/developer-portal-cli-v2:latest


# Update properties in Keboola Developer Portal
echo "Updating long description"
value=`cat component_config/component_long_description.md`
echo "$value"
if [ ! -z "$value" ]
then
    docker run --rm \
            -e KBC_DEVELOPERPORTAL_USERNAME \
            -e KBC_DEVELOPERPORTAL_PASSWORD \
            quay.io/keboola/developer-portal-cli-v2:latest \
            update-app-property ${KBC_DEVELOPERPORTAL_VENDOR} ${KBC_DEVELOPERPORTAL_APP} longDescription --value="$value"
else
    echo "longDescription is empty!"
    exit 1
fi

echo "Updating config schema"
value=`cat component_config/configSchema.json`
echo "$value"
if [ ! -z "$value" ]
then
    docker run --rm \
            -e KBC_DEVELOPERPORTAL_USERNAME \
            -e KBC_DEVELOPERPORTAL_PASSWORD \
            quay.io/keboola/developer-portal-cli-v2:latest \
            update-app-property ${KBC_DEVELOPERPORTAL_VENDOR} ${KBC_DEVELOPERPORTAL_APP} configurationSchema --value="$value"
else
    echo "configurationSchema is empty!"
fi


echo "Updating config description"

value=`cat component_config/configuration_description.md`
echo "$value"
if [ ! -z "$value" ]
then
    docker run --rm \
            -e KBC_DEVELOPERPORTAL_USERNAME \
            -e KBC_DEVELOPERPORTAL_PASSWORD \
            quay.io/keboola/developer-portal-cli-v2:latest \
            update-app-property ${KBC_DEVELOPERPORTAL_VENDOR} ${KBC_DEVELOPERPORTAL_APP} configurationDescription --value="$value"
else
    echo "configurationDescription is empty!"
fi


echo "Updating short description"

value=`cat component_config/component_short_description.md`
echo "$value"
if [ ! -z "$value" ]
then
    docker run --rm \
            -e KBC_DEVELOPERPORTAL_USERNAME \
            -e KBC_DEVELOPERPORTAL_PASSWORD \
            quay.io/keboola/developer-portal-cli-v2:latest \
            update-app-property ${KBC_DEVELOPERPORTAL_VENDOR} ${KBC_DEVELOPERPORTAL_APP} shortDescription --value="$value"
else
    echo "shortDescription is empty!"
    exit 1
fi


================================================
FILE: src/component.py
================================================
'''
Template Component main class.

'''

import logging
import sys
import os  # noqa
import datetime  # noqa
import requests

from kbc.env_handler import KBCEnvHandler
from kbc.result import KBCTableDef  # noqa
from kbc.result import ResultWriter  # noqa

from klaviyo import Klaviyo


# configuration variables
KEY_DEBUG = 'debug'
KEY_API_TOKEN = '#api_token'
KEY_ENDPOINT = 'endpoint'
KEY_LIST_ID = 'list_id'

MANDATORY_PARS = [
    KEY_ENDPOINT,
    KEY_API_TOKEN,
    KEY_LIST_ID
]
MANDATORY_IMAGE_PARS = []

APP_VERSION = '0.0.2'


class Component(KBCEnvHandler):

    def __init__(self, debug=False):
        KBCEnvHandler.__init__(self, MANDATORY_PARS)
        logging.info('Running version %s', APP_VERSION)
        logging.info('Loading configuration...')

        # Disabling list of libraries you want to output in the logger
        disable_libraries = []
        for library in disable_libraries:
            logging.getLogger(library).disabled = True

        # override debug from config
        if self.cfg_params.get(KEY_DEBUG):
            debug = True

        log_level = logging.DEBUG if debug else logging.INFO
        # setup GELF if available
        if os.getenv('KBC_LOGGER_ADDR', None):
            self.set_gelf_logger(log_level)
        else:
            self.set_default_logger(log_level)

        try:
            self.validate_config()
            self.validate_image_parameters(MANDATORY_IMAGE_PARS)
        except ValueError as e:
            logging.error(e)
            exit(1)

    def get_tables(self, tables, mapping):
        """
        Evaluate input and output table names.
        Only taking the first one into consideration!
        mapping: input_mapping, output_mappings
        """
        # input file
        table_list = []
        for table in tables:

            if mapping == "input_mapping":
                destination = table["destination"]
            elif mapping == "output_mapping":
                destination = table["source"]
            table_list.append(destination)

        return table_list

    def run(self):
        '''
        Main execution code
        '''
        # Get proper list of tables
        in_tables = self.configuration.get_input_tables()
        out_tables = self.configuration.get_expected_output_tables()
        in_table_names = self.get_tables(in_tables, 'input_mapping')
        out_table_names = self.get_tables(out_tables, 'output_mapping')
        logging.info("IN tables mapped: "+str(in_table_names))
        logging.info("OUT tables mapped: "+str(out_table_names))

        params = self.cfg_params  # noqa
        # Validating User inputs
        self.validate_user_input(params, in_tables)

        # Configuratio parameters
        api_token = params.get(KEY_API_TOKEN)
        endpoint = params.get(KEY_ENDPOINT)
        list_id = params.get(KEY_LIST_ID)

        # Klaviyo Class
        klaviyo = Klaviyo(api_token=api_token)

        for table in in_tables:

            logging.info(f'Processing [{table["destination"]}]')
            klaviyo.process(
                endpoint=endpoint,
                input_table_path=table['full_path'],
                input_table_name=table['destination'],
                list_id=list_id
            )

        logging.info("Klaviyo Writer finished")

    def validate_user_input(self, params, in_tables):
        # User Input Validation
        if not params:
            logging.error('Input configurations are missing.')
            sys.exit(1)

        else:
            if params[KEY_API_TOKEN] == '' or params[KEY_ENDPOINT] == '':
                logging.error(
                    'Required parameters are missing: [API token] & [Endpoint]')
                sys.exit(1)

            elif len(in_tables) == 0:
                logging.error('Input Mapping is missing.')
                sys.exit(1)

            elif params[KEY_ENDPOINT] in ['subscribe_profiles_to_list', 'add_profiles_to_list'] \
                    and params[KEY_LIST_ID] == '':
                logging.error('[List ID] is required.')
                sys.exit(1)

        # Testing input API token
        test_url = 'https://a.klaviyo.com/api/v2/lists'
        test_params = {
            'api_key': params[KEY_API_TOKEN]
        }
        r = requests.get(test_url, params=test_params)
        if r.status_code not in (200, 201):
            error_msg = r.json()['message']
            logging.error(error_msg)
            sys.exit(1)


"""
        Main entrypoint
"""
if __name__ == "__main__":
    if len(sys.argv) > 1:
        debug = sys.argv[1]
    else:
        debug = True
    comp = Component(debug)
    comp.run()



================================================
FILE: src/klaviyo.py
================================================
import logging
import sys
import requests
import time
import json
import pandas as pd
import copy

CURRENT_TIMESTAMP = int(time.time())
# Default Table Output Destination
DEFAULT_TABLE_SOURCE = "/data/in/tables/"
DEFAULT_TABLE_DESTINATION = "/data/out/tables/"
DEFAULT_FILE_DESTINATION = "/data/out/files/"
DEFAULT_FILE_SOURCE = "/data/in/files/"


class Klaviyo():

    def __init__(self, api_token):
        self.api_token = api_token

    def process(self, endpoint, input_table_path, input_table_name, list_id=None):

        processed_counter = 0
        for chunk in pd.read_csv(input_table_path, chunksize=1000, dtype=str):

            if endpoint == 'add_update_profile':
                request_log = self.add_update_profile(
                    data_in=chunk,
                    input_table_name=input_table_name)

            elif endpoint == 'add_profiles_to_list':
                request_log = self.add_profiles_to_list(
                    data_in=chunk,
                    input_table_name=input_table_name,
                    list_id=list_id,
                    list_type='members')

            elif endpoint == 'subscribe_profiles_to_list':
                request_log = self.add_profiles_to_list(
                    data_in=chunk,
                    input_table_name=input_table_name,
                    list_id=list_id,
                    list_type='subscribe')

            # Output Request Log
            request_log_df = pd.DataFrame(request_log)
            request_log_df.to_csv(
                DEFAULT_TABLE_DESTINATION+'log.csv', index=False, mode='a', header=False)

            # Processor counter
            processed_counter += len(chunk.index)
            logging.info(f'Processed {processed_counter} records')

        manifest = {
            'incremental': True,
            'primary_key': [
                'timestamp',
                'request_url',
                'request_data'
            ],
            'columns': [
                'timestamp',
                'request_url',
                'request_data',
                'request_status',
                'request_response'
            ]
        }
        with open(DEFAULT_TABLE_DESTINATION+'log.csv.manifest', 'w') as f:
            json.dump(manifest, f)

    def add_update_profile(self, data_in, input_table_name):

        col_headers = list(data_in.columns)
        # Klaviyo default properties
        # required to alter the properties name
        klaviyo_default_properties = [
            'email',
            'first_name',
            'last_name',
            'phone_number',
            'title',
            'organization',
            'city',
            'region',
            'country',
            'zip',
            'image'
        ]
        # Request log
        request_log = []

        if 'id' not in col_headers:
            logging.error(f'Table [{input_table_name}] is missing required column: [id]')
            sys.exit(1)

        for index, row in data_in.iterrows():

            request_data = {
                'api_key': self.api_token
            }
            request_url = f'https://a.klaviyo.com/api/v1/person/{row["id"]}'

            for column in col_headers:

                if column == 'id':
                    continue

                param_name = f'${column}' if column in klaviyo_default_properties else column
                param_value = row[column]

                if not pd.isnull(param_value) and param_value != '':
                    request_data[param_name] = param_value

            # Data Request
            request_data_cloned = copy.deepcopy(request_data)
            del request_data_cloned['api_key']
            logging.debug(f'Posting: {request_data_cloned}')
            r = requests.put(request_url, data=request_data)

            # Outputting request log
            del request_data['api_key']
            log = self.construct_log(
                r, request_url, request_data)
            request_log.append(log)

        return request_log

    def add_profiles_to_list(self, data_in, input_table_name, list_id, list_type):
        col_headers = list(data_in.columns)

        # Input mapping validation
        # Ensuring all the required columns are included
        if 'email' not in col_headers or 'phone_number' not in col_headers:
            logging.error(
                f'Table {input_table_name} is missing one of [email] or [phone_numbe] key.')
            sys.exit(1)

        # Request Parameters
        request_log = []
        request_data = {
            'api_key': self.api_token,
            'profiles': []
        }
        request_headers = {
            'Content-Type': 'application/json'
        }
        request_url = f'https://a.klaviyo.com/api/v2/list/{list_id}/{list_type}'

        for index, row in data_in.iterrows():

            tmp_data = {}
            consent_validation = True

            for column in col_headers:

                param_name = column
                param_value = row[column]

                if not pd.isnull(param_value) and param_value != '':

                    # Re-configuring the variable 'consent'
                    if list_type == 'subscribe' and param_name == 'consent':
                        consent_values = ['email', 'web',
                                          'sms', 'directmail', 'mobile']

                        if param_value not in consent_values:
                            logging.debug(
                                'Entered consent value is not supported.')
                            logging.debug(
                                'Updating consent variable as a custom variable.')
                            consent_validation = False

                        else:
                            param_name = '$consent'

                    tmp_data[param_name] = param_value

            request_data['profiles'] = [tmp_data]

            # Data Request
            logging.debug(f'Posting: {request_data["profiles"][0]}')
            r = requests.post(request_url, json=request_data,
                              headers=request_headers)

            # Outputting request log
            request_data_log = request_data['profiles'][0]
            log = self.construct_log(
                r, request_url, request_data_log, consent_validation)
            request_log.append(log)

        return request_log

    def construct_log(self, request_response, request_url, request_data, consent=None):

        request_data_cloned = copy.deepcopy(request_data)
        # del request_data_cloned['api_key']

        log = {
            'timestamp': CURRENT_TIMESTAMP,
            'request_url': request_url,
            'request_data': request_data_cloned,
            'request_status': request_response.status_code,
            'request_response': ''
        }

        if consent is False and request_response.status_code == 200:
            consent_msg = 'WARNING: Entered consent value is not supported.'\
                'Updating consent variable as a custom variable.'
            log['request_response'] = consent_msg

        elif request_response.status_code != 200:
            log['request_response'] = request_response.text

        return log



================================================
FILE: tests/__init__.py
================================================
import sys
import os
sys.path.append(os.path.dirname(os.path.realpath(__file__)) + "/../src")


================================================
FILE: tests/test_component.py
================================================
'''
Created on 12. 11. 2018

@author: esner
'''
import unittest
import mock
import os
from freezegun import freeze_time

from component import Component


class TestComponent(unittest.TestCase):

    # set global time to 2010-10-10 - affects functions like datetime.now()
    @freeze_time("2010-10-10")
    # set KBC_DATADIR env to non-existing dir
    @mock.patch.dict(os.environ, {'KBC_DATADIR': './non-existing-dir'})
    def test_run_no_cfg_fails(self):
        with self.assertRaises(ValueError):
            comp = Component()
            comp.run()


if __name__ == "__main__":
    # import sys;sys.argv = ['', 'Test.testName']
    unittest.main()


