Directory structure:
└── keboola-developers-docs/
    ├── README.md
    ├── 404.md
    ├── LICENSE
    ├── _config.yml
    ├── docker-compose.yml
    ├── google9cde6c6b9250e5a4.html
    ├── index.md
    ├── _data/
    │   ├── navigation.yml
    │   └── figures/
    │       ├── async-jobs
    │       ├── docker-runner.xml
    │       ├── docker-sync-actions.xml
    │       ├── variables.drawio
    │       └── variables.xml
    ├── _includes/
    │   ├── async-create.py
    │   ├── branches-beta-warning.html
    │   ├── breadcrumbs-item.html
    │   ├── breadcrumbs.html
    │   ├── config-events.js
    │   ├── config-map.json
    │   ├── gtm-body.html
    │   ├── gtm-head.html
    │   ├── nav-items.html
    │   ├── navigation.html
    │   ├── writer-config-events.js
    │   └── writer-config-map.json
    ├── _layouts/
    │   └── main.html
    ├── _sass/
    │   ├── _bootstrap-compass.scss
    │   ├── _bootstrap-mincer.scss
    │   ├── _bootstrap-sprockets.scss
    │   ├── highlight.scss
    │   ├── magnific-popup.scss
    │   ├── variables.scss
    │   └── bootstrap/
    │       ├── _alerts.scss
    │       ├── _badges.scss
    │       ├── _breadcrumbs.scss
    │       ├── _button-groups.scss
    │       ├── _buttons.scss
    │       ├── _carousel.scss
    │       ├── _close.scss
    │       ├── _code.scss
    │       ├── _component-animations.scss
    │       ├── _dropdowns.scss
    │       ├── _forms.scss
    │       ├── _glyphicons.scss
    │       ├── _grid.scss
    │       ├── _input-groups.scss
    │       ├── _jumbotron.scss
    │       ├── _labels.scss
    │       ├── _list-group.scss
    │       ├── _media.scss
    │       ├── _mixins.scss
    │       ├── _modals.scss
    │       ├── _navbar.scss
    │       ├── _navs.scss
    │       ├── _normalize.scss
    │       ├── _pager.scss
    │       ├── _pagination.scss
    │       ├── _panels.scss
    │       ├── _popovers.scss
    │       ├── _print.scss
    │       ├── _progress-bars.scss
    │       ├── _responsive-embed.scss
    │       ├── _responsive-utilities.scss
    │       ├── _scaffolding.scss
    │       ├── _tables.scss
    │       ├── _theme.scss
    │       ├── _thumbnails.scss
    │       ├── _tooltip.scss
    │       ├── _type.scss
    │       ├── _utilities.scss
    │       ├── _variables.scss
    │       ├── _wells.scss
    │       └── mixins/
    │           ├── _alerts.scss
    │           ├── _background-variant.scss
    │           ├── _border-radius.scss
    │           ├── _buttons.scss
    │           ├── _center-block.scss
    │           ├── _clearfix.scss
    │           ├── _forms.scss
    │           ├── _gradients.scss
    │           ├── _grid-framework.scss
    │           ├── _grid.scss
    │           ├── _hide-text.scss
    │           ├── _image.scss
    │           ├── _labels.scss
    │           ├── _list-group.scss
    │           ├── _nav-divider.scss
    │           ├── _nav-vertical-align.scss
    │           ├── _opacity.scss
    │           ├── _pagination.scss
    │           ├── _panels.scss
    │           ├── _progress-bar.scss
    │           ├── _reset-filter.scss
    │           ├── _reset-text.scss
    │           ├── _resize.scss
    │           ├── _responsive-visibility.scss
    │           ├── _size.scss
    │           ├── _tab-focus.scss
    │           ├── _table-row.scss
    │           ├── _text-emphasis.scss
    │           ├── _text-overflow.scss
    │           └── _vendor-prefixes.scss
    ├── assets/
    │   ├── css/
    │   │   └── style.scss
    │   ├── img/
    │   └── js/
    │       └── magnific-popup.js
    ├── automate/
    │   ├── index.md
    │   ├── run-job.md
    │   ├── run-orchestration.md
    │   └── set-schedule.md
    ├── cli/
    │   ├── index.md
    │   ├── commands/
    │   │   ├── index.md
    │   │   ├── ci/
    │   │   │   ├── index.md
    │   │   │   └── workflows/
    │   │   │       └── index.md
    │   │   ├── dbt/
    │   │   │   ├── index.md
    │   │   │   ├── generate/
    │   │   │   │   ├── index.md
    │   │   │   │   ├── env/
    │   │   │   │   │   └── index.md
    │   │   │   │   ├── profile/
    │   │   │   │   │   └── index.md
    │   │   │   │   └── sources/
    │   │   │   │       └── index.md
    │   │   │   └── init/
    │   │   │       └── index.md
    │   │   ├── help/
    │   │   │   └── index.md
    │   │   ├── local/
    │   │   │   ├── index.md
    │   │   │   ├── create/
    │   │   │   │   ├── index.md
    │   │   │   │   ├── config/
    │   │   │   │   │   └── index.md
    │   │   │   │   └── row/
    │   │   │   │       └── index.md
    │   │   │   ├── encrypt/
    │   │   │   │   └── index.md
    │   │   │   ├── fix-paths/
    │   │   │   │   └── index.md
    │   │   │   ├── persist/
    │   │   │   │   └── index.md
    │   │   │   ├── template/
    │   │   │   │   ├── index.md
    │   │   │   │   ├── delete/
    │   │   │   │   │   └── index.md
    │   │   │   │   ├── list/
    │   │   │   │   │   └── index.md
    │   │   │   │   ├── upgrade/
    │   │   │   │   │   └── index.md
    │   │   │   │   └── use/
    │   │   │   │       └── index.md
    │   │   │   └── validate/
    │   │   │       ├── index.md
    │   │   │       ├── config/
    │   │   │       │   └── index.md
    │   │   │       ├── row/
    │   │   │       │   └── index.md
    │   │   │       └── schema/
    │   │   │           └── index.md
    │   │   ├── remote/
    │   │   │   ├── index.md
    │   │   │   ├── create/
    │   │   │   │   ├── index.md
    │   │   │   │   ├── branch/
    │   │   │   │   │   └── index.md
    │   │   │   │   └── bucket/
    │   │   │   │       └── index.md
    │   │   │   ├── file/
    │   │   │   │   ├── index.md
    │   │   │   │   ├── download/
    │   │   │   │   │   └── index.md
    │   │   │   │   └── upload/
    │   │   │   │       └── index.md
    │   │   │   ├── job/
    │   │   │   │   ├── index.md
    │   │   │   │   └── run/
    │   │   │   │       └── index.md
    │   │   │   ├── table/
    │   │   │   │   ├── index.md
    │   │   │   │   ├── create/
    │   │   │   │   │   └── index.md
    │   │   │   │   ├── detail/
    │   │   │   │   │   └── index.md
    │   │   │   │   ├── download/
    │   │   │   │   │   └── index.md
    │   │   │   │   ├── import/
    │   │   │   │   │   └── index.md
    │   │   │   │   ├── preview/
    │   │   │   │   │   └── index.md
    │   │   │   │   ├── unload/
    │   │   │   │   │   └── index.md
    │   │   │   │   └── upload/
    │   │   │   │       └── index.md
    │   │   │   └── workspace/
    │   │   │       ├── index.md
    │   │   │       ├── create/
    │   │   │       │   └── index.md
    │   │   │       ├── delete/
    │   │   │       │   └── index.md
    │   │   │       ├── detail/
    │   │   │       │   └── index.md
    │   │   │       └── list/
    │   │   │           └── index.md
    │   │   ├── status/
    │   │   │   └── index.md
    │   │   ├── sync/
    │   │   │   ├── index.md
    │   │   │   ├── diff/
    │   │   │   │   └── index.md
    │   │   │   ├── init/
    │   │   │   │   └── index.md
    │   │   │   ├── pull/
    │   │   │   │   └── index.md
    │   │   │   └── push/
    │   │   │       └── index.md
    │   │   └── template/
    │   │       ├── index.md
    │   │       ├── create/
    │   │       │   └── index.md
    │   │       ├── describe/
    │   │       │   └── index.md
    │   │       ├── list/
    │   │       │   └── index.md
    │   │       ├── repository/
    │   │       │   ├── index.md
    │   │       │   └── init/
    │   │       │       └── index.md
    │   │       └── test/
    │   │           ├── index.md
    │   │           ├── create/
    │   │           │   └── index.md
    │   │           └── run/
    │   │               └── index.md
    │   ├── dbt/
    │   │   └── index.md
    │   ├── devops-use-cases/
    │   │   └── index.md
    │   ├── getting-started/
    │   │   └── index.md
    │   ├── github-integration/
    │   │   └── index.md
    │   ├── installation/
    │   │   └── index.md
    │   ├── structure/
    │   │   └── index.md
    │   └── templates/
    │       ├── index.md
    │       ├── structure/
    │       │   ├── index.md
    │       │   ├── inputs/
    │       │   │   └── index.md
    │       │   └── jsonnet-files/
    │       │       └── index.md
    │       ├── tests/
    │       │   └── index.md
    │       └── tutorial/
    │           └── index.md
    ├── extend/
    │   ├── data.zip
    │   ├── index.md
    │   ├── common-interface/
    │   │   ├── actions.md
    │   │   ├── config-file.md
    │   │   ├── development-branches.md
    │   │   ├── environment.md
    │   │   ├── folders.md
    │   │   ├── index.md
    │   │   ├── logging-development.md
    │   │   ├── logging.md
    │   │   ├── manifest-files.md
    │   │   ├── oauth.md
    │   │   └── manifest-files/
    │   │       ├── in-files-abs-staging.md
    │   │       ├── in-files-manifests.md
    │   │       ├── in-files-s3-staging.md
    │   │       ├── in-tables-manifests.md
    │   │       ├── out-files-manifests.md
    │   │       ├── out-tables-manifests-native-types.md
    │   │       └── out-tables-manifests.md
    │   ├── component/
    │   │   ├── index.md
    │   │   ├── processors.md
    │   │   ├── code-patterns/
    │   │   │   ├── index.md
    │   │   │   ├── interface.md
    │   │   │   └── tutorial.md
    │   │   ├── deployment/
    │   │   │   └── index.md
    │   │   ├── docker-tutorial/
    │   │   │   ├── howto.md
    │   │   │   ├── index.md
    │   │   │   ├── registry.md
    │   │   │   └── setup.md
    │   │   ├── implementation/
    │   │   │   ├── index.md
    │   │   │   ├── php.md
    │   │   │   ├── python.md
    │   │   │   └── r.md
    │   │   ├── running/
    │   │   │   └── index.md
    │   │   ├── tutorial/
    │   │   │   ├── configuration.md
    │   │   │   ├── debugging.md
    │   │   │   ├── index.md
    │   │   │   ├── input-mapping.md
    │   │   │   ├── output-mapping.md
    │   │   │   └── processors.md
    │   │   └── ui-options/
    │   │       ├── configuration-schema.md
    │   │       ├── index.md
    │   │       ├── default-configuration/
    │   │       │   └── index.md
    │   │       └── ui-examples/
    │   │           ├── configuration-schema-examples.md
    │   │           └── sync-action-examples.md
    │   ├── docker-runner/
    │   │   └── index.md
    │   ├── generic-extractor/
    │   │   ├── functions.md
    │   │   ├── incremental.md
    │   │   ├── index.md
    │   │   ├── map.md
    │   │   ├── publish.md
    │   │   ├── running.md
    │   │   ├── configuration/
    │   │   │   ├── configuration.md
    │   │   │   ├── iterations.md
    │   │   │   ├── api/
    │   │   │   │   ├── index.md
    │   │   │   │   ├── authentication/
    │   │   │   │   │   ├── api_key.md
    │   │   │   │   │   ├── basic.md
    │   │   │   │   │   ├── bearer_token.md
    │   │   │   │   │   ├── index.md
    │   │   │   │   │   ├── login.md
    │   │   │   │   │   ├── oauth10.md
    │   │   │   │   │   ├── oauth20-login.md
    │   │   │   │   │   ├── oauth20.md
    │   │   │   │   │   ├── oauth_cc.md
    │   │   │   │   │   └── query.md
    │   │   │   │   └── pagination/
    │   │   │   │       ├── cursor.md
    │   │   │   │       ├── index.md
    │   │   │   │       ├── multiple.md
    │   │   │   │       ├── offset.md
    │   │   │   │       ├── pagenum.md
    │   │   │   │       ├── response-param.md
    │   │   │   │       └── response-url.md
    │   │   │   ├── aws-signature/
    │   │   │   │   └── index.md
    │   │   │   ├── config/
    │   │   │   │   ├── index.md
    │   │   │   │   ├── mappings.md
    │   │   │   │   └── jobs/
    │   │   │   │       ├── children.md
    │   │   │   │       └── index.md
    │   │   │   └── ssh-proxy/
    │   │   │       └── index.md
    │   │   └── tutorial/
    │   │       ├── basic.md
    │   │       ├── index.md
    │   │       ├── jobs.md
    │   │       ├── json.md
    │   │       ├── mapping.md
    │   │       ├── pagination.md
    │   │       └── rest.md
    │   ├── generic-writer/
    │   │   ├── index.md
    │   │   └── configuration/
    │   │       ├── configuration-examples.md
    │   │       └── configuration.md
    │   └── publish/
    │       ├── checklist.md
    │       └── index.md
    ├── integrate/
    │   ├── index.md
    │   ├── artifacts/
    │   │   ├── index.md
    │   │   └── tutorial.md
    │   ├── data-streams/
    │   │   ├── index.md
    │   │   ├── overview/
    │   │   │   └── index.md
    │   │   └── tutorial/
    │   │       └── index.md
    │   ├── database/
    │   │   └── index.md
    │   ├── jobs/
    │   │   └── index.md
    │   ├── orchestrator/
    │   │   └── index.md
    │   ├── storage/
    │   │   ├── docker-cli-client.md
    │   │   ├── index.md
    │   │   ├── new-table.csv
    │   │   ├── php-client.md
    │   │   ├── python-client.md
    │   │   ├── r-client.md
    │   │   ├── sys.c-table-importer.test-config.csv
    │   │   └── api/
    │   │       ├── configurations.md
    │   │       ├── import-export.md
    │   │       ├── importer.md
    │   │       ├── index.md
    │   │       └── tde-exporter.md
    │   └── variables/
    │       ├── countries.csv
    │       ├── index.md
    │       └── tutorial.md
    ├── overview/
    │   ├── encryption.md
    │   ├── index.md
    │   ├── repositories.md
    │   └── api/
    │       └── index.md
    └── .github/
        ├── PULL_REQUEST_TEMPLATE.md
        └── workflows/
            ├── branch.yml
            └── main.yml

================================================
File: README.md
================================================
# Keboola Developers Documentation

[![Build and deploy](https://github.com/keboola/developers-docs/actions/workflows/main.yml/badge.svg)](https://github.com/keboola/developers-docs/actions/workflows/main.yml)

How to write documentation [https://sites.google.com/keboola.com/devel-internal/dokumentace](https://sites.google.com/keboola.com/devel-internal/dokumentace)

## Documentation Development

### Running in Docker

```bash
docker compose run --rm --service-ports jekyll
```

Documentation will be available at http://localhost:4000

### Publish

* `git push origin HEAD` - on `master` branch

New version is published immediately after push by [Travis](https://travis-ci.org/keboola/developers-docs)

## License

MIT licensed, see [LICENSE](./LICENSE) file.


================================================
File: 404.md
================================================
---
title: Page Not Found
permalink: /404.html
showBreadcrumbs: false
sitemap: false
---

**The Page you requested doesn't exist. Sorry about that. If we did something wrong, let us know at
[support@keboola.com](mailto:support@keboola.com).**

{: .text-center}
![Confused Octopus](/keboola-kolecko.png)

If you are looking for some other stuff that does not exist, you might want to visit:

- [connection.keboola.com](https://connection.keboola.com) -- for logging in into Keboola
- [status.keboola.com](http://status.keboola.com/) -- for getting Keboola Status updates (service status and changelog); we recommend subscribing to the feed or monitoring it in a Slack channel to keep up to date.
- [help.keboola.com](https://help.keboola.com) -- for general help with using Keboola
- [developers.keboola.com](https://developers.keboola.com) -- for developing a Keboola component
- [blog.keboola.com](http://blog.keboola.com/) -- something to read for data analysts
- [500.keboola.com](https://500.keboola.com/) -- something to read for tech geeks

Feel free to

- Check us out on [Twitter](https://twitter.com/keboola_support).
- Visit our main web page at [www.keboola.com](http://www.keboola.com/).
- Send us a wishing for a new or updated project feature to [wishlist@keboola.com](mailto:wishlist@keboola.com).

To get in touch with our [**partners**](/overview/environment/), please use the following email addresses:

- If in Europe, write to [cz.support@keboola.com](mailto:cz.support@keboola.com).
- If in North America, write to [support.ca@keboola.com](mailto:support.ca@keboola.com).
- If in Asia, write to [apac.support@keboola.com](mailto:apac.support@keboola.com).


================================================
File: LICENSE
================================================
MIT License

Copyright (c) Keboola :(){:|:&};: s.r.o.

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
SOFTWARE.


================================================
File: _config.yml
================================================
defaults:
  -
    scope:
      path: "" # an empty string here means all files in the project
    values:
      layout: "main"

url: "https://developers.keboola.com"

exclude:
  - docker-compose.yml
  - README.md
  - .idea
  - .github

sass:
  style: compressed

plugins:
  - jekyll-sitemap
  - jekyll-redirect-from


================================================
File: docker-compose.yml
================================================
version: '3'

services:
  jekyll:
    image: quay.io/keboola/docs-jekyll
    tty: true
    stdin_open: true
    volumes:
      - ./:/code:cached
    working_dir: /code
    ports:
      - "4000:4000"
    command: jekyll serve --watch -H 0.0.0.0 --force_polling

  aws:
    image: public.ecr.aws/aws-cli/aws-cli:latest
    volumes:
      - ./:/code
    working_dir: /code


================================================
File: google9cde6c6b9250e5a4.html
================================================
google-site-verification: google9cde6c6b9250e5a4.html

================================================
File: index.md
================================================
---
title: Keboola Developers Documentation
permalink: /
---

This documentation site is aimed for developers who are working with Keboola programmatically.
For end-users, there is a separate documentation ready at [help.keboola.com](https://help.keboola.com/).

* TOC
{:toc}

## What Keboola Is
Cloud based, extremely open and extendable, Keboola is the ideal environment for working with your data, be it loading from various sources,
manipulating, enriching, or finally, pushing the data to new systems and consumption methods.

The Keboola system consists of many independent and loosely connected [**components**](/overview/),
such as Extractors, Storage or Writers, that are orchestrated together through (mostly REST) [APIs](/overview/api/).

## Where to Start
In this documentation, we will show you how to

- [**Integrate Keboola with other systems**](/integrate/).
	- Use Keboola just to exchange data (using the [Storage API](/integrate/storage/)).
	- Use Keboola as a [data-handling backbone](/overview/api/) for your product.
	- Wrap Keboola in your own UI for your customers.
	- Control whole data processing pipeline within Keboola from the [outside](/integrate/).
- [**Extend Keboola by building your own components**](/extend/) for your own use or for other Keboola users and customers.
	- [Extend Keboola with arbitrary Docker images](/extend/component/).
	- Build your own [extractors](/extend/generic-extractor/) for services we do not support yet.
- [**Automate your processes**](/automate/) to run any component in specified intervals or at specified times of the day.
	- Control any component of Keboola [programmatically](/integrate/jobs/) (for example, you can trigger data load when something happens in your system).

## Development Project
If you are a **3rd party developer** working with Keboola, chances are that you do not have an access to
a project in Keboola. It is not strictly necessary to have a Keboola project, but it certainly helps because you can test your code in action.

You can apply for a development project with the following features:

- 3.5GB storage space
- Snowflake backend
- 10 users
- 3 orchestrations

Under the following conditions:

- You do not belong to a company which already has a project in Keboola.
- You will use the project fairly (not abuse it or use it for production).
- You will remain active in the development.

Note that once you [register](/extend/component/tutorial/#before-you-start) (and join a vendor) in
our [Developer portal](https://components.keboola.com/), you will gain access to a development project.
If you don't have it, or need a development project for other reasons,
[send us an email](mailto:support@keboola.com). Not into creative writing? Feel free to use our template:

	Hello,
	I'm *XY* (from the *YZ* company) and I'd like to develop an *extractor|writer|application* for Keboola.
	My component will do *some really awesome things*.


================================================
File: _data/navigation.yml
================================================
items:
  - url: /
    title: Home

  - url: /overview/
    title: Keboola Overview
    items:
      - url: /overview/api/
        title: Our APIs

      - url: /overview/encryption/
        title: Encryption

  - url: /extend/
    title: Extending Keboola
    items:
      - url: /extend/component/
        title: Components
        items:
          - url: /extend/component/docker-tutorial/
            title: About Docker
            items:
              - url: /extend/component/docker-tutorial/setup/
                title: Installation and Running

              - url: /extend/component/docker-tutorial/howto/
                title: Creating Dockerized App

              - url: /extend/component/docker-tutorial/registry/
                title: Docker Registry

          - url: /extend/component/tutorial/
            title: Tutorial
            items:
              - url: /extend/component/tutorial/input-mapping/
                title: Input Mapping

              - url: /extend/component/tutorial/output-mapping/
                title: Output Mapping

              - url: /extend/component/tutorial/configuration/
                title: Configuration

              - url: /extend/component/tutorial/processors/
                title: Processors

              - url: /extend/component/tutorial/debugging/
                title: Debugging

          - url: /extend/component/processors/
            title: Processors

          - url: /extend/component/code-patterns/
            title: Code Patterns
            items:
              - url: /extend/component/code-patterns/interface/
                title: Interface

              - url: /extend/component/code-patterns/tutorial/
                title: Tutorial

          - url: /extend/component/implementation/
            title: Implementation Notes
            items:
              - url: /extend/component/implementation/php/
                title: PHP Implementation Notes

              - url: /extend/component/implementation/python/
                title: Python Implementation Notes

              - url: /extend/component/implementation/r/
                title: R Implementation Notes

          - url: /extend/component/running/
            title: Running Components

          - url: /extend/component/ui-options/
            title: UI Options
            items:
              - url: /extend/component/ui-options/configuration-schema/
                title: Configuration Schema
                items:
                  - url: /extend/component/ui-options/configuration-schema/examples
                    title: Examples
                  - url: /extend/component/ui-options/configuration-schema/sync-action-examples
                    title: Sync Action Examples
              - url: /extend/component/ui-options/default-configuration/
                title: Default Configuration

          - url: /extend/component/deployment/
            title: Deployment

      - url: /extend/generic-extractor/
        title: Generic Extractor
        items:
          - url: /extend/generic-extractor/tutorial/
            title: Generic Extractor Tutorial
            items:
              - url: /extend/generic-extractor/tutorial/rest/
                title: REST HTTP API Introduction

              - url: /extend/generic-extractor/tutorial/json/
                title: JSON Introduction

              - url: /extend/generic-extractor/tutorial/basic/
                title: Basic Configuration

              - url: /extend/generic-extractor/tutorial/pagination/
                title: Pagination Tutorial

              - url: /extend/generic-extractor/tutorial/jobs/
                title: Jobs Tutorial

              - url: /extend/generic-extractor/tutorial/mapping/
                title: Mapping Tutorial

          - url: /extend/generic-extractor/configuration/
            title: Configuration
            items:
              - url: /extend/generic-extractor/configuration/api/
                title: API Configuration
                items:
                  - url: /extend/generic-extractor/configuration/api/pagination/
                    title: Pagination
                    items:
                      - url: /extend/generic-extractor/configuration/api/pagination/response-url/
                        title: Response URL Scroller

                      - url: /extend/generic-extractor/configuration/api/pagination/response-param/
                        title: Response Parameter Scroller

                      - url: /extend/generic-extractor/configuration/api/pagination/offset/
                        title: Offset Scroller

                      - url: /extend/generic-extractor/configuration/api/pagination/pagenum/
                        title: Page Number Scroller

                      - url: /extend/generic-extractor/configuration/api/pagination/cursor/
                        title: Cursor Scroller

                      - url: /extend/generic-extractor/configuration/api/pagination/multiple/
                        title: Multiple Scrollers

                  - url: /extend/generic-extractor/configuration/api/authentication/
                    title: Authentication
                    items:
                      - url: /extend/generic-extractor/configuration/api/authentication/query/
                        title: Query

                      - url: /extend/generic-extractor/configuration/api/authentication/basic/
                        title: Basic

                      - url: /extend/generic-extractor/configuration/api/authentication/bearer_token/
                        title: Bearer Token

                      - url: /extend/generic-extractor/configuration/api/authentication/api_key/
                        title: API Key

                      - url: /extend/generic-extractor/configuration/api/authentication/login/
                        title: Login

                      - url: /extend/generic-extractor/configuration/api/authentication/oauth_cc/
                        title: OAuth 2.0 Client Credentials

                      - url: /extend/generic-extractor/configuration/api/authentication/oauth10/
                        title: OAuth 1.0

                      - url: /extend/generic-extractor/configuration/api/authentication/oauth20/
                        title: OAuth 2.0

                      - url: /extend/generic-extractor/configuration/api/authentication/oauth20-login/
                        title: Login using OAuth 2.0

              - url: /extend/generic-extractor/configuration/config/
                title: Extraction Configuration
                items:
                  - url: /extend/generic-extractor/configuration/config/jobs/
                    title: Jobs
                    items:
                      - url: /extend/generic-extractor/configuration/config/jobs/children/
                        title: Child Jobs

                  - url: /extend/generic-extractor/configuration/config/mappings/
                    title: Mappings

              - url: /extend/generic-extractor/configuration/iterations/
                title: Iterations

              - url: /extend/generic-extractor/configuration/ssh-proxy/
                title: SSH Proxy Configuration

          - url: /extend/generic-extractor/map/
            title: Configuration Map

          - url: /extend/generic-extractor/functions/
            title: Functions

          - url: /extend/generic-extractor/incremental/
            title: Incremental Extraction

          - url: /extend/generic-extractor/running/
            title: Running Generic Extractor

          - url: /extend/generic-extractor/publish/
            title: Publishing Component

      - url: /extend/generic-writer/
        title: Generic Writer
        items:
          - url: /extend/generic-writer/configuration/
            title: Configuration

          - url: /extend/generic-writer/configuration-examples/
            title: Configuration Examples

      - url: /extend/common-interface/
        title: Common Interface
        items:
          - url: /extend/common-interface/folders/
            title: Data Folders

          - url: /extend/common-interface/config-file/
            title: Configuration File

          - url: /extend/common-interface/environment/
            title: Environment

          - url: /extend/common-interface/manifest-files/
            title: Manifest Files
            items:
              - url: /extend/common-interface/manifest-files/in-tables-manifests/
                title: IN tables

              - url: /extend/common-interface/manifest-files/in-files-manifests/
                title: IN files

              - url: /extend/common-interface/manifest-files/in-files-s3-staging/
                title: IN files S3 staging

              - url: /extend/common-interface/manifest-files/in-files-abs-staging/
                title: IN files ABS staging

              - url: /extend/common-interface/manifest-files/out-tables-manifests/
                title: OUT tables

              - url: /extend/common-interface/manifest-files/out-tables-manifests-native-types/
                title: OUT tables with Native Types

              - url: /extend/common-interface/manifest-files/out-files-manifests/
                title: OUT files

          - url: /extend/common-interface/oauth/
            title: OAuth2

          - url: /extend/common-interface/actions/
            title: Actions

          - url: /extend/common-interface/logging/
            title: Logging
            items:
              - url: /extend/common-interface/logging/development/
                title: Local Development

          - url: /extend/common-interface/development-branches/
            title: Development branches

      - url: /extend/docker-runner/
        title: Docker Runner

      - url: /extend/publish/
        title: Publishing Component
        items:
          - url: /extend/publish/checklist/
            title: Checklist

  - url: /integrate/
    title: Integration
    items:
      - url: /integrate/storage/
        title: Storage
        items:
          - url: /integrate/storage/php-client/
            title: PHP client library

          - url: /integrate/storage/r-client/
            title: R client library

          - url: /integrate/storage/python-client/
            title: Python client library

          - url: /integrate/storage/docker-cli-client/
            title: Docker CLI client

          - url: /integrate/storage/api/
            title: Using API
            items:
              - url: /integrate/storage/api/configurations/
                title: Configurations API

              - url: /integrate/storage/api/importer/
                title: Storage API Importer

              - url: /integrate/storage/api/import-export/
                title: Manually importing and exporting data

              - url: /integrate/storage/api/tde-exporter/
                title: TDE Exporter

      - url: /integrate/jobs/
        title: Component Jobs

      - url: /integrate/variables/
        title: Variables
        items:
          - url: /integrate/variables/tutorial/
            title: Tutorial

      - url: /integrate/artifacts/
        title: Artifacts
        items:
          - url: /integrate/artifacts/tutorial/
            title: Tutorial

      - url: /integrate/database/
        title: SSH Tunnel for Database Extractors

      - url: /integrate/data-streams/
        title: Data Streams
        items:
          - url: /integrate/data-streams/tutorial/
            title: Tutorial

          - url: /integrate/data-streams/overview/
            title: Overview

  - url: /automate/
    title: Automation/Common Tasks
    items:
      - url: /automate/run-job/
        title: Run Job

      - url: /automate/run-orchestration/
        title: Run Orchestration

      - url: /automate/set-schedule/
        title: Set Schedule

  - url: /cli/
    title: CLI
    items:
      - url: /cli/installation/
        title: Installation
      - url: /cli/getting-started/
        title: Getting Started
      - url: /cli/structure/
        title: Structure
      - url: /cli/commands/
        title: Commands
        items:
          - url: /cli/commands/help/
            title: help
          - url: /cli/commands/status/
            title: status
          - url: /cli/commands/sync/
            title: sync
            items:
              - url: /cli/commands/sync/init/
                title: init
              - url: /cli/commands/sync/pull/
                title: pull
              - url: /cli/commands/sync/push/
                title: push
              - url: /cli/commands/sync/diff/
                title: diff
          - url: /cli/commands/ci/
            title: ci
            items:
              - url: /cli/commands/ci/workflows/
                title: workflows
          - url: /cli/commands/local/
            title: local
            items:
              - url: /cli/commands/local/create/
                title: create
                items:
                  - url: /cli/commands/local/create/config/
                    title: config
                  - url: /cli/commands/local/create/row/
                    title: row
              - url: /cli/commands/local/persist/
                title: persist
              - url: /cli/commands/local/encrypt/
                title: encrypt
              - url: /cli/commands/local/validate/
                title: validate
                items:
                  - url: /cli/commands/local/validate/config/
                    title: config
                  - url: /cli/commands/local/validate/row/
                    title: row
                  - url: /cli/commands/local/validate/schema/
                    title: schema
              - url: /cli/commands/local/fix-paths/
                title: fix-paths
              - url: /cli/commands/local/template/
                title: template
                items:
                  - url: /cli/commands/local/template/delete/
                    title: delete
                  - url: /cli/commands/local/template/list/
                    title: list
                  - url: /cli/commands/local/template/use/
                    title: use
          - url: /cli/commands/remote/
            title: remote
            items:
              - url: /cli/commands/remote/create/
                title: create
                items:
                  - url: /cli/commands/remote/create/branch/
                    title: branch
                  - url: /cli/commands/remote/create/bucket/
                    title: bucket
                  - url: /cli/commands/remote/create/table/
                    title: table
              - url: /cli/commands/remote/file/
                title: file
                items:
                  - url: /cli/commands/remote/file/download/
                    title: download
                  - url: /cli/commands/remote/file/upload/
                    title: upload
              - url: /cli/commands/remote/job/
                title: job
                items:
                  - url: /cli/commands/remote/job/run/
                    title: run
              - url: /cli/commands/remote/table/
                title: table
                items:
                  - url: /cli/commands/remote/table/create/
                    title: create
                  - url: /cli/commands/remote/table/upload/
                    title: upload
                  - url: /cli/commands/remote/table/download/
                    title: download
                  - url: /cli/commands/remote/table/preview/
                    title: preview
                  - url: /cli/commands/remote/table/detail/
                    title: detail
                  - url: /cli/commands/remote/table/import/
                    title: import
                  - url: /cli/commands/remote/table/unload/
                    title: unload
              - url: /cli/commands/remote/workspace/
                title: workspace
                items:
                  - url: /cli/commands/remote/workspace/create/
                    title: create
                  - url: /cli/commands/remote/workspace/delete/
                    title: delete
                  - url: /cli/commands/remote/workspace/detail/
                    title: detail
                  - url: /cli/commands/remote/workspace/list/
                    title: list
          - url: /cli/commands/template/
            title: template
            items:
              - url: /cli/commands/template/repository/
                title: repository
                items:
                  - url: /cli/commands/template/repository/init/
                    title: init
              - url: /cli/commands/template/create/
                title: create
              - url: /cli/commands/template/describe/
                title: describe
              - url: /cli/commands/template/list/
                title: list
              - url: /cli/commands/template/test/
                title: test
                items:
                  - url: /cli/commands/template/test/create/
                    title: create
                  - url: /cli/commands/template/test/run/
                    title: run
          - url: /cli/commands/dbt/
            title: dbt
            items:
              - url: /cli/commands/dbt/init/
                title: init
              - url: /cli/commands/dbt/generate/
                title: generate
                items:
                  - url: /cli/commands/dbt/generate/profile/
                    title: profile
                  - url: /cli/commands/dbt/generate/sources/
                    title: sources
                  - url: /cli/commands/dbt/generate/env/
                    title: env
      - url: /cli/github-integration/
        title: GitHub Integration
      - url: /cli/devops-use-cases/
        title: DevOps Use Cases
      - url: /cli/templates/
        title: Templates
        items:
          - url: /cli/templates/tutorial/
            title: Create Template Tutorial
          - url: /cli/templates/structure/
            title: Structure
            items:
              - url: /cli/templates/structure/jsonnet-files/
                title: Jsonnet Files
              - url: /cli/templates/structure/inputs/
                title: Inputs
          - url: /cli/templates/tests/
            title: Tests
      - url: /cli/dbt/
        title: dbt



================================================
File: _data/figures/async-jobs
================================================
<mxfile userAgent="Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/61.0.3163.91 Safari/537.36 OPR/48.0.2685.32" version="7.5.3" editor="www.draw.io" type="github"><diagram id="d724f6d2-910a-2ae3-02e3-ecb25b8bd61b" name="Page-1">5Vpdc6M2FP01nmkfkgEEGD/aTrJNu51J4+m0fZRBxjQyokIkdn99JZAwIBxjG5zddB+y6OoiiXvux5HkEZhvtl8oTNa/kgDhkWUE2xG4G1nWxAP8rxDsCoFrGoUgpFFQiMy9YBH9i6RQqWVRgNKaIiMEsyipC30Sx8hnNRmklLzV1VYE12dNYIg0wcKHWJf+EQVsXUg9x9jLf0JRuFYzm4bsWUL/JaQki+V8Iwus8n9F9waqsaR+uoYBeauIwP0IzCkhrHjabOcIC9MqsxXvPRzoLddNUcy6vGBbxRuvEGdILdnF/N1ZEL2KBbKdNIr7TyZWNWNoy24gjsJ4BKZcA6MV2/fyp1D+n4+SJjBWsl9mcyXmK6r2VMT5tEpq1VZgcWsl4pGvQCyQZMu8x+SN3OZIfJXBW2/riKFFAn3R/cZdlMvWbIOlcml10QgxTFP5XsooeUFzggnNZwSGMfUeuPFmqwjjinxu31u5XBriLrcCmL0iyiLuR1MpZkRMHVIYRBwRNUBMYlR+XxUsiZ8YBW0rIgneF0Q2iNEdV5G9pSPJQDOdovm291obSJV1xWPtsVSEMlLCcui9t/AH6TDtzqP7zj33e8v4PUWU//fD9OlxJNb3IGSPP2pwnoRZJ0Mfxq8PWx81tTkezNQTzdbPKEGQfahRE0Qj/imIihmiOJSTVmNFunot4nrAAtSxAAqbChheCxZlnr4EC1WkKljMSbyKwoxCFhGe1IzHQMMFBbzCyCahbE1CEkN8v5c2UlgFJbSN2J9CfOvI1l+qJ+Zrr3SJpur7GzG2k6UVZoxw0X7er0RAm+v5GX3NZzXPC6CUZNSXHzmWtRrSEEktrxCJz+8CrHFr2RM5MkWYG/S1XpPbkJOjPZGIr22vQlarFDEN2nLSTmgD0CeUXUFJuQnZVDAZLvBFhYp8JX6IMB4MLmB1xKszOF3DaqxF1YIRKoiaZeSVpI9E53Nz8OI0dKVw6+lprGcn02pJT24P2UkvFHOySXgWzkNDJCY+iSBccCNsFC/TpELAKuyrmdPuIIMdedoVAqTPrOXpYTA+NWsZjuPWML9RJercLLZtjNMct9cs52le0yuxGDTa7KPBZrfRsj6YgK2Z7Wey7L/+913lDxOKCyPJVJv1SiiZXSvKxQyA10u4qygkIpLSw6EFGoxeUcaHA/ruu+r8oVjAoGzEOcOxath38LKqj3E0nO58pDu96d3NFJbXJy5qNZUscEf8l3wP/JzFcf7wnTMYy7gihTFBVw5zjLMI1c/IWFROreVZ87Q8e2PcAledTXwTWy31VZ+BhbQFzGA0RGdvCwZZlqo4MQpW8ozSDOsnRv8PZuK0RIx7KjMBwHJqMN+YZ7H8S5mK7ZzEVBrq12Eq7vBMhacwA4A6XRlPVPtJnU6O1OH+N8VhWhzyAzmMo6eQHc0SLvotQ9knOIMBzjUZjH6YNcTG8EOoh9uSSJ1TE6l+XGKdlUj145JGpizb/TIV9/MwlbbAGIyp6KeTaqt09DxSbaU68fnLEhOGS4Rn5VV+4y6rcRXsurPiKnhQ0Jxxg1+q+Kmg5g6UzVQI6cXhKGiyeFwBs2FDBhxn923WLy+ELzK/fr7wKD6a53guXfhrFGRYREaPCah5E7wkjJGNwBam67KUiMYTZGItucQyuv+gIo+xJ5JG+VYd3NHCauXMXxv9xV10H5HUoPAu0HlBC5TA6wFKdbvWdsn1/UZDy4n7UKkI6CfuOqGKgwMsXxe33LKr52I7UW5r5X7D8tz6fsPxyg2IvuG4iGmptFvbIXQ95Klg4bRg4fTDtpqxBCaN37oU3yPfemfD6owbA9mNgQojaAOdwd1sPZ3qLtTTTrXnLWfporemDepuWrglb/fthG03OpOOTnipdzl1p7Bs79ZzxqZtFX8nZ/rapHmPY7837AHPO3yE0903eXP/U89Cff9zWnD/Hw==</diagram></mxfile>

================================================
File: _data/figures/docker-runner.xml
================================================
<mxfile userAgent="Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/61.0.3163.91 Safari/537.36 OPR/48.0.2685.32" version="7.5.3" editor="www.draw.io" type="github"><diagram id="504e1022-b558-5aae-80ab-cc4a7f751d5f" name="Page-1">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</diagram></mxfile>

================================================
File: _data/figures/docker-sync-actions.xml
================================================
<mxfile userAgent="Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.81 Safari/537.36 OPR/45.0.2552.812" version="6.6.3" editor="www.draw.io" type="github"><diagram name="Page-1">5VpLc6M4EP41rpo92KUH2OboOMlMtvaRnRxm56iAbJhgRAnhx/z6FSCMBQI/YjvZCYeU1GokpP7U/XXHPTxdrD9zEvt/Mo+GPQS8dQ/f9hAaj5D8mwk2hcCycSGY88ArRLASPAU/qRICJU0DjyaaomAsFEGsC10WRdQVmoxwzla62oyF+qoxmdOG4MklYVP6LfCEr7Zlg0r+hQZzv1wZAjXyTNyXOWdppNbrITzLn2J4Qcq5lH7iE4+tdkT4roennDFRtBbrKQ2zoy2PrXjvvmV0+92cRuKgF4bqO8Sm3Dv15FGoLuPCZ3MWkfCukt64KV/SbAIoO/lm8x6QPV8sQjUgv4Bv/lXyvPM96wzssvtIebCggnKl84MKsVFYIKlgUlSt/wdjsZp4xiKh1KAl+8UOss9uPQQlSljKXaWlACkIn1OlZW0NIHFNmfw2vpEqnIZEBEt9dqIQNt/qVacsG+qgWw7dKeZYkjBVs/7OnntoGMoPufGCpWzOs+bdUu4gKQfktDtjF7Pbm5thaDaD8i19MIDyKV5T7qWP7KJ/sKny6Seck82OQsyC/Li3qz9mgmppBGxtWQRql6umDx3QpS8bxRe0rFZbzNZ3w2azRJ5YHXbbAzsIidgMRPBPSqUAgU8k2USuz1nE0uS3BuQSwdnL1kMiHUfStcWZ3mI9z2LEYBaylesTLgYxZy5N5D5uVn4g6FNMcjSspJoBV7MgDKcsZDxfE8Nb5MhGobcjv8+fLQ6XlAu67kZiK8agVTPcUPVXVTCAWMn83UBQxoFXuQd8BZ88GA7Hu35ZXisAX+uZ6ToQxewjjFT/+85Yfd7TXIbVdBkQmO15WX9gY0eHiWN3+gMbjbr0dX9wwm2GdvM6P/39lyGwfKVJzKKE/tKhxYATe19owcDCmo3KW35ZJFlD3eHAcXdksRy7S39PZOljYNzjWUMLHL1nkrN1hLCnkVP8PsipAbp4L3ShPa6xoqtgF+MaUcHd2G3oO0exImDe41mxazWge8vcF4kFBL6mMuPkH4YJWaDGhJCBCTkGJmSfgQg5bx6ITru9dvP2vja1PI2f2MdFFRt26r+en4xb+Amo+MgvwTwMAOhOaiX5HmOdeFzJedeJx56Udo9+m/M+q3dustzJ44MUfCaCrvLdf/qQWas11m1jGVw1vFTS2rzaBqrnC5EVcCfZrJLn5TG1z/OIOnihz4yFZOCyxXYs0xvdTNlCOgd5CA9ebyRnvieuCFhUDE6KdiYvlnvmFXk8iFK2c0SVzZbtnfKlIZc9OEc+zqOdxyENmw6pOxUCAzS29Wz1OpkQqpVe7Ov7F4iOx3Ky4Wl8BIZPxOoF6kAy99RTIIBemwP5jAc/JW5JqF6sg7iqE0mOt1MmUiWos1WKDLDfm0YBa2xpCOxbzinAb2bdlmOe96zgHTawOw2D7IzeJgq2RLu26HiGKFiv3ZqiILhUFITNzDERHkubx///JLYlfTggtakCiR5F0DWiSL2eVqsxHKu/ryahvQsvUZEoJzWVJB4W2X+zPwzLrVUk8KEVifNccNiwwySOw8AlBSUFU+a9D1sAMBkXvvaKtnAMtkAGW9QrzgeYQnarn0UUN6j66Qm++w8=</diagram></mxfile>

================================================
File: _data/figures/variables.drawio
================================================
<mxfile host="app.diagrams.net" modified="2020-04-07T16:39:00.428Z" agent="5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/80.0.3987.149 Safari/537.36 OPR/67.0.3575.115" etag="PKazv-QyjEEhooXQQId_" version="12.9.9" type="device"><diagram id="b6f3jVojfKmbGVbtELNX" name="Page-1">5Vrbcts2EP0azSQP0gDgTXq0ZKfpNJl64mnq9CUDkRCJmiJYENQlX1+QBC8gRVm2dUvryYyB5WIB7p7dPUQ8MGbLzS8cx8Fn5pFwgIC3GRi3A4SgidAg+we8bSGZQKsQ+Jx6SqkWPNAfRAmBkqbUI4mmKBgLBY11ocuiiLhCk2HO2VpXW7BQ3zXGPukIHlwcdqV/Uk8EhXRsgVr+kVA/KHeGQD1Z4lJZCZIAe2zdEBl3A2PGGRPFaLmZkTBzXumXYt2HnqfVwTiJxCELwG/pdPX4VzJBH58+TP+w6NpJhioYKxym6oVXmFM8D0nyXS4sDi62pTeIJ52jpoyLgPkswuFdLZ1ylkYeybYEclbrfGIslkIohX8TIbYq0jgVTIoCsQzVU7Kh4rEx/paZGllqdrtRlvPJtpxEgm8fm5PGqmxaL8tn5bri/bKX6vWpEiUs5S7Z48gSm5j7ROzRQ1XkZcoQtiTyPHKdyhcwUna2ehZwEmJBV/oxsYK2X5lRlm84x9uGQsxoJJLGxveZoN7VGANtV2S3kPQyfTkoTtBaXR6HLRaJ9JG+ouGNWpQj+AVoti8K2BEAYw20cIJOAls35av8xOX294RT6TvCL4drczeuDwauBoWXxh3C3jL2PZftLGaCbIQeShxSP5JjV7opc+Z0RbigshncqAdL6nkFakhCf2T2lcdVikm71nRg3VYxyAyQjfb2qlOpxXV/0Cp5L7p7S8cQjAxk2Vpi2q+pHp10h+YImJrdoeGMQMvO6bK6G9zPmEZSMmPRgvoply/H5NwOs3DOuRz52ejdikQe4yOXLWMWSd++70BgHVBBHmKcp8BaMpgWHpK44BQLuskSrj+ondTqjRO0W8WzJAzrml7AEhNBk1qUwqOnD+o4+GtJAg7w8hOZS0KGRxVxuAo3m+0edXk3jztudnPXvqJpaR3gzR3siO3COLBd9ATvPO1i0tstvubN4tfXEN/jhqSiBtXk7Iz20FD2dP6K0YLJWO9K1SfSG/uSbbRS3GxlbnF0tWoPn60OVLa3SnD65mZ0sPg7dwOSiLLeXr6UtjuWeflSavZ2LCktklgOvsjP7SvwnwV1/0Gz67/JDvdNTuU9iK6nvoGRYzVLHDxfgSvD8myFMy7ZrGC3QvTQhp/tewY+dxcCJo6jF2ZkHKVzlGZKs865qj00ryfzWswCnfOy7NDMe+utQg9xAD3fBs8Qh5feq9mOvo812X+v1taHttECYeNe7WiQtDv1pfzIS2IcaWC1/0mz2+rpgkVimOQIu5EKEMYb+SvHCJhj98nPUTp0Wch4ocL9+TtkWZkWkucErfH72nb5Xdml5MWh5EsW5yrUfv4quJ8/Z9c6DkI6LsAby+AZCh3ooOpLmoFpP7tNAhxnw3QZ3riCNYP1Cc9JeM8Smi80budMCLaUCmH2YFqhblaATlozFvnPjoAL1qJ9LBUhjcis+k+kLPoLGoa7rB2BEhoTS68MdpcSGjsooX2yKyDr4o3piP0FmQf2l4teQ6Bu5f2PMLsCTXuYnekYrZJmHoXYVQSr+pK3z0XtkNOJ5vXeKjXp3jeN7Z2c+x2cm6fhfpahc39oHcb9jgaT7tVF0Rhb1+z/08aIWtf28GR9UU7rv70oolv/BYtx9y8=</diagram></mxfile>

================================================
File: _data/figures/variables.xml
================================================
<?xml version="1.0" encoding="UTF-8"?>
<mxfile host="app.diagrams.net" modified="2020-04-07T16:39:29.766Z" agent="5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/80.0.3987.149 Safari/537.36 OPR/67.0.3575.115" etag="NnRkRhuff6RXscVzXvZq" version="12.9.9" type="device"><diagram id="b6f3jVojfKmbGVbtELNX" name="Page-1">5Vrbcts2EP0azSQP0gDgTXq0ZKfpNJl64mnq9CUDkRCJmiJYENQlX1+QBC8gRVm2dUvryYyB5WIB7p7dPUQ8MGbLzS8cx8Fn5pFwgIC3GRi3A4SgidAg+we8bSGZQKsQ+Jx6SqkWPNAfRAmBkqbUI4mmKBgLBY11ocuiiLhCk2HO2VpXW7BQ3zXGPukIHlwcdqV/Uk8EhXRsgVr+kVA/KHeGQD1Z4lJZCZIAe2zdEBl3A2PGGRPFaLmZkTBzXumXYt2HnqfVwTiJxCELwG/pdPX4VzJBH58+TP+w6NpJhioYKxym6oVXmFM8D0nyXS4sDi62pTeIJ52jpoyLgPkswuFdLZ1ylkYeybYEclbrfGIslkIohX8TIbYq0jgVTIoCsQzVU7Kh4rEx/paZGllqdrtRlvPJtpxEgm8fm5PGqmxaL8tn5bri/bKX6vWpEiUs5S7Z48gSm5j7ROzRQ1XkZcoQtiTyPHKdyhcwUna2ehZwEmJBV/oxsYK2X5lRlm84x9uGQsxoJJLGxveZoN7VGANtV2S3kPQyfTkoTtBaXR6HLRaJ9JG+ouGNWpQj+AVoti8K2BEAYw20cIJOAls35av8xOX294RT6TvCL4drczeuDwauBoWXxh3C3jL2PZftLGaCbIQeShxSP5JjV7opc+Z0RbigshncqAdL6nkFakhCf2T2lcdVikm71nRg3VYxyAyQjfb2qlOpxXV/0Cp5L7p7S8cQjAxk2Vpi2q+pHp10h+YImJrdoeGMQMvO6bK6G9zPmEZSMmPRgvoply/H5NwOs3DOuRz52ejdikQe4yOXLWMWSd++70BgHVBBHmKcp8BaMpgWHpK44BQLuskSrj+ondTqjRO0W8WzJAzrml7AEhNBk1qUwqOnD+o4+GtJAg7w8hOZS0KGRxVxuAo3m+0edXk3jztudnPXvqJpaR3gzR3siO3COLBd9ATvPO1i0tstvubN4tfXEN/jhqSiBtXk7Iz20FD2dP6K0YLJWO9K1SfSG/uSbbRS3GxlbnF0tWoPn60OVLa3SnD65mZ0sPg7dwOSiLLeXr6UtjuWeflSavZ2LCktklgOvsjP7SvwnwV1/0Gz67/JDvdNTuU9iK6nvoGRYzVLHDxfgSvD8myFMy7ZrGC3QvTQhp/tewY+dxcCJo6jF2ZkHKVzlGZKs865qj00ryfzWswCnfOy7NDMe+utQg9xAD3fBs8Qh5feq9mOvo812X+v1taHttECYeNe7WiQtDv1pfzIS2IcaWC1/0mz2+rpgkVimOQIu5EKEMYb+SvHCJhj98nPUTp0Wch4ocL9+TtkWZkWkucErfH72nb5Xdml5MWh5EsW5yrUfv4quJ8/Z9c6DkI6LsAby+AZCh3ooOpLmoFpP7tNAhxnw3QZ3riCNYP1Cc9JeM8Smi80budMCLaUCmH2YFqhblaATlozFvnPjoAL1qJ9LBUhjcis+k+kLPoLGoa7rB2BEhoTS68MdpcSGjsooX2yKyDr4o3piP0FmQf2l4teQ6Bu5f2PMLsCTXuYnekYrZJmHoXYVQSr+pK3z0XtkNOJ5vXeKjXp3jeN7Z2c+x2cm6fhfpahc39oHcb9jgaT7tVF0Rhb1+z/08aIWtf28GR9UU7rv70oolv/BYtx9y8=</diagram></mxfile>

================================================
File: _includes/async-create.py
================================================
import requests
import os
import json
import boto3
from time import sleep

storageToken = 'yourToken'
# Source filename (including path)
fileName = 'simple.csv'
# Target Storage Bucket (assumed to exist)
bucketName = 'in.c-main'
# Target Storage Table (assumed NOT to exist)
tableName = 'my-new-table'

print('\nCreating upload file')

# Create a new file in Storage
# See https://keboola.docs.apiary.io/#reference/files/upload-file/create-file-resource
response = requests.post(
    'https://connection.keboola.com/v2/storage/files/prepare',
    data={
        'name': fileName,
        'sizeBytes': os.stat(fileName).st_size,
        'federationToken': 1
    },
    headers={'X-StorageApi-Token': storageToken}
)
parsed = json.loads(response.content.decode('utf-8'))
# print(response.request.body)
# print(json.dumps(parsed, indent=4))

# Get AWS Credentials
accessKeyId = parsed['uploadParams']['credentials']['AccessKeyId']
accessKeySecret = parsed['uploadParams']['credentials']['SecretAccessKey']
sessionToken = parsed['uploadParams']['credentials']['SessionToken']
region = parsed['region']
fileId = parsed['id']

print('\nUploading to S3')

# Upload file to S3
# See https://boto3.amazonaws.com/v1/documentation/api/latest/guide/configuration.html
s3 = boto3.resource('s3', region_name=region, aws_access_key_id=accessKeyId, aws_secret_access_key=accessKeySecret, aws_session_token=sessionToken)
data = open(fileName, 'rb')
s3.Bucket(parsed['uploadParams']['bucket']).put_object(Key=parsed['uploadParams']['key'], Body=data)

print('\nCreating table')

# Load data from file into the Storage table
# See https://keboola.docs.apiary.io/#reference/tables/create-table-asynchronously/create-new-table-from-csv-file-asynchronously
response = requests.post(
    'https://connection.keboola.com/v2/storage/buckets/%s/tables-async' % bucketName,
    data={'name': tableName, 'dataFileId': fileId, 'delimiter': ',', 'enclosure': '"'},
    headers={'X-StorageApi-Token': storageToken},
)
parsed = json.loads(response.content.decode('utf-8'))
# print(json.dumps(parsed, indent=4))
if (parsed['status'] == 'error'):
    print(parsed['error'])
    exit(2)

status = parsed['status']
while (status == 'waiting') or (status == 'processing'):
    print('\nWaiting for import to finish')
    # See https://keboola.docs.apiary.io/#reference/jobs/manage-jobs/job-detail
    response = requests.get(parsed['url'], headers={'X-StorageApi-Token': storageToken})
    jobParsed = json.loads(response.content.decode('utf-8'))
    status = jobParsed['status']
    sleep(1)

# print(json.dumps(jobParsed, indent=4))
if (jobParsed['status'] == 'error'):
    print(jobParsed['error']['message'])
    exit(2)


================================================
File: _includes/branches-beta-warning.html
================================================
<div class="clearfix"></div><div class="alert alert-warning">
    <p><strong>Public Beta Warning:</strong><br>
        This feature is currently in public beta. Please provide feedback using the feedback button in your project.</p>
</div>


================================================
File: _includes/breadcrumbs-item.html
================================================
{% assign parts = include.parts %}
{% assign current = include.current %}

{% for item in include.items %}
    {% assign url = current | prepend: '/' | append: '/' %}
    {% if item.url == url %}
        {% if parts.size > 0 and item.items %}
            <li><a href="{{ item.url | prepend: site.baseurl}}">{{ item.title }}</a></li>

            {% assign current = current | append: '/' | append: parts.first %}
            {% assign parts = parts | join: '/' | remove_first: '/' | remove_first: parts.first | split: '/' %}

            {% include breadcrumbs-item.html items=item.items parts=parts current=current %}

        {% else %}
            <li>{{ item.title }}</li>
        {% endif %}
    {% endif %}
{% endfor %}


================================================
File: _includes/breadcrumbs.html
================================================
{% assign parts = page.url | strip | remove_first: '/' | split: '/' %}

{% if parts.size > 0 %}
{% assign current = parts.first %}
<ol class="breadcrumb">
    <li><a href="{{ '/' | prepend: site.baseurl}}">Home</a></li>
    {% assign parts = parts | join: '/' | remove_first: current | remove_first: '/' | split: '/' %}
    {% include breadcrumbs-item.html items=site.data.navigation.items parts=parts current=current %}
</ol>
{% endif %}


================================================
File: _includes/config-events.js
================================================
document.addEventListener('DOMContentLoaded', function() {
    // Api
    $("span:contains('\"baseUrl\"')").wrap("<a href='/extend/generic-extractor/configuration/api/#base-url'></a>");
    $("span:contains('\"caCertificate\"')").wrap("<a href='/extend/generic-extractor/configuration/api/#ca-certificate'></a>");
    $("span:contains('\"retryConfig\"')").wrap("<a href='/extend/generic-extractor/configuration/api/#retry-configuration'></a>");
    $("span:contains('\"http\"')").first().wrap("<a href='/extend/generic-extractor/configuration/api/#default-http-options'></a>");
    $("span:contains('\"headers\"')").first().wrap("<a href='/extend/generic-extractor/configuration/api/#headers'></a>");
    $("span:contains('\"params\"')").first().wrap("<a href='/extend/generic-extractor/configuration/api/#default-request-parameters'></a>");
    $("span:contains('\"defaultOptions\"')").wrap("<a href='/extend/generic-extractor/configuration/api/#default-request-parameters'></a>");
    $("span:contains('\"requiredHeaders\"')").wrap("<a href='/extend/generic-extractor/configuration/api/#required-headers'></a>");
    $("span:contains('\"ignoreErrors\"')").wrap("<a href='/extend/generic-extractor/configuration/api/#ignore-errors'></a>");
    $("span:contains('\"connectTimeout\"')").wrap("<a href='/extend/generic-extractor/configuration/api/#connect-timeout'></a>");
    $("span:contains('\"requestTimeout\"')").wrap("<a href='/extend/generic-extractor/configuration/api/#request-timeout'></a>");
    $("span:contains('\"pagination\"')").wrap("<a href='/extend/generic-extractor/configuration/api/pagination/'></a>");
    $("span:contains('\"scrollers\"')").wrap("<a href='/extend/generic-extractor/configuration/api/pagination/multiple/'></a>");
    $("span:contains('\"method\"')").first().wrap("<a href='/extend/generic-extractor/configuration/api/pagination/#paging-strategy'></a>");
    $("span:contains('\"authentication\"')").wrap("<a href='/extend/generic-extractor/configuration/api/authentication'></a>");

    // AWS Signature
    $("span:contains('\"signature\"')").wrap("<a href='/extend/generic-extractor/configuration/aws-signature'></a>");
    $("span:contains('\"credentials\"')").first().wrap("<a href='/extend/generic-extractor/configuration/aws-signature#aws-signature-credentials'></a>");

    // Jobs
    $("span:contains('\"endpoint\"')").wrap("<a href='/extend/generic-extractor/configuration/config/jobs/#endpoint'></a>");
    $("span:contains('\"params\"')").last().wrap("<a href='/extend/generic-extractor/configuration/config/jobs/#request-parameters'></a>");
    $("span:contains('\"method\"')").last().wrap("<a href='/extend/generic-extractor/configuration/config/jobs/#method'></a>");
    $("span:contains('\"dataField\"')").wrap("<a href='/extend/generic-extractor/configuration/config/jobs/#data-field'></a>");
    $("span:contains('\"dataType\"')").wrap("<a href='/extend/generic-extractor/configuration/config/jobs/#data-type'></a>");
    $("span:contains('\"responseFilter\"')").wrap("<a href='/extend/generic-extractor/configuration/config/jobs/#response-filter'></a>");
    $("span:contains('\"responseFilterDelimiter\"')").wrap("<a href='/extend/generic-extractor/configuration/config/jobs/#response-filter'></a>");
    $("span:contains('\"scroller\"')").last().wrap("<a href='/extend/generic-extractor/configuration/config/jobs/#scroller'></a>");

    // Child jobs
    $("span:contains('\"children\"')").wrap("<a href='/extend/generic-extractor/configuration/config/jobs/#children'></a>");
    $("span:contains('\"recursionFilter\"')").wrap("<a href='/extend/generic-extractor/configuration/config/jobs/children/#filter'></a>");
    $("span:contains('\"placeholders\"')").wrap("<a href='/extend/generic-extractor/configuration/config/jobs/children/#placeholders'></a>");

    // Config root
    $("span:contains('\"api\"')").wrap("<a href='/extend/generic-extractor/configuration/api/'></a>");
    $("span:contains('\"config\"')").wrap("<a href='/extend/generic-extractor/configuration/config/'></a>");
    $("span:contains('\"sshProxy\"')").wrap("<a href='/extend/generic-extractor/configuration/ssh-proxy/'></a>");
    $("span:contains('\"iterations\"')").wrap("<a href='/extend/generic-extractor/configuration/iterations/'></a>");

    // Configuration
    $("span:contains('\"debug\"')").wrap("<a href='/extend/generic-extractor/running/#debug-mode'></a>");
    $("span:contains('\"incrementalOutput\"')").wrap("<a href='/extend/generic-extractor/incremental/'></a>");
    $("span:contains('\"jobs\"')").wrap("<a href='/extend/generic-extractor/configuration/config/jobs/'></a>");
    $("span:contains('\"mappings\"')").wrap("<a href='/extend/generic-extractor/configuration/config/mappings/'></a>");
    $("span:contains('\"outputBucket\"')").wrap("<a href='/extend/generic-extractor/configuration/config/#output-bucket'></a>");
    $("span:contains('\"http\"')").last().wrap("<a href='/extend/generic-extractor/configuration/config/#http'></a>");
    $("span:contains('\"userData\"')").last().wrap("<a href='/extend/generic-extractor/configuration/config/#user-data'></a>");
    $("span:contains('\"compatLevel\"')").wrap("<a href='/extend/generic-extractor/configuration/config/#compatibility-level'></a>");

    // Mappings
    $("span:contains('\"column\"')").wrap("<a href='/extend/generic-extractor/configuration/config/mappings/#column-mapping'></a>");
    $("span:contains('\"user\"')").first().wrap("<a href='/extend/generic-extractor/configuration/config/mappings/#user-mapping'></a>");
    $("span:contains('\"table\"')").wrap("<a href='/extend/generic-extractor/configuration/config/mappings/#table-mapping'></a>");
    $("span:contains('\"mapping\"')").wrap("<a href='/extend/generic-extractor/configuration/config/mappings/#column-mapping'></a>");
    $("span:contains('\"tableMapping\"')").wrap("<a href='/extend/generic-extractor/configuration/config/mappings/#table-mapping'></a>");
    $("span:contains('\"delimiter\"')").wrap("<a" +
        " href='/extend/generic-extractor/tutorial/mapping/#key-containing-a-dot-character'></a>");

    // Authorization
    $("span:contains('\"authorization\"')").wrap("<a href='/extend/generic-extractor/configuration/api/authentication/#oauth'></a>");
    $("span:contains('\"oauth_api\"')").wrap("<a href='/extend/generic-extractor/configuration/api/authentication/#oauth'></a>");
    $("span:contains('\"credentials\"')").last().wrap("<a href='/extend/generic-extractor/configuration/api/authentication/#oauth'></a>");
}, false);


================================================
File: _includes/config-map.json
================================================
{
    "parameters": {
        "api": {
            "baseUrl": "https://example.com/v3.0/",
            "caCertificate": "-----BEGIN CERTIFICATE-----\nMIIFaz....",
            "pagination": {
                "method": "multiple",
                "scrollers": {
                    "offset_scroll": {
                        "method": "offset",
                        "offsetParam": "offset",
                        "limitParam": "count"
                    }
                }
            },
            "authentication": {
                "type": "basic"
            },
            "retryConfig": {
                "maxRetries": 3
            },
            "http": {
                "headers": {
                    "Accept": "application/json"
                },
                "defaultOptions": {
                    "params": {
                        "company": 123
                    }
                },
                "requiredHeaders": ["X-AppKey"],
                "ignoreErrors": [405],
                "connectTimeout": 30,
                "requestTimeout": 300
            }
        },
        "aws": {
            "signature": {
                "credentials": {
                    "accessKeyId": "testAccessKey",
                    "#secretKey": "testSecretKey",
                    "serviceName": "testService",
                    "regionName": "testRegion"
                }
            }
        },
        "config": {
            "debug": true,
            "username": "dummy",
            "#password": "secret",
            "outputBucket": "ge-tutorial",
            "incrementalOutput": true,
            "compatLevel": 2,
            "http": {
                "headers": {
                    "X-AppKey": "ThisIsSecret"
                }
            },
            "jobs": [
                {
                    "endpoint": "users",
                    "method": "get",
                    "dataField": "items",
                    "dataType": "users",
                    "params": {
                        "type": {
                            "attr": "userType"
                        }
                    },
                    "responseFilter": "additional.address/details",
                    "responseFilterDelimiter": "/",
                    "scroller": "offset_scroll",
                    "children": [
                        {
                            "endpoint": "users/{user_id}/orders",
                            "dataField": "items",
                            "recursionFilter": "id>20",
                            "placeholders": {
                                "user_id": "id"
                            }
                        }
                    ]
                }
            ],
            "mappings": {
                "content": {
                    "parent_id": {
                        "type": "user",
                        "mapping": {
                            "destination": "campaign_id",
                            "primaryKey": true
                        }
                    },
                    "name": {
                        "type": "column",
                        "mapping": {
                            "destination": "text"
                        }
                    },
                    "address": {
                        "type": "table",
                        "destination": "addresses",
                        "tableMapping": {
                            "street": {
                                "type": "column",
                                "mapping": {
                                    "destination": "streetName"
                                }
                            }
                        }
                    },
                    "created.date": {
                        "delimiter": "/",
                        "type": "column",
                        "mapping": {
                            "destination": "createdDate"
                        }
                    }
                }
            },
            "userData": {
                "tag": "development"
            }
        },
        "iterations": [
            {
                "userType": "active"
            },
            {
                "userType": "inactive"
            }
        ],
        "sshProxy": {
            "host": "proxy.example.com",
            "user": "proxy",
            "port": 22,
            "#privateKey": "-----BEGIN RSA PRIVATE KEY-----\n...\n-----END RSA PRIVATE KEY-----"
        }
    },
    "authorization": {
        "oauth_api": {
            "credentials": {
                "#data": "{\"status\": \"ok\",\"refresh_token\": \"1234abcd5678efgh\"}",
                "appKey": "someId",
                "#appSecret": "clientSecret"
            }
        }
    }
}


================================================
File: _includes/gtm-body.html
================================================
<!-- Google Tag Manager (noscript) -->
<noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-WMTTBS"
                  height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
<!-- End Google Tag Manager (noscript) -->

================================================
File: _includes/gtm-head.html
================================================
<!-- Google Tag Manager -->
<script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
        new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
        j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
        'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
})(window,document,'script','dataLayer','GTM-WMTTBS');</script>
<!-- End Google Tag Manager -->

================================================
File: _includes/nav-items.html
================================================
<ul class="nav">
{% for item in include.items %}
    {% assign pageUrlSplitByItemUrl = page.url | split: item.url %}

    {% if item.url == page.url %}
        {% assign cssClass = 'current active' %}
    {% elsif page.url contains item.url and pageUrlSplitByItemUrl.first.size == 0 and item.url != '/' %}
        {% assign cssClass = 'active' %}
    {% else %}
        {% assign cssClass = '' %}
    {% endif %}

    <li class="{{ cssClass }}">
        <a href="{{ item.url }}">{{ item.title }}</a>
        {% if item.items %}
        {% include nav-items.html items=item.items %}
        {% endif %}
    </li>
{% endfor %}
</ul>


================================================
File: _includes/navigation.html
================================================
{% comment %}

{% capture html %}
<ul class="kbc-nav-sidebar nav nav-sidebar">
    {% if include.context == "/" %}
        <li class="{% if page.url == "/" %}active{% endif %}">
            <a href="{{ site.baseurl }}/">{{ site.title }}</a>
        </li>
    {% endif %}

    {% assign entries = site.pages | sort: "path" %}
    {% for entry in entries %}

        {% capture slug    %}{{ entry.url | split: "/"   | last                       }}{% endcapture %}
        {% capture current %}{{ entry.url | remove: slug | remove: "//" | append: "/" }}{% endcapture %}

        {% if current == include.context %}
            <li class="{% if page.url contains entry.url %}active{% endif %}">
                <a href="{{ site.baseurl }}{{ entry.url }}">{{ entry.title }}</a>
                {% include navigation.html context=entry.url %}
            </li>
        {% endif %}

    {% endfor %}
</ul>
{% endcapture %}{{ html | strip_newlines | replace:'    ','' | replace:'    ','' | replace:'  ',' ' }}
{% endcomment %}

{% include nav-items.html items=site.data.navigation.items %}


================================================
File: _includes/writer-config-events.js
================================================
document.addEventListener('DOMContentLoaded', function() {
    // Api
    $("span:contains('\"debug\"')").wrap("<a href='/extend/generic-writer/configuration/#debug'></a>");
    $("span:contains('\"api\"')").wrap("<a href='/extend/generic-writer/configuration/#api'></a>");
    $("span:contains('\"base_url\"')").wrap("<a href='/extend/generic-writer/configuration/#base-url'></a>");
    $("span:contains('\"default_query_parameters\"')").wrap("<a href='/extend/generic-writer/configuration/#default-query-parameters'></a>");
    $("span:contains('\"default_headers\"')").first().wrap("<a href='/extend/generic-writer/configuration/#default-headers'></a>");
    $("span:contains('\"retry_config\"')").first().wrap("<a href='/extend/generic-writer/configuration/#retry-config'></a>");
    $("span:contains('\"authentication\"')").first().wrap("<a href='/extend/generic-writer/configuration/#authentication '></a>");


    $("span:contains('\"user_parameters\"')").first().wrap("<a href='/extend/generic-writer/configuration/#user-parameters '></a>");

    // Request options
    $("span:contains('\"request_parameters\"')").wrap("<a href='/extend/generic-writer/configuration/#request-parameters'></a>");
    $("span:contains('\"api_request\"')").wrap("<a href='/extend/generic-writer/configuration/#api-request'></a>");
    $("span:contains('\"method\"')").wrap("<a href='/extend/generic-writer/configuration/#method'></a>");
    $("span:contains('\"endpoint_path\"')").first().wrap("<a href='/extend/generic-writer/configuration/#endpoint-path'></a>");
    $("span:contains('\"headers\"')").first().wrap("<a href='/extend/generic-writer/configuration/#headers'></a>");
    $("span:contains('\"query_parameters\"')").first().wrap("<a href='/extend/generic-writer/configuration/#query-parameters'></a>");

    // Content
    $("span:contains('\"request_content\"')").first().wrap("<a href='/extend/generic-writer/configuration/#request-content'></a>");
    $("span:contains('\"content_type\"')").first().wrap("<a href='/extend/generic-writer/configuration/#content-type'></a>");

    // JSON CONFIG
    $("span:contains('\"json_mapping\"')").wrap("<a href='/extend/generic-writer/configuration/#json-mapping'></a>");
    $("span:contains('\"chunk_size\"')").wrap("<a href='/extend/generic-writer/configuration/#chunk_size'></a>");
    $("span:contains('\"nesting_delimiter\"')").wrap("<a href='/extend/generic-writer/configuration/#nesting-delimiter'></a>");
    $("span:contains('\"request_data_wrapper\"')").wrap("<a href='/extend/generic-writer/configuration/#request-data-wrapper'></a>");
    $("span:contains('\"autodetect\"')").first().wrap("<a href='/extend/generic-writer/configuration/#autodetect'></a>");
    $("span:contains('\"column_data_types\"')").wrap("<a href='/extend/generic-writer/configuration/#column-data-types'></a>");
    $("span:contains('\"datatype_override\"')").wrap("<a href='/extend/generic-writer/configuration/#column-datatype-override'></a>");
    $("span:contains('\"column_names_override\"')").wrap("<a href='/extend/generic-writer/configuration/#datatype-override'></a>");
    $("span:contains('\"iterate_by_columns\"')").wrap("<a href='/extend/generic-writer/configuration/#iterate-by-columns'></a>");

    // Configuration
    $("span:contains('\"debug\"')").wrap("<a href='/extend/generic-writer/configuration/#debug'></a>");

}, false);


================================================
File: _includes/writer-config-map.json
================================================
{
  "parameters": {
    "debug": false,
    "api": {
      "base_url": "https://example.com/api",
      "default_query_parameters": {
        "content_type": "json"
      },
      "default_headers": {
        "Authorization": {
          "attr": "#token"
        }
      },
      "retry_config": {
        "max_retries": 5,
        "codes": [
          500,
          429
        ]
      },
      "ssl_verification": true,
      "timeout": 5
    },
    "user_parameters": {
      "#token": "Bearer 123456",
      "date": {
        "function": "concat",
        "args": [
          {
            "function": "string_to_date",
            "args": [
              "yesterday",
              "%Y-%m-%d"
            ]
          },
          "T"
        ]
      }
    },
    "request_parameters": {
      "method": "POST",
      "endpoint_path": "/customer/[[id]]",
      "headers": {
        "Content-Type": "application/json"
      },
      "query_parameters": {
        "date": {
          "attr": "date"
        }
      }
    },
    "request_content": {
      "content_type": "JSON",
      "json_mapping": {
        "nesting_delimiter": "__",
        "chunk_size": 100,
        "column_data_types": {
          "autodetect": true,
          "datatype_override": [
            {
              "column": "phone",
              "type": "string"
            },
            {
              "column": "rank",
              "type": "number"
            },
            {
              "column": "is_active",
              "type": "bool"
            }
          ]
        },
        "request_data_wrapper": "{ \"data\": [[data]]}",
        "column_names_override": {
          "full_name": "FULL|NAME"
        }
      },
      "iterate_by_columns": [
        "id"
      ]
    }
  }
}


================================================
File: _layouts/main.html
================================================
<!DOCTYPE html>
<html lang="en">
<head>
	{% include gtm-head.html %}
	<meta charset="utf-8">
	<meta http-equiv="X-UA-Compatible" content="IE=edge">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<meta name="author" content="Keboola">
	<title>{{ page.title }} | Keboola Developers Knowledge Base</title>
	<script src="https://ajax.googleapis.com/ajax/libs/webfont/1.6.26/webfont.js"></script>
	<script>
      WebFont.load({
        google: {
          families: ['Lato:400,700,400italic,700italic']
        }
      });
	</script>
	<link rel="stylesheet" href="{{ '/assets/css/style.css' | prepend: site.baseurl }}">
	<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/docsearch.js@2/dist/cdn/docsearch.min.css" />
</head>
<body>
{% include gtm-body.html %}
	<div class="root">
		<div class="container header nocontent">
			<div class="inside">
				<a href="{{ '/' | prepend: site.baseurl }}" class="logo"><img src="{{ '/assets/img/logo.png' | prepend: site.baseurl }}"></a>
				<span class="label">DEVELOPERS DOCS</span>

				<div class="keboola-algolia-docsearch">
					<input size="30" type="text" class="form-control"
						   id="keboola-algolia-docsearch-dropdown"
						   placeholder="Search documentation"
					/>
				</div>
			</div>
		</div>

		<div class="container main">
			<div class="inside">
				<div class="row">

					<div class="col-md-3 sidebar nocontent">
						<div class="navigation">
						{% include navigation.html context="/" %}
						</div>
					</div>
					<div class="col-md-9 content">

						<div class="page">
							{% if page.showBreadcrumbs != false %}
							{% include breadcrumbs.html %}
							{% endif %}

							<h1>{{ page.title }}</h1>

						 	{{ content }}

							<script type="text/javascript" src="https://keboola.atlassian.net/s/d41d8cd98f00b204e9800998ecf8427e-T/-3ddrgv/b/8/c95134bc67d3a521bb3f4331beb9b804/_/download/batch/com.atlassian.jira.collector.plugin.jira-issue-collector-plugin:issuecollector/com.atlassian.jira.collector.plugin.jira-issue-collector-plugin:issuecollector.js?locale=en-US&collectorId=712ca69e"></script>
						</div>

					</div>

				</div>
			</div>
		</div>

		<div class="container footer nocontent">
			<div class="inside">
				<p>
					&copy; {{ 'now' | date: "%Y" }} Keboola
				</p>
			</div>
		</div>

	</div>
	<script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.3/jquery.min.js"></script>
	<script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.6/js/bootstrap.min.js" integrity="sha384-0mSbJDEHialfmuBBQP6A4Qrprq5OVfW37PRR3j5ELqxss1yVqOtnepnHVP9aJ7xS" crossorigin="anonymous"></script>
	<script src="https://cdnjs.cloudflare.com/ajax/libs/anchor-js/4.1.0/anchor.js" integrity="sha256-YJ/0BNvdkt0S5QIAGO0w4v7/WSgeHaszrsu7wxMB/G4=" crossorigin="anonymous"></script>
	<script>
		anchors.add();
	</script>
	<script src="{{ '/assets/js/magnific-popup.js' | prepend: site.baseurl }}"></script>
	<script>
	$(document).ready(function() {
	  $('.image-popup').magnificPopup({type:'image', delegate:'img',
		callbacks: {
		  elementParse: function(item) { item.src = item.el.attr('src'); }
		}});
	});
	</script>
<script type="text/javascript" src="https://cdn.jsdelivr.net/npm/docsearch.js@2/dist/cdn/docsearch.min.js"></script>
<script type="text/javascript"> docsearch({
  apiKey: 'cec3ebcc7b489812bd2bd194c17f3c79',
  indexName: 'keboola_developers',
  appId: '0TAPCAT1M3',
  inputSelector: '#keboola-algolia-docsearch-dropdown',
  debug: false, // Set debug to true if you want to inspect the dropdown
  algoliaOptions: {
    hitsPerPage: 10
  }
});
</script>
<!-- Begin KAI chatbot -->
<script src="https://www.gstatic.com/dialogflow-console/fast/df-messenger/prod/v1/df-messenger.js"></script>
<df-messenger
		location="us-central1"
		project-id="keboola-ai"
		agent-id="2400cda3-8b20-435d-8770-11569a61ced0"
		language-code="en"
		intent=WELCOME>
		<df-messenger-chat-bubble
			chat-title="Kai Documentation Chatbot (Beta)">
	</df-messenger-chat-bubble>
</df-messenger>
<style>
	df-messenger {
		z-index: 999;
		position: fixed;
		bottom: 16px;
		right: 16px;
		--df-messenger-chat-border-radius: 6px;
		--df-messenger-chat-window-box-shadow: 0px 0px 59px 0px rgba(0, 0, 0, 0.25);
		--df-messenger-titlebar-title-font-size: 16px;
		--df-messenger-send-icon-color: #a2aab8;
		--df-messenger-send-icon-color-active: #0B57D0;
		--df-messenger-send-icon-color-hover: #0B57D0;
		--df-messenger-input-padding: 8px 0 8px 16px;
 	}
</style>
<!-- End KAI chatbot -->
</body>
</html>


================================================
File: _sass/_bootstrap-compass.scss
================================================
@function twbs-font-path($path) {
  @return font-url($path, true);
}

@function twbs-image-path($path) {
  @return image-url($path, true);
}

$bootstrap-sass-asset-helper: true;


================================================
File: _sass/_bootstrap-mincer.scss
================================================
// Mincer asset helper functions
//
// This must be imported into a .css.ejs.scss file.
// Then, <% %>-interpolations will be parsed as strings by Sass, and evaluated by EJS after Sass compilation.


@function twbs-font-path($path) {
  // do something like following
  // from "path/to/font.ext#suffix" to "<%- asset_path(path/to/font.ext)) + #suffix %>"
  // from "path/to/font.ext?#suffix" to "<%- asset_path(path/to/font.ext)) + ?#suffix %>"
  // or from "path/to/font.ext" just "<%- asset_path(path/to/font.ext)) %>"
  @return "<%- asset_path("#{$path}".replace(/[#?].*$/, '')) + "#{$path}".replace(/(^[^#?]*)([#?]?.*$)/, '$2') %>";
}

@function twbs-image-path($file) {
  @return "<%- asset_path("#{$file}") %>";
}

$bootstrap-sass-asset-helper: true;


================================================
File: _sass/_bootstrap-sprockets.scss
================================================
@function twbs-font-path($path) {
  @return font-path($path);
}

@function twbs-image-path($path) {
  @return image-path($path);
}

$bootstrap-sass-asset-helper: true;


================================================
File: _sass/highlight.scss
================================================
.highlight .hll { background-color: #ffffcc }
.highlight .c { color: #999988; font-style: italic } /* Comment */
.highlight .err { color: #a61717; background-color: #e3d2d2 } /* Error */
.highlight .k { color: #000000; font-weight: bold } /* Keyword */
.highlight .o { color: #000000; font-weight: bold } /* Operator */
.highlight .cm { color: #999988; font-style: italic } /* Comment.Multiline */
.highlight .cp { color: #999999; font-weight: bold; } /* Comment.Preproc */
.highlight .c1 { color: #999988; font-style: italic } /* Comment.Single */
.highlight .cs { color: #999999; font-weight: bold; font-style: italic } /* Comment.Special */
.highlight .gd { color: #000000; background-color: #ffdddd } /* Generic.Deleted */
.highlight .ge { color: #000000; font-style: italic } /* Generic.Emph */
.highlight .gr { color: #aa0000 } /* Generic.Error */
.highlight .gh { color: #999999 } /* Generic.Heading */
.highlight .gi { color: #000000; background-color: #ddffdd } /* Generic.Inserted */
.highlight .go { color: #888888 } /* Generic.Output */
.highlight .gp { color: #555555 } /* Generic.Prompt */
.highlight .gs { font-weight: bold } /* Generic.Strong */
.highlight .gu { color: #aaaaaa } /* Generic.Subheading */
.highlight .gt { color: #aa0000 } /* Generic.Traceback */
.highlight .kc { color: #000000; font-weight: bold } /* Keyword.Constant */
.highlight .kd { color: #000000; font-weight: bold } /* Keyword.Declaration */
.highlight .kn { color: #000000; font-weight: bold } /* Keyword.Namespace */
.highlight .kp { color: #000000; font-weight: bold } /* Keyword.Pseudo */
.highlight .kr { color: #000000; font-weight: bold } /* Keyword.Reserved */
.highlight .kt { color: #445588; font-weight: bold } /* Keyword.Type */
.highlight .m { color: #009999 } /* Literal.Number */
.highlight .s { color: #d01040 } /* Literal.String */
.highlight .na { color: #008080 } /* Name.Attribute */
.highlight .nb { color: #0086B3 } /* Name.Builtin */
.highlight .nc { color: #445588; font-weight: bold } /* Name.Class */
.highlight .no { color: #008080 } /* Name.Constant */
.highlight .nd { color: #3c5d5d; font-weight: bold } /* Name.Decorator */
.highlight .ni { color: #800080 } /* Name.Entity */
.highlight .ne { color: #990000; font-weight: bold } /* Name.Exception */
.highlight .nf { color: #990000; font-weight: bold } /* Name.Function */
.highlight .nl { color: #990000; font-weight: bold } /* Name.Label */
.highlight .nn { color: #555555 } /* Name.Namespace */
.highlight .nt { color: #000080 } /* Name.Tag */
.highlight .nv { color: #008080 } /* Name.Variable */
.highlight .ow { color: #000000; font-weight: bold } /* Operator.Word */
.highlight .w { color: #bbbbbb } /* Text.Whitespace */
.highlight .mf { color: #009999 } /* Literal.Number.Float */
.highlight .mh { color: #009999 } /* Literal.Number.Hex */
.highlight .mi { color: #009999 } /* Literal.Number.Integer */
.highlight .mo { color: #009999 } /* Literal.Number.Oct */
.highlight .sb { color: #d01040 } /* Literal.String.Backtick */
.highlight .sc { color: #d01040 } /* Literal.String.Char */
.highlight .sd { color: #d01040 } /* Literal.String.Doc */
.highlight .s2 { color: #d01040 } /* Literal.String.Double */
.highlight .se { color: #d01040 } /* Literal.String.Escape */
.highlight .sh { color: #d01040 } /* Literal.String.Heredoc */
.highlight .si { color: #d01040 } /* Literal.String.Interpol */
.highlight .sx { color: #d01040 } /* Literal.String.Other */
.highlight .sr { color: #009926 } /* Literal.String.Regex */
.highlight .s1 { color: #d01040 } /* Literal.String.Single */
.highlight .ss { color: #990073 } /* Literal.String.Symbol */
.highlight .bp { color: #999999 } /* Name.Builtin.Pseudo */
.highlight .vc { color: #008080 } /* Name.Variable.Class */
.highlight .vg { color: #008080 } /* Name.Variable.Global */
.highlight .vi { color: #008080 } /* Name.Variable.Instance */
.highlight .il { color: #009999 } /* Literal.Number.Integer.Long */


================================================
File: _sass/magnific-popup.scss
================================================
/* Magnific Popup CSS */
.mfp-bg {
  top: 0;
  left: 0;
  width: 100%;
  height: 100%;
  z-index: 1042;
  overflow: hidden;
  position: fixed;
  background: #0b0b0b;
  opacity: 0.8; }

.mfp-wrap {
  top: 0;
  left: 0;
  width: 100%;
  height: 100%;
  z-index: 1043;
  position: fixed;
  outline: none !important;
  -webkit-backface-visibility: hidden; }

.mfp-container {
  text-align: center;
  position: absolute;
  width: 100%;
  height: 100%;
  left: 0;
  top: 0;
  padding: 0 8px;
  box-sizing: border-box; }

.mfp-container:before {
  content: '';
  display: inline-block;
  height: 100%;
  vertical-align: middle; }

.mfp-align-top .mfp-container:before {
  display: none; }

.mfp-content {
  position: relative;
  display: inline-block;
  vertical-align: middle;
  margin: 0 auto;
  text-align: left;
  z-index: 1045; }

.mfp-inline-holder .mfp-content,
.mfp-ajax-holder .mfp-content {
  width: 100%;
  cursor: auto; }

.mfp-ajax-cur {
  cursor: progress; }

.mfp-zoom {
  cursor: pointer;
  cursor: -webkit-zoom-in;
  cursor: -moz-zoom-in;
  cursor: zoom-in; }

.mfp-auto-cursor .mfp-content {
  cursor: auto; }

.mfp-close,
.mfp-arrow,
.mfp-preloader,
.mfp-counter {
  -webkit-user-select: none;
  -moz-user-select: none;
  user-select: none; }

.mfp-loading.mfp-figure {
  display: none; }

.mfp-hide {
  display: none !important; }

.mfp-preloader {
  color: #CCC;
  position: absolute;
  top: 50%;
  width: auto;
  text-align: center;
  margin-top: -0.8em;
  left: 8px;
  right: 8px;
  z-index: 1044; }
  .mfp-preloader a {
    color: #CCC; }
    .mfp-preloader a:hover {
      color: #FFF; }

.mfp-s-ready .mfp-preloader {
  display: none; }

.mfp-s-error .mfp-content {
  display: none; }

button.mfp-close,
button.mfp-arrow {
  overflow: visible;
  cursor: pointer;
  background: transparent;
  border: 0;
  -webkit-appearance: none;
  display: block;
  outline: none;
  padding: 0;
  z-index: 1046;
  box-shadow: none;
  touch-action: manipulation; }

button::-moz-focus-inner {
  padding: 0;
  border: 0; }

.mfp-close {
  width: 44px;
  height: 44px;
  line-height: 44px;
  position: absolute;
  right: 0;
  top: 0;
  text-decoration: none;
  text-align: center;
  opacity: 0.65;
  padding: 0 0 18px 10px;
  color: #FFF;
  font-style: normal;
  font-size: 28px;
  font-family: Arial, Baskerville, monospace; }
  .mfp-close:hover,
  .mfp-close:focus {
    opacity: 1; }
  .mfp-close:active {
    top: 1px; }

.mfp-close-btn-in .mfp-close {
  color: #333; }

.mfp-image-holder .mfp-close,
.mfp-iframe-holder .mfp-close {
  color: #FFF;
  right: -6px;
  text-align: right;
  padding-right: 6px;
  width: 100%; }

.mfp-counter {
  position: absolute;
  top: 0;
  right: 0;
  color: #CCC;
  font-size: 12px;
  line-height: 18px;
  white-space: nowrap; }

.mfp-arrow {
  position: absolute;
  opacity: 0.65;
  margin: 0;
  top: 50%;
  margin-top: -55px;
  padding: 0;
  width: 90px;
  height: 110px;
  -webkit-tap-highlight-color: transparent; }
  .mfp-arrow:active {
    margin-top: -54px; }
  .mfp-arrow:hover,
  .mfp-arrow:focus {
    opacity: 1; }
  .mfp-arrow:before,
  .mfp-arrow:after {
    content: '';
    display: block;
    width: 0;
    height: 0;
    position: absolute;
    left: 0;
    top: 0;
    margin-top: 35px;
    margin-left: 35px;
    border: medium inset transparent; }
  .mfp-arrow:after {
    border-top-width: 13px;
    border-bottom-width: 13px;
    top: 8px; }
  .mfp-arrow:before {
    border-top-width: 21px;
    border-bottom-width: 21px;
    opacity: 0.7; }

.mfp-arrow-left {
  left: 0; }
  .mfp-arrow-left:after {
    border-right: 17px solid #FFF;
    margin-left: 31px; }
  .mfp-arrow-left:before {
    margin-left: 25px;
    border-right: 27px solid #3F3F3F; }

.mfp-arrow-right {
  right: 0; }
  .mfp-arrow-right:after {
    border-left: 17px solid #FFF;
    margin-left: 39px; }
  .mfp-arrow-right:before {
    border-left: 27px solid #3F3F3F; }

.mfp-iframe-holder {
  padding-top: 40px;
  padding-bottom: 40px; }
  .mfp-iframe-holder .mfp-content {
    line-height: 0;
    width: 100%;
    max-width: 900px; }
  .mfp-iframe-holder .mfp-close {
    top: -40px; }

.mfp-iframe-scaler {
  width: 100%;
  height: 0;
  overflow: hidden;
  padding-top: 56.25%; }
  .mfp-iframe-scaler iframe {
    position: absolute;
    display: block;
    top: 0;
    left: 0;
    width: 100%;
    height: 100%;
    box-shadow: 0 0 8px rgba(0, 0, 0, 0.6);
    background: #000; }

/* Main image in popup */
img.mfp-img {
  width: auto;
  max-width: 100%;
  height: auto;
  display: block;
  line-height: 0;
  box-sizing: border-box;
  padding: 40px 0 40px;
  margin: 0 auto; }

/* The shadow behind the image */
.mfp-figure {
  line-height: 0; }
  .mfp-figure:after {
    content: '';
    position: absolute;
    left: 0;
    top: 40px;
    bottom: 40px;
    display: block;
    right: 0;
    width: auto;
    height: auto;
    z-index: -1;
    box-shadow: 0 0 8px rgba(0, 0, 0, 0.6);
    background: #444; }
  .mfp-figure small {
    color: #BDBDBD;
    display: block;
    font-size: 12px;
    line-height: 14px; }
  .mfp-figure figure {
    margin: 0; }

.mfp-bottom-bar {
  margin-top: -36px;
  position: absolute;
  top: 100%;
  left: 0;
  width: 100%;
  cursor: auto; }

.mfp-title {
  text-align: left;
  line-height: 18px;
  color: #F3F3F3;
  word-wrap: break-word;
  padding-right: 36px; }

.mfp-image-holder .mfp-content {
  max-width: 100%; }

.mfp-gallery .mfp-image-holder .mfp-figure {
  cursor: pointer; }

@media screen and (max-width: 800px) and (orientation: landscape), screen and (max-height: 300px) {
  /**
       * Remove all paddings around the image on small screen
       */
  .mfp-img-mobile .mfp-image-holder {
    padding-left: 0;
    padding-right: 0; }
  .mfp-img-mobile img.mfp-img {
    padding: 0; }
  .mfp-img-mobile .mfp-figure:after {
    top: 0;
    bottom: 0; }
  .mfp-img-mobile .mfp-figure small {
    display: inline;
    margin-left: 5px; }
  .mfp-img-mobile .mfp-bottom-bar {
    background: rgba(0, 0, 0, 0.6);
    bottom: 0;
    margin: 0;
    top: auto;
    padding: 3px 5px;
    position: fixed;
    box-sizing: border-box; }
    .mfp-img-mobile .mfp-bottom-bar:empty {
      padding: 0; }
  .mfp-img-mobile .mfp-counter {
    right: 5px;
    top: 3px; }
  .mfp-img-mobile .mfp-close {
    top: 0;
    right: 0;
    width: 35px;
    height: 35px;
    line-height: 35px;
    background: rgba(0, 0, 0, 0.6);
    position: fixed;
    text-align: center;
    padding: 0; } }

@media all and (max-width: 900px) {
  .mfp-arrow {
    -webkit-transform: scale(0.75);
    transform: scale(0.75); }
  .mfp-arrow-left {
    -webkit-transform-origin: 0;
    transform-origin: 0; }
  .mfp-arrow-right {
    -webkit-transform-origin: 100%;
    transform-origin: 100%; }
  .mfp-container {
    padding-left: 6px;
    padding-right: 6px; } }


================================================
File: _sass/variables.scss
================================================
// Keboola variables

$keboola-violet: #413075;
$keboola-violet-light: #615192;
$keboola-violet-lighter: #887BAF;





$bootstrap-sass-asset-helper: false !default;
//
// Variables
// --------------------------------------------------


//== Colors
//
//## Gray and brand colors for use across Bootstrap.

$gray-base:              #000 !default;
$gray-darker:            lighten($gray-base, 13.5%) !default; // #222
$gray-dark:              lighten($gray-base, 20%) !default;   // #333
$gray:                   lighten($gray-base, 33.5%) !default; // #555
$gray-light:             lighten($gray-base, 46.7%) !default; // #777
$gray-lighter:           lighten($gray-base, 93.5%) !default; // #eee

$brand-primary:         darken(#428bca, 6.5%) !default; // #337ab7
$brand-success:         #5cb85c !default;
$brand-info:            #5bc0de !default;
$brand-warning:         #f0ad4e !default;
$brand-danger:          #d9534f !default;


//== Scaffolding
//
//## Settings for some of the most global styles.

//** Background color for `<body>`.
$body-bg:               #f5f5f5 !default;
//** Global text color on `<body>`.
$text-color:            $gray-dark !default;

//** Global textual link color.
$link-color:            $brand-primary !default;
//** Link hover color set via `darken()` function.
$link-hover-color:      darken($link-color, 15%) !default;
//** Link hover decoration.
$link-hover-decoration: underline !default;


//== Typography
//
//## Font, line-height, and color for body text, headings, and more.

$font-family-sans-serif:  Helvetica, Arial, sans-serif !default;
$font-family-serif:       Georgia, "Times New Roman", Times, serif !default;
//** Default monospace fonts for `<code>`, `<kbd>`, and `<pre>`.
$font-family-monospace:   Consolas, "Liberation Mono", Menlo, Courier, monospace !default;
$font-family-base:        $font-family-sans-serif !default;

$font-size-base:          16px !default;
$font-size-large:         ceil(($font-size-base * 1.25)) !default;
$font-size-small:         ceil(($font-size-base * 0.85)) !default;

$font-size-h1:            floor(($font-size-base * 2.1)) !default;
$font-size-h2:            floor(($font-size-base * 1.8)) !default;
$font-size-h3:            ceil(($font-size-base * 1.5)) !default;
$font-size-h4:            ceil(($font-size-base * 1.2)) !default;
$font-size-h5:            $font-size-base !default;
$font-size-h6:            ceil(($font-size-base * 0.85)) !default;

//** Unit-less `line-height` for use in components like buttons.
$line-height-base:        1.55 !default;
//** Computed "line-height" (`font-size` * `line-height`) for use with `margin`, `padding`, etc.
$line-height-computed:    floor(($font-size-base * $line-height-base)) !default; // ~20px

//** By default, this inherits from the `<body>`.
$headings-font-family:    inherit !default;
$headings-font-weight:    700 !default;
$headings-line-height:    1.1 !default;
$headings-color:          inherit !default;


//== Iconography
//
//## Specify custom location and filename of the included Glyphicons icon font. Useful for those including Bootstrap via Bower.

//** Load fonts from this directory.

// [converter] If $bootstrap-sass-asset-helper if used, provide path relative to the assets load path.
// [converter] This is because some asset helpers, such as Sprockets, do not work with file-relative paths.
$icon-font-path: if($bootstrap-sass-asset-helper, "bootstrap/", "../fonts/bootstrap/") !default;

//** File name for all font files.
$icon-font-name:          "glyphicons-halflings-regular" !default;
//** Element ID within SVG icon file.
$icon-font-svg-id:        "glyphicons_halflingsregular" !default;


//== Components
//
//## Define common padding and border radius sizes and more. Values based on 14px text and 1.428 line-height (~20px to start).

$padding-base-vertical:     6px !default;
$padding-base-horizontal:   12px !default;

$padding-large-vertical:    10px !default;
$padding-large-horizontal:  16px !default;

$padding-small-vertical:    5px !default;
$padding-small-horizontal:  10px !default;

$padding-xs-vertical:       1px !default;
$padding-xs-horizontal:     5px !default;

$line-height-large:         1.3333333 !default; // extra decimals for Win 8.1 Chrome
$line-height-small:         1.5 !default;

$border-radius-base:        4px !default;
$border-radius-large:       6px !default;
$border-radius-small:       3px !default;

//** Global color for active items (e.g., navs or dropdowns).
$component-active-color:    #fff !default;
//** Global background color for active items (e.g., navs or dropdowns).
$component-active-bg:       $brand-primary !default;

//** Width of the `border` for generating carets that indicator dropdowns.
$caret-width-base:          4px !default;
//** Carets increase slightly in size for larger components.
$caret-width-large:         5px !default;


//== Tables
//
//## Customizes the `.table` component with basic values, each used across all table variations.

//** Padding for `<th>`s and `<td>`s.
$table-cell-padding:            8px !default;
//** Padding for cells in `.table-condensed`.
$table-condensed-cell-padding:  5px !default;

//** Default background color used for all tables.
$table-bg:                      transparent !default;
//** Background color used for `.table-striped`.
$table-bg-accent:               #f9f9f9 !default;
//** Background color used for `.table-hover`.
$table-bg-hover:                #f5f5f5 !default;
$table-bg-active:               $table-bg-hover !default;

//** Border color for table and cell borders.
$table-border-color:            #ddd !default;


//== Buttons
//
//## For each of Bootstrap's buttons, define text, background and border color.

$btn-font-weight:                normal !default;

$btn-default-color:              #333 !default;
$btn-default-bg:                 #fff !default;
$btn-default-border:             #ccc !default;

$btn-primary-color:              #fff !default;
$btn-primary-bg:                 $brand-primary !default;
$btn-primary-border:             darken($btn-primary-bg, 5%) !default;

$btn-success-color:              #fff !default;
$btn-success-bg:                 $brand-success !default;
$btn-success-border:             darken($btn-success-bg, 5%) !default;

$btn-info-color:                 #fff !default;
$btn-info-bg:                    $brand-info !default;
$btn-info-border:                darken($btn-info-bg, 5%) !default;

$btn-warning-color:              #fff !default;
$btn-warning-bg:                 $brand-warning !default;
$btn-warning-border:             darken($btn-warning-bg, 5%) !default;

$btn-danger-color:               #fff !default;
$btn-danger-bg:                  $brand-danger !default;
$btn-danger-border:              darken($btn-danger-bg, 5%) !default;

$btn-link-disabled-color:        $gray-light !default;

// Allows for customizing button radius independently from global border radius
$btn-border-radius-base:         $border-radius-base !default;
$btn-border-radius-large:        $border-radius-large !default;
$btn-border-radius-small:        $border-radius-small !default;


//== Forms
//
//##

//** `<input>` background color
$input-bg:                       #fff !default;
//** `<input disabled>` background color
$input-bg-disabled:              $gray-lighter !default;

//** Text color for `<input>`s
$input-color:                    $gray !default;
//** `<input>` border color
$input-border:                   #ccc !default;

// TODO: Rename `$input-border-radius` to `$input-border-radius-base` in v4
//** Default `.form-control` border radius
// This has no effect on `<select>`s in some browsers, due to the limited stylability of `<select>`s in CSS.
$input-border-radius:            $border-radius-base !default;
//** Large `.form-control` border radius
$input-border-radius-large:      $border-radius-large !default;
//** Small `.form-control` border radius
$input-border-radius-small:      $border-radius-small !default;

//** Border color for inputs on focus
$input-border-focus:             $keboola-violet-lighter !default;

//** Placeholder text color
$input-color-placeholder:        #999 !default;

//** Default `.form-control` height
$input-height-base:              ($line-height-computed + ($padding-base-vertical * 2) + 2) !default;
//** Large `.form-control` height
$input-height-large:             (ceil($font-size-large * $line-height-large) + ($padding-large-vertical * 2) + 2) !default;
//** Small `.form-control` height
$input-height-small:             (floor($font-size-small * $line-height-small) + ($padding-small-vertical * 2) + 2) !default;

//** `.form-group` margin
$form-group-margin-bottom:       15px !default;

$legend-color:                   $gray-dark !default;
$legend-border-color:            #e5e5e5 !default;

//** Background color for textual input addons
$input-group-addon-bg:           $gray-lighter !default;
//** Border color for textual input addons
$input-group-addon-border-color: $input-border !default;

//** Disabled cursor for form controls and buttons.
$cursor-disabled:                not-allowed !default;


//== Dropdowns
//
//## Dropdown menu container and contents.

//** Background for the dropdown menu.
$dropdown-bg:                    #fff !default;
//** Dropdown menu `border-color`.
$dropdown-border:                rgba(0,0,0,.15) !default;
//** Dropdown menu `border-color` **for IE8**.
$dropdown-fallback-border:       #ccc !default;
//** Divider color for between dropdown items.
$dropdown-divider-bg:            #e5e5e5 !default;

//** Dropdown link text color.
$dropdown-link-color:            $gray-dark !default;
//** Hover color for dropdown links.
$dropdown-link-hover-color:      darken($gray-dark, 5%) !default;
//** Hover background for dropdown links.
$dropdown-link-hover-bg:         #f5f5f5 !default;

//** Active dropdown menu item text color.
$dropdown-link-active-color:     $component-active-color !default;
//** Active dropdown menu item background color.
$dropdown-link-active-bg:        $component-active-bg !default;

//** Disabled dropdown menu item background color.
$dropdown-link-disabled-color:   $gray-light !default;

//** Text color for headers within dropdown menus.
$dropdown-header-color:          $gray-light !default;

//** Deprecated `$dropdown-caret-color` as of v3.1.0
$dropdown-caret-color:           #000 !default;


//-- Z-index master list
//
// Warning: Avoid customizing these values. They're used for a bird's eye view
// of components dependent on the z-axis and are designed to all work together.
//
// Note: These variables are not generated into the Customizer.

$zindex-navbar:            1000 !default;
$zindex-dropdown:          1000 !default;
$zindex-popover:           1060 !default;
$zindex-tooltip:           1070 !default;
$zindex-navbar-fixed:      1030 !default;
$zindex-modal-background:  1040 !default;
$zindex-modal:             1050 !default;


//== Media queries breakpoints
//
//## Define the breakpoints at which your layout will change, adapting to different screen sizes.

// Extra small screen / phone
//** Deprecated `$screen-xs` as of v3.0.1
$screen-xs:                  480px !default;
//** Deprecated `$screen-xs-min` as of v3.2.0
$screen-xs-min:              $screen-xs !default;
//** Deprecated `$screen-phone` as of v3.0.1
$screen-phone:               $screen-xs-min !default;

// Small screen / tablet
//** Deprecated `$screen-sm` as of v3.0.1
$screen-sm:                  768px !default;
$screen-sm-min:              $screen-sm !default;
//** Deprecated `$screen-tablet` as of v3.0.1
$screen-tablet:              $screen-sm-min !default;

// Medium screen / desktop
//** Deprecated `$screen-md` as of v3.0.1
$screen-md:                  992px !default;
$screen-md-min:              $screen-md !default;
//** Deprecated `$screen-desktop` as of v3.0.1
$screen-desktop:             $screen-md-min !default;

// Large screen / wide desktop
//** Deprecated `$screen-lg` as of v3.0.1
$screen-lg:                  1200px !default;
$screen-lg-min:              $screen-lg !default;
//** Deprecated `$screen-lg-desktop` as of v3.0.1
$screen-lg-desktop:          $screen-lg-min !default;

// So media queries don't overlap when required, provide a maximum
$screen-xs-max:              ($screen-sm-min - 1) !default;
$screen-sm-max:              ($screen-md-min - 1) !default;
$screen-md-max:              ($screen-lg-min - 1) !default;


//== Grid system
//
//## Define your custom responsive grid.

//** Number of columns in the grid.
$grid-columns:              12 !default;
//** Padding between columns. Gets divided in half for the left and right.
$grid-gutter-width:         30px !default;
// Navbar collapse
//** Point at which the navbar becomes uncollapsed.
$grid-float-breakpoint:     $screen-sm-min !default;
//** Point at which the navbar begins collapsing.
$grid-float-breakpoint-max: ($grid-float-breakpoint - 1) !default;


//== Container sizes
//
//## Define the maximum width of `.container` for different screen sizes.

// Small screen / tablet
$container-tablet:             (720px + $grid-gutter-width) !default;
//** For `$screen-sm-min` and up.
$container-sm:                 $container-tablet !default;

// Medium screen / desktop
$container-desktop:            (940px + $grid-gutter-width) !default;
//** For `$screen-md-min` and up.
$container-md:                 $container-desktop !default;

// Large screen / wide desktop
$container-large-desktop:      (1140px + $grid-gutter-width) !default;
//** For `$screen-lg-min` and up.
$container-lg:                 $container-large-desktop !default;


//== Navbar
//
//##

// Basics of a navbar
$navbar-height:                    50px !default;
$navbar-margin-bottom:             $line-height-computed !default;
$navbar-border-radius:             $border-radius-base !default;
$navbar-padding-horizontal:        floor(($grid-gutter-width / 2)) !default;
$navbar-padding-vertical:          (($navbar-height - $line-height-computed) / 2) !default;
$navbar-collapse-max-height:       340px !default;

$navbar-default-color:             #777 !default;
$navbar-default-bg:                #f8f8f8 !default;
$navbar-default-border:            darken($navbar-default-bg, 6.5%) !default;

// Navbar links
$navbar-default-link-color:                #777 !default;
$navbar-default-link-hover-color:          #333 !default;
$navbar-default-link-hover-bg:             transparent !default;
$navbar-default-link-active-color:         #555 !default;
$navbar-default-link-active-bg:            darken($navbar-default-bg, 6.5%) !default;
$navbar-default-link-disabled-color:       #ccc !default;
$navbar-default-link-disabled-bg:          transparent !default;

// Navbar brand label
$navbar-default-brand-color:               $navbar-default-link-color !default;
$navbar-default-brand-hover-color:         darken($navbar-default-brand-color, 10%) !default;
$navbar-default-brand-hover-bg:            transparent !default;

// Navbar toggle
$navbar-default-toggle-hover-bg:           #ddd !default;
$navbar-default-toggle-icon-bar-bg:        #888 !default;
$navbar-default-toggle-border-color:       #ddd !default;


//=== Inverted navbar
// Reset inverted navbar basics
$navbar-inverse-color:                      lighten($gray-light, 15%) !default;
$navbar-inverse-bg:                         #222 !default;
$navbar-inverse-border:                     darken($navbar-inverse-bg, 10%) !default;

// Inverted navbar links
$navbar-inverse-link-color:                 lighten($gray-light, 15%) !default;
$navbar-inverse-link-hover-color:           #fff !default;
$navbar-inverse-link-hover-bg:              transparent !default;
$navbar-inverse-link-active-color:          $navbar-inverse-link-hover-color !default;
$navbar-inverse-link-active-bg:             darken($navbar-inverse-bg, 10%) !default;
$navbar-inverse-link-disabled-color:        #444 !default;
$navbar-inverse-link-disabled-bg:           transparent !default;

// Inverted navbar brand label
$navbar-inverse-brand-color:                $navbar-inverse-link-color !default;
$navbar-inverse-brand-hover-color:          #fff !default;
$navbar-inverse-brand-hover-bg:             transparent !default;

// Inverted navbar toggle
$navbar-inverse-toggle-hover-bg:            #333 !default;
$navbar-inverse-toggle-icon-bar-bg:         #fff !default;
$navbar-inverse-toggle-border-color:        #333 !default;


//== Navs
//
//##

//=== Shared nav styles
$nav-link-padding:                          10px 15px !default;
$nav-link-hover-bg:                         $gray-lighter !default;

$nav-disabled-link-color:                   $gray-light !default;
$nav-disabled-link-hover-color:             $gray-light !default;

//== Tabs
$nav-tabs-border-color:                     #ddd !default;

$nav-tabs-link-hover-border-color:          $gray-lighter !default;

$nav-tabs-active-link-hover-bg:             $body-bg !default;
$nav-tabs-active-link-hover-color:          $gray !default;
$nav-tabs-active-link-hover-border-color:   #ddd !default;

$nav-tabs-justified-link-border-color:            #ddd !default;
$nav-tabs-justified-active-link-border-color:     $body-bg !default;

//== Pills
$nav-pills-border-radius:                   $border-radius-base !default;
$nav-pills-active-link-hover-bg:            $component-active-bg !default;
$nav-pills-active-link-hover-color:         $component-active-color !default;


//== Pagination
//
//##

$pagination-color:                     $link-color !default;
$pagination-bg:                        #fff !default;
$pagination-border:                    #ddd !default;

$pagination-hover-color:               $link-hover-color !default;
$pagination-hover-bg:                  $gray-lighter !default;
$pagination-hover-border:              #ddd !default;

$pagination-active-color:              #fff !default;
$pagination-active-bg:                 $brand-primary !default;
$pagination-active-border:             $brand-primary !default;

$pagination-disabled-color:            $gray-light !default;
$pagination-disabled-bg:               #fff !default;
$pagination-disabled-border:           #ddd !default;


//== Pager
//
//##

$pager-bg:                             $pagination-bg !default;
$pager-border:                         $pagination-border !default;
$pager-border-radius:                  15px !default;

$pager-hover-bg:                       $pagination-hover-bg !default;

$pager-active-bg:                      $pagination-active-bg !default;
$pager-active-color:                   $pagination-active-color !default;

$pager-disabled-color:                 $pagination-disabled-color !default;


//== Jumbotron
//
//##

$jumbotron-padding:              30px !default;
$jumbotron-color:                inherit !default;
$jumbotron-bg:                   $gray-lighter !default;
$jumbotron-heading-color:        inherit !default;
$jumbotron-font-size:            ceil(($font-size-base * 1.5)) !default;
$jumbotron-heading-font-size:    ceil(($font-size-base * 4.5)) !default;


//== Form states and alerts
//
//## Define colors for form feedback states and, by default, alerts.

$state-success-text:             #3c763d !default;
$state-success-bg:               #dff0d8 !default;
$state-success-border:           darken(adjust-hue($state-success-bg, -10), 5%) !default;

$state-info-text:                #31708f !default;
$state-info-bg:                  #d9edf7 !default;
$state-info-border:              darken(adjust-hue($state-info-bg, -10), 7%) !default;

$state-warning-text:             #8a6d3b !default;
$state-warning-bg:               #fcf8e3 !default;
$state-warning-border:           darken(adjust-hue($state-warning-bg, -10), 5%) !default;

$state-danger-text:              #a94442 !default;
$state-danger-bg:                #f2dede !default;
$state-danger-border:            darken(adjust-hue($state-danger-bg, -10), 5%) !default;


//== Tooltips
//
//##

//** Tooltip max width
$tooltip-max-width:           200px !default;
//** Tooltip text color
$tooltip-color:               #fff !default;
//** Tooltip background color
$tooltip-bg:                  #000 !default;
$tooltip-opacity:             .9 !default;

//** Tooltip arrow width
$tooltip-arrow-width:         5px !default;
//** Tooltip arrow color
$tooltip-arrow-color:         $tooltip-bg !default;


//== Popovers
//
//##

//** Popover body background color
$popover-bg:                          #fff !default;
//** Popover maximum width
$popover-max-width:                   276px !default;
//** Popover border color
$popover-border-color:                rgba(0,0,0,.2) !default;
//** Popover fallback border color
$popover-fallback-border-color:       #ccc !default;

//** Popover title background color
$popover-title-bg:                    darken($popover-bg, 3%) !default;

//** Popover arrow width
$popover-arrow-width:                 10px !default;
//** Popover arrow color
$popover-arrow-color:                 $popover-bg !default;

//** Popover outer arrow width
$popover-arrow-outer-width:           ($popover-arrow-width + 1) !default;
//** Popover outer arrow color
$popover-arrow-outer-color:           fade_in($popover-border-color, 0.05) !default;
//** Popover outer arrow fallback color
$popover-arrow-outer-fallback-color:  darken($popover-fallback-border-color, 20%) !default;


//== Labels
//
//##

//** Default label background color
$label-default-bg:            $gray-light !default;
//** Primary label background color
$label-primary-bg:            $brand-primary !default;
//** Success label background color
$label-success-bg:            $brand-success !default;
//** Info label background color
$label-info-bg:               $brand-info !default;
//** Warning label background color
$label-warning-bg:            $brand-warning !default;
//** Danger label background color
$label-danger-bg:             $brand-danger !default;

//** Default label text color
$label-color:                 #fff !default;
//** Default text color of a linked label
$label-link-hover-color:      #fff !default;


//== Modals
//
//##

//** Padding applied to the modal body
$modal-inner-padding:         15px !default;

//** Padding applied to the modal title
$modal-title-padding:         15px !default;
//** Modal title line-height
$modal-title-line-height:     $line-height-base !default;

//** Background color of modal content area
$modal-content-bg:                             #fff !default;
//** Modal content border color
$modal-content-border-color:                   rgba(0,0,0,.2) !default;
//** Modal content border color **for IE8**
$modal-content-fallback-border-color:          #999 !default;

//** Modal backdrop background color
$modal-backdrop-bg:           #000 !default;
//** Modal backdrop opacity
$modal-backdrop-opacity:      .5 !default;
//** Modal header border color
$modal-header-border-color:   #e5e5e5 !default;
//** Modal footer border color
$modal-footer-border-color:   $modal-header-border-color !default;

$modal-lg:                    900px !default;
$modal-md:                    600px !default;
$modal-sm:                    300px !default;


//== Alerts
//
//## Define alert colors, border radius, and padding.

$alert-padding:               15px !default;
$alert-border-radius:         $border-radius-base !default;
$alert-link-font-weight:      bold !default;

$alert-success-bg:            $state-success-bg !default;
$alert-success-text:          $state-success-text !default;
$alert-success-border:        $state-success-border !default;

$alert-info-bg:               $state-info-bg !default;
$alert-info-text:             $state-info-text !default;
$alert-info-border:           $state-info-border !default;

$alert-warning-bg:            $state-warning-bg !default;
$alert-warning-text:          $state-warning-text !default;
$alert-warning-border:        $state-warning-border !default;

$alert-danger-bg:             $state-danger-bg !default;
$alert-danger-text:           $state-danger-text !default;
$alert-danger-border:         $state-danger-border !default;


//== Progress bars
//
//##

//** Background color of the whole progress component
$progress-bg:                 #f5f5f5 !default;
//** Progress bar text color
$progress-bar-color:          #fff !default;
//** Variable for setting rounded corners on progress bar.
$progress-border-radius:      $border-radius-base !default;

//** Default progress bar color
$progress-bar-bg:             $brand-primary !default;
//** Success progress bar color
$progress-bar-success-bg:     $brand-success !default;
//** Warning progress bar color
$progress-bar-warning-bg:     $brand-warning !default;
//** Danger progress bar color
$progress-bar-danger-bg:      $brand-danger !default;
//** Info progress bar color
$progress-bar-info-bg:        $brand-info !default;


//== List group
//
//##

//** Background color on `.list-group-item`
$list-group-bg:                 #fff !default;
//** `.list-group-item` border color
$list-group-border:             #ddd !default;
//** List group border radius
$list-group-border-radius:      $border-radius-base !default;

//** Background color of single list items on hover
$list-group-hover-bg:           #f5f5f5 !default;
//** Text color of active list items
$list-group-active-color:       $component-active-color !default;
//** Background color of active list items
$list-group-active-bg:          $component-active-bg !default;
//** Border color of active list elements
$list-group-active-border:      $list-group-active-bg !default;
//** Text color for content within active list items
$list-group-active-text-color:  lighten($list-group-active-bg, 40%) !default;

//** Text color of disabled list items
$list-group-disabled-color:      $gray-light !default;
//** Background color of disabled list items
$list-group-disabled-bg:         $gray-lighter !default;
//** Text color for content within disabled list items
$list-group-disabled-text-color: $list-group-disabled-color !default;

$list-group-link-color:         #555 !default;
$list-group-link-hover-color:   $list-group-link-color !default;
$list-group-link-heading-color: #333 !default;


//== Panels
//
//##

$panel-bg:                    #fff !default;
$panel-body-padding:          15px !default;
$panel-heading-padding:       10px 15px !default;
$panel-footer-padding:        $panel-heading-padding !default;
$panel-border-radius:         $border-radius-base !default;

//** Border color for elements within panels
$panel-inner-border:          #ddd !default;
$panel-footer-bg:             #f5f5f5 !default;

$panel-default-text:          $gray-dark !default;
$panel-default-border:        #ddd !default;
$panel-default-heading-bg:    #f5f5f5 !default;

$panel-primary-text:          #fff !default;
$panel-primary-border:        $brand-primary !default;
$panel-primary-heading-bg:    $brand-primary !default;

$panel-success-text:          $state-success-text !default;
$panel-success-border:        $state-success-border !default;
$panel-success-heading-bg:    $state-success-bg !default;

$panel-info-text:             $state-info-text !default;
$panel-info-border:           $state-info-border !default;
$panel-info-heading-bg:       $state-info-bg !default;

$panel-warning-text:          $state-warning-text !default;
$panel-warning-border:        $state-warning-border !default;
$panel-warning-heading-bg:    $state-warning-bg !default;

$panel-danger-text:           $state-danger-text !default;
$panel-danger-border:         $state-danger-border !default;
$panel-danger-heading-bg:     $state-danger-bg !default;


//== Thumbnails
//
//##

//** Padding around the thumbnail image
$thumbnail-padding:           4px !default;
//** Thumbnail background color
$thumbnail-bg:                $body-bg !default;
//** Thumbnail border color
$thumbnail-border:            #ddd !default;
//** Thumbnail border radius
$thumbnail-border-radius:     $border-radius-base !default;

//** Custom text color for thumbnail captions
$thumbnail-caption-color:     $text-color !default;
//** Padding around the thumbnail caption
$thumbnail-caption-padding:   9px !default;


//== Wells
//
//##

$well-bg:                     #f5f5f5 !default;
$well-border:                 darken($well-bg, 7%) !default;


//== Badges
//
//##

$badge-color:                 #fff !default;
//** Linked badge text color on hover
$badge-link-hover-color:      #fff !default;
$badge-bg:                    $gray-light !default;

//** Badge text color in active nav link
$badge-active-color:          $link-color !default;
//** Badge background color in active nav link
$badge-active-bg:             #fff !default;

$badge-font-weight:           bold !default;
$badge-line-height:           1 !default;
$badge-border-radius:         10px !default;


//== Breadcrumbs
//
//##

$breadcrumb-padding-vertical:   8px !default;
$breadcrumb-padding-horizontal: 15px !default;
//** Breadcrumb background color
$breadcrumb-bg:                 #f5f5f5 !default;
//** Breadcrumb text color
$breadcrumb-color:              #ccc !default;
//** Text color of current page in the breadcrumb
$breadcrumb-active-color:       $gray-light !default;
//** Textual separator for between breadcrumb elements
$breadcrumb-separator:          "/" !default;


//== Carousel
//
//##

$carousel-text-shadow:                        0 1px 2px rgba(0,0,0,.6) !default;

$carousel-control-color:                      #fff !default;
$carousel-control-width:                      15% !default;
$carousel-control-opacity:                    .5 !default;
$carousel-control-font-size:                  20px !default;

$carousel-indicator-active-bg:                #fff !default;
$carousel-indicator-border-color:             #fff !default;

$carousel-caption-color:                      #fff !default;


//== Close
//
//##

$close-font-weight:           bold !default;
$close-color:                 #000 !default;
$close-text-shadow:           0 1px 0 #fff !default;


//== Code
//
//##

$code-color:                  #c7254e !default;
$code-bg:                     #f9f2f4 !default;

$kbd-color:                   #fff !default;
$kbd-bg:                      #333 !default;

$pre-bg:                      #f5f5f5 !default;
$pre-color:                   $gray-dark !default;
$pre-border-color:            #ccc !default;
$pre-scrollable-max-height:   340px !default;


//== Type
//
//##

//** Horizontal offset for forms and lists.
$component-offset-horizontal: 180px !default;
//** Text muted color
$text-muted:                  $gray-light !default;
//** Abbreviations and acronyms border color
$abbr-border-color:           $gray-light !default;
//** Headings small color
$headings-small-color:        $gray-light !default;
//** Blockquote small color
$blockquote-small-color:      $gray-light !default;
//** Blockquote font size
$blockquote-font-size:        ($font-size-base * 1.25) !default;
//** Blockquote border color
$blockquote-border-color:     $gray-lighter !default;
//** Page header border color
$page-header-border-color:    $gray-lighter !default;
//** Width of horizontal description list titles
$dl-horizontal-offset:        $component-offset-horizontal !default;
//** Point at which .dl-horizontal becomes horizontal
$dl-horizontal-breakpoint:    $grid-float-breakpoint !default;
//** Horizontal line color.
$hr-border:                   $gray-lighter !default;


================================================
File: _sass/bootstrap/_alerts.scss
================================================
//
// Alerts
// --------------------------------------------------


// Base styles
// -------------------------

.alert {
  padding: $alert-padding;
  margin-bottom: $line-height-computed;
  border: 1px solid transparent;
  border-radius: $alert-border-radius;

  // Headings for larger alerts
  h4 {
    margin-top: 0;
    // Specified for the h4 to prevent conflicts of changing $headings-color
    color: inherit;
  }

  // Provide class for links that match alerts
  .alert-link {
    font-weight: $alert-link-font-weight;
  }

  // Improve alignment and spacing of inner content
  > p,
  > ul {
    margin-bottom: 0;
  }

  > p + p {
    margin-top: 5px;
  }
}

// Dismissible alerts
//
// Expand the right padding and account for the close button's positioning.

.alert-dismissable, // The misspelled .alert-dismissable was deprecated in 3.2.0.
.alert-dismissible {
  padding-right: ($alert-padding + 20);

  // Adjust close link position
  .close {
    position: relative;
    top: -2px;
    right: -21px;
    color: inherit;
  }
}

// Alternate styles
//
// Generate contextual modifier classes for colorizing the alert.

.alert-success {
  @include alert-variant($alert-success-bg, $alert-success-border, $alert-success-text);
}

.alert-info {
  @include alert-variant($alert-info-bg, $alert-info-border, $alert-info-text);
}

.alert-warning {
  @include alert-variant($alert-warning-bg, $alert-warning-border, $alert-warning-text);
}

.alert-danger {
  @include alert-variant($alert-danger-bg, $alert-danger-border, $alert-danger-text);
}


================================================
File: _sass/bootstrap/_badges.scss
================================================
//
// Badges
// --------------------------------------------------


// Base class
.badge {
  display: inline-block;
  min-width: 10px;
  padding: 3px 7px;
  font-size: $font-size-small;
  font-weight: $badge-font-weight;
  color: $badge-color;
  line-height: $badge-line-height;
  vertical-align: middle;
  white-space: nowrap;
  text-align: center;
  background-color: $badge-bg;
  border-radius: $badge-border-radius;

  // Empty badges collapse automatically (not available in IE8)
  &:empty {
    display: none;
  }

  // Quick fix for badges in buttons
  .btn & {
    position: relative;
    top: -1px;
  }

  .btn-xs &,
  .btn-group-xs > .btn & {
    top: 0;
    padding: 1px 5px;
  }

  // [converter] extracted a& to a.badge

  // Account for badges in navs
  .list-group-item.active > &,
  .nav-pills > .active > a > & {
    color: $badge-active-color;
    background-color: $badge-active-bg;
  }

  .list-group-item > & {
    float: right;
  }

  .list-group-item > & + & {
    margin-right: 5px;
  }

  .nav-pills > li > a > & {
    margin-left: 3px;
  }
}

// Hover state, but only for links
a.badge {
  &:hover,
  &:focus {
    color: $badge-link-hover-color;
    text-decoration: none;
    cursor: pointer;
  }
}


================================================
File: _sass/bootstrap/_breadcrumbs.scss
================================================
//
// Breadcrumbs
// --------------------------------------------------


.breadcrumb {
  padding: $breadcrumb-padding-vertical $breadcrumb-padding-horizontal;
  margin-bottom: $line-height-computed;
  list-style: none;
  background-color: $breadcrumb-bg;
  border-radius: $border-radius-base;

  > li {
    display: inline-block;

    + li:before {
      // [converter] Workaround for https://github.com/sass/libsass/issues/1115
      $nbsp: "\00a0";
      content: "#{$breadcrumb-separator}#{$nbsp}"; // Unicode space added since inline-block means non-collapsing white-space
      padding: 0 5px;
      color: $breadcrumb-color;
    }
  }

  > .active {
    color: $breadcrumb-active-color;
  }
}


================================================
File: _sass/bootstrap/_button-groups.scss
================================================
//
// Button groups
// --------------------------------------------------

// Make the div behave like a button
.btn-group,
.btn-group-vertical {
  position: relative;
  display: inline-block;
  vertical-align: middle; // match .btn alignment given font-size hack above
  > .btn {
    position: relative;
    float: left;
    // Bring the "active" button to the front
    &:hover,
    &:focus,
    &:active,
    &.active {
      z-index: 2;
    }
  }
}

// Prevent double borders when buttons are next to each other
.btn-group {
  .btn + .btn,
  .btn + .btn-group,
  .btn-group + .btn,
  .btn-group + .btn-group {
    margin-left: -1px;
  }
}

// Optional: Group multiple button groups together for a toolbar
.btn-toolbar {
  margin-left: -5px; // Offset the first child's margin
  @include clearfix;

  .btn,
  .btn-group,
  .input-group {
    float: left;
  }
  > .btn,
  > .btn-group,
  > .input-group {
    margin-left: 5px;
  }
}

.btn-group > .btn:not(:first-child):not(:last-child):not(.dropdown-toggle) {
  border-radius: 0;
}

// Set corners individual because sometimes a single button can be in a .btn-group and we need :first-child and :last-child to both match
.btn-group > .btn:first-child {
  margin-left: 0;
  &:not(:last-child):not(.dropdown-toggle) {
    @include border-right-radius(0);
  }
}
// Need .dropdown-toggle since :last-child doesn't apply given a .dropdown-menu immediately after it
.btn-group > .btn:last-child:not(:first-child),
.btn-group > .dropdown-toggle:not(:first-child) {
  @include border-left-radius(0);
}

// Custom edits for including btn-groups within btn-groups (useful for including dropdown buttons within a btn-group)
.btn-group > .btn-group {
  float: left;
}
.btn-group > .btn-group:not(:first-child):not(:last-child) > .btn {
  border-radius: 0;
}
.btn-group > .btn-group:first-child:not(:last-child) {
  > .btn:last-child,
  > .dropdown-toggle {
    @include border-right-radius(0);
  }
}
.btn-group > .btn-group:last-child:not(:first-child) > .btn:first-child {
  @include border-left-radius(0);
}

// On active and open, don't show outline
.btn-group .dropdown-toggle:active,
.btn-group.open .dropdown-toggle {
  outline: 0;
}


// Sizing
//
// Remix the default button sizing classes into new ones for easier manipulation.

.btn-group-xs > .btn { @extend .btn-xs; }
.btn-group-sm > .btn { @extend .btn-sm; }
.btn-group-lg > .btn { @extend .btn-lg; }


// Split button dropdowns
// ----------------------

// Give the line between buttons some depth
.btn-group > .btn + .dropdown-toggle {
  padding-left: 8px;
  padding-right: 8px;
}
.btn-group > .btn-lg + .dropdown-toggle {
  padding-left: 12px;
  padding-right: 12px;
}

// The clickable button for toggling the menu
// Remove the gradient and set the same inset shadow as the :active state
.btn-group.open .dropdown-toggle {
  @include box-shadow(inset 0 3px 5px rgba(0,0,0,.125));

  // Show no shadow for `.btn-link` since it has no other button styles.
  &.btn-link {
    @include box-shadow(none);
  }
}


// Reposition the caret
.btn .caret {
  margin-left: 0;
}
// Carets in other button sizes
.btn-lg .caret {
  border-width: $caret-width-large $caret-width-large 0;
  border-bottom-width: 0;
}
// Upside down carets for .dropup
.dropup .btn-lg .caret {
  border-width: 0 $caret-width-large $caret-width-large;
}


// Vertical button groups
// ----------------------

.btn-group-vertical {
  > .btn,
  > .btn-group,
  > .btn-group > .btn {
    display: block;
    float: none;
    width: 100%;
    max-width: 100%;
  }

  // Clear floats so dropdown menus can be properly placed
  > .btn-group {
    @include clearfix;
    > .btn {
      float: none;
    }
  }

  > .btn + .btn,
  > .btn + .btn-group,
  > .btn-group + .btn,
  > .btn-group + .btn-group {
    margin-top: -1px;
    margin-left: 0;
  }
}

.btn-group-vertical > .btn {
  &:not(:first-child):not(:last-child) {
    border-radius: 0;
  }
  &:first-child:not(:last-child) {
    @include border-top-radius($btn-border-radius-base);
    @include border-bottom-radius(0);
  }
  &:last-child:not(:first-child) {
    @include border-top-radius(0);
    @include border-bottom-radius($btn-border-radius-base);
  }
}
.btn-group-vertical > .btn-group:not(:first-child):not(:last-child) > .btn {
  border-radius: 0;
}
.btn-group-vertical > .btn-group:first-child:not(:last-child) {
  > .btn:last-child,
  > .dropdown-toggle {
    @include border-bottom-radius(0);
  }
}
.btn-group-vertical > .btn-group:last-child:not(:first-child) > .btn:first-child {
  @include border-top-radius(0);
}


// Justified button groups
// ----------------------

.btn-group-justified {
  display: table;
  width: 100%;
  table-layout: fixed;
  border-collapse: separate;
  > .btn,
  > .btn-group {
    float: none;
    display: table-cell;
    width: 1%;
  }
  > .btn-group .btn {
    width: 100%;
  }

  > .btn-group .dropdown-menu {
    left: auto;
  }
}


// Checkbox and radio options
//
// In order to support the browser's form validation feedback, powered by the
// `required` attribute, we have to "hide" the inputs via `clip`. We cannot use
// `display: none;` or `visibility: hidden;` as that also hides the popover.
// Simply visually hiding the inputs via `opacity` would leave them clickable in
// certain cases which is prevented by using `clip` and `pointer-events`.
// This way, we ensure a DOM element is visible to position the popover from.
//
// See https://github.com/twbs/bootstrap/pull/12794 and
// https://github.com/twbs/bootstrap/pull/14559 for more information.

[data-toggle="buttons"] {
  > .btn,
  > .btn-group > .btn {
    input[type="radio"],
    input[type="checkbox"] {
      position: absolute;
      clip: rect(0,0,0,0);
      pointer-events: none;
    }
  }
}


================================================
File: _sass/bootstrap/_buttons.scss
================================================
//
// Buttons
// --------------------------------------------------


// Base styles
// --------------------------------------------------

.btn {
  display: inline-block;
  margin-bottom: 0; // For input.btn
  font-weight: $btn-font-weight;
  text-align: center;
  vertical-align: middle;
  touch-action: manipulation;
  cursor: pointer;
  background-image: none; // Reset unusual Firefox-on-Android default style; see https://github.com/necolas/normalize.css/issues/214
  border: 1px solid transparent;
  white-space: nowrap;
  @include button-size($padding-base-vertical, $padding-base-horizontal, $font-size-base, $line-height-base, $btn-border-radius-base);
  @include user-select(none);

  &,
  &:active,
  &.active {
    &:focus,
    &.focus {
      @include tab-focus;
    }
  }

  &:hover,
  &:focus,
  &.focus {
    color: $btn-default-color;
    text-decoration: none;
  }

  &:active,
  &.active {
    outline: 0;
    background-image: none;
    @include box-shadow(inset 0 3px 5px rgba(0,0,0,.125));
  }

  &.disabled,
  &[disabled],
  fieldset[disabled] & {
    cursor: $cursor-disabled;
    @include opacity(.65);
    @include box-shadow(none);
  }

  // [converter] extracted a& to a.btn
}

a.btn {
  &.disabled,
  fieldset[disabled] & {
    pointer-events: none; // Future-proof disabling of clicks on `<a>` elements
  }
}


// Alternate buttons
// --------------------------------------------------

.btn-default {
  @include button-variant($btn-default-color, $btn-default-bg, $btn-default-border);
}
.btn-primary {
  @include button-variant($btn-primary-color, $btn-primary-bg, $btn-primary-border);
}
// Success appears as green
.btn-success {
  @include button-variant($btn-success-color, $btn-success-bg, $btn-success-border);
}
// Info appears as blue-green
.btn-info {
  @include button-variant($btn-info-color, $btn-info-bg, $btn-info-border);
}
// Warning appears as orange
.btn-warning {
  @include button-variant($btn-warning-color, $btn-warning-bg, $btn-warning-border);
}
// Danger and error appear as red
.btn-danger {
  @include button-variant($btn-danger-color, $btn-danger-bg, $btn-danger-border);
}


// Link buttons
// -------------------------

// Make a button look and behave like a link
.btn-link {
  color: $link-color;
  font-weight: normal;
  border-radius: 0;

  &,
  &:active,
  &.active,
  &[disabled],
  fieldset[disabled] & {
    background-color: transparent;
    @include box-shadow(none);
  }
  &,
  &:hover,
  &:focus,
  &:active {
    border-color: transparent;
  }
  &:hover,
  &:focus {
    color: $link-hover-color;
    text-decoration: $link-hover-decoration;
    background-color: transparent;
  }
  &[disabled],
  fieldset[disabled] & {
    &:hover,
    &:focus {
      color: $btn-link-disabled-color;
      text-decoration: none;
    }
  }
}


// Button Sizes
// --------------------------------------------------

.btn-lg {
  // line-height: ensure even-numbered height of button next to large input
  @include button-size($padding-large-vertical, $padding-large-horizontal, $font-size-large, $line-height-large, $btn-border-radius-large);
}
.btn-sm {
  // line-height: ensure proper height of button next to small input
  @include button-size($padding-small-vertical, $padding-small-horizontal, $font-size-small, $line-height-small, $btn-border-radius-small);
}
.btn-xs {
  @include button-size($padding-xs-vertical, $padding-xs-horizontal, $font-size-small, $line-height-small, $btn-border-radius-small);
}


// Block button
// --------------------------------------------------

.btn-block {
  display: block;
  width: 100%;
}

// Vertically space out multiple block buttons
.btn-block + .btn-block {
  margin-top: 5px;
}

// Specificity overrides
input[type="submit"],
input[type="reset"],
input[type="button"] {
  &.btn-block {
    width: 100%;
  }
}


================================================
File: _sass/bootstrap/_carousel.scss
================================================
//
// Carousel
// --------------------------------------------------


// Wrapper for the slide container and indicators
.carousel {
  position: relative;
}

.carousel-inner {
  position: relative;
  overflow: hidden;
  width: 100%;

  > .item {
    display: none;
    position: relative;
    @include transition(.6s ease-in-out left);

    // Account for jankitude on images
    > img,
    > a > img {
      @include img-responsive;
      line-height: 1;
    }

    // WebKit CSS3 transforms for supported devices
    @media all and (transform-3d), (-webkit-transform-3d) {
      @include transition-transform(0.6s ease-in-out);
      @include backface-visibility(hidden);
      @include perspective(1000px);

      &.next,
      &.active.right {
        @include translate3d(100%, 0, 0);
        left: 0;
      }
      &.prev,
      &.active.left {
        @include translate3d(-100%, 0, 0);
        left: 0;
      }
      &.next.left,
      &.prev.right,
      &.active {
        @include translate3d(0, 0, 0);
        left: 0;
      }
    }
  }

  > .active,
  > .next,
  > .prev {
    display: block;
  }

  > .active {
    left: 0;
  }

  > .next,
  > .prev {
    position: absolute;
    top: 0;
    width: 100%;
  }

  > .next {
    left: 100%;
  }
  > .prev {
    left: -100%;
  }
  > .next.left,
  > .prev.right {
    left: 0;
  }

  > .active.left {
    left: -100%;
  }
  > .active.right {
    left: 100%;
  }

}

// Left/right controls for nav
// ---------------------------

.carousel-control {
  position: absolute;
  top: 0;
  left: 0;
  bottom: 0;
  width: $carousel-control-width;
  @include opacity($carousel-control-opacity);
  font-size: $carousel-control-font-size;
  color: $carousel-control-color;
  text-align: center;
  text-shadow: $carousel-text-shadow;
  background-color: rgba(0, 0, 0, 0); // Fix IE9 click-thru bug
  // We can't have this transition here because WebKit cancels the carousel
  // animation if you trip this while in the middle of another animation.

  // Set gradients for backgrounds
  &.left {
    @include gradient-horizontal($start-color: rgba(0,0,0,.5), $end-color: rgba(0,0,0,.0001));
  }
  &.right {
    left: auto;
    right: 0;
    @include gradient-horizontal($start-color: rgba(0,0,0,.0001), $end-color: rgba(0,0,0,.5));
  }

  // Hover/focus state
  &:hover,
  &:focus {
    outline: 0;
    color: $carousel-control-color;
    text-decoration: none;
    @include opacity(.9);
  }

  // Toggles
  .icon-prev,
  .icon-next,
  .glyphicon-chevron-left,
  .glyphicon-chevron-right {
    position: absolute;
    top: 50%;
    margin-top: -10px;
    z-index: 5;
    display: inline-block;
  }
  .icon-prev,
  .glyphicon-chevron-left {
    left: 50%;
    margin-left: -10px;
  }
  .icon-next,
  .glyphicon-chevron-right {
    right: 50%;
    margin-right: -10px;
  }
  .icon-prev,
  .icon-next {
    width:  20px;
    height: 20px;
    line-height: 1;
    font-family: serif;
  }


  .icon-prev {
    &:before {
      content: '\2039';// SINGLE LEFT-POINTING ANGLE QUOTATION MARK (U+2039)
    }
  }
  .icon-next {
    &:before {
      content: '\203a';// SINGLE RIGHT-POINTING ANGLE QUOTATION MARK (U+203A)
    }
  }
}

// Optional indicator pips
//
// Add an unordered list with the following class and add a list item for each
// slide your carousel holds.

.carousel-indicators {
  position: absolute;
  bottom: 10px;
  left: 50%;
  z-index: 15;
  width: 60%;
  margin-left: -30%;
  padding-left: 0;
  list-style: none;
  text-align: center;

  li {
    display: inline-block;
    width:  10px;
    height: 10px;
    margin: 1px;
    text-indent: -999px;
    border: 1px solid $carousel-indicator-border-color;
    border-radius: 10px;
    cursor: pointer;

    // IE8-9 hack for event handling
    //
    // Internet Explorer 8-9 does not support clicks on elements without a set
    // `background-color`. We cannot use `filter` since that's not viewed as a
    // background color by the browser. Thus, a hack is needed.
    // See https://developer.mozilla.org/en-US/docs/Web/Events/click#Internet_Explorer
    //
    // For IE8, we set solid black as it doesn't support `rgba()`. For IE9, we
    // set alpha transparency for the best results possible.
    background-color: #000 \9; // IE8
    background-color: rgba(0,0,0,0); // IE9
  }
  .active {
    margin: 0;
    width:  12px;
    height: 12px;
    background-color: $carousel-indicator-active-bg;
  }
}

// Optional captions
// -----------------------------
// Hidden by default for smaller viewports
.carousel-caption {
  position: absolute;
  left: 15%;
  right: 15%;
  bottom: 20px;
  z-index: 10;
  padding-top: 20px;
  padding-bottom: 20px;
  color: $carousel-caption-color;
  text-align: center;
  text-shadow: $carousel-text-shadow;
  & .btn {
    text-shadow: none; // No shadow for button elements in carousel-caption
  }
}


// Scale up controls for tablets and up
@media screen and (min-width: $screen-sm-min) {

  // Scale up the controls a smidge
  .carousel-control {
    .glyphicon-chevron-left,
    .glyphicon-chevron-right,
    .icon-prev,
    .icon-next {
      width: ($carousel-control-font-size * 1.5);
      height: ($carousel-control-font-size * 1.5);
      margin-top: ($carousel-control-font-size / -2);
      font-size: ($carousel-control-font-size * 1.5);
    }
    .glyphicon-chevron-left,
    .icon-prev {
      margin-left: ($carousel-control-font-size / -2);
    }
    .glyphicon-chevron-right,
    .icon-next {
      margin-right: ($carousel-control-font-size / -2);
    }
  }

  // Show and left align the captions
  .carousel-caption {
    left: 20%;
    right: 20%;
    padding-bottom: 30px;
  }

  // Move up the indicators
  .carousel-indicators {
    bottom: 20px;
  }
}


================================================
File: _sass/bootstrap/_close.scss
================================================
//
// Close icons
// --------------------------------------------------


.close {
  float: right;
  font-size: ($font-size-base * 1.5);
  font-weight: $close-font-weight;
  line-height: 1;
  color: $close-color;
  text-shadow: $close-text-shadow;
  @include opacity(.2);

  &:hover,
  &:focus {
    color: $close-color;
    text-decoration: none;
    cursor: pointer;
    @include opacity(.5);
  }

  // [converter] extracted button& to button.close
}

// Additional properties for button version
// iOS requires the button element instead of an anchor tag.
// If you want the anchor version, it requires `href="#"`.
// See https://developer.mozilla.org/en-US/docs/Web/Events/click#Safari_Mobile
button.close {
  padding: 0;
  cursor: pointer;
  background: transparent;
  border: 0;
  -webkit-appearance: none;
}


================================================
File: _sass/bootstrap/_code.scss
================================================
//
// Code (inline and block)
// --------------------------------------------------


// Inline and block code styles
code,
kbd,
pre,
samp {
  font-family: $font-family-monospace;
}

// Inline code
code {
  padding: 2px 4px;
  font-size: 90%;
  color: $code-color;
  background-color: $code-bg;
  border-radius: $border-radius-base;
}

// User input typically entered via keyboard
kbd {
  padding: 2px 4px;
  font-size: 90%;
  color: $kbd-color;
  background-color: $kbd-bg;
  border-radius: $border-radius-small;
  box-shadow: inset 0 -1px 0 rgba(0,0,0,.25);

  kbd {
    padding: 0;
    font-size: 100%;
    font-weight: bold;
    box-shadow: none;
  }
}

// Blocks of code
pre {
  display: block;
  padding: (($line-height-computed - 1) / 2);
  margin: 0 0 ($line-height-computed / 2);
  font-size: ($font-size-base - 1); // 14px to 13px
  line-height: $line-height-base;
  word-break: break-all;
  word-wrap: break-word;
  color: $pre-color;
  background-color: $pre-bg;
  border: 1px solid $pre-border-color;
  border-radius: $border-radius-base;

  // Account for some code outputs that place code tags in pre tags
  code {
    padding: 0;
    font-size: inherit;
    color: inherit;
    white-space: pre-wrap;
    background-color: transparent;
    border-radius: 0;
  }
}

// Enable scrollable blocks of code
.pre-scrollable {
  max-height: $pre-scrollable-max-height;
  overflow-y: scroll;
}


================================================
File: _sass/bootstrap/_component-animations.scss
================================================
//
// Component animations
// --------------------------------------------------

// Heads up!
//
// We don't use the `.opacity()` mixin here since it causes a bug with text
// fields in IE7-8. Source: https://github.com/twbs/bootstrap/pull/3552.

.fade {
  opacity: 0;
  @include transition(opacity .15s linear);
  &.in {
    opacity: 1;
  }
}

.collapse {
  display: none;

  &.in      { display: block; }
  // [converter] extracted tr&.in to tr.collapse.in
  // [converter] extracted tbody&.in to tbody.collapse.in
}

tr.collapse.in    { display: table-row; }

tbody.collapse.in { display: table-row-group; }

.collapsing {
  position: relative;
  height: 0;
  overflow: hidden;
  @include transition-property(height, visibility);
  @include transition-duration(.35s);
  @include transition-timing-function(ease);
}


================================================
File: _sass/bootstrap/_dropdowns.scss
================================================
//
// Dropdown menus
// --------------------------------------------------


// Dropdown arrow/caret
.caret {
  display: inline-block;
  width: 0;
  height: 0;
  margin-left: 2px;
  vertical-align: middle;
  border-top:   $caret-width-base dashed;
  border-top:   $caret-width-base solid \9; // IE8
  border-right: $caret-width-base solid transparent;
  border-left:  $caret-width-base solid transparent;
}

// The dropdown wrapper (div)
.dropup,
.dropdown {
  position: relative;
}

// Prevent the focus on the dropdown toggle when closing dropdowns
.dropdown-toggle:focus {
  outline: 0;
}

// The dropdown menu (ul)
.dropdown-menu {
  position: absolute;
  top: 100%;
  left: 0;
  z-index: $zindex-dropdown;
  display: none; // none by default, but block on "open" of the menu
  float: left;
  min-width: 160px;
  padding: 5px 0;
  margin: 2px 0 0; // override default ul
  list-style: none;
  font-size: $font-size-base;
  text-align: left; // Ensures proper alignment if parent has it changed (e.g., modal footer)
  background-color: $dropdown-bg;
  border: 1px solid $dropdown-fallback-border; // IE8 fallback
  border: 1px solid $dropdown-border;
  border-radius: $border-radius-base;
  @include box-shadow(0 6px 12px rgba(0,0,0,.175));
  background-clip: padding-box;

  // Aligns the dropdown menu to right
  //
  // Deprecated as of 3.1.0 in favor of `.dropdown-menu-[dir]`
  &.pull-right {
    right: 0;
    left: auto;
  }

  // Dividers (basically an hr) within the dropdown
  .divider {
    @include nav-divider($dropdown-divider-bg);
  }

  // Links within the dropdown menu
  > li > a {
    display: block;
    padding: 3px 20px;
    clear: both;
    font-weight: normal;
    line-height: $line-height-base;
    color: $dropdown-link-color;
    white-space: nowrap; // prevent links from randomly breaking onto new lines
  }
}

// Hover/Focus state
.dropdown-menu > li > a {
  &:hover,
  &:focus {
    text-decoration: none;
    color: $dropdown-link-hover-color;
    background-color: $dropdown-link-hover-bg;
  }
}

// Active state
.dropdown-menu > .active > a {
  &,
  &:hover,
  &:focus {
    color: $dropdown-link-active-color;
    text-decoration: none;
    outline: 0;
    background-color: $dropdown-link-active-bg;
  }
}

// Disabled state
//
// Gray out text and ensure the hover/focus state remains gray

.dropdown-menu > .disabled > a {
  &,
  &:hover,
  &:focus {
    color: $dropdown-link-disabled-color;
  }

  // Nuke hover/focus effects
  &:hover,
  &:focus {
    text-decoration: none;
    background-color: transparent;
    background-image: none; // Remove CSS gradient
    @include reset-filter;
    cursor: $cursor-disabled;
  }
}

// Open state for the dropdown
.open {
  // Show the menu
  > .dropdown-menu {
    display: block;
  }

  // Remove the outline when :focus is triggered
  > a {
    outline: 0;
  }
}

// Menu positioning
//
// Add extra class to `.dropdown-menu` to flip the alignment of the dropdown
// menu with the parent.
.dropdown-menu-right {
  left: auto; // Reset the default from `.dropdown-menu`
  right: 0;
}
// With v3, we enabled auto-flipping if you have a dropdown within a right
// aligned nav component. To enable the undoing of that, we provide an override
// to restore the default dropdown menu alignment.
//
// This is only for left-aligning a dropdown menu within a `.navbar-right` or
// `.pull-right` nav component.
.dropdown-menu-left {
  left: 0;
  right: auto;
}

// Dropdown section headers
.dropdown-header {
  display: block;
  padding: 3px 20px;
  font-size: $font-size-small;
  line-height: $line-height-base;
  color: $dropdown-header-color;
  white-space: nowrap; // as with > li > a
}

// Backdrop to catch body clicks on mobile, etc.
.dropdown-backdrop {
  position: fixed;
  left: 0;
  right: 0;
  bottom: 0;
  top: 0;
  z-index: ($zindex-dropdown - 10);
}

// Right aligned dropdowns
.pull-right > .dropdown-menu {
  right: 0;
  left: auto;
}

// Allow for dropdowns to go bottom up (aka, dropup-menu)
//
// Just add .dropup after the standard .dropdown class and you're set, bro.
// TODO: abstract this so that the navbar fixed styles are not placed here?

.dropup,
.navbar-fixed-bottom .dropdown {
  // Reverse the caret
  .caret {
    border-top: 0;
    border-bottom: $caret-width-base dashed;
    border-bottom: $caret-width-base solid \9; // IE8
    content: "";
  }
  // Different positioning for bottom up menu
  .dropdown-menu {
    top: auto;
    bottom: 100%;
    margin-bottom: 2px;
  }
}


// Component alignment
//
// Reiterate per navbar.less and the modified component alignment there.

@media (min-width: $grid-float-breakpoint) {
  .navbar-right {
    .dropdown-menu {
      right: 0; left: auto;
    }
    // Necessary for overrides of the default right aligned menu.
    // Will remove come v4 in all likelihood.
    .dropdown-menu-left {
      left: 0; right: auto;
    }
  }
}


================================================
File: _sass/bootstrap/_forms.scss
================================================
//
// Forms
// --------------------------------------------------


// Normalize non-controls
//
// Restyle and baseline non-control form elements.

fieldset {
  padding: 0;
  margin: 0;
  border: 0;
  // Chrome and Firefox set a `min-width: min-content;` on fieldsets,
  // so we reset that to ensure it behaves more like a standard block element.
  // See https://github.com/twbs/bootstrap/issues/12359.
  min-width: 0;
}

legend {
  display: block;
  width: 100%;
  padding: 0;
  margin-bottom: $line-height-computed;
  font-size: ($font-size-base * 1.5);
  line-height: inherit;
  color: $legend-color;
  border: 0;
  border-bottom: 1px solid $legend-border-color;
}

label {
  display: inline-block;
  max-width: 100%; // Force IE8 to wrap long content (see https://github.com/twbs/bootstrap/issues/13141)
  margin-bottom: 5px;
  font-weight: bold;
}


// Normalize form controls
//
// While most of our form styles require extra classes, some basic normalization
// is required to ensure optimum display with or without those classes to better
// address browser inconsistencies.

// Override content-box in Normalize (* isn't specific enough)
input[type="search"] {
  @include box-sizing(border-box);
}

// Position radios and checkboxes better
input[type="radio"],
input[type="checkbox"] {
  margin: 4px 0 0;
  margin-top: 1px \9; // IE8-9
  line-height: normal;
}

input[type="file"] {
  display: block;
}

// Make range inputs behave like textual form controls
input[type="range"] {
  display: block;
  width: 100%;
}

// Make multiple select elements height not fixed
select[multiple],
select[size] {
  height: auto;
}

// Focus for file, radio, and checkbox
input[type="file"]:focus,
input[type="radio"]:focus,
input[type="checkbox"]:focus {
  @include tab-focus;
}

// Adjust output element
output {
  display: block;
  padding-top: ($padding-base-vertical + 1);
  font-size: $font-size-base;
  line-height: $line-height-base;
  color: $input-color;
}


// Common form controls
//
// Shared size and type resets for form controls. Apply `.form-control` to any
// of the following form controls:
//
// select
// textarea
// input[type="text"]
// input[type="password"]
// input[type="datetime"]
// input[type="datetime-local"]
// input[type="date"]
// input[type="month"]
// input[type="time"]
// input[type="week"]
// input[type="number"]
// input[type="email"]
// input[type="url"]
// input[type="search"]
// input[type="tel"]
// input[type="color"]

.form-control {
  display: block;
  width: 100%;
  height: $input-height-base; // Make inputs at least the height of their button counterpart (base line-height + padding + border)
  padding: $padding-base-vertical $padding-base-horizontal;
  font-size: $font-size-base;
  line-height: $line-height-base;
  color: $input-color;
  background-color: $input-bg;
  background-image: none; // Reset unusual Firefox-on-Android default style; see https://github.com/necolas/normalize.css/issues/214
  border: 1px solid $input-border;
  border-radius: $input-border-radius; // Note: This has no effect on <select>s in some browsers, due to the limited stylability of <select>s in CSS.
  @include box-shadow(inset 0 1px 1px rgba(0,0,0,.075));
  @include transition(border-color ease-in-out .15s, box-shadow ease-in-out .15s);

  // Customize the `:focus` state to imitate native WebKit styles.
  @include form-control-focus;

  // Placeholder
  @include placeholder;

  // Unstyle the caret on `<select>`s in IE10+.
  &::-ms-expand {
    border: 0;
    background-color: transparent;
  }

  // Disabled and read-only inputs
  //
  // HTML5 says that controls under a fieldset > legend:first-child won't be
  // disabled if the fieldset is disabled. Due to implementation difficulty, we
  // don't honor that edge case; we style them as disabled anyway.
  &[disabled],
  &[readonly],
  fieldset[disabled] & {
    background-color: $input-bg-disabled;
    opacity: 1; // iOS fix for unreadable disabled content; see https://github.com/twbs/bootstrap/issues/11655
  }

  &[disabled],
  fieldset[disabled] & {
    cursor: $cursor-disabled;
  }

  // [converter] extracted textarea& to textarea.form-control
}

// Reset height for `textarea`s
textarea.form-control {
  height: auto;
}


// Search inputs in iOS
//
// This overrides the extra rounded corners on search inputs in iOS so that our
// `.form-control` class can properly style them. Note that this cannot simply
// be added to `.form-control` as it's not specific enough. For details, see
// https://github.com/twbs/bootstrap/issues/11586.

input[type="search"] {
  -webkit-appearance: none;
}


// Special styles for iOS temporal inputs
//
// In Mobile Safari, setting `display: block` on temporal inputs causes the
// text within the input to become vertically misaligned. As a workaround, we
// set a pixel line-height that matches the given height of the input, but only
// for Safari. See https://bugs.webkit.org/show_bug.cgi?id=139848
//
// Note that as of 8.3, iOS doesn't support `datetime` or `week`.

@media screen and (-webkit-min-device-pixel-ratio: 0) {
  input[type="date"],
  input[type="time"],
  input[type="datetime-local"],
  input[type="month"] {
    &.form-control {
      line-height: $input-height-base;
    }

    &.input-sm,
    .input-group-sm & {
      line-height: $input-height-small;
    }

    &.input-lg,
    .input-group-lg & {
      line-height: $input-height-large;
    }
  }
}


// Form groups
//
// Designed to help with the organization and spacing of vertical forms. For
// horizontal forms, use the predefined grid classes.

.form-group {
  margin-bottom: $form-group-margin-bottom;
}


// Checkboxes and radios
//
// Indent the labels to position radios/checkboxes as hanging controls.

.radio,
.checkbox {
  position: relative;
  display: block;
  margin-top: 10px;
  margin-bottom: 10px;

  label {
    min-height: $line-height-computed; // Ensure the input doesn't jump when there is no text
    padding-left: 20px;
    margin-bottom: 0;
    font-weight: normal;
    cursor: pointer;
  }
}
.radio input[type="radio"],
.radio-inline input[type="radio"],
.checkbox input[type="checkbox"],
.checkbox-inline input[type="checkbox"] {
  position: absolute;
  margin-left: -20px;
  margin-top: 4px \9;
}

.radio + .radio,
.checkbox + .checkbox {
  margin-top: -5px; // Move up sibling radios or checkboxes for tighter spacing
}

// Radios and checkboxes on same line
.radio-inline,
.checkbox-inline {
  position: relative;
  display: inline-block;
  padding-left: 20px;
  margin-bottom: 0;
  vertical-align: middle;
  font-weight: normal;
  cursor: pointer;
}
.radio-inline + .radio-inline,
.checkbox-inline + .checkbox-inline {
  margin-top: 0;
  margin-left: 10px; // space out consecutive inline controls
}

// Apply same disabled cursor tweak as for inputs
// Some special care is needed because <label>s don't inherit their parent's `cursor`.
//
// Note: Neither radios nor checkboxes can be readonly.
input[type="radio"],
input[type="checkbox"] {
  &[disabled],
  &.disabled,
  fieldset[disabled] & {
    cursor: $cursor-disabled;
  }
}
// These classes are used directly on <label>s
.radio-inline,
.checkbox-inline {
  &.disabled,
  fieldset[disabled] & {
    cursor: $cursor-disabled;
  }
}
// These classes are used on elements with <label> descendants
.radio,
.checkbox {
  &.disabled,
  fieldset[disabled] & {
    label {
      cursor: $cursor-disabled;
    }
  }
}


// Static form control text
//
// Apply class to a `p` element to make any string of text align with labels in
// a horizontal form layout.

.form-control-static {
  // Size it appropriately next to real form controls
  padding-top: ($padding-base-vertical + 1);
  padding-bottom: ($padding-base-vertical + 1);
  // Remove default margin from `p`
  margin-bottom: 0;
  min-height: ($line-height-computed + $font-size-base);

  &.input-lg,
  &.input-sm {
    padding-left: 0;
    padding-right: 0;
  }
}


// Form control sizing
//
// Build on `.form-control` with modifier classes to decrease or increase the
// height and font-size of form controls.
//
// The `.form-group-* form-control` variations are sadly duplicated to avoid the
// issue documented in https://github.com/twbs/bootstrap/issues/15074.

@include input-size('.input-sm', $input-height-small, $padding-small-vertical, $padding-small-horizontal, $font-size-small, $line-height-small, $input-border-radius-small);
.form-group-sm {
  .form-control {
    height: $input-height-small;
    padding: $padding-small-vertical $padding-small-horizontal;
    font-size: $font-size-small;
    line-height: $line-height-small;
    border-radius: $input-border-radius-small;
  }
  select.form-control {
    height: $input-height-small;
    line-height: $input-height-small;
  }
  textarea.form-control,
  select[multiple].form-control {
    height: auto;
  }
  .form-control-static {
    height: $input-height-small;
    min-height: ($line-height-computed + $font-size-small);
    padding: ($padding-small-vertical + 1) $padding-small-horizontal;
    font-size: $font-size-small;
    line-height: $line-height-small;
  }
}

@include input-size('.input-lg', $input-height-large, $padding-large-vertical, $padding-large-horizontal, $font-size-large, $line-height-large, $input-border-radius-large);
.form-group-lg {
  .form-control {
    height: $input-height-large;
    padding: $padding-large-vertical $padding-large-horizontal;
    font-size: $font-size-large;
    line-height: $line-height-large;
    border-radius: $input-border-radius-large;
  }
  select.form-control {
    height: $input-height-large;
    line-height: $input-height-large;
  }
  textarea.form-control,
  select[multiple].form-control {
    height: auto;
  }
  .form-control-static {
    height: $input-height-large;
    min-height: ($line-height-computed + $font-size-large);
    padding: ($padding-large-vertical + 1) $padding-large-horizontal;
    font-size: $font-size-large;
    line-height: $line-height-large;
  }
}


// Form control feedback states
//
// Apply contextual and semantic states to individual form controls.

.has-feedback {
  // Enable absolute positioning
  position: relative;

  // Ensure icons don't overlap text
  .form-control {
    padding-right: ($input-height-base * 1.25);
  }
}
// Feedback icon (requires .glyphicon classes)
.form-control-feedback {
  position: absolute;
  top: 0;
  right: 0;
  z-index: 2; // Ensure icon is above input groups
  display: block;
  width: $input-height-base;
  height: $input-height-base;
  line-height: $input-height-base;
  text-align: center;
  pointer-events: none;
}
.input-lg + .form-control-feedback,
.input-group-lg + .form-control-feedback,
.form-group-lg .form-control + .form-control-feedback {
  width: $input-height-large;
  height: $input-height-large;
  line-height: $input-height-large;
}
.input-sm + .form-control-feedback,
.input-group-sm + .form-control-feedback,
.form-group-sm .form-control + .form-control-feedback {
  width: $input-height-small;
  height: $input-height-small;
  line-height: $input-height-small;
}

// Feedback states
.has-success {
  @include form-control-validation($state-success-text, $state-success-text, $state-success-bg);
}
.has-warning {
  @include form-control-validation($state-warning-text, $state-warning-text, $state-warning-bg);
}
.has-error {
  @include form-control-validation($state-danger-text, $state-danger-text, $state-danger-bg);
}

// Reposition feedback icon if input has visible label above
.has-feedback label {

  & ~ .form-control-feedback {
    top: ($line-height-computed + 5); // Height of the `label` and its margin
  }
  &.sr-only ~ .form-control-feedback {
    top: 0;
  }
}


// Help text
//
// Apply to any element you wish to create light text for placement immediately
// below a form control. Use for general help, formatting, or instructional text.

.help-block {
  display: block; // account for any element using help-block
  margin-top: 5px;
  margin-bottom: 10px;
  color: lighten($text-color, 25%); // lighten the text some for contrast
}


// Inline forms
//
// Make forms appear inline(-block) by adding the `.form-inline` class. Inline
// forms begin stacked on extra small (mobile) devices and then go inline when
// viewports reach <768px.
//
// Requires wrapping inputs and labels with `.form-group` for proper display of
// default HTML form controls and our custom form controls (e.g., input groups).
//
// Heads up! This is mixin-ed into `.navbar-form` in navbars.less.

// [converter] extracted from `.form-inline` for libsass compatibility
@mixin form-inline {

  // Kick in the inline
  @media (min-width: $screen-sm-min) {
    // Inline-block all the things for "inline"
    .form-group {
      display: inline-block;
      margin-bottom: 0;
      vertical-align: middle;
    }

    // In navbar-form, allow folks to *not* use `.form-group`
    .form-control {
      display: inline-block;
      width: auto; // Prevent labels from stacking above inputs in `.form-group`
      vertical-align: middle;
    }

    // Make static controls behave like regular ones
    .form-control-static {
      display: inline-block;
    }

    .input-group {
      display: inline-table;
      vertical-align: middle;

      .input-group-addon,
      .input-group-btn,
      .form-control {
        width: auto;
      }
    }

    // Input groups need that 100% width though
    .input-group > .form-control {
      width: 100%;
    }

    .control-label {
      margin-bottom: 0;
      vertical-align: middle;
    }

    // Remove default margin on radios/checkboxes that were used for stacking, and
    // then undo the floating of radios and checkboxes to match.
    .radio,
    .checkbox {
      display: inline-block;
      margin-top: 0;
      margin-bottom: 0;
      vertical-align: middle;

      label {
        padding-left: 0;
      }
    }
    .radio input[type="radio"],
    .checkbox input[type="checkbox"] {
      position: relative;
      margin-left: 0;
    }

    // Re-override the feedback icon.
    .has-feedback .form-control-feedback {
      top: 0;
    }
  }
}
// [converter] extracted as `@mixin form-inline` for libsass compatibility
.form-inline {
  @include form-inline;
}



// Horizontal forms
//
// Horizontal forms are built on grid classes and allow you to create forms with
// labels on the left and inputs on the right.

.form-horizontal {

  // Consistent vertical alignment of radios and checkboxes
  //
  // Labels also get some reset styles, but that is scoped to a media query below.
  .radio,
  .checkbox,
  .radio-inline,
  .checkbox-inline {
    margin-top: 0;
    margin-bottom: 0;
    padding-top: ($padding-base-vertical + 1); // Default padding plus a border
  }
  // Account for padding we're adding to ensure the alignment and of help text
  // and other content below items
  .radio,
  .checkbox {
    min-height: ($line-height-computed + ($padding-base-vertical + 1));
  }

  // Make form groups behave like rows
  .form-group {
    @include make-row;
  }

  // Reset spacing and right align labels, but scope to media queries so that
  // labels on narrow viewports stack the same as a default form example.
  @media (min-width: $screen-sm-min) {
    .control-label {
      text-align: right;
      margin-bottom: 0;
      padding-top: ($padding-base-vertical + 1); // Default padding plus a border
    }
  }

  // Validation states
  //
  // Reposition the icon because it's now within a grid column and columns have
  // `position: relative;` on them. Also accounts for the grid gutter padding.
  .has-feedback .form-control-feedback {
    right: floor(($grid-gutter-width / 2));
  }

  // Form group sizes
  //
  // Quick utility class for applying `.input-lg` and `.input-sm` styles to the
  // inputs and labels within a `.form-group`.
  .form-group-lg {
    @media (min-width: $screen-sm-min) {
      .control-label {
        padding-top: ($padding-large-vertical + 1);
        font-size: $font-size-large;
      }
    }
  }
  .form-group-sm {
    @media (min-width: $screen-sm-min) {
      .control-label {
        padding-top: ($padding-small-vertical + 1);
        font-size: $font-size-small;
      }
    }
  }
}


================================================
File: _sass/bootstrap/_glyphicons.scss
================================================
//
// Glyphicons for Bootstrap
//
// Since icons are fonts, they can be placed anywhere text is placed and are
// thus automatically sized to match the surrounding child. To use, create an
// inline element with the appropriate classes, like so:
//
// <a href="#"><span class="glyphicon glyphicon-star"></span> Star</a>

@at-root {
  // Import the fonts
  @font-face {
    font-family: 'Glyphicons Halflings';
    src: url(if($bootstrap-sass-asset-helper, twbs-font-path('#{$icon-font-path}#{$icon-font-name}.eot'), '#{$icon-font-path}#{$icon-font-name}.eot'));
    src: url(if($bootstrap-sass-asset-helper, twbs-font-path('#{$icon-font-path}#{$icon-font-name}.eot?#iefix'), '#{$icon-font-path}#{$icon-font-name}.eot?#iefix')) format('embedded-opentype'),
         url(if($bootstrap-sass-asset-helper, twbs-font-path('#{$icon-font-path}#{$icon-font-name}.woff2'), '#{$icon-font-path}#{$icon-font-name}.woff2')) format('woff2'),
         url(if($bootstrap-sass-asset-helper, twbs-font-path('#{$icon-font-path}#{$icon-font-name}.woff'), '#{$icon-font-path}#{$icon-font-name}.woff')) format('woff'),
         url(if($bootstrap-sass-asset-helper, twbs-font-path('#{$icon-font-path}#{$icon-font-name}.ttf'), '#{$icon-font-path}#{$icon-font-name}.ttf')) format('truetype'),
         url(if($bootstrap-sass-asset-helper, twbs-font-path('#{$icon-font-path}#{$icon-font-name}.svg##{$icon-font-svg-id}'), '#{$icon-font-path}#{$icon-font-name}.svg##{$icon-font-svg-id}')) format('svg');
  }
}

// Catchall baseclass
.glyphicon {
  position: relative;
  top: 1px;
  display: inline-block;
  font-family: 'Glyphicons Halflings';
  font-style: normal;
  font-weight: normal;
  line-height: 1;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
}

// Individual icons
.glyphicon-asterisk               { &:before { content: "\002a"; } }
.glyphicon-plus                   { &:before { content: "\002b"; } }
.glyphicon-euro,
.glyphicon-eur                    { &:before { content: "\20ac"; } }
.glyphicon-minus                  { &:before { content: "\2212"; } }
.glyphicon-cloud                  { &:before { content: "\2601"; } }
.glyphicon-envelope               { &:before { content: "\2709"; } }
.glyphicon-pencil                 { &:before { content: "\270f"; } }
.glyphicon-glass                  { &:before { content: "\e001"; } }
.glyphicon-music                  { &:before { content: "\e002"; } }
.glyphicon-search                 { &:before { content: "\e003"; } }
.glyphicon-heart                  { &:before { content: "\e005"; } }
.glyphicon-star                   { &:before { content: "\e006"; } }
.glyphicon-star-empty             { &:before { content: "\e007"; } }
.glyphicon-user                   { &:before { content: "\e008"; } }
.glyphicon-film                   { &:before { content: "\e009"; } }
.glyphicon-th-large               { &:before { content: "\e010"; } }
.glyphicon-th                     { &:before { content: "\e011"; } }
.glyphicon-th-list                { &:before { content: "\e012"; } }
.glyphicon-ok                     { &:before { content: "\e013"; } }
.glyphicon-remove                 { &:before { content: "\e014"; } }
.glyphicon-zoom-in                { &:before { content: "\e015"; } }
.glyphicon-zoom-out               { &:before { content: "\e016"; } }
.glyphicon-off                    { &:before { content: "\e017"; } }
.glyphicon-signal                 { &:before { content: "\e018"; } }
.glyphicon-cog                    { &:before { content: "\e019"; } }
.glyphicon-trash                  { &:before { content: "\e020"; } }
.glyphicon-home                   { &:before { content: "\e021"; } }
.glyphicon-file                   { &:before { content: "\e022"; } }
.glyphicon-time                   { &:before { content: "\e023"; } }
.glyphicon-road                   { &:before { content: "\e024"; } }
.glyphicon-download-alt           { &:before { content: "\e025"; } }
.glyphicon-download               { &:before { content: "\e026"; } }
.glyphicon-upload                 { &:before { content: "\e027"; } }
.glyphicon-inbox                  { &:before { content: "\e028"; } }
.glyphicon-play-circle            { &:before { content: "\e029"; } }
.glyphicon-repeat                 { &:before { content: "\e030"; } }
.glyphicon-refresh                { &:before { content: "\e031"; } }
.glyphicon-list-alt               { &:before { content: "\e032"; } }
.glyphicon-lock                   { &:before { content: "\e033"; } }
.glyphicon-flag                   { &:before { content: "\e034"; } }
.glyphicon-headphones             { &:before { content: "\e035"; } }
.glyphicon-volume-off             { &:before { content: "\e036"; } }
.glyphicon-volume-down            { &:before { content: "\e037"; } }
.glyphicon-volume-up              { &:before { content: "\e038"; } }
.glyphicon-qrcode                 { &:before { content: "\e039"; } }
.glyphicon-barcode                { &:before { content: "\e040"; } }
.glyphicon-tag                    { &:before { content: "\e041"; } }
.glyphicon-tags                   { &:before { content: "\e042"; } }
.glyphicon-book                   { &:before { content: "\e043"; } }
.glyphicon-bookmark               { &:before { content: "\e044"; } }
.glyphicon-print                  { &:before { content: "\e045"; } }
.glyphicon-camera                 { &:before { content: "\e046"; } }
.glyphicon-font                   { &:before { content: "\e047"; } }
.glyphicon-bold                   { &:before { content: "\e048"; } }
.glyphicon-italic                 { &:before { content: "\e049"; } }
.glyphicon-text-height            { &:before { content: "\e050"; } }
.glyphicon-text-width             { &:before { content: "\e051"; } }
.glyphicon-align-left             { &:before { content: "\e052"; } }
.glyphicon-align-center           { &:before { content: "\e053"; } }
.glyphicon-align-right            { &:before { content: "\e054"; } }
.glyphicon-align-justify          { &:before { content: "\e055"; } }
.glyphicon-list                   { &:before { content: "\e056"; } }
.glyphicon-indent-left            { &:before { content: "\e057"; } }
.glyphicon-indent-right           { &:before { content: "\e058"; } }
.glyphicon-facetime-video         { &:before { content: "\e059"; } }
.glyphicon-picture                { &:before { content: "\e060"; } }
.glyphicon-map-marker             { &:before { content: "\e062"; } }
.glyphicon-adjust                 { &:before { content: "\e063"; } }
.glyphicon-tint                   { &:before { content: "\e064"; } }
.glyphicon-edit                   { &:before { content: "\e065"; } }
.glyphicon-share                  { &:before { content: "\e066"; } }
.glyphicon-check                  { &:before { content: "\e067"; } }
.glyphicon-move                   { &:before { content: "\e068"; } }
.glyphicon-step-backward          { &:before { content: "\e069"; } }
.glyphicon-fast-backward          { &:before { content: "\e070"; } }
.glyphicon-backward               { &:before { content: "\e071"; } }
.glyphicon-play                   { &:before { content: "\e072"; } }
.glyphicon-pause                  { &:before { content: "\e073"; } }
.glyphicon-stop                   { &:before { content: "\e074"; } }
.glyphicon-forward                { &:before { content: "\e075"; } }
.glyphicon-fast-forward           { &:before { content: "\e076"; } }
.glyphicon-step-forward           { &:before { content: "\e077"; } }
.glyphicon-eject                  { &:before { content: "\e078"; } }
.glyphicon-chevron-left           { &:before { content: "\e079"; } }
.glyphicon-chevron-right          { &:before { content: "\e080"; } }
.glyphicon-plus-sign              { &:before { content: "\e081"; } }
.glyphicon-minus-sign             { &:before { content: "\e082"; } }
.glyphicon-remove-sign            { &:before { content: "\e083"; } }
.glyphicon-ok-sign                { &:before { content: "\e084"; } }
.glyphicon-question-sign          { &:before { content: "\e085"; } }
.glyphicon-info-sign              { &:before { content: "\e086"; } }
.glyphicon-screenshot             { &:before { content: "\e087"; } }
.glyphicon-remove-circle          { &:before { content: "\e088"; } }
.glyphicon-ok-circle              { &:before { content: "\e089"; } }
.glyphicon-ban-circle             { &:before { content: "\e090"; } }
.glyphicon-arrow-left             { &:before { content: "\e091"; } }
.glyphicon-arrow-right            { &:before { content: "\e092"; } }
.glyphicon-arrow-up               { &:before { content: "\e093"; } }
.glyphicon-arrow-down             { &:before { content: "\e094"; } }
.glyphicon-share-alt              { &:before { content: "\e095"; } }
.glyphicon-resize-full            { &:before { content: "\e096"; } }
.glyphicon-resize-small           { &:before { content: "\e097"; } }
.glyphicon-exclamation-sign       { &:before { content: "\e101"; } }
.glyphicon-gift                   { &:before { content: "\e102"; } }
.glyphicon-leaf                   { &:before { content: "\e103"; } }
.glyphicon-fire                   { &:before { content: "\e104"; } }
.glyphicon-eye-open               { &:before { content: "\e105"; } }
.glyphicon-eye-close              { &:before { content: "\e106"; } }
.glyphicon-warning-sign           { &:before { content: "\e107"; } }
.glyphicon-plane                  { &:before { content: "\e108"; } }
.glyphicon-calendar               { &:before { content: "\e109"; } }
.glyphicon-random                 { &:before { content: "\e110"; } }
.glyphicon-comment                { &:before { content: "\e111"; } }
.glyphicon-magnet                 { &:before { content: "\e112"; } }
.glyphicon-chevron-up             { &:before { content: "\e113"; } }
.glyphicon-chevron-down           { &:before { content: "\e114"; } }
.glyphicon-retweet                { &:before { content: "\e115"; } }
.glyphicon-shopping-cart          { &:before { content: "\e116"; } }
.glyphicon-folder-close           { &:before { content: "\e117"; } }
.glyphicon-folder-open            { &:before { content: "\e118"; } }
.glyphicon-resize-vertical        { &:before { content: "\e119"; } }
.glyphicon-resize-horizontal      { &:before { content: "\e120"; } }
.glyphicon-hdd                    { &:before { content: "\e121"; } }
.glyphicon-bullhorn               { &:before { content: "\e122"; } }
.glyphicon-bell                   { &:before { content: "\e123"; } }
.glyphicon-certificate            { &:before { content: "\e124"; } }
.glyphicon-thumbs-up              { &:before { content: "\e125"; } }
.glyphicon-thumbs-down            { &:before { content: "\e126"; } }
.glyphicon-hand-right             { &:before { content: "\e127"; } }
.glyphicon-hand-left              { &:before { content: "\e128"; } }
.glyphicon-hand-up                { &:before { content: "\e129"; } }
.glyphicon-hand-down              { &:before { content: "\e130"; } }
.glyphicon-circle-arrow-right     { &:before { content: "\e131"; } }
.glyphicon-circle-arrow-left      { &:before { content: "\e132"; } }
.glyphicon-circle-arrow-up        { &:before { content: "\e133"; } }
.glyphicon-circle-arrow-down      { &:before { content: "\e134"; } }
.glyphicon-globe                  { &:before { content: "\e135"; } }
.glyphicon-wrench                 { &:before { content: "\e136"; } }
.glyphicon-tasks                  { &:before { content: "\e137"; } }
.glyphicon-filter                 { &:before { content: "\e138"; } }
.glyphicon-briefcase              { &:before { content: "\e139"; } }
.glyphicon-fullscreen             { &:before { content: "\e140"; } }
.glyphicon-dashboard              { &:before { content: "\e141"; } }
.glyphicon-paperclip              { &:before { content: "\e142"; } }
.glyphicon-heart-empty            { &:before { content: "\e143"; } }
.glyphicon-link                   { &:before { content: "\e144"; } }
.glyphicon-phone                  { &:before { content: "\e145"; } }
.glyphicon-pushpin                { &:before { content: "\e146"; } }
.glyphicon-usd                    { &:before { content: "\e148"; } }
.glyphicon-gbp                    { &:before { content: "\e149"; } }
.glyphicon-sort                   { &:before { content: "\e150"; } }
.glyphicon-sort-by-alphabet       { &:before { content: "\e151"; } }
.glyphicon-sort-by-alphabet-alt   { &:before { content: "\e152"; } }
.glyphicon-sort-by-order          { &:before { content: "\e153"; } }
.glyphicon-sort-by-order-alt      { &:before { content: "\e154"; } }
.glyphicon-sort-by-attributes     { &:before { content: "\e155"; } }
.glyphicon-sort-by-attributes-alt { &:before { content: "\e156"; } }
.glyphicon-unchecked              { &:before { content: "\e157"; } }
.glyphicon-expand                 { &:before { content: "\e158"; } }
.glyphicon-collapse-down          { &:before { content: "\e159"; } }
.glyphicon-collapse-up            { &:before { content: "\e160"; } }
.glyphicon-log-in                 { &:before { content: "\e161"; } }
.glyphicon-flash                  { &:before { content: "\e162"; } }
.glyphicon-log-out                { &:before { content: "\e163"; } }
.glyphicon-new-window             { &:before { content: "\e164"; } }
.glyphicon-record                 { &:before { content: "\e165"; } }
.glyphicon-save                   { &:before { content: "\e166"; } }
.glyphicon-open                   { &:before { content: "\e167"; } }
.glyphicon-saved                  { &:before { content: "\e168"; } }
.glyphicon-import                 { &:before { content: "\e169"; } }
.glyphicon-export                 { &:before { content: "\e170"; } }
.glyphicon-send                   { &:before { content: "\e171"; } }
.glyphicon-floppy-disk            { &:before { content: "\e172"; } }
.glyphicon-floppy-saved           { &:before { content: "\e173"; } }
.glyphicon-floppy-remove          { &:before { content: "\e174"; } }
.glyphicon-floppy-save            { &:before { content: "\e175"; } }
.glyphicon-floppy-open            { &:before { content: "\e176"; } }
.glyphicon-credit-card            { &:before { content: "\e177"; } }
.glyphicon-transfer               { &:before { content: "\e178"; } }
.glyphicon-cutlery                { &:before { content: "\e179"; } }
.glyphicon-header                 { &:before { content: "\e180"; } }
.glyphicon-compressed             { &:before { content: "\e181"; } }
.glyphicon-earphone               { &:before { content: "\e182"; } }
.glyphicon-phone-alt              { &:before { content: "\e183"; } }
.glyphicon-tower                  { &:before { content: "\e184"; } }
.glyphicon-stats                  { &:before { content: "\e185"; } }
.glyphicon-sd-video               { &:before { content: "\e186"; } }
.glyphicon-hd-video               { &:before { content: "\e187"; } }
.glyphicon-subtitles              { &:before { content: "\e188"; } }
.glyphicon-sound-stereo           { &:before { content: "\e189"; } }
.glyphicon-sound-dolby            { &:before { content: "\e190"; } }
.glyphicon-sound-5-1              { &:before { content: "\e191"; } }
.glyphicon-sound-6-1              { &:before { content: "\e192"; } }
.glyphicon-sound-7-1              { &:before { content: "\e193"; } }
.glyphicon-copyright-mark         { &:before { content: "\e194"; } }
.glyphicon-registration-mark      { &:before { content: "\e195"; } }
.glyphicon-cloud-download         { &:before { content: "\e197"; } }
.glyphicon-cloud-upload           { &:before { content: "\e198"; } }
.glyphicon-tree-conifer           { &:before { content: "\e199"; } }
.glyphicon-tree-deciduous         { &:before { content: "\e200"; } }
.glyphicon-cd                     { &:before { content: "\e201"; } }
.glyphicon-save-file              { &:before { content: "\e202"; } }
.glyphicon-open-file              { &:before { content: "\e203"; } }
.glyphicon-level-up               { &:before { content: "\e204"; } }
.glyphicon-copy                   { &:before { content: "\e205"; } }
.glyphicon-paste                  { &:before { content: "\e206"; } }
// The following 2 Glyphicons are omitted for the time being because
// they currently use Unicode codepoints that are outside the
// Basic Multilingual Plane (BMP). Older buggy versions of WebKit can't handle
// non-BMP codepoints in CSS string escapes, and thus can't display these two icons.
// Notably, the bug affects some older versions of the Android Browser.
// More info: https://github.com/twbs/bootstrap/issues/10106
// .glyphicon-door                   { &:before { content: "\1f6aa"; } }
// .glyphicon-key                    { &:before { content: "\1f511"; } }
.glyphicon-alert                  { &:before { content: "\e209"; } }
.glyphicon-equalizer              { &:before { content: "\e210"; } }
.glyphicon-king                   { &:before { content: "\e211"; } }
.glyphicon-queen                  { &:before { content: "\e212"; } }
.glyphicon-pawn                   { &:before { content: "\e213"; } }
.glyphicon-bishop                 { &:before { content: "\e214"; } }
.glyphicon-knight                 { &:before { content: "\e215"; } }
.glyphicon-baby-formula           { &:before { content: "\e216"; } }
.glyphicon-tent                   { &:before { content: "\26fa"; } }
.glyphicon-blackboard             { &:before { content: "\e218"; } }
.glyphicon-bed                    { &:before { content: "\e219"; } }
.glyphicon-apple                  { &:before { content: "\f8ff"; } }
.glyphicon-erase                  { &:before { content: "\e221"; } }
.glyphicon-hourglass              { &:before { content: "\231b"; } }
.glyphicon-lamp                   { &:before { content: "\e223"; } }
.glyphicon-duplicate              { &:before { content: "\e224"; } }
.glyphicon-piggy-bank             { &:before { content: "\e225"; } }
.glyphicon-scissors               { &:before { content: "\e226"; } }
.glyphicon-bitcoin                { &:before { content: "\e227"; } }
.glyphicon-btc                    { &:before { content: "\e227"; } }
.glyphicon-xbt                    { &:before { content: "\e227"; } }
.glyphicon-yen                    { &:before { content: "\00a5"; } }
.glyphicon-jpy                    { &:before { content: "\00a5"; } }
.glyphicon-ruble                  { &:before { content: "\20bd"; } }
.glyphicon-rub                    { &:before { content: "\20bd"; } }
.glyphicon-scale                  { &:before { content: "\e230"; } }
.glyphicon-ice-lolly              { &:before { content: "\e231"; } }
.glyphicon-ice-lolly-tasted       { &:before { content: "\e232"; } }
.glyphicon-education              { &:before { content: "\e233"; } }
.glyphicon-option-horizontal      { &:before { content: "\e234"; } }
.glyphicon-option-vertical        { &:before { content: "\e235"; } }
.glyphicon-menu-hamburger         { &:before { content: "\e236"; } }
.glyphicon-modal-window           { &:before { content: "\e237"; } }
.glyphicon-oil                    { &:before { content: "\e238"; } }
.glyphicon-grain                  { &:before { content: "\e239"; } }
.glyphicon-sunglasses             { &:before { content: "\e240"; } }
.glyphicon-text-size              { &:before { content: "\e241"; } }
.glyphicon-text-color             { &:before { content: "\e242"; } }
.glyphicon-text-background        { &:before { content: "\e243"; } }
.glyphicon-object-align-top       { &:before { content: "\e244"; } }
.glyphicon-object-align-bottom    { &:before { content: "\e245"; } }
.glyphicon-object-align-horizontal{ &:before { content: "\e246"; } }
.glyphicon-object-align-left      { &:before { content: "\e247"; } }
.glyphicon-object-align-vertical  { &:before { content: "\e248"; } }
.glyphicon-object-align-right     { &:before { content: "\e249"; } }
.glyphicon-triangle-right         { &:before { content: "\e250"; } }
.glyphicon-triangle-left          { &:before { content: "\e251"; } }
.glyphicon-triangle-bottom        { &:before { content: "\e252"; } }
.glyphicon-triangle-top           { &:before { content: "\e253"; } }
.glyphicon-console                { &:before { content: "\e254"; } }
.glyphicon-superscript            { &:before { content: "\e255"; } }
.glyphicon-subscript              { &:before { content: "\e256"; } }
.glyphicon-menu-left              { &:before { content: "\e257"; } }
.glyphicon-menu-right             { &:before { content: "\e258"; } }
.glyphicon-menu-down              { &:before { content: "\e259"; } }
.glyphicon-menu-up                { &:before { content: "\e260"; } }


================================================
File: _sass/bootstrap/_grid.scss
================================================
//
// Grid system
// --------------------------------------------------


// Container widths
//
// Set the container width, and override it for fixed navbars in media queries.

.container {
  @include container-fixed;

  @media (min-width: $screen-sm-min) {
    width: $container-sm;
  }
  @media (min-width: $screen-md-min) {
    width: $container-md;
  }
  @media (min-width: $screen-lg-min) {
    width: $container-lg;
  }
}


// Fluid container
//
// Utilizes the mixin meant for fixed width containers, but without any defined
// width for fluid, full width layouts.

.container-fluid {
  @include container-fixed;
}


// Row
//
// Rows contain and clear the floats of your columns.

.row {
  @include make-row;
}


// Columns
//
// Common styles for small and large grid columns

@include make-grid-columns;


// Extra small grid
//
// Columns, offsets, pushes, and pulls for extra small devices like
// smartphones.

@include make-grid(xs);


// Small grid
//
// Columns, offsets, pushes, and pulls for the small device range, from phones
// to tablets.

@media (min-width: $screen-sm-min) {
  @include make-grid(sm);
}


// Medium grid
//
// Columns, offsets, pushes, and pulls for the desktop device range.

@media (min-width: $screen-md-min) {
  @include make-grid(md);
}


// Large grid
//
// Columns, offsets, pushes, and pulls for the large desktop device range.

@media (min-width: $screen-lg-min) {
  @include make-grid(lg);
}


================================================
File: _sass/bootstrap/_input-groups.scss
================================================
//
// Input groups
// --------------------------------------------------

// Base styles
// -------------------------
.input-group {
  position: relative; // For dropdowns
  display: table;
  border-collapse: separate; // prevent input groups from inheriting border styles from table cells when placed within a table

  // Undo padding and float of grid classes
  &[class*="col-"] {
    float: none;
    padding-left: 0;
    padding-right: 0;
  }

  .form-control {
    // Ensure that the input is always above the *appended* addon button for
    // proper border colors.
    position: relative;
    z-index: 2;

    // IE9 fubars the placeholder attribute in text inputs and the arrows on
    // select elements in input groups. To fix it, we float the input. Details:
    // https://github.com/twbs/bootstrap/issues/11561#issuecomment-28936855
    float: left;

    width: 100%;
    margin-bottom: 0;
    
    &:focus {
      z-index: 3;
    }
  }
}

// Sizing options
//
// Remix the default form control sizing classes into new ones for easier
// manipulation.

.input-group-lg > .form-control,
.input-group-lg > .input-group-addon,
.input-group-lg > .input-group-btn > .btn {
  @extend .input-lg;
}
.input-group-sm > .form-control,
.input-group-sm > .input-group-addon,
.input-group-sm > .input-group-btn > .btn {
  @extend .input-sm;
}


// Display as table-cell
// -------------------------
.input-group-addon,
.input-group-btn,
.input-group .form-control {
  display: table-cell;

  &:not(:first-child):not(:last-child) {
    border-radius: 0;
  }
}
// Addon and addon wrapper for buttons
.input-group-addon,
.input-group-btn {
  width: 1%;
  white-space: nowrap;
  vertical-align: middle; // Match the inputs
}

// Text input groups
// -------------------------
.input-group-addon {
  padding: $padding-base-vertical $padding-base-horizontal;
  font-size: $font-size-base;
  font-weight: normal;
  line-height: 1;
  color: $input-color;
  text-align: center;
  background-color: $input-group-addon-bg;
  border: 1px solid $input-group-addon-border-color;
  border-radius: $input-border-radius;

  // Sizing
  &.input-sm {
    padding: $padding-small-vertical $padding-small-horizontal;
    font-size: $font-size-small;
    border-radius: $input-border-radius-small;
  }
  &.input-lg {
    padding: $padding-large-vertical $padding-large-horizontal;
    font-size: $font-size-large;
    border-radius: $input-border-radius-large;
  }

  // Nuke default margins from checkboxes and radios to vertically center within.
  input[type="radio"],
  input[type="checkbox"] {
    margin-top: 0;
  }
}

// Reset rounded corners
.input-group .form-control:first-child,
.input-group-addon:first-child,
.input-group-btn:first-child > .btn,
.input-group-btn:first-child > .btn-group > .btn,
.input-group-btn:first-child > .dropdown-toggle,
.input-group-btn:last-child > .btn:not(:last-child):not(.dropdown-toggle),
.input-group-btn:last-child > .btn-group:not(:last-child) > .btn {
  @include border-right-radius(0);
}
.input-group-addon:first-child {
  border-right: 0;
}
.input-group .form-control:last-child,
.input-group-addon:last-child,
.input-group-btn:last-child > .btn,
.input-group-btn:last-child > .btn-group > .btn,
.input-group-btn:last-child > .dropdown-toggle,
.input-group-btn:first-child > .btn:not(:first-child),
.input-group-btn:first-child > .btn-group:not(:first-child) > .btn {
  @include border-left-radius(0);
}
.input-group-addon:last-child {
  border-left: 0;
}

// Button input groups
// -------------------------
.input-group-btn {
  position: relative;
  // Jankily prevent input button groups from wrapping with `white-space` and
  // `font-size` in combination with `inline-block` on buttons.
  font-size: 0;
  white-space: nowrap;

  // Negative margin for spacing, position for bringing hovered/focused/actived
  // element above the siblings.
  > .btn {
    position: relative;
    + .btn {
      margin-left: -1px;
    }
    // Bring the "active" button to the front
    &:hover,
    &:focus,
    &:active {
      z-index: 2;
    }
  }

  // Negative margin to only have a 1px border between the two
  &:first-child {
    > .btn,
    > .btn-group {
      margin-right: -1px;
    }
  }
  &:last-child {
    > .btn,
    > .btn-group {
      z-index: 2;
      margin-left: -1px;
    }
  }
}


================================================
File: _sass/bootstrap/_jumbotron.scss
================================================
//
// Jumbotron
// --------------------------------------------------


.jumbotron {
  padding-top:    $jumbotron-padding;
  padding-bottom: $jumbotron-padding;
  margin-bottom: $jumbotron-padding;
  color: $jumbotron-color;
  background-color: $jumbotron-bg;

  h1,
  .h1 {
    color: $jumbotron-heading-color;
  }

  p {
    margin-bottom: ($jumbotron-padding / 2);
    font-size: $jumbotron-font-size;
    font-weight: 200;
  }

  > hr {
    border-top-color: darken($jumbotron-bg, 10%);
  }

  .container &,
  .container-fluid & {
    border-radius: $border-radius-large; // Only round corners at higher resolutions if contained in a container
    padding-left:  ($grid-gutter-width / 2);
    padding-right: ($grid-gutter-width / 2);
  }

  .container {
    max-width: 100%;
  }

  @media screen and (min-width: $screen-sm-min) {
    padding-top:    ($jumbotron-padding * 1.6);
    padding-bottom: ($jumbotron-padding * 1.6);

    .container &,
    .container-fluid & {
      padding-left:  ($jumbotron-padding * 2);
      padding-right: ($jumbotron-padding * 2);
    }

    h1,
    .h1 {
      font-size: $jumbotron-heading-font-size;
    }
  }
}


================================================
File: _sass/bootstrap/_labels.scss
================================================
//
// Labels
// --------------------------------------------------

.label {
  display: inline;
  padding: .2em .6em .3em;
  font-size: 75%;
  font-weight: bold;
  line-height: 1;
  color: $label-color;
  text-align: center;
  white-space: nowrap;
  vertical-align: baseline;
  border-radius: .25em;

  // [converter] extracted a& to a.label

  // Empty labels collapse automatically (not available in IE8)
  &:empty {
    display: none;
  }

  // Quick fix for labels in buttons
  .btn & {
    position: relative;
    top: -1px;
  }
}

// Add hover effects, but only for links
a.label {
  &:hover,
  &:focus {
    color: $label-link-hover-color;
    text-decoration: none;
    cursor: pointer;
  }
}

// Colors
// Contextual variations (linked labels get darker on :hover)

.label-default {
  @include label-variant($label-default-bg);
}

.label-primary {
  @include label-variant($label-primary-bg);
}

.label-success {
  @include label-variant($label-success-bg);
}

.label-info {
  @include label-variant($label-info-bg);
}

.label-warning {
  @include label-variant($label-warning-bg);
}

.label-danger {
  @include label-variant($label-danger-bg);
}


================================================
File: _sass/bootstrap/_list-group.scss
================================================
//
// List groups
// --------------------------------------------------


// Base class
//
// Easily usable on <ul>, <ol>, or <div>.

.list-group {
  // No need to set list-style: none; since .list-group-item is block level
  margin-bottom: 20px;
  padding-left: 0; // reset padding because ul and ol
}


// Individual list items
//
// Use on `li`s or `div`s within the `.list-group` parent.

.list-group-item {
  position: relative;
  display: block;
  padding: 10px 15px;
  // Place the border on the list items and negative margin up for better styling
  margin-bottom: -1px;
  background-color: $list-group-bg;
  border: 1px solid $list-group-border;

  // Round the first and last items
  &:first-child {
    @include border-top-radius($list-group-border-radius);
  }
  &:last-child {
    margin-bottom: 0;
    @include border-bottom-radius($list-group-border-radius);
  }
}


// Interactive list items
//
// Use anchor or button elements instead of `li`s or `div`s to create interactive items.
// Includes an extra `.active` modifier class for showing selected items.

a.list-group-item,
button.list-group-item {
  color: $list-group-link-color;

  .list-group-item-heading {
    color: $list-group-link-heading-color;
  }

  // Hover state
  &:hover,
  &:focus {
    text-decoration: none;
    color: $list-group-link-hover-color;
    background-color: $list-group-hover-bg;
  }
}

button.list-group-item {
  width: 100%;
  text-align: left;
}

.list-group-item {
  // Disabled state
  &.disabled,
  &.disabled:hover,
  &.disabled:focus {
    background-color: $list-group-disabled-bg;
    color: $list-group-disabled-color;
    cursor: $cursor-disabled;

    // Force color to inherit for custom content
    .list-group-item-heading {
      color: inherit;
    }
    .list-group-item-text {
      color: $list-group-disabled-text-color;
    }
  }

  // Active class on item itself, not parent
  &.active,
  &.active:hover,
  &.active:focus {
    z-index: 2; // Place active items above their siblings for proper border styling
    color: $list-group-active-color;
    background-color: $list-group-active-bg;
    border-color: $list-group-active-border;

    // Force color to inherit for custom content
    .list-group-item-heading,
    .list-group-item-heading > small,
    .list-group-item-heading > .small {
      color: inherit;
    }
    .list-group-item-text {
      color: $list-group-active-text-color;
    }
  }
}


// Contextual variants
//
// Add modifier classes to change text and background color on individual items.
// Organizationally, this must come after the `:hover` states.

@include list-group-item-variant(success, $state-success-bg, $state-success-text);
@include list-group-item-variant(info, $state-info-bg, $state-info-text);
@include list-group-item-variant(warning, $state-warning-bg, $state-warning-text);
@include list-group-item-variant(danger, $state-danger-bg, $state-danger-text);


// Custom content options
//
// Extra classes for creating well-formatted content within `.list-group-item`s.

.list-group-item-heading {
  margin-top: 0;
  margin-bottom: 5px;
}
.list-group-item-text {
  margin-bottom: 0;
  line-height: 1.3;
}


================================================
File: _sass/bootstrap/_media.scss
================================================
.media {
  // Proper spacing between instances of .media
  margin-top: 15px;

  &:first-child {
    margin-top: 0;
  }
}

.media,
.media-body {
  zoom: 1;
  overflow: hidden;
}

.media-body {
  width: 10000px;
}

.media-object {
  display: block;

  // Fix collapse in webkit from max-width: 100% and display: table-cell.
  &.img-thumbnail {
    max-width: none;
  }
}

.media-right,
.media > .pull-right {
  padding-left: 10px;
}

.media-left,
.media > .pull-left {
  padding-right: 10px;
}

.media-left,
.media-right,
.media-body {
  display: table-cell;
  vertical-align: top;
}

.media-middle {
  vertical-align: middle;
}

.media-bottom {
  vertical-align: bottom;
}

// Reset margins on headings for tighter default spacing
.media-heading {
  margin-top: 0;
  margin-bottom: 5px;
}

// Media list variation
//
// Undo default ul/ol styles
.media-list {
  padding-left: 0;
  list-style: none;
}


================================================
File: _sass/bootstrap/_mixins.scss
================================================
// Mixins
// --------------------------------------------------

// Utilities
@import "mixins/hide-text";
@import "mixins/opacity";
@import "mixins/image";
@import "mixins/labels";
@import "mixins/reset-filter";
@import "mixins/resize";
@import "mixins/responsive-visibility";
@import "mixins/size";
@import "mixins/tab-focus";
@import "mixins/reset-text";
@import "mixins/text-emphasis";
@import "mixins/text-overflow";
@import "mixins/vendor-prefixes";

// Components
@import "mixins/alerts";
@import "mixins/buttons";
@import "mixins/panels";
@import "mixins/pagination";
@import "mixins/list-group";
@import "mixins/nav-divider";
@import "mixins/forms";
@import "mixins/progress-bar";
@import "mixins/table-row";

// Skins
@import "mixins/background-variant";
@import "mixins/border-radius";
@import "mixins/gradients";

// Layout
@import "mixins/clearfix";
@import "mixins/center-block";
@import "mixins/nav-vertical-align";
@import "mixins/grid-framework";
@import "mixins/grid";


================================================
File: _sass/bootstrap/_modals.scss
================================================
//
// Modals
// --------------------------------------------------

// .modal-open      - body class for killing the scroll
// .modal           - container to scroll within
// .modal-dialog    - positioning shell for the actual modal
// .modal-content   - actual modal w/ bg and corners and shit

// Kill the scroll on the body
.modal-open {
  overflow: hidden;
}

// Container that the modal scrolls within
.modal {
  display: none;
  overflow: hidden;
  position: fixed;
  top: 0;
  right: 0;
  bottom: 0;
  left: 0;
  z-index: $zindex-modal;
  -webkit-overflow-scrolling: touch;

  // Prevent Chrome on Windows from adding a focus outline. For details, see
  // https://github.com/twbs/bootstrap/pull/10951.
  outline: 0;

  // When fading in the modal, animate it to slide down
  &.fade .modal-dialog {
    @include translate(0, -25%);
    @include transition-transform(0.3s ease-out);
  }
  &.in .modal-dialog { @include translate(0, 0) }
}
.modal-open .modal {
  overflow-x: hidden;
  overflow-y: auto;
}

// Shell div to position the modal with bottom padding
.modal-dialog {
  position: relative;
  width: auto;
  margin: 10px;
}

// Actual modal
.modal-content {
  position: relative;
  background-color: $modal-content-bg;
  border: 1px solid $modal-content-fallback-border-color; //old browsers fallback (ie8 etc)
  border: 1px solid $modal-content-border-color;
  border-radius: $border-radius-large;
  @include box-shadow(0 3px 9px rgba(0,0,0,.5));
  background-clip: padding-box;
  // Remove focus outline from opened modal
  outline: 0;
}

// Modal background
.modal-backdrop {
  position: fixed;
  top: 0;
  right: 0;
  bottom: 0;
  left: 0;
  z-index: $zindex-modal-background;
  background-color: $modal-backdrop-bg;
  // Fade for backdrop
  &.fade { @include opacity(0); }
  &.in { @include opacity($modal-backdrop-opacity); }
}

// Modal header
// Top section of the modal w/ title and dismiss
.modal-header {
  padding: $modal-title-padding;
  border-bottom: 1px solid $modal-header-border-color;
  @include clearfix;
}
// Close icon
.modal-header .close {
  margin-top: -2px;
}

// Title text within header
.modal-title {
  margin: 0;
  line-height: $modal-title-line-height;
}

// Modal body
// Where all modal content resides (sibling of .modal-header and .modal-footer)
.modal-body {
  position: relative;
  padding: $modal-inner-padding;
}

// Footer (for actions)
.modal-footer {
  padding: $modal-inner-padding;
  text-align: right; // right align buttons
  border-top: 1px solid $modal-footer-border-color;
  @include clearfix; // clear it in case folks use .pull-* classes on buttons

  // Properly space out buttons
  .btn + .btn {
    margin-left: 5px;
    margin-bottom: 0; // account for input[type="submit"] which gets the bottom margin like all other inputs
  }
  // but override that for button groups
  .btn-group .btn + .btn {
    margin-left: -1px;
  }
  // and override it for block buttons as well
  .btn-block + .btn-block {
    margin-left: 0;
  }
}

// Measure scrollbar width for padding body during modal show/hide
.modal-scrollbar-measure {
  position: absolute;
  top: -9999px;
  width: 50px;
  height: 50px;
  overflow: scroll;
}

// Scale up the modal
@media (min-width: $screen-sm-min) {
  // Automatically set modal's width for larger viewports
  .modal-dialog {
    width: $modal-md;
    margin: 30px auto;
  }
  .modal-content {
    @include box-shadow(0 5px 15px rgba(0,0,0,.5));
  }

  // Modal sizes
  .modal-sm { width: $modal-sm; }
}

@media (min-width: $screen-md-min) {
  .modal-lg { width: $modal-lg; }
}


================================================
File: _sass/bootstrap/_navbar.scss
================================================
//
// Navbars
// --------------------------------------------------


// Wrapper and base class
//
// Provide a static navbar from which we expand to create full-width, fixed, and
// other navbar variations.

.navbar {
  position: relative;
  min-height: $navbar-height; // Ensure a navbar always shows (e.g., without a .navbar-brand in collapsed mode)
  margin-bottom: $navbar-margin-bottom;
  border: 1px solid transparent;

  // Prevent floats from breaking the navbar
  @include clearfix;

  @media (min-width: $grid-float-breakpoint) {
    border-radius: $navbar-border-radius;
  }
}


// Navbar heading
//
// Groups `.navbar-brand` and `.navbar-toggle` into a single component for easy
// styling of responsive aspects.

.navbar-header {
  @include clearfix;

  @media (min-width: $grid-float-breakpoint) {
    float: left;
  }
}


// Navbar collapse (body)
//
// Group your navbar content into this for easy collapsing and expanding across
// various device sizes. By default, this content is collapsed when <768px, but
// will expand past that for a horizontal display.
//
// To start (on mobile devices) the navbar links, forms, and buttons are stacked
// vertically and include a `max-height` to overflow in case you have too much
// content for the user's viewport.

.navbar-collapse {
  overflow-x: visible;
  padding-right: $navbar-padding-horizontal;
  padding-left:  $navbar-padding-horizontal;
  border-top: 1px solid transparent;
  box-shadow: inset 0 1px 0 rgba(255,255,255,.1);
  @include clearfix;
  -webkit-overflow-scrolling: touch;

  &.in {
    overflow-y: auto;
  }

  @media (min-width: $grid-float-breakpoint) {
    width: auto;
    border-top: 0;
    box-shadow: none;

    &.collapse {
      display: block !important;
      height: auto !important;
      padding-bottom: 0; // Override default setting
      overflow: visible !important;
    }

    &.in {
      overflow-y: visible;
    }

    // Undo the collapse side padding for navbars with containers to ensure
    // alignment of right-aligned contents.
    .navbar-fixed-top &,
    .navbar-static-top &,
    .navbar-fixed-bottom & {
      padding-left: 0;
      padding-right: 0;
    }
  }
}

.navbar-fixed-top,
.navbar-fixed-bottom {
  .navbar-collapse {
    max-height: $navbar-collapse-max-height;

    @media (max-device-width: $screen-xs-min) and (orientation: landscape) {
      max-height: 200px;
    }
  }
}


// Both navbar header and collapse
//
// When a container is present, change the behavior of the header and collapse.

.container,
.container-fluid {
  > .navbar-header,
  > .navbar-collapse {
    margin-right: -$navbar-padding-horizontal;
    margin-left:  -$navbar-padding-horizontal;

    @media (min-width: $grid-float-breakpoint) {
      margin-right: 0;
      margin-left:  0;
    }
  }
}


//
// Navbar alignment options
//
// Display the navbar across the entirety of the page or fixed it to the top or
// bottom of the page.

// Static top (unfixed, but 100% wide) navbar
.navbar-static-top {
  z-index: $zindex-navbar;
  border-width: 0 0 1px;

  @media (min-width: $grid-float-breakpoint) {
    border-radius: 0;
  }
}

// Fix the top/bottom navbars when screen real estate supports it
.navbar-fixed-top,
.navbar-fixed-bottom {
  position: fixed;
  right: 0;
  left: 0;
  z-index: $zindex-navbar-fixed;

  // Undo the rounded corners
  @media (min-width: $grid-float-breakpoint) {
    border-radius: 0;
  }
}
.navbar-fixed-top {
  top: 0;
  border-width: 0 0 1px;
}
.navbar-fixed-bottom {
  bottom: 0;
  margin-bottom: 0; // override .navbar defaults
  border-width: 1px 0 0;
}


// Brand/project name

.navbar-brand {
  float: left;
  padding: $navbar-padding-vertical $navbar-padding-horizontal;
  font-size: $font-size-large;
  line-height: $line-height-computed;
  height: $navbar-height;

  &:hover,
  &:focus {
    text-decoration: none;
  }

  > img {
    display: block;
  }

  @media (min-width: $grid-float-breakpoint) {
    .navbar > .container &,
    .navbar > .container-fluid & {
      margin-left: -$navbar-padding-horizontal;
    }
  }
}


// Navbar toggle
//
// Custom button for toggling the `.navbar-collapse`, powered by the collapse
// JavaScript plugin.

.navbar-toggle {
  position: relative;
  float: right;
  margin-right: $navbar-padding-horizontal;
  padding: 9px 10px;
  @include navbar-vertical-align(34px);
  background-color: transparent;
  background-image: none; // Reset unusual Firefox-on-Android default style; see https://github.com/necolas/normalize.css/issues/214
  border: 1px solid transparent;
  border-radius: $border-radius-base;

  // We remove the `outline` here, but later compensate by attaching `:hover`
  // styles to `:focus`.
  &:focus {
    outline: 0;
  }

  // Bars
  .icon-bar {
    display: block;
    width: 22px;
    height: 2px;
    border-radius: 1px;
  }
  .icon-bar + .icon-bar {
    margin-top: 4px;
  }

  @media (min-width: $grid-float-breakpoint) {
    display: none;
  }
}


// Navbar nav links
//
// Builds on top of the `.nav` components with its own modifier class to make
// the nav the full height of the horizontal nav (above 768px).

.navbar-nav {
  margin: ($navbar-padding-vertical / 2) (-$navbar-padding-horizontal);

  > li > a {
    padding-top:    10px;
    padding-bottom: 10px;
    line-height: $line-height-computed;
  }

  @media (max-width: $grid-float-breakpoint-max) {
    // Dropdowns get custom display when collapsed
    .open .dropdown-menu {
      position: static;
      float: none;
      width: auto;
      margin-top: 0;
      background-color: transparent;
      border: 0;
      box-shadow: none;
      > li > a,
      .dropdown-header {
        padding: 5px 15px 5px 25px;
      }
      > li > a {
        line-height: $line-height-computed;
        &:hover,
        &:focus {
          background-image: none;
        }
      }
    }
  }

  // Uncollapse the nav
  @media (min-width: $grid-float-breakpoint) {
    float: left;
    margin: 0;

    > li {
      float: left;
      > a {
        padding-top:    $navbar-padding-vertical;
        padding-bottom: $navbar-padding-vertical;
      }
    }
  }
}


// Navbar form
//
// Extension of the `.form-inline` with some extra flavor for optimum display in
// our navbars.

.navbar-form {
  margin-left: -$navbar-padding-horizontal;
  margin-right: -$navbar-padding-horizontal;
  padding: 10px $navbar-padding-horizontal;
  border-top: 1px solid transparent;
  border-bottom: 1px solid transparent;
  $shadow: inset 0 1px 0 rgba(255,255,255,.1), 0 1px 0 rgba(255,255,255,.1);
  @include box-shadow($shadow);

  // Mixin behavior for optimum display
  @include form-inline;

  .form-group {
    @media (max-width: $grid-float-breakpoint-max) {
      margin-bottom: 5px;

      &:last-child {
        margin-bottom: 0;
      }
    }
  }

  // Vertically center in expanded, horizontal navbar
  @include navbar-vertical-align($input-height-base);

  // Undo 100% width for pull classes
  @media (min-width: $grid-float-breakpoint) {
    width: auto;
    border: 0;
    margin-left: 0;
    margin-right: 0;
    padding-top: 0;
    padding-bottom: 0;
    @include box-shadow(none);
  }
}


// Dropdown menus

// Menu position and menu carets
.navbar-nav > li > .dropdown-menu {
  margin-top: 0;
  @include border-top-radius(0);
}
// Menu position and menu caret support for dropups via extra dropup class
.navbar-fixed-bottom .navbar-nav > li > .dropdown-menu {
  margin-bottom: 0;
  @include border-top-radius($navbar-border-radius);
  @include border-bottom-radius(0);
}


// Buttons in navbars
//
// Vertically center a button within a navbar (when *not* in a form).

.navbar-btn {
  @include navbar-vertical-align($input-height-base);

  &.btn-sm {
    @include navbar-vertical-align($input-height-small);
  }
  &.btn-xs {
    @include navbar-vertical-align(22);
  }
}


// Text in navbars
//
// Add a class to make any element properly align itself vertically within the navbars.

.navbar-text {
  @include navbar-vertical-align($line-height-computed);

  @media (min-width: $grid-float-breakpoint) {
    float: left;
    margin-left: $navbar-padding-horizontal;
    margin-right: $navbar-padding-horizontal;
  }
}


// Component alignment
//
// Repurpose the pull utilities as their own navbar utilities to avoid specificity
// issues with parents and chaining. Only do this when the navbar is uncollapsed
// though so that navbar contents properly stack and align in mobile.
//
// Declared after the navbar components to ensure more specificity on the margins.

@media (min-width: $grid-float-breakpoint) {
  .navbar-left {
    float: left !important;
  }
  .navbar-right {
    float: right !important;
  margin-right: -$navbar-padding-horizontal;

    ~ .navbar-right {
      margin-right: 0;
    }
  }
}


// Alternate navbars
// --------------------------------------------------

// Default navbar
.navbar-default {
  background-color: $navbar-default-bg;
  border-color: $navbar-default-border;

  .navbar-brand {
    color: $navbar-default-brand-color;
    &:hover,
    &:focus {
      color: $navbar-default-brand-hover-color;
      background-color: $navbar-default-brand-hover-bg;
    }
  }

  .navbar-text {
    color: $navbar-default-color;
  }

  .navbar-nav {
    > li > a {
      color: $navbar-default-link-color;

      &:hover,
      &:focus {
        color: $navbar-default-link-hover-color;
        background-color: $navbar-default-link-hover-bg;
      }
    }
    > .active > a {
      &,
      &:hover,
      &:focus {
        color: $navbar-default-link-active-color;
        background-color: $navbar-default-link-active-bg;
      }
    }
    > .disabled > a {
      &,
      &:hover,
      &:focus {
        color: $navbar-default-link-disabled-color;
        background-color: $navbar-default-link-disabled-bg;
      }
    }
  }

  .navbar-toggle {
    border-color: $navbar-default-toggle-border-color;
    &:hover,
    &:focus {
      background-color: $navbar-default-toggle-hover-bg;
    }
    .icon-bar {
      background-color: $navbar-default-toggle-icon-bar-bg;
    }
  }

  .navbar-collapse,
  .navbar-form {
    border-color: $navbar-default-border;
  }

  // Dropdown menu items
  .navbar-nav {
    // Remove background color from open dropdown
    > .open > a {
      &,
      &:hover,
      &:focus {
        background-color: $navbar-default-link-active-bg;
        color: $navbar-default-link-active-color;
      }
    }

    @media (max-width: $grid-float-breakpoint-max) {
      // Dropdowns get custom display when collapsed
      .open .dropdown-menu {
        > li > a {
          color: $navbar-default-link-color;
          &:hover,
          &:focus {
            color: $navbar-default-link-hover-color;
            background-color: $navbar-default-link-hover-bg;
          }
        }
        > .active > a {
          &,
          &:hover,
          &:focus {
            color: $navbar-default-link-active-color;
            background-color: $navbar-default-link-active-bg;
          }
        }
        > .disabled > a {
          &,
          &:hover,
          &:focus {
            color: $navbar-default-link-disabled-color;
            background-color: $navbar-default-link-disabled-bg;
          }
        }
      }
    }
  }


  // Links in navbars
  //
  // Add a class to ensure links outside the navbar nav are colored correctly.

  .navbar-link {
    color: $navbar-default-link-color;
    &:hover {
      color: $navbar-default-link-hover-color;
    }
  }

  .btn-link {
    color: $navbar-default-link-color;
    &:hover,
    &:focus {
      color: $navbar-default-link-hover-color;
    }
    &[disabled],
    fieldset[disabled] & {
      &:hover,
      &:focus {
        color: $navbar-default-link-disabled-color;
      }
    }
  }
}

// Inverse navbar

.navbar-inverse {
  background-color: $navbar-inverse-bg;
  border-color: $navbar-inverse-border;

  .navbar-brand {
    color: $navbar-inverse-brand-color;
    &:hover,
    &:focus {
      color: $navbar-inverse-brand-hover-color;
      background-color: $navbar-inverse-brand-hover-bg;
    }
  }

  .navbar-text {
    color: $navbar-inverse-color;
  }

  .navbar-nav {
    > li > a {
      color: $navbar-inverse-link-color;

      &:hover,
      &:focus {
        color: $navbar-inverse-link-hover-color;
        background-color: $navbar-inverse-link-hover-bg;
      }
    }
    > .active > a {
      &,
      &:hover,
      &:focus {
        color: $navbar-inverse-link-active-color;
        background-color: $navbar-inverse-link-active-bg;
      }
    }
    > .disabled > a {
      &,
      &:hover,
      &:focus {
        color: $navbar-inverse-link-disabled-color;
        background-color: $navbar-inverse-link-disabled-bg;
      }
    }
  }

  // Darken the responsive nav toggle
  .navbar-toggle {
    border-color: $navbar-inverse-toggle-border-color;
    &:hover,
    &:focus {
      background-color: $navbar-inverse-toggle-hover-bg;
    }
    .icon-bar {
      background-color: $navbar-inverse-toggle-icon-bar-bg;
    }
  }

  .navbar-collapse,
  .navbar-form {
    border-color: darken($navbar-inverse-bg, 7%);
  }

  // Dropdowns
  .navbar-nav {
    > .open > a {
      &,
      &:hover,
      &:focus {
        background-color: $navbar-inverse-link-active-bg;
        color: $navbar-inverse-link-active-color;
      }
    }

    @media (max-width: $grid-float-breakpoint-max) {
      // Dropdowns get custom display
      .open .dropdown-menu {
        > .dropdown-header {
          border-color: $navbar-inverse-border;
        }
        .divider {
          background-color: $navbar-inverse-border;
        }
        > li > a {
          color: $navbar-inverse-link-color;
          &:hover,
          &:focus {
            color: $navbar-inverse-link-hover-color;
            background-color: $navbar-inverse-link-hover-bg;
          }
        }
        > .active > a {
          &,
          &:hover,
          &:focus {
            color: $navbar-inverse-link-active-color;
            background-color: $navbar-inverse-link-active-bg;
          }
        }
        > .disabled > a {
          &,
          &:hover,
          &:focus {
            color: $navbar-inverse-link-disabled-color;
            background-color: $navbar-inverse-link-disabled-bg;
          }
        }
      }
    }
  }

  .navbar-link {
    color: $navbar-inverse-link-color;
    &:hover {
      color: $navbar-inverse-link-hover-color;
    }
  }

  .btn-link {
    color: $navbar-inverse-link-color;
    &:hover,
    &:focus {
      color: $navbar-inverse-link-hover-color;
    }
    &[disabled],
    fieldset[disabled] & {
      &:hover,
      &:focus {
        color: $navbar-inverse-link-disabled-color;
      }
    }
  }
}


================================================
File: _sass/bootstrap/_navs.scss
================================================
//
// Navs
// --------------------------------------------------


// Base class
// --------------------------------------------------

.nav {
  margin-bottom: 0;
  padding-left: 0; // Override default ul/ol
  list-style: none;
  @include clearfix;

  > li {
    position: relative;
    display: block;

    > a {
      position: relative;
      display: block;
      padding: $nav-link-padding;
      &:hover,
      &:focus {
        text-decoration: none;
        background-color: $nav-link-hover-bg;
      }
    }

    // Disabled state sets text to gray and nukes hover/tab effects
    &.disabled > a {
      color: $nav-disabled-link-color;

      &:hover,
      &:focus {
        color: $nav-disabled-link-hover-color;
        text-decoration: none;
        background-color: transparent;
        cursor: $cursor-disabled;
      }
    }
  }

  // Open dropdowns
  .open > a {
    &,
    &:hover,
    &:focus {
      background-color: $nav-link-hover-bg;
      border-color: $link-color;
    }
  }

  // Nav dividers (deprecated with v3.0.1)
  //
  // This should have been removed in v3 with the dropping of `.nav-list`, but
  // we missed it. We don't currently support this anywhere, but in the interest
  // of maintaining backward compatibility in case you use it, it's deprecated.
  .nav-divider {
    @include nav-divider;
  }

  // Prevent IE8 from misplacing imgs
  //
  // See https://github.com/h5bp/html5-boilerplate/issues/984#issuecomment-3985989
  > li > a > img {
    max-width: none;
  }
}


// Tabs
// -------------------------

// Give the tabs something to sit on
.nav-tabs {
  border-bottom: 1px solid $nav-tabs-border-color;
  > li {
    float: left;
    // Make the list-items overlay the bottom border
    margin-bottom: -1px;

    // Actual tabs (as links)
    > a {
      margin-right: 2px;
      line-height: $line-height-base;
      border: 1px solid transparent;
      border-radius: $border-radius-base $border-radius-base 0 0;
      &:hover {
        border-color: $nav-tabs-link-hover-border-color $nav-tabs-link-hover-border-color $nav-tabs-border-color;
      }
    }

    // Active state, and its :hover to override normal :hover
    &.active > a {
      &,
      &:hover,
      &:focus {
        color: $nav-tabs-active-link-hover-color;
        background-color: $nav-tabs-active-link-hover-bg;
        border: 1px solid $nav-tabs-active-link-hover-border-color;
        border-bottom-color: transparent;
        cursor: default;
      }
    }
  }
  // pulling this in mainly for less shorthand
  &.nav-justified {
    @extend .nav-justified;
    @extend .nav-tabs-justified;
  }
}


// Pills
// -------------------------
.nav-pills {
  > li {
    float: left;

    // Links rendered as pills
    > a {
      border-radius: $nav-pills-border-radius;
    }
    + li {
      margin-left: 2px;
    }

    // Active state
    &.active > a {
      &,
      &:hover,
      &:focus {
        color: $nav-pills-active-link-hover-color;
        background-color: $nav-pills-active-link-hover-bg;
      }
    }
  }
}


// Stacked pills
.nav-stacked {
  > li {
    float: none;
    + li {
      margin-top: 2px;
      margin-left: 0; // no need for this gap between nav items
    }
  }
}


// Nav variations
// --------------------------------------------------

// Justified nav links
// -------------------------

.nav-justified {
  width: 100%;

  > li {
    float: none;
    > a {
      text-align: center;
      margin-bottom: 5px;
    }
  }

  > .dropdown .dropdown-menu {
    top: auto;
    left: auto;
  }

  @media (min-width: $screen-sm-min) {
    > li {
      display: table-cell;
      width: 1%;
      > a {
        margin-bottom: 0;
      }
    }
  }
}

// Move borders to anchors instead of bottom of list
//
// Mixin for adding on top the shared `.nav-justified` styles for our tabs
.nav-tabs-justified {
  border-bottom: 0;

  > li > a {
    // Override margin from .nav-tabs
    margin-right: 0;
    border-radius: $border-radius-base;
  }

  > .active > a,
  > .active > a:hover,
  > .active > a:focus {
    border: 1px solid $nav-tabs-justified-link-border-color;
  }

  @media (min-width: $screen-sm-min) {
    > li > a {
      border-bottom: 1px solid $nav-tabs-justified-link-border-color;
      border-radius: $border-radius-base $border-radius-base 0 0;
    }
    > .active > a,
    > .active > a:hover,
    > .active > a:focus {
      border-bottom-color: $nav-tabs-justified-active-link-border-color;
    }
  }
}


// Tabbable tabs
// -------------------------

// Hide tabbable panes to start, show them when `.active`
.tab-content {
  > .tab-pane {
    display: none;
  }
  > .active {
    display: block;
  }
}


// Dropdowns
// -------------------------

// Specific dropdowns
.nav-tabs .dropdown-menu {
  // make dropdown border overlap tab border
  margin-top: -1px;
  // Remove the top rounded corners here since there is a hard edge above the menu
  @include border-top-radius(0);
}


================================================
File: _sass/bootstrap/_normalize.scss
================================================
/*! normalize.css v3.0.3 | MIT License | github.com/necolas/normalize.css */

//
// 1. Set default font family to sans-serif.
// 2. Prevent iOS and IE text size adjust after device orientation change,
//    without disabling user zoom.
//

html {
  font-family: sans-serif; // 1
  -ms-text-size-adjust: 100%; // 2
  -webkit-text-size-adjust: 100%; // 2
}

//
// Remove default margin.
//

body {
  margin: 0;
}

// HTML5 display definitions
// ==========================================================================

//
// Correct `block` display not defined for any HTML5 element in IE 8/9.
// Correct `block` display not defined for `details` or `summary` in IE 10/11
// and Firefox.
// Correct `block` display not defined for `main` in IE 11.
//

article,
aside,
details,
figcaption,
figure,
footer,
header,
hgroup,
main,
menu,
nav,
section,
summary {
  display: block;
}

//
// 1. Correct `inline-block` display not defined in IE 8/9.
// 2. Normalize vertical alignment of `progress` in Chrome, Firefox, and Opera.
//

audio,
canvas,
progress,
video {
  display: inline-block; // 1
  vertical-align: baseline; // 2
}

//
// Prevent modern browsers from displaying `audio` without controls.
// Remove excess height in iOS 5 devices.
//

audio:not([controls]) {
  display: none;
  height: 0;
}

//
// Address `[hidden]` styling not present in IE 8/9/10.
// Hide the `template` element in IE 8/9/10/11, Safari, and Firefox < 22.
//

[hidden],
template {
  display: none;
}

// Links
// ==========================================================================

//
// Remove the gray background color from active links in IE 10.
//

a {
  background-color: transparent;
}

//
// Improve readability of focused elements when they are also in an
// active/hover state.
//

a:active,
a:hover {
  outline: 0;
}

// Text-level semantics
// ==========================================================================

//
// Address styling not present in IE 8/9/10/11, Safari, and Chrome.
//

abbr[title] {
  border-bottom: 1px dotted;
}

//
// Address style set to `bolder` in Firefox 4+, Safari, and Chrome.
//

b,
strong {
  font-weight: bold;
}

//
// Address styling not present in Safari and Chrome.
//

dfn {
  font-style: italic;
}

//
// Address variable `h1` font-size and margin within `section` and `article`
// contexts in Firefox 4+, Safari, and Chrome.
//

h1 {
  font-size: 2em;
  margin: 0.67em 0;
}

//
// Address styling not present in IE 8/9.
//

mark {
  background: #ff0;
  color: #000;
}

//
// Address inconsistent and variable font size in all browsers.
//

small {
  font-size: 80%;
}

//
// Prevent `sub` and `sup` affecting `line-height` in all browsers.
//

sub,
sup {
  font-size: 75%;
  line-height: 0;
  position: relative;
  vertical-align: baseline;
}

sup {
  top: -0.5em;
}

sub {
  bottom: -0.25em;
}

// Embedded content
// ==========================================================================

//
// Remove border when inside `a` element in IE 8/9/10.
//

img {
  border: 0;
}

//
// Correct overflow not hidden in IE 9/10/11.
//

svg:not(:root) {
  overflow: hidden;
}

// Grouping content
// ==========================================================================

//
// Address margin not present in IE 8/9 and Safari.
//

figure {
  margin: 1em 40px;
}

//
// Address differences between Firefox and other browsers.
//

hr {
  box-sizing: content-box;
  height: 0;
}

//
// Contain overflow in all browsers.
//

pre {
  overflow: auto;
}

//
// Address odd `em`-unit font size rendering in all browsers.
//

code,
kbd,
pre,
samp {
  font-family: monospace, monospace;
  font-size: 1em;
}

// Forms
// ==========================================================================

//
// Known limitation: by default, Chrome and Safari on OS X allow very limited
// styling of `select`, unless a `border` property is set.
//

//
// 1. Correct color not being inherited.
//    Known issue: affects color of disabled elements.
// 2. Correct font properties not being inherited.
// 3. Address margins set differently in Firefox 4+, Safari, and Chrome.
//

button,
input,
optgroup,
select,
textarea {
  color: inherit; // 1
  font: inherit; // 2
  margin: 0; // 3
}

//
// Address `overflow` set to `hidden` in IE 8/9/10/11.
//

button {
  overflow: visible;
}

//
// Address inconsistent `text-transform` inheritance for `button` and `select`.
// All other form control elements do not inherit `text-transform` values.
// Correct `button` style inheritance in Firefox, IE 8/9/10/11, and Opera.
// Correct `select` style inheritance in Firefox.
//

button,
select {
  text-transform: none;
}

//
// 1. Avoid the WebKit bug in Android 4.0.* where (2) destroys native `audio`
//    and `video` controls.
// 2. Correct inability to style clickable `input` types in iOS.
// 3. Improve usability and consistency of cursor style between image-type
//    `input` and others.
//

button,
html input[type="button"], // 1
input[type="reset"],
input[type="submit"] {
  -webkit-appearance: button; // 2
  cursor: pointer; // 3
}

//
// Re-set default cursor for disabled elements.
//

button[disabled],
html input[disabled] {
  cursor: default;
}

//
// Remove inner padding and border in Firefox 4+.
//

button::-moz-focus-inner,
input::-moz-focus-inner {
  border: 0;
  padding: 0;
}

//
// Address Firefox 4+ setting `line-height` on `input` using `!important` in
// the UA stylesheet.
//

input {
  line-height: normal;
}

//
// It's recommended that you don't attempt to style these elements.
// Firefox's implementation doesn't respect box-sizing, padding, or width.
//
// 1. Address box sizing set to `content-box` in IE 8/9/10.
// 2. Remove excess padding in IE 8/9/10.
//

input[type="checkbox"],
input[type="radio"] {
  box-sizing: border-box; // 1
  padding: 0; // 2
}

//
// Fix the cursor style for Chrome's increment/decrement buttons. For certain
// `font-size` values of the `input`, it causes the cursor style of the
// decrement button to change from `default` to `text`.
//

input[type="number"]::-webkit-inner-spin-button,
input[type="number"]::-webkit-outer-spin-button {
  height: auto;
}

//
// 1. Address `appearance` set to `searchfield` in Safari and Chrome.
// 2. Address `box-sizing` set to `border-box` in Safari and Chrome.
//

input[type="search"] {
  -webkit-appearance: textfield; // 1
  box-sizing: content-box; //2
}

//
// Remove inner padding and search cancel button in Safari and Chrome on OS X.
// Safari (but not Chrome) clips the cancel button when the search input has
// padding (and `textfield` appearance).
//

input[type="search"]::-webkit-search-cancel-button,
input[type="search"]::-webkit-search-decoration {
  -webkit-appearance: none;
}

//
// Define consistent border, margin, and padding.
//

fieldset {
  border: 1px solid #c0c0c0;
  margin: 0 2px;
  padding: 0.35em 0.625em 0.75em;
}

//
// 1. Correct `color` not being inherited in IE 8/9/10/11.
// 2. Remove padding so people aren't caught out if they zero out fieldsets.
//

legend {
  border: 0; // 1
  padding: 0; // 2
}

//
// Remove default vertical scrollbar in IE 8/9/10/11.
//

textarea {
  overflow: auto;
}

//
// Don't inherit the `font-weight` (applied by a rule above).
// NOTE: the default cannot safely be changed in Chrome and Safari on OS X.
//

optgroup {
  font-weight: bold;
}

// Tables
// ==========================================================================

//
// Remove most spacing between table cells.
//

table {
  border-collapse: collapse;
  border-spacing: 0;
}

td,
th {
  padding: 0;
}


================================================
File: _sass/bootstrap/_pager.scss
================================================
//
// Pager pagination
// --------------------------------------------------


.pager {
  padding-left: 0;
  margin: $line-height-computed 0;
  list-style: none;
  text-align: center;
  @include clearfix;
  li {
    display: inline;
    > a,
    > span {
      display: inline-block;
      padding: 5px 14px;
      background-color: $pager-bg;
      border: 1px solid $pager-border;
      border-radius: $pager-border-radius;
    }

    > a:hover,
    > a:focus {
      text-decoration: none;
      background-color: $pager-hover-bg;
    }
  }

  .next {
    > a,
    > span {
      float: right;
    }
  }

  .previous {
    > a,
    > span {
      float: left;
    }
  }

  .disabled {
    > a,
    > a:hover,
    > a:focus,
    > span {
      color: $pager-disabled-color;
      background-color: $pager-bg;
      cursor: $cursor-disabled;
    }
  }
}


================================================
File: _sass/bootstrap/_pagination.scss
================================================
//
// Pagination (multiple pages)
// --------------------------------------------------
.pagination {
  display: inline-block;
  padding-left: 0;
  margin: $line-height-computed 0;
  border-radius: $border-radius-base;

  > li {
    display: inline; // Remove list-style and block-level defaults
    > a,
    > span {
      position: relative;
      float: left; // Collapse white-space
      padding: $padding-base-vertical $padding-base-horizontal;
      line-height: $line-height-base;
      text-decoration: none;
      color: $pagination-color;
      background-color: $pagination-bg;
      border: 1px solid $pagination-border;
      margin-left: -1px;
    }
    &:first-child {
      > a,
      > span {
        margin-left: 0;
        @include border-left-radius($border-radius-base);
      }
    }
    &:last-child {
      > a,
      > span {
        @include border-right-radius($border-radius-base);
      }
    }
  }

  > li > a,
  > li > span {
    &:hover,
    &:focus {
      z-index: 2;
      color: $pagination-hover-color;
      background-color: $pagination-hover-bg;
      border-color: $pagination-hover-border;
    }
  }

  > .active > a,
  > .active > span {
    &,
    &:hover,
    &:focus {
      z-index: 3;
      color: $pagination-active-color;
      background-color: $pagination-active-bg;
      border-color: $pagination-active-border;
      cursor: default;
    }
  }

  > .disabled {
    > span,
    > span:hover,
    > span:focus,
    > a,
    > a:hover,
    > a:focus {
      color: $pagination-disabled-color;
      background-color: $pagination-disabled-bg;
      border-color: $pagination-disabled-border;
      cursor: $cursor-disabled;
    }
  }
}

// Sizing
// --------------------------------------------------

// Large
.pagination-lg {
  @include pagination-size($padding-large-vertical, $padding-large-horizontal, $font-size-large, $line-height-large, $border-radius-large);
}

// Small
.pagination-sm {
  @include pagination-size($padding-small-vertical, $padding-small-horizontal, $font-size-small, $line-height-small, $border-radius-small);
}


================================================
File: _sass/bootstrap/_panels.scss
================================================
//
// Panels
// --------------------------------------------------


// Base class
.panel {
  margin-bottom: $line-height-computed;
  background-color: $panel-bg;
  border: 1px solid transparent;
  border-radius: $panel-border-radius;
  @include box-shadow(0 1px 1px rgba(0,0,0,.05));
}

// Panel contents
.panel-body {
  padding: $panel-body-padding;
  @include clearfix;
}

// Optional heading
.panel-heading {
  padding: $panel-heading-padding;
  border-bottom: 1px solid transparent;
  @include border-top-radius(($panel-border-radius - 1));

  > .dropdown .dropdown-toggle {
    color: inherit;
  }
}

// Within heading, strip any `h*` tag of its default margins for spacing.
.panel-title {
  margin-top: 0;
  margin-bottom: 0;
  font-size: ceil(($font-size-base * 1.125));
  color: inherit;

  > a,
  > small,
  > .small,
  > small > a,
  > .small > a {
    color: inherit;
  }
}

// Optional footer (stays gray in every modifier class)
.panel-footer {
  padding: $panel-footer-padding;
  background-color: $panel-footer-bg;
  border-top: 1px solid $panel-inner-border;
  @include border-bottom-radius(($panel-border-radius - 1));
}


// List groups in panels
//
// By default, space out list group content from panel headings to account for
// any kind of custom content between the two.

.panel {
  > .list-group,
  > .panel-collapse > .list-group {
    margin-bottom: 0;

    .list-group-item {
      border-width: 1px 0;
      border-radius: 0;
    }

    // Add border top radius for first one
    &:first-child {
      .list-group-item:first-child {
        border-top: 0;
        @include border-top-radius(($panel-border-radius - 1));
      }
    }

    // Add border bottom radius for last one
    &:last-child {
      .list-group-item:last-child {
        border-bottom: 0;
        @include border-bottom-radius(($panel-border-radius - 1));
      }
    }
  }
  > .panel-heading + .panel-collapse > .list-group {
    .list-group-item:first-child {
      @include border-top-radius(0);
    }
  }
}
// Collapse space between when there's no additional content.
.panel-heading + .list-group {
  .list-group-item:first-child {
    border-top-width: 0;
  }
}
.list-group + .panel-footer {
  border-top-width: 0;
}

// Tables in panels
//
// Place a non-bordered `.table` within a panel (not within a `.panel-body`) and
// watch it go full width.

.panel {
  > .table,
  > .table-responsive > .table,
  > .panel-collapse > .table {
    margin-bottom: 0;

    caption {
      padding-left: $panel-body-padding;
      padding-right: $panel-body-padding;
    }
  }
  // Add border top radius for first one
  > .table:first-child,
  > .table-responsive:first-child > .table:first-child {
    @include border-top-radius(($panel-border-radius - 1));

    > thead:first-child,
    > tbody:first-child {
      > tr:first-child {
        border-top-left-radius: ($panel-border-radius - 1);
        border-top-right-radius: ($panel-border-radius - 1);

        td:first-child,
        th:first-child {
          border-top-left-radius: ($panel-border-radius - 1);
        }
        td:last-child,
        th:last-child {
          border-top-right-radius: ($panel-border-radius - 1);
        }
      }
    }
  }
  // Add border bottom radius for last one
  > .table:last-child,
  > .table-responsive:last-child > .table:last-child {
    @include border-bottom-radius(($panel-border-radius - 1));

    > tbody:last-child,
    > tfoot:last-child {
      > tr:last-child {
        border-bottom-left-radius: ($panel-border-radius - 1);
        border-bottom-right-radius: ($panel-border-radius - 1);

        td:first-child,
        th:first-child {
          border-bottom-left-radius: ($panel-border-radius - 1);
        }
        td:last-child,
        th:last-child {
          border-bottom-right-radius: ($panel-border-radius - 1);
        }
      }
    }
  }
  > .panel-body + .table,
  > .panel-body + .table-responsive,
  > .table + .panel-body,
  > .table-responsive + .panel-body {
    border-top: 1px solid $table-border-color;
  }
  > .table > tbody:first-child > tr:first-child th,
  > .table > tbody:first-child > tr:first-child td {
    border-top: 0;
  }
  > .table-bordered,
  > .table-responsive > .table-bordered {
    border: 0;
    > thead,
    > tbody,
    > tfoot {
      > tr {
        > th:first-child,
        > td:first-child {
          border-left: 0;
        }
        > th:last-child,
        > td:last-child {
          border-right: 0;
        }
      }
    }
    > thead,
    > tbody {
      > tr:first-child {
        > td,
        > th {
          border-bottom: 0;
        }
      }
    }
    > tbody,
    > tfoot {
      > tr:last-child {
        > td,
        > th {
          border-bottom: 0;
        }
      }
    }
  }
  > .table-responsive {
    border: 0;
    margin-bottom: 0;
  }
}


// Collapsable panels (aka, accordion)
//
// Wrap a series of panels in `.panel-group` to turn them into an accordion with
// the help of our collapse JavaScript plugin.

.panel-group {
  margin-bottom: $line-height-computed;

  // Tighten up margin so it's only between panels
  .panel {
    margin-bottom: 0;
    border-radius: $panel-border-radius;

    + .panel {
      margin-top: 5px;
    }
  }

  .panel-heading {
    border-bottom: 0;

    + .panel-collapse > .panel-body,
    + .panel-collapse > .list-group {
      border-top: 1px solid $panel-inner-border;
    }
  }

  .panel-footer {
    border-top: 0;
    + .panel-collapse .panel-body {
      border-bottom: 1px solid $panel-inner-border;
    }
  }
}


// Contextual variations
.panel-default {
  @include panel-variant($panel-default-border, $panel-default-text, $panel-default-heading-bg, $panel-default-border);
}
.panel-primary {
  @include panel-variant($panel-primary-border, $panel-primary-text, $panel-primary-heading-bg, $panel-primary-border);
}
.panel-success {
  @include panel-variant($panel-success-border, $panel-success-text, $panel-success-heading-bg, $panel-success-border);
}
.panel-info {
  @include panel-variant($panel-info-border, $panel-info-text, $panel-info-heading-bg, $panel-info-border);
}
.panel-warning {
  @include panel-variant($panel-warning-border, $panel-warning-text, $panel-warning-heading-bg, $panel-warning-border);
}
.panel-danger {
  @include panel-variant($panel-danger-border, $panel-danger-text, $panel-danger-heading-bg, $panel-danger-border);
}


================================================
File: _sass/bootstrap/_popovers.scss
================================================
//
// Popovers
// --------------------------------------------------


.popover {
  position: absolute;
  top: 0;
  left: 0;
  z-index: $zindex-popover;
  display: none;
  max-width: $popover-max-width;
  padding: 1px;
  // Our parent element can be arbitrary since popovers are by default inserted as a sibling of their target element.
  // So reset our font and text properties to avoid inheriting weird values.
  @include reset-text;
  font-size: $font-size-base;

  background-color: $popover-bg;
  background-clip: padding-box;
  border: 1px solid $popover-fallback-border-color;
  border: 1px solid $popover-border-color;
  border-radius: $border-radius-large;
  @include box-shadow(0 5px 10px rgba(0,0,0,.2));

  // Offset the popover to account for the popover arrow
  &.top     { margin-top: -$popover-arrow-width; }
  &.right   { margin-left: $popover-arrow-width; }
  &.bottom  { margin-top: $popover-arrow-width; }
  &.left    { margin-left: -$popover-arrow-width; }
}

.popover-title {
  margin: 0; // reset heading margin
  padding: 8px 14px;
  font-size: $font-size-base;
  background-color: $popover-title-bg;
  border-bottom: 1px solid darken($popover-title-bg, 5%);
  border-radius: ($border-radius-large - 1) ($border-radius-large - 1) 0 0;
}

.popover-content {
  padding: 9px 14px;
}

// Arrows
//
// .arrow is outer, .arrow:after is inner

.popover > .arrow {
  &,
  &:after {
    position: absolute;
    display: block;
    width: 0;
    height: 0;
    border-color: transparent;
    border-style: solid;
  }
}
.popover > .arrow {
  border-width: $popover-arrow-outer-width;
}
.popover > .arrow:after {
  border-width: $popover-arrow-width;
  content: "";
}

.popover {
  &.top > .arrow {
    left: 50%;
    margin-left: -$popover-arrow-outer-width;
    border-bottom-width: 0;
    border-top-color: $popover-arrow-outer-fallback-color; // IE8 fallback
    border-top-color: $popover-arrow-outer-color;
    bottom: -$popover-arrow-outer-width;
    &:after {
      content: " ";
      bottom: 1px;
      margin-left: -$popover-arrow-width;
      border-bottom-width: 0;
      border-top-color: $popover-arrow-color;
    }
  }
  &.right > .arrow {
    top: 50%;
    left: -$popover-arrow-outer-width;
    margin-top: -$popover-arrow-outer-width;
    border-left-width: 0;
    border-right-color: $popover-arrow-outer-fallback-color; // IE8 fallback
    border-right-color: $popover-arrow-outer-color;
    &:after {
      content: " ";
      left: 1px;
      bottom: -$popover-arrow-width;
      border-left-width: 0;
      border-right-color: $popover-arrow-color;
    }
  }
  &.bottom > .arrow {
    left: 50%;
    margin-left: -$popover-arrow-outer-width;
    border-top-width: 0;
    border-bottom-color: $popover-arrow-outer-fallback-color; // IE8 fallback
    border-bottom-color: $popover-arrow-outer-color;
    top: -$popover-arrow-outer-width;
    &:after {
      content: " ";
      top: 1px;
      margin-left: -$popover-arrow-width;
      border-top-width: 0;
      border-bottom-color: $popover-arrow-color;
    }
  }

  &.left > .arrow {
    top: 50%;
    right: -$popover-arrow-outer-width;
    margin-top: -$popover-arrow-outer-width;
    border-right-width: 0;
    border-left-color: $popover-arrow-outer-fallback-color; // IE8 fallback
    border-left-color: $popover-arrow-outer-color;
    &:after {
      content: " ";
      right: 1px;
      border-right-width: 0;
      border-left-color: $popover-arrow-color;
      bottom: -$popover-arrow-width;
    }
  }
}


================================================
File: _sass/bootstrap/_print.scss
================================================
/*! Source: https://github.com/h5bp/html5-boilerplate/blob/master/src/css/main.css */

// ==========================================================================
// Print styles.
// Inlined to avoid the additional HTTP request: h5bp.com/r
// ==========================================================================

@media print {
    *,
    *:before,
    *:after {
        background: transparent !important;
        color: #000 !important; // Black prints faster: h5bp.com/s
        box-shadow: none !important;
        text-shadow: none !important;
    }

    a,
    a:visited {
        text-decoration: underline;
    }

    a[href]:after {
        content: " (" attr(href) ")";
    }

    abbr[title]:after {
        content: " (" attr(title) ")";
    }

    // Don't show links that are fragment identifiers,
    // or use the `javascript:` pseudo protocol
    a[href^="#"]:after,
    a[href^="javascript:"]:after {
        content: "";
    }

    pre,
    blockquote {
        border: 1px solid #999;
        page-break-inside: avoid;
    }

    thead {
        display: table-header-group; // h5bp.com/t
    }

    tr,
    img {
        page-break-inside: avoid;
    }

    img {
        max-width: 100% !important;
    }

    p,
    h2,
    h3 {
        orphans: 3;
        widows: 3;
    }

    h2,
    h3 {
        page-break-after: avoid;
    }

    // Bootstrap specific changes start

    // Bootstrap components
    .navbar {
        display: none;
    }
    .btn,
    .dropup > .btn {
        > .caret {
            border-top-color: #000 !important;
        }
    }
    .label {
        border: 1px solid #000;
    }

    .table {
        border-collapse: collapse !important;

        td,
        th {
            background-color: #fff !important;
        }
    }
    .table-bordered {
        th,
        td {
            border: 1px solid #ddd !important;
        }
    }

    // Bootstrap specific changes end
}


================================================
File: _sass/bootstrap/_progress-bars.scss
================================================
//
// Progress bars
// --------------------------------------------------


// Bar animations
// -------------------------

// WebKit
@-webkit-keyframes progress-bar-stripes {
  from  { background-position: 40px 0; }
  to    { background-position: 0 0; }
}

// Spec and IE10+
@keyframes progress-bar-stripes {
  from  { background-position: 40px 0; }
  to    { background-position: 0 0; }
}


// Bar itself
// -------------------------

// Outer container
.progress {
  overflow: hidden;
  height: $line-height-computed;
  margin-bottom: $line-height-computed;
  background-color: $progress-bg;
  border-radius: $progress-border-radius;
  @include box-shadow(inset 0 1px 2px rgba(0,0,0,.1));
}

// Bar of progress
.progress-bar {
  float: left;
  width: 0%;
  height: 100%;
  font-size: $font-size-small;
  line-height: $line-height-computed;
  color: $progress-bar-color;
  text-align: center;
  background-color: $progress-bar-bg;
  @include box-shadow(inset 0 -1px 0 rgba(0,0,0,.15));
  @include transition(width .6s ease);
}

// Striped bars
//
// `.progress-striped .progress-bar` is deprecated as of v3.2.0 in favor of the
// `.progress-bar-striped` class, which you just add to an existing
// `.progress-bar`.
.progress-striped .progress-bar,
.progress-bar-striped {
  @include gradient-striped;
  background-size: 40px 40px;
}

// Call animation for the active one
//
// `.progress.active .progress-bar` is deprecated as of v3.2.0 in favor of the
// `.progress-bar.active` approach.
.progress.active .progress-bar,
.progress-bar.active {
  @include animation(progress-bar-stripes 2s linear infinite);
}


// Variations
// -------------------------

.progress-bar-success {
  @include progress-bar-variant($progress-bar-success-bg);
}

.progress-bar-info {
  @include progress-bar-variant($progress-bar-info-bg);
}

.progress-bar-warning {
  @include progress-bar-variant($progress-bar-warning-bg);
}

.progress-bar-danger {
  @include progress-bar-variant($progress-bar-danger-bg);
}


================================================
File: _sass/bootstrap/_responsive-embed.scss
================================================
// Embeds responsive
//
// Credit: Nicolas Gallagher and SUIT CSS.

.embed-responsive {
  position: relative;
  display: block;
  height: 0;
  padding: 0;
  overflow: hidden;

  .embed-responsive-item,
  iframe,
  embed,
  object,
  video {
    position: absolute;
    top: 0;
    left: 0;
    bottom: 0;
    height: 100%;
    width: 100%;
    border: 0;
  }
}

// Modifier class for 16:9 aspect ratio
.embed-responsive-16by9 {
  padding-bottom: 56.25%;
}

// Modifier class for 4:3 aspect ratio
.embed-responsive-4by3 {
  padding-bottom: 75%;
}


================================================
File: _sass/bootstrap/_responsive-utilities.scss
================================================
//
// Responsive: Utility classes
// --------------------------------------------------


// IE10 in Windows (Phone) 8
//
// Support for responsive views via media queries is kind of borked in IE10, for
// Surface/desktop in split view and for Windows Phone 8. This particular fix
// must be accompanied by a snippet of JavaScript to sniff the user agent and
// apply some conditional CSS to *only* the Surface/desktop Windows 8. Look at
// our Getting Started page for more information on this bug.
//
// For more information, see the following:
//
// Issue: https://github.com/twbs/bootstrap/issues/10497
// Docs: http://getbootstrap.com/getting-started/#support-ie10-width
// Source: http://timkadlec.com/2013/01/windows-phone-8-and-device-width/
// Source: http://timkadlec.com/2012/10/ie10-snap-mode-and-responsive-design/

@at-root {
  @-ms-viewport {
    width: device-width;
  }
}


// Visibility utilities
// Note: Deprecated .visible-xs, .visible-sm, .visible-md, and .visible-lg as of v3.2.0

@include responsive-invisibility('.visible-xs');
@include responsive-invisibility('.visible-sm');
@include responsive-invisibility('.visible-md');
@include responsive-invisibility('.visible-lg');

.visible-xs-block,
.visible-xs-inline,
.visible-xs-inline-block,
.visible-sm-block,
.visible-sm-inline,
.visible-sm-inline-block,
.visible-md-block,
.visible-md-inline,
.visible-md-inline-block,
.visible-lg-block,
.visible-lg-inline,
.visible-lg-inline-block {
  display: none !important;
}

@media (max-width: $screen-xs-max) {
  @include responsive-visibility('.visible-xs');
}
.visible-xs-block {
  @media (max-width: $screen-xs-max) {
    display: block !important;
  }
}
.visible-xs-inline {
  @media (max-width: $screen-xs-max) {
    display: inline !important;
  }
}
.visible-xs-inline-block {
  @media (max-width: $screen-xs-max) {
    display: inline-block !important;
  }
}

@media (min-width: $screen-sm-min) and (max-width: $screen-sm-max) {
  @include responsive-visibility('.visible-sm');
}
.visible-sm-block {
  @media (min-width: $screen-sm-min) and (max-width: $screen-sm-max) {
    display: block !important;
  }
}
.visible-sm-inline {
  @media (min-width: $screen-sm-min) and (max-width: $screen-sm-max) {
    display: inline !important;
  }
}
.visible-sm-inline-block {
  @media (min-width: $screen-sm-min) and (max-width: $screen-sm-max) {
    display: inline-block !important;
  }
}

@media (min-width: $screen-md-min) and (max-width: $screen-md-max) {
  @include responsive-visibility('.visible-md');
}
.visible-md-block {
  @media (min-width: $screen-md-min) and (max-width: $screen-md-max) {
    display: block !important;
  }
}
.visible-md-inline {
  @media (min-width: $screen-md-min) and (max-width: $screen-md-max) {
    display: inline !important;
  }
}
.visible-md-inline-block {
  @media (min-width: $screen-md-min) and (max-width: $screen-md-max) {
    display: inline-block !important;
  }
}

@media (min-width: $screen-lg-min) {
  @include responsive-visibility('.visible-lg');
}
.visible-lg-block {
  @media (min-width: $screen-lg-min) {
    display: block !important;
  }
}
.visible-lg-inline {
  @media (min-width: $screen-lg-min) {
    display: inline !important;
  }
}
.visible-lg-inline-block {
  @media (min-width: $screen-lg-min) {
    display: inline-block !important;
  }
}

@media (max-width: $screen-xs-max) {
  @include responsive-invisibility('.hidden-xs');
}

@media (min-width: $screen-sm-min) and (max-width: $screen-sm-max) {
  @include responsive-invisibility('.hidden-sm');
}

@media (min-width: $screen-md-min) and (max-width: $screen-md-max) {
  @include responsive-invisibility('.hidden-md');
}

@media (min-width: $screen-lg-min) {
  @include responsive-invisibility('.hidden-lg');
}


// Print utilities
//
// Media queries are placed on the inside to be mixin-friendly.

// Note: Deprecated .visible-print as of v3.2.0

@include responsive-invisibility('.visible-print');

@media print {
  @include responsive-visibility('.visible-print');
}
.visible-print-block {
  display: none !important;

  @media print {
    display: block !important;
  }
}
.visible-print-inline {
  display: none !important;

  @media print {
    display: inline !important;
  }
}
.visible-print-inline-block {
  display: none !important;

  @media print {
    display: inline-block !important;
  }
}

@media print {
  @include responsive-invisibility('.hidden-print');
}


================================================
File: _sass/bootstrap/_scaffolding.scss
================================================
//
// Scaffolding
// --------------------------------------------------


// Reset the box-sizing
//
// Heads up! This reset may cause conflicts with some third-party widgets.
// For recommendations on resolving such conflicts, see
// http://getbootstrap.com/getting-started/#third-box-sizing
* {
  @include box-sizing(border-box);
}
*:before,
*:after {
  @include box-sizing(border-box);
}


// Body reset

html {
  font-size: 10px;
  -webkit-tap-highlight-color: rgba(0,0,0,0);
}

body {
  font-family: $font-family-base;
  font-size: $font-size-base;
  line-height: $line-height-base;
  color: $text-color;
  background-color: $body-bg;
}

// Reset fonts for relevant elements
input,
button,
select,
textarea {
  font-family: inherit;
  font-size: inherit;
  line-height: inherit;
}


// Links

a {
  color: $link-color;
  text-decoration: none;

  &:hover,
  &:focus {
    color: $link-hover-color;
    text-decoration: $link-hover-decoration;
  }

  &:focus {
    @include tab-focus;
  }
}


// Figures
//
// We reset this here because previously Normalize had no `figure` margins. This
// ensures we don't break anyone's use of the element.

figure {
  margin: 0;
}


// Images

img {
  vertical-align: middle;
}

// Responsive images (ensure images don't scale beyond their parents)
.img-responsive {
  @include img-responsive;
}

// Rounded corners
.img-rounded {
  border-radius: $border-radius-large;
}

// Image thumbnails
//
// Heads up! This is mixin-ed into thumbnails.less for `.thumbnail`.
.img-thumbnail {
  padding: $thumbnail-padding;
  line-height: $line-height-base;
  background-color: $thumbnail-bg;
  border: 1px solid $thumbnail-border;
  border-radius: $thumbnail-border-radius;
  @include transition(all .2s ease-in-out);

  // Keep them at most 100% wide
  @include img-responsive(inline-block);
}

// Perfect circle
.img-circle {
  border-radius: 50%; // set radius in percents
}


// Horizontal rules

hr {
  margin-top:    $line-height-computed;
  margin-bottom: $line-height-computed;
  border: 0;
  border-top: 1px solid $hr-border;
}


// Only display content to screen readers
//
// See: http://a11yproject.com/posts/how-to-hide-content/

.sr-only {
  position: absolute;
  width: 1px;
  height: 1px;
  margin: -1px;
  padding: 0;
  overflow: hidden;
  clip: rect(0,0,0,0);
  border: 0;
}

// Use in conjunction with .sr-only to only display content when it's focused.
// Useful for "Skip to main content" links; see http://www.w3.org/TR/2013/NOTE-WCAG20-TECHS-20130905/G1
// Credit: HTML5 Boilerplate

.sr-only-focusable {
  &:active,
  &:focus {
    position: static;
    width: auto;
    height: auto;
    margin: 0;
    overflow: visible;
    clip: auto;
  }
}


// iOS "clickable elements" fix for role="button"
//
// Fixes "clickability" issue (and more generally, the firing of events such as focus as well)
// for traditionally non-focusable elements with role="button"
// see https://developer.mozilla.org/en-US/docs/Web/Events/click#Safari_Mobile

[role="button"] {
  cursor: pointer;
}


================================================
File: _sass/bootstrap/_tables.scss
================================================
//
// Tables
// --------------------------------------------------


table {
  background-color: $table-bg;
}
caption {
  padding-top: $table-cell-padding;
  padding-bottom: $table-cell-padding;
  color: $text-muted;
  text-align: left;
}
th {
  text-align: left;
}


// Baseline styles

.table {
  width: 100%;
  max-width: 100%;
  margin-bottom: $line-height-computed;
  // Cells
  > thead,
  > tbody,
  > tfoot {
    > tr {
      > th,
      > td {
        padding: $table-cell-padding;
        line-height: $line-height-base;
        vertical-align: top;
        border-top: 1px solid $table-border-color;
      }
    }
  }
  // Bottom align for column headings
  > thead > tr > th {
    vertical-align: bottom;
    border-bottom: 2px solid $table-border-color;
  }
  // Remove top border from thead by default
  > caption + thead,
  > colgroup + thead,
  > thead:first-child {
    > tr:first-child {
      > th,
      > td {
        border-top: 0;
      }
    }
  }
  // Account for multiple tbody instances
  > tbody + tbody {
    border-top: 2px solid $table-border-color;
  }

  // Nesting
  .table {
    background-color: $body-bg;
  }
}


// Condensed table w/ half padding

.table-condensed {
  > thead,
  > tbody,
  > tfoot {
    > tr {
      > th,
      > td {
        padding: $table-condensed-cell-padding;
      }
    }
  }
}


// Bordered version
//
// Add borders all around the table and between all the columns.

.table-bordered {
  border: 1px solid $table-border-color;
  > thead,
  > tbody,
  > tfoot {
    > tr {
      > th,
      > td {
        border: 1px solid $table-border-color;
      }
    }
  }
  > thead > tr {
    > th,
    > td {
      border-bottom-width: 2px;
    }
  }
}


// Zebra-striping
//
// Default zebra-stripe styles (alternating gray and transparent backgrounds)

.table-striped {
  > tbody > tr:nth-of-type(odd) {
    background-color: $table-bg-accent;
  }
}


// Hover effect
//
// Placed here since it has to come after the potential zebra striping

.table-hover {
  > tbody > tr:hover {
    background-color: $table-bg-hover;
  }
}


// Table cell sizing
//
// Reset default table behavior

table col[class*="col-"] {
  position: static; // Prevent border hiding in Firefox and IE9-11 (see https://github.com/twbs/bootstrap/issues/11623)
  float: none;
  display: table-column;
}
table {
  td,
  th {
    &[class*="col-"] {
      position: static; // Prevent border hiding in Firefox and IE9-11 (see https://github.com/twbs/bootstrap/issues/11623)
      float: none;
      display: table-cell;
    }
  }
}


// Table backgrounds
//
// Exact selectors below required to override `.table-striped` and prevent
// inheritance to nested tables.

// Generate the contextual variants
@include table-row-variant('active', $table-bg-active);
@include table-row-variant('success', $state-success-bg);
@include table-row-variant('info', $state-info-bg);
@include table-row-variant('warning', $state-warning-bg);
@include table-row-variant('danger', $state-danger-bg);


// Responsive tables
//
// Wrap your tables in `.table-responsive` and we'll make them mobile friendly
// by enabling horizontal scrolling. Only applies <768px. Everything above that
// will display normally.

.table-responsive {
  overflow-x: auto;
  min-height: 0.01%; // Workaround for IE9 bug (see https://github.com/twbs/bootstrap/issues/14837)

  @media screen and (max-width: $screen-xs-max) {
    width: 100%;
    margin-bottom: ($line-height-computed * 0.75);
    overflow-y: hidden;
    -ms-overflow-style: -ms-autohiding-scrollbar;
    border: 1px solid $table-border-color;

    // Tighten up spacing
    > .table {
      margin-bottom: 0;

      // Ensure the content doesn't wrap
      > thead,
      > tbody,
      > tfoot {
        > tr {
          > th,
          > td {
            white-space: nowrap;
          }
        }
      }
    }

    // Special overrides for the bordered tables
    > .table-bordered {
      border: 0;

      // Nuke the appropriate borders so that the parent can handle them
      > thead,
      > tbody,
      > tfoot {
        > tr {
          > th:first-child,
          > td:first-child {
            border-left: 0;
          }
          > th:last-child,
          > td:last-child {
            border-right: 0;
          }
        }
      }

      // Only nuke the last row's bottom-border in `tbody` and `tfoot` since
      // chances are there will be only one `tr` in a `thead` and that would
      // remove the border altogether.
      > tbody,
      > tfoot {
        > tr:last-child {
          > th,
          > td {
            border-bottom: 0;
          }
        }
      }

    }
  }
}


================================================
File: _sass/bootstrap/_theme.scss
================================================
/*!
 * Bootstrap v3.3.6 (http://getbootstrap.com)
 * Copyright 2011-2015 Twitter, Inc.
 * Licensed under MIT (https://github.com/twbs/bootstrap/blob/master/LICENSE)
 */

//
// Load core variables and mixins
// --------------------------------------------------

@import "variables";
@import "mixins";


//
// Buttons
// --------------------------------------------------

// Common styles
.btn-default,
.btn-primary,
.btn-success,
.btn-info,
.btn-warning,
.btn-danger {
  text-shadow: 0 -1px 0 rgba(0,0,0,.2);
  $shadow: inset 0 1px 0 rgba(255,255,255,.15), 0 1px 1px rgba(0,0,0,.075);
  @include box-shadow($shadow);

  // Reset the shadow
  &:active,
  &.active {
    @include box-shadow(inset 0 3px 5px rgba(0,0,0,.125));
  }

  &.disabled,
  &[disabled],
  fieldset[disabled] & {
    @include box-shadow(none);
  }

  .badge {
    text-shadow: none;
  }
}

// Mixin for generating new styles
@mixin btn-styles($btn-color: #555) {
  @include gradient-vertical($start-color: $btn-color, $end-color: darken($btn-color, 12%));
  @include reset-filter; // Disable gradients for IE9 because filter bleeds through rounded corners; see https://github.com/twbs/bootstrap/issues/10620
  background-repeat: repeat-x;
  border-color: darken($btn-color, 14%);

  &:hover,
  &:focus  {
    background-color: darken($btn-color, 12%);
    background-position: 0 -15px;
  }

  &:active,
  &.active {
    background-color: darken($btn-color, 12%);
    border-color: darken($btn-color, 14%);
  }

  &.disabled,
  &[disabled],
  fieldset[disabled] & {
    &,
    &:hover,
    &:focus,
    &.focus,
    &:active,
    &.active {
      background-color: darken($btn-color, 12%);
      background-image: none;
    }
  }
}

// Common styles
.btn {
  // Remove the gradient for the pressed/active state
  &:active,
  &.active {
    background-image: none;
  }
}

// Apply the mixin to the buttons
.btn-default { @include btn-styles($btn-default-bg); text-shadow: 0 1px 0 #fff; border-color: #ccc; }
.btn-primary { @include btn-styles($btn-primary-bg); }
.btn-success { @include btn-styles($btn-success-bg); }
.btn-info    { @include btn-styles($btn-info-bg); }
.btn-warning { @include btn-styles($btn-warning-bg); }
.btn-danger  { @include btn-styles($btn-danger-bg); }


//
// Images
// --------------------------------------------------

.thumbnail,
.img-thumbnail {
  @include box-shadow(0 1px 2px rgba(0,0,0,.075));
}


//
// Dropdowns
// --------------------------------------------------

.dropdown-menu > li > a:hover,
.dropdown-menu > li > a:focus {
  @include gradient-vertical($start-color: $dropdown-link-hover-bg, $end-color: darken($dropdown-link-hover-bg, 5%));
  background-color: darken($dropdown-link-hover-bg, 5%);
}
.dropdown-menu > .active > a,
.dropdown-menu > .active > a:hover,
.dropdown-menu > .active > a:focus {
  @include gradient-vertical($start-color: $dropdown-link-active-bg, $end-color: darken($dropdown-link-active-bg, 5%));
  background-color: darken($dropdown-link-active-bg, 5%);
}


//
// Navbar
// --------------------------------------------------

// Default navbar
.navbar-default {
  @include gradient-vertical($start-color: lighten($navbar-default-bg, 10%), $end-color: $navbar-default-bg);
  @include reset-filter; // Remove gradient in IE<10 to fix bug where dropdowns don't get triggered
  border-radius: $navbar-border-radius;
  $shadow: inset 0 1px 0 rgba(255,255,255,.15), 0 1px 5px rgba(0,0,0,.075);
  @include box-shadow($shadow);

  .navbar-nav > .open > a,
  .navbar-nav > .active > a {
    @include gradient-vertical($start-color: darken($navbar-default-link-active-bg, 5%), $end-color: darken($navbar-default-link-active-bg, 2%));
    @include box-shadow(inset 0 3px 9px rgba(0,0,0,.075));
  }
}
.navbar-brand,
.navbar-nav > li > a {
  text-shadow: 0 1px 0 rgba(255,255,255,.25);
}

// Inverted navbar
.navbar-inverse {
  @include gradient-vertical($start-color: lighten($navbar-inverse-bg, 10%), $end-color: $navbar-inverse-bg);
  @include reset-filter; // Remove gradient in IE<10 to fix bug where dropdowns don't get triggered; see https://github.com/twbs/bootstrap/issues/10257
  border-radius: $navbar-border-radius;
  .navbar-nav > .open > a,
  .navbar-nav > .active > a {
    @include gradient-vertical($start-color: $navbar-inverse-link-active-bg, $end-color: lighten($navbar-inverse-link-active-bg, 2.5%));
    @include box-shadow(inset 0 3px 9px rgba(0,0,0,.25));
  }

  .navbar-brand,
  .navbar-nav > li > a {
    text-shadow: 0 -1px 0 rgba(0,0,0,.25);
  }
}

// Undo rounded corners in static and fixed navbars
.navbar-static-top,
.navbar-fixed-top,
.navbar-fixed-bottom {
  border-radius: 0;
}

// Fix active state of dropdown items in collapsed mode
@media (max-width: $grid-float-breakpoint-max) {
  .navbar .navbar-nav .open .dropdown-menu > .active > a {
    &,
    &:hover,
    &:focus {
      color: #fff;
      @include gradient-vertical($start-color: $dropdown-link-active-bg, $end-color: darken($dropdown-link-active-bg, 5%));
    }
  }
}


//
// Alerts
// --------------------------------------------------

// Common styles
.alert {
  text-shadow: 0 1px 0 rgba(255,255,255,.2);
  $shadow: inset 0 1px 0 rgba(255,255,255,.25), 0 1px 2px rgba(0,0,0,.05);
  @include box-shadow($shadow);
}

// Mixin for generating new styles
@mixin alert-styles($color) {
  @include gradient-vertical($start-color: $color, $end-color: darken($color, 7.5%));
  border-color: darken($color, 15%);
}

// Apply the mixin to the alerts
.alert-success    { @include alert-styles($alert-success-bg); }
.alert-info       { @include alert-styles($alert-info-bg); }
.alert-warning    { @include alert-styles($alert-warning-bg); }
.alert-danger     { @include alert-styles($alert-danger-bg); }


//
// Progress bars
// --------------------------------------------------

// Give the progress background some depth
.progress {
  @include gradient-vertical($start-color: darken($progress-bg, 4%), $end-color: $progress-bg)
}

// Mixin for generating new styles
@mixin progress-bar-styles($color) {
  @include gradient-vertical($start-color: $color, $end-color: darken($color, 10%));
}

// Apply the mixin to the progress bars
.progress-bar            { @include progress-bar-styles($progress-bar-bg); }
.progress-bar-success    { @include progress-bar-styles($progress-bar-success-bg); }
.progress-bar-info       { @include progress-bar-styles($progress-bar-info-bg); }
.progress-bar-warning    { @include progress-bar-styles($progress-bar-warning-bg); }
.progress-bar-danger     { @include progress-bar-styles($progress-bar-danger-bg); }

// Reset the striped class because our mixins don't do multiple gradients and
// the above custom styles override the new `.progress-bar-striped` in v3.2.0.
.progress-bar-striped {
  @include gradient-striped;
}


//
// List groups
// --------------------------------------------------

.list-group {
  border-radius: $border-radius-base;
  @include box-shadow(0 1px 2px rgba(0,0,0,.075));
}
.list-group-item.active,
.list-group-item.active:hover,
.list-group-item.active:focus {
  text-shadow: 0 -1px 0 darken($list-group-active-bg, 10%);
  @include gradient-vertical($start-color: $list-group-active-bg, $end-color: darken($list-group-active-bg, 7.5%));
  border-color: darken($list-group-active-border, 7.5%);

  .badge {
    text-shadow: none;
  }
}


//
// Panels
// --------------------------------------------------

// Common styles
.panel {
  @include box-shadow(0 1px 2px rgba(0,0,0,.05));
}

// Mixin for generating new styles
@mixin panel-heading-styles($color) {
  @include gradient-vertical($start-color: $color, $end-color: darken($color, 5%));
}

// Apply the mixin to the panel headings only
.panel-default > .panel-heading   { @include panel-heading-styles($panel-default-heading-bg); }
.panel-primary > .panel-heading   { @include panel-heading-styles($panel-primary-heading-bg); }
.panel-success > .panel-heading   { @include panel-heading-styles($panel-success-heading-bg); }
.panel-info > .panel-heading      { @include panel-heading-styles($panel-info-heading-bg); }
.panel-warning > .panel-heading   { @include panel-heading-styles($panel-warning-heading-bg); }
.panel-danger > .panel-heading    { @include panel-heading-styles($panel-danger-heading-bg); }


//
// Wells
// --------------------------------------------------

.well {
  @include gradient-vertical($start-color: darken($well-bg, 5%), $end-color: $well-bg);
  border-color: darken($well-bg, 10%);
  $shadow: inset 0 1px 3px rgba(0,0,0,.05), 0 1px 0 rgba(255,255,255,.1);
  @include box-shadow($shadow);
}


================================================
File: _sass/bootstrap/_thumbnails.scss
================================================
//
// Thumbnails
// --------------------------------------------------


// Mixin and adjust the regular image class
.thumbnail {
  display: block;
  padding: $thumbnail-padding;
  margin-bottom: $line-height-computed;
  line-height: $line-height-base;
  background-color: $thumbnail-bg;
  border: 1px solid $thumbnail-border;
  border-radius: $thumbnail-border-radius;
  @include transition(border .2s ease-in-out);

  > img,
  a > img {
    @include img-responsive;
    margin-left: auto;
    margin-right: auto;
  }

  // [converter] extracted a&:hover, a&:focus, a&.active to a.thumbnail:hover, a.thumbnail:focus, a.thumbnail.active

  // Image captions
  .caption {
    padding: $thumbnail-caption-padding;
    color: $thumbnail-caption-color;
  }
}

// Add a hover state for linked versions only
a.thumbnail:hover,
a.thumbnail:focus,
a.thumbnail.active {
  border-color: $link-color;
}


================================================
File: _sass/bootstrap/_tooltip.scss
================================================
//
// Tooltips
// --------------------------------------------------


// Base class
.tooltip {
  position: absolute;
  z-index: $zindex-tooltip;
  display: block;
  // Our parent element can be arbitrary since tooltips are by default inserted as a sibling of their target element.
  // So reset our font and text properties to avoid inheriting weird values.
  @include reset-text;
  font-size: $font-size-small;

  @include opacity(0);

  &.in     { @include opacity($tooltip-opacity); }
  &.top    { margin-top:  -3px; padding: $tooltip-arrow-width 0; }
  &.right  { margin-left:  3px; padding: 0 $tooltip-arrow-width; }
  &.bottom { margin-top:   3px; padding: $tooltip-arrow-width 0; }
  &.left   { margin-left: -3px; padding: 0 $tooltip-arrow-width; }
}

// Wrapper for the tooltip content
.tooltip-inner {
  max-width: $tooltip-max-width;
  padding: 3px 8px;
  color: $tooltip-color;
  text-align: center;
  background-color: $tooltip-bg;
  border-radius: $border-radius-base;
}

// Arrows
.tooltip-arrow {
  position: absolute;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
}
// Note: Deprecated .top-left, .top-right, .bottom-left, and .bottom-right as of v3.3.1
.tooltip {
  &.top .tooltip-arrow {
    bottom: 0;
    left: 50%;
    margin-left: -$tooltip-arrow-width;
    border-width: $tooltip-arrow-width $tooltip-arrow-width 0;
    border-top-color: $tooltip-arrow-color;
  }
  &.top-left .tooltip-arrow {
    bottom: 0;
    right: $tooltip-arrow-width;
    margin-bottom: -$tooltip-arrow-width;
    border-width: $tooltip-arrow-width $tooltip-arrow-width 0;
    border-top-color: $tooltip-arrow-color;
  }
  &.top-right .tooltip-arrow {
    bottom: 0;
    left: $tooltip-arrow-width;
    margin-bottom: -$tooltip-arrow-width;
    border-width: $tooltip-arrow-width $tooltip-arrow-width 0;
    border-top-color: $tooltip-arrow-color;
  }
  &.right .tooltip-arrow {
    top: 50%;
    left: 0;
    margin-top: -$tooltip-arrow-width;
    border-width: $tooltip-arrow-width $tooltip-arrow-width $tooltip-arrow-width 0;
    border-right-color: $tooltip-arrow-color;
  }
  &.left .tooltip-arrow {
    top: 50%;
    right: 0;
    margin-top: -$tooltip-arrow-width;
    border-width: $tooltip-arrow-width 0 $tooltip-arrow-width $tooltip-arrow-width;
    border-left-color: $tooltip-arrow-color;
  }
  &.bottom .tooltip-arrow {
    top: 0;
    left: 50%;
    margin-left: -$tooltip-arrow-width;
    border-width: 0 $tooltip-arrow-width $tooltip-arrow-width;
    border-bottom-color: $tooltip-arrow-color;
  }
  &.bottom-left .tooltip-arrow {
    top: 0;
    right: $tooltip-arrow-width;
    margin-top: -$tooltip-arrow-width;
    border-width: 0 $tooltip-arrow-width $tooltip-arrow-width;
    border-bottom-color: $tooltip-arrow-color;
  }
  &.bottom-right .tooltip-arrow {
    top: 0;
    left: $tooltip-arrow-width;
    margin-top: -$tooltip-arrow-width;
    border-width: 0 $tooltip-arrow-width $tooltip-arrow-width;
    border-bottom-color: $tooltip-arrow-color;
  }
}


================================================
File: _sass/bootstrap/_type.scss
================================================
//
// Typography
// --------------------------------------------------


// Headings
// -------------------------

h1, h2, h3, h4, h5, h6,
.h1, .h2, .h3, .h4, .h5, .h6 {
  font-family: $headings-font-family;
  font-weight: $headings-font-weight;
  line-height: $headings-line-height;
  color: $headings-color;

  small,
  .small {
    font-weight: normal;
    line-height: 1;
    color: $headings-small-color;
  }
}

h1, .h1,
h2, .h2,
h3, .h3 {
  margin-top: $line-height-computed;
  margin-bottom: ($line-height-computed / 2);

  small,
  .small {
    font-size: 65%;
  }
}
h4, .h4,
h5, .h5,
h6, .h6 {
  margin-top: ($line-height-computed / 2);
  margin-bottom: ($line-height-computed / 2);

  small,
  .small {
    font-size: 75%;
  }
}

h1, .h1 { font-size: $font-size-h1; }
h2, .h2 { font-size: $font-size-h2; }
h3, .h3 { font-size: $font-size-h3; }
h4, .h4 { font-size: $font-size-h4; }
h5, .h5 { font-size: $font-size-h5; }
h6, .h6 { font-size: $font-size-h6; }


// Body text
// -------------------------

p {
  margin: 0 0 ($line-height-computed / 2);
}

.lead {
  margin-bottom: $line-height-computed;
  font-size: floor(($font-size-base * 1.15));
  font-weight: 300;
  line-height: 1.4;

  @media (min-width: $screen-sm-min) {
    font-size: ($font-size-base * 1.5);
  }
}


// Emphasis & misc
// -------------------------

// Ex: (12px small font / 14px base font) * 100% = about 85%
small,
.small {
  font-size: floor((100% * $font-size-small / $font-size-base));
}

mark,
.mark {
  background-color: $state-warning-bg;
  padding: .2em;
}

// Alignment
.text-left           { text-align: left; }
.text-right          { text-align: right; }
.text-center         { text-align: center; }
.text-justify        { text-align: justify; }
.text-nowrap         { white-space: nowrap; }

// Transformation
.text-lowercase      { text-transform: lowercase; }
.text-uppercase      { text-transform: uppercase; }
.text-capitalize     { text-transform: capitalize; }

// Contextual colors
.text-muted {
  color: $text-muted;
}

@include text-emphasis-variant('.text-primary', $brand-primary);

@include text-emphasis-variant('.text-success', $state-success-text);

@include text-emphasis-variant('.text-info', $state-info-text);

@include text-emphasis-variant('.text-warning', $state-warning-text);

@include text-emphasis-variant('.text-danger', $state-danger-text);

// Contextual backgrounds
// For now we'll leave these alongside the text classes until v4 when we can
// safely shift things around (per SemVer rules).
.bg-primary {
  // Given the contrast here, this is the only class to have its color inverted
  // automatically.
  color: #fff;
}
@include bg-variant('.bg-primary', $brand-primary);

@include bg-variant('.bg-success', $state-success-bg);

@include bg-variant('.bg-info', $state-info-bg);

@include bg-variant('.bg-warning', $state-warning-bg);

@include bg-variant('.bg-danger', $state-danger-bg);


// Page header
// -------------------------

.page-header {
  padding-bottom: (($line-height-computed / 2) - 1);
  margin: ($line-height-computed * 2) 0 $line-height-computed;
  border-bottom: 1px solid $page-header-border-color;
}


// Lists
// -------------------------

// Unordered and Ordered lists
ul,
ol {
  margin-top: 0;
  margin-bottom: ($line-height-computed / 2);
  ul,
  ol {
    margin-bottom: 0;
  }
}

// List options

// [converter] extracted from `.list-unstyled` for libsass compatibility
@mixin list-unstyled {
  padding-left: 0;
  list-style: none;
}
// [converter] extracted as `@mixin list-unstyled` for libsass compatibility
.list-unstyled {
  @include list-unstyled;
}


// Inline turns list items into inline-block
.list-inline {
  @include list-unstyled;
  margin-left: -5px;

  > li {
    display: inline-block;
    padding-left: 5px;
    padding-right: 5px;
  }
}

// Description Lists
dl {
  margin-top: 0; // Remove browser default
  margin-bottom: $line-height-computed;
}
dt,
dd {
  line-height: $line-height-base;
}
dt {
  font-weight: bold;
}
dd {
  margin-left: 0; // Undo browser default
}

// Horizontal description lists
//
// Defaults to being stacked without any of the below styles applied, until the
// grid breakpoint is reached (default of ~768px).

.dl-horizontal {
  dd {
    @include clearfix; // Clear the floated `dt` if an empty `dd` is present
  }

  @media (min-width: $dl-horizontal-breakpoint) {
    dt {
      float: left;
      width: ($dl-horizontal-offset - 20);
      clear: left;
      text-align: right;
      @include text-overflow;
    }
    dd {
      margin-left: $dl-horizontal-offset;
    }
  }
}


// Misc
// -------------------------

// Abbreviations and acronyms
abbr[title],
// Add data-* attribute to help out our tooltip plugin, per https://github.com/twbs/bootstrap/issues/5257
abbr[data-original-title] {
  cursor: help;
  border-bottom: 1px dotted $abbr-border-color;
}
.initialism {
  font-size: 90%;
  @extend .text-uppercase;
}

// Blockquotes
blockquote {
  padding: ($line-height-computed / 2) $line-height-computed;
  margin: 0 0 $line-height-computed;
  font-size: $blockquote-font-size;
  border-left: 5px solid $blockquote-border-color;

  p,
  ul,
  ol {
    &:last-child {
      margin-bottom: 0;
    }
  }

  // Note: Deprecated small and .small as of v3.1.0
  // Context: https://github.com/twbs/bootstrap/issues/11660
  footer,
  small,
  .small {
    display: block;
    font-size: 80%; // back to default font-size
    line-height: $line-height-base;
    color: $blockquote-small-color;

    &:before {
      content: '\2014 \00A0'; // em dash, nbsp
    }
  }
}

// Opposite alignment of blockquote
//
// Heads up: `blockquote.pull-right` has been deprecated as of v3.1.0.
.blockquote-reverse,
blockquote.pull-right {
  padding-right: 15px;
  padding-left: 0;
  border-right: 5px solid $blockquote-border-color;
  border-left: 0;
  text-align: right;

  // Account for citation
  footer,
  small,
  .small {
    &:before { content: ''; }
    &:after {
      content: '\00A0 \2014'; // nbsp, em dash
    }
  }
}

// Addresses
address {
  margin-bottom: $line-height-computed;
  font-style: normal;
  line-height: $line-height-base;
}


================================================
File: _sass/bootstrap/_utilities.scss
================================================
//
// Utility classes
// --------------------------------------------------


// Floats
// -------------------------

.clearfix {
  @include clearfix;
}
.center-block {
  @include center-block;
}
.pull-right {
  float: right !important;
}
.pull-left {
  float: left !important;
}


// Toggling content
// -------------------------

// Note: Deprecated .hide in favor of .hidden or .sr-only (as appropriate) in v3.0.1
.hide {
  display: none !important;
}
.show {
  display: block !important;
}
.invisible {
  visibility: hidden;
}
.text-hide {
  @include text-hide;
}


// Hide from screenreaders and browsers
//
// Credit: HTML5 Boilerplate

.hidden {
  display: none !important;
}


// For Affix plugin
// -------------------------

.affix {
  position: fixed;
}


================================================
File: _sass/bootstrap/_variables.scss
================================================
$bootstrap-sass-asset-helper: false !default;
//
// Variables
// --------------------------------------------------


//== Colors
//
//## Gray and brand colors for use across Bootstrap.

$gray-base:              #000 !default;
$gray-darker:            lighten($gray-base, 13.5%) !default; // #222
$gray-dark:              lighten($gray-base, 20%) !default;   // #333
$gray:                   lighten($gray-base, 33.5%) !default; // #555
$gray-light:             lighten($gray-base, 46.7%) !default; // #777
$gray-lighter:           lighten($gray-base, 93.5%) !default; // #eee

$brand-primary:         darken(#428bca, 6.5%) !default; // #337ab7
$brand-success:         #5cb85c !default;
$brand-info:            #5bc0de !default;
$brand-warning:         #f0ad4e !default;
$brand-danger:          #d9534f !default;


//== Scaffolding
//
//## Settings for some of the most global styles.

//** Background color for `<body>`.
$body-bg:               #fff !default;
//** Global text color on `<body>`.
$text-color:            $gray-dark !default;

//** Global textual link color.
$link-color:            $brand-primary !default;
//** Link hover color set via `darken()` function.
$link-hover-color:      darken($link-color, 15%) !default;
//** Link hover decoration.
$link-hover-decoration: underline !default;


//== Typography
//
//## Font, line-height, and color for body text, headings, and more.

$font-family-sans-serif:  "Helvetica Neue", Helvetica, Arial, sans-serif !default;
$font-family-serif:       Georgia, "Times New Roman", Times, serif !default;
//** Default monospace fonts for `<code>`, `<kbd>`, and `<pre>`.
$font-family-monospace:   Menlo, Monaco, Consolas, "Courier New", monospace !default;
$font-family-base:        $font-family-sans-serif !default;

$font-size-base:          14px !default;
$font-size-large:         ceil(($font-size-base * 1.25)) !default; // ~18px
$font-size-small:         ceil(($font-size-base * 0.85)) !default; // ~12px

$font-size-h1:            floor(($font-size-base * 2.6)) !default; // ~36px
$font-size-h2:            floor(($font-size-base * 2.15)) !default; // ~30px
$font-size-h3:            ceil(($font-size-base * 1.7)) !default; // ~24px
$font-size-h4:            ceil(($font-size-base * 1.25)) !default; // ~18px
$font-size-h5:            $font-size-base !default;
$font-size-h6:            ceil(($font-size-base * 0.85)) !default; // ~12px

//** Unit-less `line-height` for use in components like buttons.
$line-height-base:        1.428571429 !default; // 20/14
//** Computed "line-height" (`font-size` * `line-height`) for use with `margin`, `padding`, etc.
$line-height-computed:    floor(($font-size-base * $line-height-base)) !default; // ~20px

//** By default, this inherits from the `<body>`.
$headings-font-family:    inherit !default;
$headings-font-weight:    500 !default;
$headings-line-height:    1.1 !default;
$headings-color:          inherit !default;


//== Iconography
//
//## Specify custom location and filename of the included Glyphicons icon font. Useful for those including Bootstrap via Bower.

//** Load fonts from this directory.

// [converter] If $bootstrap-sass-asset-helper if used, provide path relative to the assets load path.
// [converter] This is because some asset helpers, such as Sprockets, do not work with file-relative paths.
$icon-font-path: if($bootstrap-sass-asset-helper, "bootstrap/", "../fonts/bootstrap/") !default;

//** File name for all font files.
$icon-font-name:          "glyphicons-halflings-regular" !default;
//** Element ID within SVG icon file.
$icon-font-svg-id:        "glyphicons_halflingsregular" !default;


//== Components
//
//## Define common padding and border radius sizes and more. Values based on 14px text and 1.428 line-height (~20px to start).

$padding-base-vertical:     6px !default;
$padding-base-horizontal:   12px !default;

$padding-large-vertical:    10px !default;
$padding-large-horizontal:  16px !default;

$padding-small-vertical:    5px !default;
$padding-small-horizontal:  10px !default;

$padding-xs-vertical:       1px !default;
$padding-xs-horizontal:     5px !default;

$line-height-large:         1.3333333 !default; // extra decimals for Win 8.1 Chrome
$line-height-small:         1.5 !default;

$border-radius-base:        4px !default;
$border-radius-large:       6px !default;
$border-radius-small:       3px !default;

//** Global color for active items (e.g., navs or dropdowns).
$component-active-color:    #fff !default;
//** Global background color for active items (e.g., navs or dropdowns).
$component-active-bg:       $brand-primary !default;

//** Width of the `border` for generating carets that indicator dropdowns.
$caret-width-base:          4px !default;
//** Carets increase slightly in size for larger components.
$caret-width-large:         5px !default;


//== Tables
//
//## Customizes the `.table` component with basic values, each used across all table variations.

//** Padding for `<th>`s and `<td>`s.
$table-cell-padding:            8px !default;
//** Padding for cells in `.table-condensed`.
$table-condensed-cell-padding:  5px !default;

//** Default background color used for all tables.
$table-bg:                      transparent !default;
//** Background color used for `.table-striped`.
$table-bg-accent:               #f9f9f9 !default;
//** Background color used for `.table-hover`.
$table-bg-hover:                #f5f5f5 !default;
$table-bg-active:               $table-bg-hover !default;

//** Border color for table and cell borders.
$table-border-color:            #ddd !default;


//== Buttons
//
//## For each of Bootstrap's buttons, define text, background and border color.

$btn-font-weight:                normal !default;

$btn-default-color:              #333 !default;
$btn-default-bg:                 #fff !default;
$btn-default-border:             #ccc !default;

$btn-primary-color:              #fff !default;
$btn-primary-bg:                 $brand-primary !default;
$btn-primary-border:             darken($btn-primary-bg, 5%) !default;

$btn-success-color:              #fff !default;
$btn-success-bg:                 $brand-success !default;
$btn-success-border:             darken($btn-success-bg, 5%) !default;

$btn-info-color:                 #fff !default;
$btn-info-bg:                    $brand-info !default;
$btn-info-border:                darken($btn-info-bg, 5%) !default;

$btn-warning-color:              #fff !default;
$btn-warning-bg:                 $brand-warning !default;
$btn-warning-border:             darken($btn-warning-bg, 5%) !default;

$btn-danger-color:               #fff !default;
$btn-danger-bg:                  $brand-danger !default;
$btn-danger-border:              darken($btn-danger-bg, 5%) !default;

$btn-link-disabled-color:        $gray-light !default;

// Allows for customizing button radius independently from global border radius
$btn-border-radius-base:         $border-radius-base !default;
$btn-border-radius-large:        $border-radius-large !default;
$btn-border-radius-small:        $border-radius-small !default;


//== Forms
//
//##

//** `<input>` background color
$input-bg:                       #fff !default;
//** `<input disabled>` background color
$input-bg-disabled:              $gray-lighter !default;

//** Text color for `<input>`s
$input-color:                    $gray !default;
//** `<input>` border color
$input-border:                   #ccc !default;

// TODO: Rename `$input-border-radius` to `$input-border-radius-base` in v4
//** Default `.form-control` border radius
// This has no effect on `<select>`s in some browsers, due to the limited stylability of `<select>`s in CSS.
$input-border-radius:            $border-radius-base !default;
//** Large `.form-control` border radius
$input-border-radius-large:      $border-radius-large !default;
//** Small `.form-control` border radius
$input-border-radius-small:      $border-radius-small !default;

//** Border color for inputs on focus
$input-border-focus:             #66afe9 !default;

//** Placeholder text color
$input-color-placeholder:        #999 !default;

//** Default `.form-control` height
$input-height-base:              ($line-height-computed + ($padding-base-vertical * 2) + 2) !default;
//** Large `.form-control` height
$input-height-large:             (ceil($font-size-large * $line-height-large) + ($padding-large-vertical * 2) + 2) !default;
//** Small `.form-control` height
$input-height-small:             (floor($font-size-small * $line-height-small) + ($padding-small-vertical * 2) + 2) !default;

//** `.form-group` margin
$form-group-margin-bottom:       15px !default;

$legend-color:                   $gray-dark !default;
$legend-border-color:            #e5e5e5 !default;

//** Background color for textual input addons
$input-group-addon-bg:           $gray-lighter !default;
//** Border color for textual input addons
$input-group-addon-border-color: $input-border !default;

//** Disabled cursor for form controls and buttons.
$cursor-disabled:                not-allowed !default;


//== Dropdowns
//
//## Dropdown menu container and contents.

//** Background for the dropdown menu.
$dropdown-bg:                    #fff !default;
//** Dropdown menu `border-color`.
$dropdown-border:                rgba(0,0,0,.15) !default;
//** Dropdown menu `border-color` **for IE8**.
$dropdown-fallback-border:       #ccc !default;
//** Divider color for between dropdown items.
$dropdown-divider-bg:            #e5e5e5 !default;

//** Dropdown link text color.
$dropdown-link-color:            $gray-dark !default;
//** Hover color for dropdown links.
$dropdown-link-hover-color:      darken($gray-dark, 5%) !default;
//** Hover background for dropdown links.
$dropdown-link-hover-bg:         #f5f5f5 !default;

//** Active dropdown menu item text color.
$dropdown-link-active-color:     $component-active-color !default;
//** Active dropdown menu item background color.
$dropdown-link-active-bg:        $component-active-bg !default;

//** Disabled dropdown menu item background color.
$dropdown-link-disabled-color:   $gray-light !default;

//** Text color for headers within dropdown menus.
$dropdown-header-color:          $gray-light !default;

//** Deprecated `$dropdown-caret-color` as of v3.1.0
$dropdown-caret-color:           #000 !default;


//-- Z-index master list
//
// Warning: Avoid customizing these values. They're used for a bird's eye view
// of components dependent on the z-axis and are designed to all work together.
//
// Note: These variables are not generated into the Customizer.

$zindex-navbar:            1000 !default;
$zindex-dropdown:          1000 !default;
$zindex-popover:           1060 !default;
$zindex-tooltip:           1070 !default;
$zindex-navbar-fixed:      1030 !default;
$zindex-modal-background:  1040 !default;
$zindex-modal:             1050 !default;


//== Media queries breakpoints
//
//## Define the breakpoints at which your layout will change, adapting to different screen sizes.

// Extra small screen / phone
//** Deprecated `$screen-xs` as of v3.0.1
$screen-xs:                  480px !default;
//** Deprecated `$screen-xs-min` as of v3.2.0
$screen-xs-min:              $screen-xs !default;
//** Deprecated `$screen-phone` as of v3.0.1
$screen-phone:               $screen-xs-min !default;

// Small screen / tablet
//** Deprecated `$screen-sm` as of v3.0.1
$screen-sm:                  768px !default;
$screen-sm-min:              $screen-sm !default;
//** Deprecated `$screen-tablet` as of v3.0.1
$screen-tablet:              $screen-sm-min !default;

// Medium screen / desktop
//** Deprecated `$screen-md` as of v3.0.1
$screen-md:                  992px !default;
$screen-md-min:              $screen-md !default;
//** Deprecated `$screen-desktop` as of v3.0.1
$screen-desktop:             $screen-md-min !default;

// Large screen / wide desktop
//** Deprecated `$screen-lg` as of v3.0.1
$screen-lg:                  1200px !default;
$screen-lg-min:              $screen-lg !default;
//** Deprecated `$screen-lg-desktop` as of v3.0.1
$screen-lg-desktop:          $screen-lg-min !default;

// So media queries don't overlap when required, provide a maximum
$screen-xs-max:              ($screen-sm-min - 1) !default;
$screen-sm-max:              ($screen-md-min - 1) !default;
$screen-md-max:              ($screen-lg-min - 1) !default;


//== Grid system
//
//## Define your custom responsive grid.

//** Number of columns in the grid.
$grid-columns:              12 !default;
//** Padding between columns. Gets divided in half for the left and right.
$grid-gutter-width:         30px !default;
// Navbar collapse
//** Point at which the navbar becomes uncollapsed.
$grid-float-breakpoint:     $screen-sm-min !default;
//** Point at which the navbar begins collapsing.
$grid-float-breakpoint-max: ($grid-float-breakpoint - 1) !default;


//== Container sizes
//
//## Define the maximum width of `.container` for different screen sizes.

// Small screen / tablet
$container-tablet:             (720px + $grid-gutter-width) !default;
//** For `$screen-sm-min` and up.
$container-sm:                 $container-tablet !default;

// Medium screen / desktop
$container-desktop:            (940px + $grid-gutter-width) !default;
//** For `$screen-md-min` and up.
$container-md:                 $container-desktop !default;

// Large screen / wide desktop
$container-large-desktop:      (1140px + $grid-gutter-width) !default;
//** For `$screen-lg-min` and up.
$container-lg:                 $container-large-desktop !default;


//== Navbar
//
//##

// Basics of a navbar
$navbar-height:                    50px !default;
$navbar-margin-bottom:             $line-height-computed !default;
$navbar-border-radius:             $border-radius-base !default;
$navbar-padding-horizontal:        floor(($grid-gutter-width / 2)) !default;
$navbar-padding-vertical:          (($navbar-height - $line-height-computed) / 2) !default;
$navbar-collapse-max-height:       340px !default;

$navbar-default-color:             #777 !default;
$navbar-default-bg:                #f8f8f8 !default;
$navbar-default-border:            darken($navbar-default-bg, 6.5%) !default;

// Navbar links
$navbar-default-link-color:                #777 !default;
$navbar-default-link-hover-color:          #333 !default;
$navbar-default-link-hover-bg:             transparent !default;
$navbar-default-link-active-color:         #555 !default;
$navbar-default-link-active-bg:            darken($navbar-default-bg, 6.5%) !default;
$navbar-default-link-disabled-color:       #ccc !default;
$navbar-default-link-disabled-bg:          transparent !default;

// Navbar brand label
$navbar-default-brand-color:               $navbar-default-link-color !default;
$navbar-default-brand-hover-color:         darken($navbar-default-brand-color, 10%) !default;
$navbar-default-brand-hover-bg:            transparent !default;

// Navbar toggle
$navbar-default-toggle-hover-bg:           #ddd !default;
$navbar-default-toggle-icon-bar-bg:        #888 !default;
$navbar-default-toggle-border-color:       #ddd !default;


//=== Inverted navbar
// Reset inverted navbar basics
$navbar-inverse-color:                      lighten($gray-light, 15%) !default;
$navbar-inverse-bg:                         #222 !default;
$navbar-inverse-border:                     darken($navbar-inverse-bg, 10%) !default;

// Inverted navbar links
$navbar-inverse-link-color:                 lighten($gray-light, 15%) !default;
$navbar-inverse-link-hover-color:           #fff !default;
$navbar-inverse-link-hover-bg:              transparent !default;
$navbar-inverse-link-active-color:          $navbar-inverse-link-hover-color !default;
$navbar-inverse-link-active-bg:             darken($navbar-inverse-bg, 10%) !default;
$navbar-inverse-link-disabled-color:        #444 !default;
$navbar-inverse-link-disabled-bg:           transparent !default;

// Inverted navbar brand label
$navbar-inverse-brand-color:                $navbar-inverse-link-color !default;
$navbar-inverse-brand-hover-color:          #fff !default;
$navbar-inverse-brand-hover-bg:             transparent !default;

// Inverted navbar toggle
$navbar-inverse-toggle-hover-bg:            #333 !default;
$navbar-inverse-toggle-icon-bar-bg:         #fff !default;
$navbar-inverse-toggle-border-color:        #333 !default;


//== Navs
//
//##

//=== Shared nav styles
$nav-link-padding:                          10px 15px !default;
$nav-link-hover-bg:                         $gray-lighter !default;

$nav-disabled-link-color:                   $gray-light !default;
$nav-disabled-link-hover-color:             $gray-light !default;

//== Tabs
$nav-tabs-border-color:                     #ddd !default;

$nav-tabs-link-hover-border-color:          $gray-lighter !default;

$nav-tabs-active-link-hover-bg:             $body-bg !default;
$nav-tabs-active-link-hover-color:          $gray !default;
$nav-tabs-active-link-hover-border-color:   #ddd !default;

$nav-tabs-justified-link-border-color:            #ddd !default;
$nav-tabs-justified-active-link-border-color:     $body-bg !default;

//== Pills
$nav-pills-border-radius:                   $border-radius-base !default;
$nav-pills-active-link-hover-bg:            $component-active-bg !default;
$nav-pills-active-link-hover-color:         $component-active-color !default;


//== Pagination
//
//##

$pagination-color:                     $link-color !default;
$pagination-bg:                        #fff !default;
$pagination-border:                    #ddd !default;

$pagination-hover-color:               $link-hover-color !default;
$pagination-hover-bg:                  $gray-lighter !default;
$pagination-hover-border:              #ddd !default;

$pagination-active-color:              #fff !default;
$pagination-active-bg:                 $brand-primary !default;
$pagination-active-border:             $brand-primary !default;

$pagination-disabled-color:            $gray-light !default;
$pagination-disabled-bg:               #fff !default;
$pagination-disabled-border:           #ddd !default;


//== Pager
//
//##

$pager-bg:                             $pagination-bg !default;
$pager-border:                         $pagination-border !default;
$pager-border-radius:                  15px !default;

$pager-hover-bg:                       $pagination-hover-bg !default;

$pager-active-bg:                      $pagination-active-bg !default;
$pager-active-color:                   $pagination-active-color !default;

$pager-disabled-color:                 $pagination-disabled-color !default;


//== Jumbotron
//
//##

$jumbotron-padding:              30px !default;
$jumbotron-color:                inherit !default;
$jumbotron-bg:                   $gray-lighter !default;
$jumbotron-heading-color:        inherit !default;
$jumbotron-font-size:            ceil(($font-size-base * 1.5)) !default;
$jumbotron-heading-font-size:    ceil(($font-size-base * 4.5)) !default;


//== Form states and alerts
//
//## Define colors for form feedback states and, by default, alerts.

$state-success-text:             #3c763d !default;
$state-success-bg:               #dff0d8 !default;
$state-success-border:           darken(adjust-hue($state-success-bg, -10), 5%) !default;

$state-info-text:                #31708f !default;
$state-info-bg:                  #d9edf7 !default;
$state-info-border:              darken(adjust-hue($state-info-bg, -10), 7%) !default;

$state-warning-text:             #8a6d3b !default;
$state-warning-bg:               #fcf8e3 !default;
$state-warning-border:           darken(adjust-hue($state-warning-bg, -10), 5%) !default;

$state-danger-text:              #a94442 !default;
$state-danger-bg:                #f2dede !default;
$state-danger-border:            darken(adjust-hue($state-danger-bg, -10), 5%) !default;


//== Tooltips
//
//##

//** Tooltip max width
$tooltip-max-width:           200px !default;
//** Tooltip text color
$tooltip-color:               #fff !default;
//** Tooltip background color
$tooltip-bg:                  #000 !default;
$tooltip-opacity:             .9 !default;

//** Tooltip arrow width
$tooltip-arrow-width:         5px !default;
//** Tooltip arrow color
$tooltip-arrow-color:         $tooltip-bg !default;


//== Popovers
//
//##

//** Popover body background color
$popover-bg:                          #fff !default;
//** Popover maximum width
$popover-max-width:                   276px !default;
//** Popover border color
$popover-border-color:                rgba(0,0,0,.2) !default;
//** Popover fallback border color
$popover-fallback-border-color:       #ccc !default;

//** Popover title background color
$popover-title-bg:                    darken($popover-bg, 3%) !default;

//** Popover arrow width
$popover-arrow-width:                 10px !default;
//** Popover arrow color
$popover-arrow-color:                 $popover-bg !default;

//** Popover outer arrow width
$popover-arrow-outer-width:           ($popover-arrow-width + 1) !default;
//** Popover outer arrow color
$popover-arrow-outer-color:           fade_in($popover-border-color, 0.05) !default;
//** Popover outer arrow fallback color
$popover-arrow-outer-fallback-color:  darken($popover-fallback-border-color, 20%) !default;


//== Labels
//
//##

//** Default label background color
$label-default-bg:            $gray-light !default;
//** Primary label background color
$label-primary-bg:            $brand-primary !default;
//** Success label background color
$label-success-bg:            $brand-success !default;
//** Info label background color
$label-info-bg:               $brand-info !default;
//** Warning label background color
$label-warning-bg:            $brand-warning !default;
//** Danger label background color
$label-danger-bg:             $brand-danger !default;

//** Default label text color
$label-color:                 #fff !default;
//** Default text color of a linked label
$label-link-hover-color:      #fff !default;


//== Modals
//
//##

//** Padding applied to the modal body
$modal-inner-padding:         15px !default;

//** Padding applied to the modal title
$modal-title-padding:         15px !default;
//** Modal title line-height
$modal-title-line-height:     $line-height-base !default;

//** Background color of modal content area
$modal-content-bg:                             #fff !default;
//** Modal content border color
$modal-content-border-color:                   rgba(0,0,0,.2) !default;
//** Modal content border color **for IE8**
$modal-content-fallback-border-color:          #999 !default;

//** Modal backdrop background color
$modal-backdrop-bg:           #000 !default;
//** Modal backdrop opacity
$modal-backdrop-opacity:      .5 !default;
//** Modal header border color
$modal-header-border-color:   #e5e5e5 !default;
//** Modal footer border color
$modal-footer-border-color:   $modal-header-border-color !default;

$modal-lg:                    900px !default;
$modal-md:                    600px !default;
$modal-sm:                    300px !default;


//== Alerts
//
//## Define alert colors, border radius, and padding.

$alert-padding:               15px !default;
$alert-border-radius:         $border-radius-base !default;
$alert-link-font-weight:      bold !default;

$alert-success-bg:            $state-success-bg !default;
$alert-success-text:          $state-success-text !default;
$alert-success-border:        $state-success-border !default;

$alert-info-bg:               $state-info-bg !default;
$alert-info-text:             $state-info-text !default;
$alert-info-border:           $state-info-border !default;

$alert-warning-bg:            $state-warning-bg !default;
$alert-warning-text:          $state-warning-text !default;
$alert-warning-border:        $state-warning-border !default;

$alert-danger-bg:             $state-danger-bg !default;
$alert-danger-text:           $state-danger-text !default;
$alert-danger-border:         $state-danger-border !default;


//== Progress bars
//
//##

//** Background color of the whole progress component
$progress-bg:                 #f5f5f5 !default;
//** Progress bar text color
$progress-bar-color:          #fff !default;
//** Variable for setting rounded corners on progress bar.
$progress-border-radius:      $border-radius-base !default;

//** Default progress bar color
$progress-bar-bg:             $brand-primary !default;
//** Success progress bar color
$progress-bar-success-bg:     $brand-success !default;
//** Warning progress bar color
$progress-bar-warning-bg:     $brand-warning !default;
//** Danger progress bar color
$progress-bar-danger-bg:      $brand-danger !default;
//** Info progress bar color
$progress-bar-info-bg:        $brand-info !default;


//== List group
//
//##

//** Background color on `.list-group-item`
$list-group-bg:                 #fff !default;
//** `.list-group-item` border color
$list-group-border:             #ddd !default;
//** List group border radius
$list-group-border-radius:      $border-radius-base !default;

//** Background color of single list items on hover
$list-group-hover-bg:           #f5f5f5 !default;
//** Text color of active list items
$list-group-active-color:       $component-active-color !default;
//** Background color of active list items
$list-group-active-bg:          $component-active-bg !default;
//** Border color of active list elements
$list-group-active-border:      $list-group-active-bg !default;
//** Text color for content within active list items
$list-group-active-text-color:  lighten($list-group-active-bg, 40%) !default;

//** Text color of disabled list items
$list-group-disabled-color:      $gray-light !default;
//** Background color of disabled list items
$list-group-disabled-bg:         $gray-lighter !default;
//** Text color for content within disabled list items
$list-group-disabled-text-color: $list-group-disabled-color !default;

$list-group-link-color:         #555 !default;
$list-group-link-hover-color:   $list-group-link-color !default;
$list-group-link-heading-color: #333 !default;


//== Panels
//
//##

$panel-bg:                    #fff !default;
$panel-body-padding:          15px !default;
$panel-heading-padding:       10px 15px !default;
$panel-footer-padding:        $panel-heading-padding !default;
$panel-border-radius:         $border-radius-base !default;

//** Border color for elements within panels
$panel-inner-border:          #ddd !default;
$panel-footer-bg:             #f5f5f5 !default;

$panel-default-text:          $gray-dark !default;
$panel-default-border:        #ddd !default;
$panel-default-heading-bg:    #f5f5f5 !default;

$panel-primary-text:          #fff !default;
$panel-primary-border:        $brand-primary !default;
$panel-primary-heading-bg:    $brand-primary !default;

$panel-success-text:          $state-success-text !default;
$panel-success-border:        $state-success-border !default;
$panel-success-heading-bg:    $state-success-bg !default;

$panel-info-text:             $state-info-text !default;
$panel-info-border:           $state-info-border !default;
$panel-info-heading-bg:       $state-info-bg !default;

$panel-warning-text:          $state-warning-text !default;
$panel-warning-border:        $state-warning-border !default;
$panel-warning-heading-bg:    $state-warning-bg !default;

$panel-danger-text:           $state-danger-text !default;
$panel-danger-border:         $state-danger-border !default;
$panel-danger-heading-bg:     $state-danger-bg !default;


//== Thumbnails
//
//##

//** Padding around the thumbnail image
$thumbnail-padding:           4px !default;
//** Thumbnail background color
$thumbnail-bg:                $body-bg !default;
//** Thumbnail border color
$thumbnail-border:            #ddd !default;
//** Thumbnail border radius
$thumbnail-border-radius:     $border-radius-base !default;

//** Custom text color for thumbnail captions
$thumbnail-caption-color:     $text-color !default;
//** Padding around the thumbnail caption
$thumbnail-caption-padding:   9px !default;


//== Wells
//
//##

$well-bg:                     #f5f5f5 !default;
$well-border:                 darken($well-bg, 7%) !default;


//== Badges
//
//##

$badge-color:                 #fff !default;
//** Linked badge text color on hover
$badge-link-hover-color:      #fff !default;
$badge-bg:                    $gray-light !default;

//** Badge text color in active nav link
$badge-active-color:          $link-color !default;
//** Badge background color in active nav link
$badge-active-bg:             #fff !default;

$badge-font-weight:           bold !default;
$badge-line-height:           1 !default;
$badge-border-radius:         10px !default;


//== Breadcrumbs
//
//##

$breadcrumb-padding-vertical:   8px !default;
$breadcrumb-padding-horizontal: 15px !default;
//** Breadcrumb background color
$breadcrumb-bg:                 #f5f5f5 !default;
//** Breadcrumb text color
$breadcrumb-color:              #ccc !default;
//** Text color of current page in the breadcrumb
$breadcrumb-active-color:       $gray-light !default;
//** Textual separator for between breadcrumb elements
$breadcrumb-separator:          "/" !default;


//== Carousel
//
//##

$carousel-text-shadow:                        0 1px 2px rgba(0,0,0,.6) !default;

$carousel-control-color:                      #fff !default;
$carousel-control-width:                      15% !default;
$carousel-control-opacity:                    .5 !default;
$carousel-control-font-size:                  20px !default;

$carousel-indicator-active-bg:                #fff !default;
$carousel-indicator-border-color:             #fff !default;

$carousel-caption-color:                      #fff !default;


//== Close
//
//##

$close-font-weight:           bold !default;
$close-color:                 #000 !default;
$close-text-shadow:           0 1px 0 #fff !default;


//== Code
//
//##

$code-color:                  #c7254e !default;
$code-bg:                     #f9f2f4 !default;

$kbd-color:                   #fff !default;
$kbd-bg:                      #333 !default;

$pre-bg:                      #f5f5f5 !default;
$pre-color:                   $gray-dark !default;
$pre-border-color:            #ccc !default;
$pre-scrollable-max-height:   340px !default;


//== Type
//
//##

//** Horizontal offset for forms and lists.
$component-offset-horizontal: 180px !default;
//** Text muted color
$text-muted:                  $gray-light !default;
//** Abbreviations and acronyms border color
$abbr-border-color:           $gray-light !default;
//** Headings small color
$headings-small-color:        $gray-light !default;
//** Blockquote small color
$blockquote-small-color:      $gray-light !default;
//** Blockquote font size
$blockquote-font-size:        ($font-size-base * 1.25) !default;
//** Blockquote border color
$blockquote-border-color:     $gray-lighter !default;
//** Page header border color
$page-header-border-color:    $gray-lighter !default;
//** Width of horizontal description list titles
$dl-horizontal-offset:        $component-offset-horizontal !default;
//** Point at which .dl-horizontal becomes horizontal
$dl-horizontal-breakpoint:    $grid-float-breakpoint !default;
//** Horizontal line color.
$hr-border:                   $gray-lighter !default;


================================================
File: _sass/bootstrap/_wells.scss
================================================
//
// Wells
// --------------------------------------------------


// Base class
.well {
  min-height: 20px;
  padding: 19px;
  margin-bottom: 20px;
  background-color: $well-bg;
  border: 1px solid $well-border;
  border-radius: $border-radius-base;
  @include box-shadow(inset 0 1px 1px rgba(0,0,0,.05));
  blockquote {
    border-color: #ddd;
    border-color: rgba(0,0,0,.15);
  }
}

// Sizes
.well-lg {
  padding: 24px;
  border-radius: $border-radius-large;
}
.well-sm {
  padding: 9px;
  border-radius: $border-radius-small;
}


================================================
File: _sass/bootstrap/mixins/_alerts.scss
================================================
// Alerts

@mixin alert-variant($background, $border, $text-color) {
  background-color: $background;
  border-color: $border;
  color: $text-color;

  hr {
    border-top-color: darken($border, 5%);
  }
  .alert-link {
    color: darken($text-color, 10%);
  }
}


================================================
File: _sass/bootstrap/mixins/_background-variant.scss
================================================
// Contextual backgrounds

// [converter] $parent hack
@mixin bg-variant($parent, $color) {
  #{$parent} {
    background-color: $color;
  }
  a#{$parent}:hover,
  a#{$parent}:focus {
    background-color: darken($color, 10%);
  }
}


================================================
File: _sass/bootstrap/mixins/_border-radius.scss
================================================
// Single side border-radius

@mixin border-top-radius($radius) {
  border-top-right-radius: $radius;
   border-top-left-radius: $radius;
}
@mixin border-right-radius($radius) {
  border-bottom-right-radius: $radius;
     border-top-right-radius: $radius;
}
@mixin border-bottom-radius($radius) {
  border-bottom-right-radius: $radius;
   border-bottom-left-radius: $radius;
}
@mixin border-left-radius($radius) {
  border-bottom-left-radius: $radius;
     border-top-left-radius: $radius;
}


================================================
File: _sass/bootstrap/mixins/_buttons.scss
================================================
// Button variants
//
// Easily pump out default styles, as well as :hover, :focus, :active,
// and disabled options for all buttons

@mixin button-variant($color, $background, $border) {
  color: $color;
  background-color: $background;
  border-color: $border;

  &:focus,
  &.focus {
    color: $color;
    background-color: darken($background, 10%);
        border-color: darken($border, 25%);
  }
  &:hover {
    color: $color;
    background-color: darken($background, 10%);
        border-color: darken($border, 12%);
  }
  &:active,
  &.active,
  .open > &.dropdown-toggle {
    color: $color;
    background-color: darken($background, 10%);
        border-color: darken($border, 12%);

    &:hover,
    &:focus,
    &.focus {
      color: $color;
      background-color: darken($background, 17%);
          border-color: darken($border, 25%);
    }
  }
  &:active,
  &.active,
  .open > &.dropdown-toggle {
    background-image: none;
  }
  &.disabled,
  &[disabled],
  fieldset[disabled] & {
    &:hover,
    &:focus,
    &.focus {
      background-color: $background;
          border-color: $border;
    }
  }

  .badge {
    color: $background;
    background-color: $color;
  }
}

// Button sizes
@mixin button-size($padding-vertical, $padding-horizontal, $font-size, $line-height, $border-radius) {
  padding: $padding-vertical $padding-horizontal;
  font-size: $font-size;
  line-height: $line-height;
  border-radius: $border-radius;
}


================================================
File: _sass/bootstrap/mixins/_center-block.scss
================================================
// Center-align a block level element

@mixin center-block() {
  display: block;
  margin-left: auto;
  margin-right: auto;
}


================================================
File: _sass/bootstrap/mixins/_clearfix.scss
================================================
// Clearfix
//
// For modern browsers
// 1. The space content is one way to avoid an Opera bug when the
//    contenteditable attribute is included anywhere else in the document.
//    Otherwise it causes space to appear at the top and bottom of elements
//    that are clearfixed.
// 2. The use of `table` rather than `block` is only necessary if using
//    `:before` to contain the top-margins of child elements.
//
// Source: http://nicolasgallagher.com/micro-clearfix-hack/

@mixin clearfix() {
  &:before,
  &:after {
    content: " "; // 1
    display: table; // 2
  }
  &:after {
    clear: both;
  }
}


================================================
File: _sass/bootstrap/mixins/_forms.scss
================================================
// Form validation states
//
// Used in forms.less to generate the form validation CSS for warnings, errors,
// and successes.

@mixin form-control-validation($text-color: #555, $border-color: #ccc, $background-color: #f5f5f5) {
  // Color the label and help text
  .help-block,
  .control-label,
  .radio,
  .checkbox,
  .radio-inline,
  .checkbox-inline,
  &.radio label,
  &.checkbox label,
  &.radio-inline label,
  &.checkbox-inline label  {
    color: $text-color;
  }
  // Set the border and box shadow on specific inputs to match
  .form-control {
    border-color: $border-color;
    @include box-shadow(inset 0 1px 1px rgba(0,0,0,.075)); // Redeclare so transitions work
    &:focus {
      border-color: darken($border-color, 10%);
      $shadow: inset 0 1px 1px rgba(0,0,0,.075), 0 0 6px lighten($border-color, 20%);
      @include box-shadow($shadow);
    }
  }
  // Set validation states also for addons
  .input-group-addon {
    color: $text-color;
    border-color: $border-color;
    background-color: $background-color;
  }
  // Optional feedback icon
  .form-control-feedback {
    color: $text-color;
  }
}


// Form control focus state
//
// Generate a customized focus state and for any input with the specified color,
// which defaults to the `$input-border-focus` variable.
//
// We highly encourage you to not customize the default value, but instead use
// this to tweak colors on an as-needed basis. This aesthetic change is based on
// WebKit's default styles, but applicable to a wider range of browsers. Its
// usability and accessibility should be taken into account with any change.
//
// Example usage: change the default blue border and shadow to white for better
// contrast against a dark gray background.
@mixin form-control-focus($color: $input-border-focus) {
  $color-rgba: rgba(red($color), green($color), blue($color), .6);
  &:focus {
    border-color: $color;
    outline: 0;
    @include box-shadow(inset 0 1px 1px rgba(0,0,0,.075), 0 0 8px $color-rgba);
  }
}

// Form control sizing
//
// Relative text size, padding, and border-radii changes for form controls. For
// horizontal sizing, wrap controls in the predefined grid classes. `<select>`
// element gets special love because it's special, and that's a fact!
// [converter] $parent hack
@mixin input-size($parent, $input-height, $padding-vertical, $padding-horizontal, $font-size, $line-height, $border-radius) {
  #{$parent} {
    height: $input-height;
    padding: $padding-vertical $padding-horizontal;
    font-size: $font-size;
    line-height: $line-height;
    border-radius: $border-radius;
  }

  select#{$parent} {
    height: $input-height;
    line-height: $input-height;
  }

  textarea#{$parent},
  select[multiple]#{$parent} {
    height: auto;
  }
}


================================================
File: _sass/bootstrap/mixins/_gradients.scss
================================================
// Gradients



// Horizontal gradient, from left to right
//
// Creates two color stops, start and end, by specifying a color and position for each color stop.
// Color stops are not available in IE9 and below.
@mixin gradient-horizontal($start-color: #555, $end-color: #333, $start-percent: 0%, $end-percent: 100%) {
  background-image: -webkit-linear-gradient(left, $start-color $start-percent, $end-color $end-percent); // Safari 5.1-6, Chrome 10+
  background-image: -o-linear-gradient(left, $start-color $start-percent, $end-color $end-percent); // Opera 12
  background-image: linear-gradient(to right, $start-color $start-percent, $end-color $end-percent); // Standard, IE10, Firefox 16+, Opera 12.10+, Safari 7+, Chrome 26+
  background-repeat: repeat-x;
  filter: progid:DXImageTransform.Microsoft.gradient(startColorstr='#{ie-hex-str($start-color)}', endColorstr='#{ie-hex-str($end-color)}', GradientType=1); // IE9 and down
}

// Vertical gradient, from top to bottom
//
// Creates two color stops, start and end, by specifying a color and position for each color stop.
// Color stops are not available in IE9 and below.
@mixin gradient-vertical($start-color: #555, $end-color: #333, $start-percent: 0%, $end-percent: 100%) {
  background-image: -webkit-linear-gradient(top, $start-color $start-percent, $end-color $end-percent);  // Safari 5.1-6, Chrome 10+
  background-image: -o-linear-gradient(top, $start-color $start-percent, $end-color $end-percent);  // Opera 12
  background-image: linear-gradient(to bottom, $start-color $start-percent, $end-color $end-percent); // Standard, IE10, Firefox 16+, Opera 12.10+, Safari 7+, Chrome 26+
  background-repeat: repeat-x;
  filter: progid:DXImageTransform.Microsoft.gradient(startColorstr='#{ie-hex-str($start-color)}', endColorstr='#{ie-hex-str($end-color)}', GradientType=0); // IE9 and down
}

@mixin gradient-directional($start-color: #555, $end-color: #333, $deg: 45deg) {
  background-repeat: repeat-x;
  background-image: -webkit-linear-gradient($deg, $start-color, $end-color); // Safari 5.1-6, Chrome 10+
  background-image: -o-linear-gradient($deg, $start-color, $end-color); // Opera 12
  background-image: linear-gradient($deg, $start-color, $end-color); // Standard, IE10, Firefox 16+, Opera 12.10+, Safari 7+, Chrome 26+
}
@mixin gradient-horizontal-three-colors($start-color: #00b3ee, $mid-color: #7a43b6, $color-stop: 50%, $end-color: #c3325f) {
  background-image: -webkit-linear-gradient(left, $start-color, $mid-color $color-stop, $end-color);
  background-image: -o-linear-gradient(left, $start-color, $mid-color $color-stop, $end-color);
  background-image: linear-gradient(to right, $start-color, $mid-color $color-stop, $end-color);
  background-repeat: no-repeat;
  filter: progid:DXImageTransform.Microsoft.gradient(startColorstr='#{ie-hex-str($start-color)}', endColorstr='#{ie-hex-str($end-color)}', GradientType=1); // IE9 and down, gets no color-stop at all for proper fallback
}
@mixin gradient-vertical-three-colors($start-color: #00b3ee, $mid-color: #7a43b6, $color-stop: 50%, $end-color: #c3325f) {
  background-image: -webkit-linear-gradient($start-color, $mid-color $color-stop, $end-color);
  background-image: -o-linear-gradient($start-color, $mid-color $color-stop, $end-color);
  background-image: linear-gradient($start-color, $mid-color $color-stop, $end-color);
  background-repeat: no-repeat;
  filter: progid:DXImageTransform.Microsoft.gradient(startColorstr='#{ie-hex-str($start-color)}', endColorstr='#{ie-hex-str($end-color)}', GradientType=0); // IE9 and down, gets no color-stop at all for proper fallback
}
@mixin gradient-radial($inner-color: #555, $outer-color: #333) {
  background-image: -webkit-radial-gradient(circle, $inner-color, $outer-color);
  background-image: radial-gradient(circle, $inner-color, $outer-color);
  background-repeat: no-repeat;
}
@mixin gradient-striped($color: rgba(255,255,255,.15), $angle: 45deg) {
  background-image: -webkit-linear-gradient($angle, $color 25%, transparent 25%, transparent 50%, $color 50%, $color 75%, transparent 75%, transparent);
  background-image: -o-linear-gradient($angle, $color 25%, transparent 25%, transparent 50%, $color 50%, $color 75%, transparent 75%, transparent);
  background-image: linear-gradient($angle, $color 25%, transparent 25%, transparent 50%, $color 50%, $color 75%, transparent 75%, transparent);
}


================================================
File: _sass/bootstrap/mixins/_grid-framework.scss
================================================
// Framework grid generation
//
// Used only by Bootstrap to generate the correct number of grid classes given
// any value of `$grid-columns`.

// [converter] This is defined recursively in LESS, but Sass supports real loops
@mixin make-grid-columns($i: 1, $list: ".col-xs-#{$i}, .col-sm-#{$i}, .col-md-#{$i}, .col-lg-#{$i}") {
  @for $i from (1 + 1) through $grid-columns {
    $list: "#{$list}, .col-xs-#{$i}, .col-sm-#{$i}, .col-md-#{$i}, .col-lg-#{$i}";
  }
  #{$list} {
    position: relative;
    // Prevent columns from collapsing when empty
    min-height: 1px;
    // Inner gutter via padding
    padding-left:  ceil(($grid-gutter-width / 2));
    padding-right: floor(($grid-gutter-width / 2));
  }
}


// [converter] This is defined recursively in LESS, but Sass supports real loops
@mixin float-grid-columns($class, $i: 1, $list: ".col-#{$class}-#{$i}") {
  @for $i from (1 + 1) through $grid-columns {
    $list: "#{$list}, .col-#{$class}-#{$i}";
  }
  #{$list} {
    float: left;
  }
}


@mixin calc-grid-column($index, $class, $type) {
  @if ($type == width) and ($index > 0) {
    .col-#{$class}-#{$index} {
      width: percentage(($index / $grid-columns));
    }
  }
  @if ($type == push) and ($index > 0) {
    .col-#{$class}-push-#{$index} {
      left: percentage(($index / $grid-columns));
    }
  }
  @if ($type == push) and ($index == 0) {
    .col-#{$class}-push-0 {
      left: auto;
    }
  }
  @if ($type == pull) and ($index > 0) {
    .col-#{$class}-pull-#{$index} {
      right: percentage(($index / $grid-columns));
    }
  }
  @if ($type == pull) and ($index == 0) {
    .col-#{$class}-pull-0 {
      right: auto;
    }
  }
  @if ($type == offset) {
    .col-#{$class}-offset-#{$index} {
      margin-left: percentage(($index / $grid-columns));
    }
  }
}

// [converter] This is defined recursively in LESS, but Sass supports real loops
@mixin loop-grid-columns($columns, $class, $type) {
  @for $i from 0 through $columns {
    @include calc-grid-column($i, $class, $type);
  }
}


// Create grid for specific class
@mixin make-grid($class) {
  @include float-grid-columns($class);
  @include loop-grid-columns($grid-columns, $class, width);
  @include loop-grid-columns($grid-columns, $class, pull);
  @include loop-grid-columns($grid-columns, $class, push);
  @include loop-grid-columns($grid-columns, $class, offset);
}


================================================
File: _sass/bootstrap/mixins/_grid.scss
================================================
// Grid system
//
// Generate semantic grid columns with these mixins.

// Centered container element
@mixin container-fixed($gutter: $grid-gutter-width) {
  margin-right: auto;
  margin-left: auto;
  padding-left:  floor(($gutter / 2));
  padding-right: ceil(($gutter / 2));
  @include clearfix;
}

// Creates a wrapper for a series of columns
@mixin make-row($gutter: $grid-gutter-width) {
  margin-left:  ceil(($gutter / -2));
  margin-right: floor(($gutter / -2));
  @include clearfix;
}

// Generate the extra small columns
@mixin make-xs-column($columns, $gutter: $grid-gutter-width) {
  position: relative;
  float: left;
  width: percentage(($columns / $grid-columns));
  min-height: 1px;
  padding-left:  ($gutter / 2);
  padding-right: ($gutter / 2);
}
@mixin make-xs-column-offset($columns) {
  margin-left: percentage(($columns / $grid-columns));
}
@mixin make-xs-column-push($columns) {
  left: percentage(($columns / $grid-columns));
}
@mixin make-xs-column-pull($columns) {
  right: percentage(($columns / $grid-columns));
}

// Generate the small columns
@mixin make-sm-column($columns, $gutter: $grid-gutter-width) {
  position: relative;
  min-height: 1px;
  padding-left:  ($gutter / 2);
  padding-right: ($gutter / 2);

  @media (min-width: $screen-sm-min) {
    float: left;
    width: percentage(($columns / $grid-columns));
  }
}
@mixin make-sm-column-offset($columns) {
  @media (min-width: $screen-sm-min) {
    margin-left: percentage(($columns / $grid-columns));
  }
}
@mixin make-sm-column-push($columns) {
  @media (min-width: $screen-sm-min) {
    left: percentage(($columns / $grid-columns));
  }
}
@mixin make-sm-column-pull($columns) {
  @media (min-width: $screen-sm-min) {
    right: percentage(($columns / $grid-columns));
  }
}

// Generate the medium columns
@mixin make-md-column($columns, $gutter: $grid-gutter-width) {
  position: relative;
  min-height: 1px;
  padding-left:  ($gutter / 2);
  padding-right: ($gutter / 2);

  @media (min-width: $screen-md-min) {
    float: left;
    width: percentage(($columns / $grid-columns));
  }
}
@mixin make-md-column-offset($columns) {
  @media (min-width: $screen-md-min) {
    margin-left: percentage(($columns / $grid-columns));
  }
}
@mixin make-md-column-push($columns) {
  @media (min-width: $screen-md-min) {
    left: percentage(($columns / $grid-columns));
  }
}
@mixin make-md-column-pull($columns) {
  @media (min-width: $screen-md-min) {
    right: percentage(($columns / $grid-columns));
  }
}

// Generate the large columns
@mixin make-lg-column($columns, $gutter: $grid-gutter-width) {
  position: relative;
  min-height: 1px;
  padding-left:  ($gutter / 2);
  padding-right: ($gutter / 2);

  @media (min-width: $screen-lg-min) {
    float: left;
    width: percentage(($columns / $grid-columns));
  }
}
@mixin make-lg-column-offset($columns) {
  @media (min-width: $screen-lg-min) {
    margin-left: percentage(($columns / $grid-columns));
  }
}
@mixin make-lg-column-push($columns) {
  @media (min-width: $screen-lg-min) {
    left: percentage(($columns / $grid-columns));
  }
}
@mixin make-lg-column-pull($columns) {
  @media (min-width: $screen-lg-min) {
    right: percentage(($columns / $grid-columns));
  }
}


================================================
File: _sass/bootstrap/mixins/_hide-text.scss
================================================
// CSS image replacement
//
// Heads up! v3 launched with only `.hide-text()`, but per our pattern for
// mixins being reused as classes with the same name, this doesn't hold up. As
// of v3.0.1 we have added `.text-hide()` and deprecated `.hide-text()`.
//
// Source: https://github.com/h5bp/html5-boilerplate/commit/aa0396eae757

// Deprecated as of v3.0.1 (has been removed in v4)
@mixin hide-text() {
  font: 0/0 a;
  color: transparent;
  text-shadow: none;
  background-color: transparent;
  border: 0;
}

// New mixin to use as of v3.0.1
@mixin text-hide() {
  @include hide-text;
}


================================================
File: _sass/bootstrap/mixins/_image.scss
================================================
// Image Mixins
// - Responsive image
// - Retina image


// Responsive image
//
// Keep images from scaling beyond the width of their parents.
@mixin img-responsive($display: block) {
  display: $display;
  max-width: 100%; // Part 1: Set a maximum relative to the parent
  height: auto; // Part 2: Scale the height according to the width, otherwise you get stretching
}


// Retina image
//
// Short retina mixin for setting background-image and -size. Note that the
// spelling of `min--moz-device-pixel-ratio` is intentional.
@mixin img-retina($file-1x, $file-2x, $width-1x, $height-1x) {
  background-image: url(if($bootstrap-sass-asset-helper, twbs-image-path("#{$file-1x}"), "#{$file-1x}"));

  @media
  only screen and (-webkit-min-device-pixel-ratio: 2),
  only screen and (   min--moz-device-pixel-ratio: 2),
  only screen and (     -o-min-device-pixel-ratio: 2/1),
  only screen and (        min-device-pixel-ratio: 2),
  only screen and (                min-resolution: 192dpi),
  only screen and (                min-resolution: 2dppx) {
    background-image: url(if($bootstrap-sass-asset-helper, twbs-image-path("#{$file-2x}"), "#{$file-2x}"));
    background-size: $width-1x $height-1x;
  }
}


================================================
File: _sass/bootstrap/mixins/_labels.scss
================================================
// Labels

@mixin label-variant($color) {
  background-color: $color;

  &[href] {
    &:hover,
    &:focus {
      background-color: darken($color, 10%);
    }
  }
}


================================================
File: _sass/bootstrap/mixins/_list-group.scss
================================================
// List Groups

@mixin list-group-item-variant($state, $background, $color) {
  .list-group-item-#{$state} {
    color: $color;
    background-color: $background;

    // [converter] extracted a&, button& to a.list-group-item-#{$state}, button.list-group-item-#{$state}
  }

  a.list-group-item-#{$state},
  button.list-group-item-#{$state} {
    color: $color;

    .list-group-item-heading {
      color: inherit;
    }

    &:hover,
    &:focus {
      color: $color;
      background-color: darken($background, 5%);
    }
    &.active,
    &.active:hover,
    &.active:focus {
      color: #fff;
      background-color: $color;
      border-color: $color;
    }
  }
}


================================================
File: _sass/bootstrap/mixins/_nav-divider.scss
================================================
// Horizontal dividers
//
// Dividers (basically an hr) within dropdowns and nav lists

@mixin nav-divider($color: #e5e5e5) {
  height: 1px;
  margin: (($line-height-computed / 2) - 1) 0;
  overflow: hidden;
  background-color: $color;
}


================================================
File: _sass/bootstrap/mixins/_nav-vertical-align.scss
================================================
// Navbar vertical align
//
// Vertically center elements in the navbar.
// Example: an element has a height of 30px, so write out `.navbar-vertical-align(30px);` to calculate the appropriate top margin.

@mixin navbar-vertical-align($element-height) {
  margin-top: (($navbar-height - $element-height) / 2);
  margin-bottom: (($navbar-height - $element-height) / 2);
}


================================================
File: _sass/bootstrap/mixins/_opacity.scss
================================================
// Opacity

@mixin opacity($opacity) {
  opacity: $opacity;
  // IE8 filter
  $opacity-ie: ($opacity * 100);
  filter: alpha(opacity=$opacity-ie);
}


================================================
File: _sass/bootstrap/mixins/_pagination.scss
================================================
// Pagination

@mixin pagination-size($padding-vertical, $padding-horizontal, $font-size, $line-height, $border-radius) {
  > li {
    > a,
    > span {
      padding: $padding-vertical $padding-horizontal;
      font-size: $font-size;
      line-height: $line-height;
    }
    &:first-child {
      > a,
      > span {
        @include border-left-radius($border-radius);
      }
    }
    &:last-child {
      > a,
      > span {
        @include border-right-radius($border-radius);
      }
    }
  }
}


================================================
File: _sass/bootstrap/mixins/_panels.scss
================================================
// Panels

@mixin panel-variant($border, $heading-text-color, $heading-bg-color, $heading-border) {
  border-color: $border;

  & > .panel-heading {
    color: $heading-text-color;
    background-color: $heading-bg-color;
    border-color: $heading-border;

    + .panel-collapse > .panel-body {
      border-top-color: $border;
    }
    .badge {
      color: $heading-bg-color;
      background-color: $heading-text-color;
    }
  }
  & > .panel-footer {
    + .panel-collapse > .panel-body {
      border-bottom-color: $border;
    }
  }
}


================================================
File: _sass/bootstrap/mixins/_progress-bar.scss
================================================
// Progress bars

@mixin progress-bar-variant($color) {
  background-color: $color;

  // Deprecated parent class requirement as of v3.2.0
  .progress-striped & {
    @include gradient-striped;
  }
}


================================================
File: _sass/bootstrap/mixins/_reset-filter.scss
================================================
// Reset filters for IE
//
// When you need to remove a gradient background, do not forget to use this to reset
// the IE filter for IE9 and below.

@mixin reset-filter() {
  filter: progid:DXImageTransform.Microsoft.gradient(enabled = false);
}


================================================
File: _sass/bootstrap/mixins/_reset-text.scss
================================================
@mixin reset-text() {
  font-family: $font-family-base;
  // We deliberately do NOT reset font-size.
  font-style: normal;
  font-weight: normal;
  letter-spacing: normal;
  line-break: auto;
  line-height: $line-height-base;
  text-align: left; // Fallback for where `start` is not supported
  text-align: start;
  text-decoration: none;
  text-shadow: none;
  text-transform: none;
  white-space: normal;
  word-break: normal;
  word-spacing: normal;
  word-wrap: normal;
}


================================================
File: _sass/bootstrap/mixins/_resize.scss
================================================
// Resize anything

@mixin resizable($direction) {
  resize: $direction; // Options: horizontal, vertical, both
  overflow: auto; // Per CSS3 UI, `resize` only applies when `overflow` isn't `visible`
}


================================================
File: _sass/bootstrap/mixins/_responsive-visibility.scss
================================================
// Responsive utilities

//
// More easily include all the states for responsive-utilities.less.
// [converter] $parent hack
@mixin responsive-visibility($parent) {
  #{$parent} {
    display: block !important;
  }
  table#{$parent}  { display: table !important; }
  tr#{$parent}     { display: table-row !important; }
  th#{$parent},
  td#{$parent}     { display: table-cell !important; }
}

// [converter] $parent hack
@mixin responsive-invisibility($parent) {
  #{$parent} {
    display: none !important;
  }
}


================================================
File: _sass/bootstrap/mixins/_size.scss
================================================
// Sizing shortcuts

@mixin size($width, $height) {
  width: $width;
  height: $height;
}

@mixin square($size) {
  @include size($size, $size);
}


================================================
File: _sass/bootstrap/mixins/_tab-focus.scss
================================================
// WebKit-style focus

@mixin tab-focus() {
  // Default
  outline: thin dotted;
  // WebKit
  outline: 5px auto -webkit-focus-ring-color;
  outline-offset: -2px;
}


================================================
File: _sass/bootstrap/mixins/_table-row.scss
================================================
// Tables

@mixin table-row-variant($state, $background) {
  // Exact selectors below required to override `.table-striped` and prevent
  // inheritance to nested tables.
  .table > thead > tr,
  .table > tbody > tr,
  .table > tfoot > tr {
    > td.#{$state},
    > th.#{$state},
    &.#{$state} > td,
    &.#{$state} > th {
      background-color: $background;
    }
  }

  // Hover states for `.table-hover`
  // Note: this is not available for cells or rows within `thead` or `tfoot`.
  .table-hover > tbody > tr {
    > td.#{$state}:hover,
    > th.#{$state}:hover,
    &.#{$state}:hover > td,
    &:hover > .#{$state},
    &.#{$state}:hover > th {
      background-color: darken($background, 5%);
    }
  }
}


================================================
File: _sass/bootstrap/mixins/_text-emphasis.scss
================================================
// Typography

// [converter] $parent hack
@mixin text-emphasis-variant($parent, $color) {
  #{$parent} {
    color: $color;
  }
  a#{$parent}:hover,
  a#{$parent}:focus {
    color: darken($color, 10%);
  }
}


================================================
File: _sass/bootstrap/mixins/_text-overflow.scss
================================================
// Text overflow
// Requires inline-block or block for proper styling

@mixin text-overflow() {
  overflow: hidden;
  text-overflow: ellipsis;
  white-space: nowrap;
}


================================================
File: _sass/bootstrap/mixins/_vendor-prefixes.scss
================================================
// Vendor Prefixes
//
// All vendor mixins are deprecated as of v3.2.0 due to the introduction of
// Autoprefixer in our Gruntfile. They have been removed in v4.

// - Animations
// - Backface visibility
// - Box shadow
// - Box sizing
// - Content columns
// - Hyphens
// - Placeholder text
// - Transformations
// - Transitions
// - User Select


// Animations
@mixin animation($animation) {
  -webkit-animation: $animation;
       -o-animation: $animation;
          animation: $animation;
}
@mixin animation-name($name) {
  -webkit-animation-name: $name;
          animation-name: $name;
}
@mixin animation-duration($duration) {
  -webkit-animation-duration: $duration;
          animation-duration: $duration;
}
@mixin animation-timing-function($timing-function) {
  -webkit-animation-timing-function: $timing-function;
          animation-timing-function: $timing-function;
}
@mixin animation-delay($delay) {
  -webkit-animation-delay: $delay;
          animation-delay: $delay;
}
@mixin animation-iteration-count($iteration-count) {
  -webkit-animation-iteration-count: $iteration-count;
          animation-iteration-count: $iteration-count;
}
@mixin animation-direction($direction) {
  -webkit-animation-direction: $direction;
          animation-direction: $direction;
}
@mixin animation-fill-mode($fill-mode) {
  -webkit-animation-fill-mode: $fill-mode;
          animation-fill-mode: $fill-mode;
}

// Backface visibility
// Prevent browsers from flickering when using CSS 3D transforms.
// Default value is `visible`, but can be changed to `hidden`

@mixin backface-visibility($visibility) {
  -webkit-backface-visibility: $visibility;
     -moz-backface-visibility: $visibility;
          backface-visibility: $visibility;
}

// Drop shadows
//
// Note: Deprecated `.box-shadow()` as of v3.1.0 since all of Bootstrap's
// supported browsers that have box shadow capabilities now support it.

@mixin box-shadow($shadow...) {
  -webkit-box-shadow: $shadow; // iOS <4.3 & Android <4.1
          box-shadow: $shadow;
}

// Box sizing
@mixin box-sizing($boxmodel) {
  -webkit-box-sizing: $boxmodel;
     -moz-box-sizing: $boxmodel;
          box-sizing: $boxmodel;
}

// CSS3 Content Columns
@mixin content-columns($column-count, $column-gap: $grid-gutter-width) {
  -webkit-column-count: $column-count;
     -moz-column-count: $column-count;
          column-count: $column-count;
  -webkit-column-gap: $column-gap;
     -moz-column-gap: $column-gap;
          column-gap: $column-gap;
}

// Optional hyphenation
@mixin hyphens($mode: auto) {
  word-wrap: break-word;
  -webkit-hyphens: $mode;
     -moz-hyphens: $mode;
      -ms-hyphens: $mode; // IE10+
       -o-hyphens: $mode;
          hyphens: $mode;
}

// Placeholder text
@mixin placeholder($color: $input-color-placeholder) {
  // Firefox
  &::-moz-placeholder {
    color: $color;
    opacity: 1; // Override Firefox's unusual default opacity; see https://github.com/twbs/bootstrap/pull/11526
  }
  &:-ms-input-placeholder { color: $color; } // Internet Explorer 10+
  &::-webkit-input-placeholder  { color: $color; } // Safari and Chrome
}

// Transformations
@mixin scale($ratio...) {
  -webkit-transform: scale($ratio);
      -ms-transform: scale($ratio); // IE9 only
       -o-transform: scale($ratio);
          transform: scale($ratio);
}

@mixin scaleX($ratio) {
  -webkit-transform: scaleX($ratio);
      -ms-transform: scaleX($ratio); // IE9 only
       -o-transform: scaleX($ratio);
          transform: scaleX($ratio);
}
@mixin scaleY($ratio) {
  -webkit-transform: scaleY($ratio);
      -ms-transform: scaleY($ratio); // IE9 only
       -o-transform: scaleY($ratio);
          transform: scaleY($ratio);
}
@mixin skew($x, $y) {
  -webkit-transform: skewX($x) skewY($y);
      -ms-transform: skewX($x) skewY($y); // See https://github.com/twbs/bootstrap/issues/4885; IE9+
       -o-transform: skewX($x) skewY($y);
          transform: skewX($x) skewY($y);
}
@mixin translate($x, $y) {
  -webkit-transform: translate($x, $y);
      -ms-transform: translate($x, $y); // IE9 only
       -o-transform: translate($x, $y);
          transform: translate($x, $y);
}
@mixin translate3d($x, $y, $z) {
  -webkit-transform: translate3d($x, $y, $z);
          transform: translate3d($x, $y, $z);
}
@mixin rotate($degrees) {
  -webkit-transform: rotate($degrees);
      -ms-transform: rotate($degrees); // IE9 only
       -o-transform: rotate($degrees);
          transform: rotate($degrees);
}
@mixin rotateX($degrees) {
  -webkit-transform: rotateX($degrees);
      -ms-transform: rotateX($degrees); // IE9 only
       -o-transform: rotateX($degrees);
          transform: rotateX($degrees);
}
@mixin rotateY($degrees) {
  -webkit-transform: rotateY($degrees);
      -ms-transform: rotateY($degrees); // IE9 only
       -o-transform: rotateY($degrees);
          transform: rotateY($degrees);
}
@mixin perspective($perspective) {
  -webkit-perspective: $perspective;
     -moz-perspective: $perspective;
          perspective: $perspective;
}
@mixin perspective-origin($perspective) {
  -webkit-perspective-origin: $perspective;
     -moz-perspective-origin: $perspective;
          perspective-origin: $perspective;
}
@mixin transform-origin($origin) {
  -webkit-transform-origin: $origin;
     -moz-transform-origin: $origin;
      -ms-transform-origin: $origin; // IE9 only
          transform-origin: $origin;
}


// Transitions

@mixin transition($transition...) {
  -webkit-transition: $transition;
       -o-transition: $transition;
          transition: $transition;
}
@mixin transition-property($transition-property...) {
  -webkit-transition-property: $transition-property;
          transition-property: $transition-property;
}
@mixin transition-delay($transition-delay) {
  -webkit-transition-delay: $transition-delay;
          transition-delay: $transition-delay;
}
@mixin transition-duration($transition-duration...) {
  -webkit-transition-duration: $transition-duration;
          transition-duration: $transition-duration;
}
@mixin transition-timing-function($timing-function) {
  -webkit-transition-timing-function: $timing-function;
          transition-timing-function: $timing-function;
}
@mixin transition-transform($transition...) {
  -webkit-transition: -webkit-transform $transition;
     -moz-transition: -moz-transform $transition;
       -o-transition: -o-transform $transition;
          transition: transform $transition;
}


// User select
// For selecting text on the page

@mixin user-select($select) {
  -webkit-user-select: $select;
     -moz-user-select: $select;
      -ms-user-select: $select; // IE10+
          user-select: $select;
}


================================================
File: assets/css/style.scss
================================================
---
# Header marking file to process by Jekyll
---

@import "bootstrap-sprockets";

// Core variables and mixins
@import "variables"; // customised variables by Keboola
@import "bootstrap/mixins";

// Reset and dependencies
@import "bootstrap/normalize";
@import "bootstrap/print";
@import "bootstrap/glyphicons";

// Core CSS
@import "bootstrap/scaffolding";
@import "bootstrap/type";
@import "bootstrap/code";
@import "bootstrap/grid";
@import "bootstrap/tables";
@import "bootstrap/forms";
//@import "bootstrap/buttons";

// Components
@import "bootstrap/component-animations";
//@import "bootstrap/dropdowns";
//@import "bootstrap/button-groups";
//@import "bootstrap/input-groups";
@import "bootstrap/navs";
@import "bootstrap/navbar";
@import "bootstrap/breadcrumbs";
//@import "bootstrap/pagination";
//@import "bootstrap/pager";
@import "bootstrap/labels";
//@import "bootstrap/badges";
//@import "bootstrap/jumbotron";
//@import "bootstrap/thumbnails";
@import "bootstrap/alerts";
//@import "bootstrap/progress-bars";
//@import "bootstrap/media";
//@import "bootstrap/list-group";
//@import "bootstrap/panels";
@import "bootstrap/responsive-embed";
//@import "bootstrap/wells";
//@import "bootstrap/close";

// Components w/ JavaScript
//@import "bootstrap/modals";
//@import "bootstrap/tooltip";
//@import "bootstrap/popovers";
//@import "bootstrap/carousel";

// Utility classes
@import "bootstrap/utilities";
@import "bootstrap/responsive-utilities";


// Additional components by Keboola
@import "magnific-popup";
@import "highlight";

$code-font-size: ($font-size-base - 2);

.wf-active {
  body {
    font-family: "Lato", $font-family-sans-serif;
  }
}

h1 {
  margin-bottom: 1em;
}
h2 {
  margin: .9em 0 .6em;
}

code {
  background-color: $gray-lighter;
  color: $gray-dark;
  font-size: $code-font-size; // standard for inline
}
pre {
  border-radius: 3px;
  background-color: $gray-lighter;
  border: none;
  padding: 1em 1.25em;
  code {
    font-size: ($code-font-size - 1); // smaller for code block
  }
}

dl {
    margin-left: 2em;
    dt {
        margin-top: 1em;
    }
    dd {
        padding: 0 1em;
        margin-bottom: 1em;
    }
}

// Baseline styles
table {
  width: 100%;
  max-width: 100%;
  margin-bottom: $line-height-computed;
  // Cells
  > thead,
  > tbody,
  > tfoot {
    > tr {
      > th,
      > td {
        padding: $table-cell-padding;
        line-height: $line-height-base;
        vertical-align: middle;
        border-top: 1px solid $table-border-color;
      }
    }
  }
  // Bottom align for column headings
  > thead > tr > th {
    vertical-align: bottom;
    border-bottom: 2px solid $table-border-color;
  }
  // Remove top border from thead by default
  > caption + thead,
  > colgroup + thead,
  > thead:first-child {
    > tr:first-child {
      > th,
      > td {
        border-top: 0;
      }
    }
  }
  // Account for multiple tbody instances
  > tbody + tbody {
    border-top: 2px solid $table-border-color;
  }

  // Nesting
  table {
    background-color: $body-bg;
  }

  code.td-break-code {
    word-break: break-all;
  }
}

.root {
  overflow: auto;

  .container {
    &.main {
      background-color: $keboola-violet;
    }
  }
}

img {
  max-width: 100% !important;
}

.header {
  .inside {
    line-height: 3em;
    @media (min-width: $screen-sm-min) {
      height: 5em;
      line-height: 5em;
    }
    margin: 1em;
    .logo {
      display: inline-block;
      img {
        padding: .5em;
        margin: 0 .5em 0 0;
      }
    }
    .keboola-algolia-docsearch {
      display: inline-block;
      line-height: 1.5em;
      padding: .5em 0;
      @media (min-width: $screen-sm-min) {
        padding: 1.8em 0 1.8em 1em;
        float: right;
      }
    }
    span.label {
      @include label-variant(#ccc);
      color: $gray;
      display: inline-block;
      margin-right: .5em;
    }
  }
}

.sidebar {
  .navigation {
    padding: 1.2em 0;
    ul.nav {
      li {
        > ul {
          display: none;
        }
        &.active {
          > ul {
            display: block;
            padding-left: 1em;
          }
          background-color: $keboola-violet-light;
          &.current {
            > a {
              background-color: $keboola-violet-lighter;
              font-weight: bold;
              &:hover {
                background-color: #fff;
              }
            }
          }
        }
        a {
          color: #fff;
          &:hover {
            background-color: #fff;
            color: $gray-dark;
          }
        }
      }
    }
    &.affix {
      @media (max-width: $screen-sm-max) {
        position: relative;
      }
      @media (min-width: $screen-md-min) {
        top: 0;
        width: 212.5px;
      }
      @media (min-width: $screen-lg-min) {
        width: 262.5px;
      }
    }
    &.affix-bottom {
      @media (min-width: $screen-md-min) {
        position: absolute;
        top: 0;
        width: 212.5px;
      }
      @media (min-width: $screen-lg-min) {
        width: 262.5px;
      }
    }
  }
}

.content {
  background-color: #fff;
  .page {
    padding: 1.8em 1em 2em;
    min-height: 100em;
    .breadcrumb {
      margin: 0 0 1em 0;
      padding: 0;
      background-color: transparent;
    }
    @media (min-width: $screen-md-min) {
      padding: 1.8em 2.5em 2em;
    }
    .link-to-github-page {
      text-align: right;
      padding: 3em 0 0;
      a {
        opacity: .75;
        font-size: .8em;
        &:hover, &:focus {
          opacity: 1;
        }
      }
    }
  }
}

.footer {
  .inside {
    text-align: center;
    padding: 2em 1em;
  }
}

// Components

// TOC
#markdown-toc {
  border: thin solid $gray-lighter;
  list-style: none;
  padding: 1em 1.5em;
  ul {
    list-style: none;
    padding: 0 0 0 1.5em;
  }
  margin-bottom: 1em;
  &:before {
    content: 'Table of contents';
    font-weight: bold;
    margin-bottom: .5em;
  }
  border-radius: 3px;
  @media (min-width: $screen-sm-min) {
    float: right;
    display: inline-block;
    margin-left: 1.5em;
    max-width: 40%;
  }
}

// image popup
.image-popup {
  img {
    max-width: 500px;
    max-height: 500px;
    cursor: pointer;
    padding: 1em;
    border: thin solid $gray-lighter;
    border-radius: 3px;
  }
}


================================================
File: assets/js/magnific-popup.js
================================================
// Magnific Popup v1.1.0 by Dmitry Semenov
// http://bit.ly/magnific-popup#build=inline+image
(function(a){typeof define=="function"&&define.amd?define(["jquery"],a):typeof exports=="object"?a(require("jquery")):a(window.jQuery||window.Zepto)})(function(a){var b="Close",c="BeforeClose",d="AfterClose",e="BeforeAppend",f="MarkupParse",g="Open",h="Change",i="mfp",j="."+i,k="mfp-ready",l="mfp-removing",m="mfp-prevent-close",n,o=function(){},p=!!window.jQuery,q,r=a(window),s,t,u,v,w=function(a,b){n.ev.on(i+a+j,b)},x=function(b,c,d,e){var f=document.createElement("div");return f.className="mfp-"+b,d&&(f.innerHTML=d),e?c&&c.appendChild(f):(f=a(f),c&&f.appendTo(c)),f},y=function(b,c){n.ev.triggerHandler(i+b,c),n.st.callbacks&&(b=b.charAt(0).toLowerCase()+b.slice(1),n.st.callbacks[b]&&n.st.callbacks[b].apply(n,a.isArray(c)?c:[c]))},z=function(b){if(b!==v||!n.currTemplate.closeBtn)n.currTemplate.closeBtn=a(n.st.closeMarkup.replace("%title%",n.st.tClose)),v=b;return n.currTemplate.closeBtn},A=function(){a.magnificPopup.instance||(n=new o,n.init(),a.magnificPopup.instance=n)},B=function(){var a=document.createElement("p").style,b=["ms","O","Moz","Webkit"];if(a.transition!==undefined)return!0;while(b.length)if(b.pop()+"Transition"in a)return!0;return!1};o.prototype={constructor:o,init:function(){var b=navigator.appVersion;n.isLowIE=n.isIE8=document.all&&!document.addEventListener,n.isAndroid=/android/gi.test(b),n.isIOS=/iphone|ipad|ipod/gi.test(b),n.supportsTransition=B(),n.probablyMobile=n.isAndroid||n.isIOS||/(Opera Mini)|Kindle|webOS|BlackBerry|(Opera Mobi)|(Windows Phone)|IEMobile/i.test(navigator.userAgent),s=a(document),n.popupsCache={}},open:function(b){var c;if(b.isObj===!1){n.items=b.items.toArray(),n.index=0;var d=b.items,e;for(c=0;c<d.length;c++){e=d[c],e.parsed&&(e=e.el[0]);if(e===b.el[0]){n.index=c;break}}}else n.items=a.isArray(b.items)?b.items:[b.items],n.index=b.index||0;if(n.isOpen){n.updateItemHTML();return}n.types=[],u="",b.mainEl&&b.mainEl.length?n.ev=b.mainEl.eq(0):n.ev=s,b.key?(n.popupsCache[b.key]||(n.popupsCache[b.key]={}),n.currTemplate=n.popupsCache[b.key]):n.currTemplate={},n.st=a.extend(!0,{},a.magnificPopup.defaults,b),n.fixedContentPos=n.st.fixedContentPos==="auto"?!n.probablyMobile:n.st.fixedContentPos,n.st.modal&&(n.st.closeOnContentClick=!1,n.st.closeOnBgClick=!1,n.st.showCloseBtn=!1,n.st.enableEscapeKey=!1),n.bgOverlay||(n.bgOverlay=x("bg").on("click"+j,function(){n.close()}),n.wrap=x("wrap").attr("tabindex",-1).on("click"+j,function(a){n._checkIfClose(a.target)&&n.close()}),n.container=x("container",n.wrap)),n.contentContainer=x("content"),n.st.preloader&&(n.preloader=x("preloader",n.container,n.st.tLoading));var h=a.magnificPopup.modules;for(c=0;c<h.length;c++){var i=h[c];i=i.charAt(0).toUpperCase()+i.slice(1),n["init"+i].call(n)}y("BeforeOpen"),n.st.showCloseBtn&&(n.st.closeBtnInside?(w(f,function(a,b,c,d){c.close_replaceWith=z(d.type)}),u+=" mfp-close-btn-in"):n.wrap.append(z())),n.st.alignTop&&(u+=" mfp-align-top"),n.fixedContentPos?n.wrap.css({overflow:n.st.overflowY,overflowX:"hidden",overflowY:n.st.overflowY}):n.wrap.css({top:r.scrollTop(),position:"absolute"}),(n.st.fixedBgPos===!1||n.st.fixedBgPos==="auto"&&!n.fixedContentPos)&&n.bgOverlay.css({height:s.height(),position:"absolute"}),n.st.enableEscapeKey&&s.on("keyup"+j,function(a){a.keyCode===27&&n.close()}),r.on("resize"+j,function(){n.updateSize()}),n.st.closeOnContentClick||(u+=" mfp-auto-cursor"),u&&n.wrap.addClass(u);var l=n.wH=r.height(),m={};if(n.fixedContentPos&&n._hasScrollBar(l)){var o=n._getScrollbarSize();o&&(m.marginRight=o)}n.fixedContentPos&&(n.isIE7?a("body, html").css("overflow","hidden"):m.overflow="hidden");var p=n.st.mainClass;return n.isIE7&&(p+=" mfp-ie7"),p&&n._addClassToMFP(p),n.updateItemHTML(),y("BuildControls"),a("html").css(m),n.bgOverlay.add(n.wrap).prependTo(n.st.prependTo||a(document.body)),n._lastFocusedEl=document.activeElement,setTimeout(function(){n.content?(n._addClassToMFP(k),n._setFocus()):n.bgOverlay.addClass(k),s.on("focusin"+j,n._onFocusIn)},16),n.isOpen=!0,n.updateSize(l),y(g),b},close:function(){if(!n.isOpen)return;y(c),n.isOpen=!1,n.st.removalDelay&&!n.isLowIE&&n.supportsTransition?(n._addClassToMFP(l),setTimeout(function(){n._close()},n.st.removalDelay)):n._close()},_close:function(){y(b);var c=l+" "+k+" ";n.bgOverlay.detach(),n.wrap.detach(),n.container.empty(),n.st.mainClass&&(c+=n.st.mainClass+" "),n._removeClassFromMFP(c);if(n.fixedContentPos){var e={marginRight:""};n.isIE7?a("body, html").css("overflow",""):e.overflow="",a("html").css(e)}s.off("keyup"+j+" focusin"+j),n.ev.off(j),n.wrap.attr("class","mfp-wrap").removeAttr("style"),n.bgOverlay.attr("class","mfp-bg"),n.container.attr("class","mfp-container"),n.st.showCloseBtn&&(!n.st.closeBtnInside||n.currTemplate[n.currItem.type]===!0)&&n.currTemplate.closeBtn&&n.currTemplate.closeBtn.detach(),n.st.autoFocusLast&&n._lastFocusedEl&&a(n._lastFocusedEl).focus(),n.currItem=null,n.content=null,n.currTemplate=null,n.prevHeight=0,y(d)},updateSize:function(a){if(n.isIOS){var b=document.documentElement.clientWidth/window.innerWidth,c=window.innerHeight*b;n.wrap.css("height",c),n.wH=c}else n.wH=a||r.height();n.fixedContentPos||n.wrap.css("height",n.wH),y("Resize")},updateItemHTML:function(){var b=n.items[n.index];n.contentContainer.detach(),n.content&&n.content.detach(),b.parsed||(b=n.parseEl(n.index));var c=b.type;y("BeforeChange",[n.currItem?n.currItem.type:"",c]),n.currItem=b;if(!n.currTemplate[c]){var d=n.st[c]?n.st[c].markup:!1;y("FirstMarkupParse",d),d?n.currTemplate[c]=a(d):n.currTemplate[c]=!0}t&&t!==b.type&&n.container.removeClass("mfp-"+t+"-holder");var e=n["get"+c.charAt(0).toUpperCase()+c.slice(1)](b,n.currTemplate[c]);n.appendContent(e,c),b.preloaded=!0,y(h,b),t=b.type,n.container.prepend(n.contentContainer),y("AfterChange")},appendContent:function(a,b){n.content=a,a?n.st.showCloseBtn&&n.st.closeBtnInside&&n.currTemplate[b]===!0?n.content.find(".mfp-close").length||n.content.append(z()):n.content=a:n.content="",y(e),n.container.addClass("mfp-"+b+"-holder"),n.contentContainer.append(n.content)},parseEl:function(b){var c=n.items[b],d;c.tagName?c={el:a(c)}:(d=c.type,c={data:c,src:c.src});if(c.el){var e=n.types;for(var f=0;f<e.length;f++)if(c.el.hasClass("mfp-"+e[f])){d=e[f];break}c.src=c.el.attr("data-mfp-src"),c.src||(c.src=c.el.attr("href"))}return c.type=d||n.st.type||"inline",c.index=b,c.parsed=!0,n.items[b]=c,y("ElementParse",c),n.items[b]},addGroup:function(a,b){var c=function(c){c.mfpEl=this,n._openClick(c,a,b)};b||(b={});var d="click.magnificPopup";b.mainEl=a,b.items?(b.isObj=!0,a.off(d).on(d,c)):(b.isObj=!1,b.delegate?a.off(d).on(d,b.delegate,c):(b.items=a,a.off(d).on(d,c)))},_openClick:function(b,c,d){var e=d.midClick!==undefined?d.midClick:a.magnificPopup.defaults.midClick;if(!e&&(b.which===2||b.ctrlKey||b.metaKey||b.altKey||b.shiftKey))return;var f=d.disableOn!==undefined?d.disableOn:a.magnificPopup.defaults.disableOn;if(f)if(a.isFunction(f)){if(!f.call(n))return!0}else if(r.width()<f)return!0;b.type&&(b.preventDefault(),n.isOpen&&b.stopPropagation()),d.el=a(b.mfpEl),d.delegate&&(d.items=c.find(d.delegate)),n.open(d)},updateStatus:function(a,b){if(n.preloader){q!==a&&n.container.removeClass("mfp-s-"+q),!b&&a==="loading"&&(b=n.st.tLoading);var c={status:a,text:b};y("UpdateStatus",c),a=c.status,b=c.text,n.preloader.html(b),n.preloader.find("a").on("click",function(a){a.stopImmediatePropagation()}),n.container.addClass("mfp-s-"+a),q=a}},_checkIfClose:function(b){if(a(b).hasClass(m))return;var c=n.st.closeOnContentClick,d=n.st.closeOnBgClick;if(c&&d)return!0;if(!n.content||a(b).hasClass("mfp-close")||n.preloader&&b===n.preloader[0])return!0;if(b!==n.content[0]&&!a.contains(n.content[0],b)){if(d&&a.contains(document,b))return!0}else if(c)return!0;return!1},_addClassToMFP:function(a){n.bgOverlay.addClass(a),n.wrap.addClass(a)},_removeClassFromMFP:function(a){this.bgOverlay.removeClass(a),n.wrap.removeClass(a)},_hasScrollBar:function(a){return(n.isIE7?s.height():document.body.scrollHeight)>(a||r.height())},_setFocus:function(){(n.st.focus?n.content.find(n.st.focus).eq(0):n.wrap).focus()},_onFocusIn:function(b){if(b.target!==n.wrap[0]&&!a.contains(n.wrap[0],b.target))return n._setFocus(),!1},_parseMarkup:function(b,c,d){var e;d.data&&(c=a.extend(d.data,c)),y(f,[b,c,d]),a.each(c,function(c,d){if(d===undefined||d===!1)return!0;e=c.split("_");if(e.length>1){var f=b.find(j+"-"+e[0]);if(f.length>0){var g=e[1];g==="replaceWith"?f[0]!==d[0]&&f.replaceWith(d):g==="img"?f.is("img")?f.attr("src",d):f.replaceWith(a("<img>").attr("src",d).attr("class",f.attr("class"))):f.attr(e[1],d)}}else b.find(j+"-"+c).html(d)})},_getScrollbarSize:function(){if(n.scrollbarSize===undefined){var a=document.createElement("div");a.style.cssText="width: 99px; height: 99px; overflow: scroll; position: absolute; top: -9999px;",document.body.appendChild(a),n.scrollbarSize=a.offsetWidth-a.clientWidth,document.body.removeChild(a)}return n.scrollbarSize}},a.magnificPopup={instance:null,proto:o.prototype,modules:[],open:function(b,c){return A(),b?b=a.extend(!0,{},b):b={},b.isObj=!0,b.index=c||0,this.instance.open(b)},close:function(){return a.magnificPopup.instance&&a.magnificPopup.instance.close()},registerModule:function(b,c){c.options&&(a.magnificPopup.defaults[b]=c.options),a.extend(this.proto,c.proto),this.modules.push(b)},defaults:{disableOn:0,key:null,midClick:!1,mainClass:"",preloader:!0,focus:"",closeOnContentClick:!1,closeOnBgClick:!0,closeBtnInside:!0,showCloseBtn:!0,enableEscapeKey:!0,modal:!1,alignTop:!1,removalDelay:0,prependTo:null,fixedContentPos:"auto",fixedBgPos:"auto",overflowY:"auto",closeMarkup:'<button title="%title%" type="button" class="mfp-close">&#215;</button>',tClose:"Close (Esc)",tLoading:"Loading...",autoFocusLast:!0}},a.fn.magnificPopup=function(b){A();var c=a(this);if(typeof b=="string")if(b==="open"){var d,e=p?c.data("magnificPopup"):c[0].magnificPopup,f=parseInt(arguments[1],10)||0;e.items?d=e.items[f]:(d=c,e.delegate&&(d=d.find(e.delegate)),d=d.eq(f)),n._openClick({mfpEl:d},c,e)}else n.isOpen&&n[b].apply(n,Array.prototype.slice.call(arguments,1));else b=a.extend(!0,{},b),p?c.data("magnificPopup",b):c[0].magnificPopup=b,n.addGroup(c,b);return c};var C="inline",D,E,F,G=function(){F&&(E.after(F.addClass(D)).detach(),F=null)};a.magnificPopup.registerModule(C,{options:{hiddenClass:"hide",markup:"",tNotFound:"Content not found"},proto:{initInline:function(){n.types.push(C),w(b+"."+C,function(){G()})},getInline:function(b,c){G();if(b.src){var d=n.st.inline,e=a(b.src);if(e.length){var f=e[0].parentNode;f&&f.tagName&&(E||(D=d.hiddenClass,E=x(D),D="mfp-"+D),F=e.after(E).detach().removeClass(D)),n.updateStatus("ready")}else n.updateStatus("error",d.tNotFound),e=a("<div>");return b.inlineElement=e,e}return n.updateStatus("ready"),n._parseMarkup(c,{},b),c}}});var H,I=function(b){if(b.data&&b.data.title!==undefined)return b.data.title;var c=n.st.image.titleSrc;if(c){if(a.isFunction(c))return c.call(n,b);if(b.el)return b.el.attr(c)||""}return""};a.magnificPopup.registerModule("image",{options:{markup:'<div class="mfp-figure"><div class="mfp-close"></div><figure><div class="mfp-img"></div><figcaption><div class="mfp-bottom-bar"><div class="mfp-title"></div><div class="mfp-counter"></div></div></figcaption></figure></div>',cursor:"mfp-zoom-out-cur",titleSrc:"title",verticalFit:!0,tError:'<a href="%url%">The image</a> could not be loaded.'},proto:{initImage:function(){var c=n.st.image,d=".image";n.types.push("image"),w(g+d,function(){n.currItem.type==="image"&&c.cursor&&a(document.body).addClass(c.cursor)}),w(b+d,function(){c.cursor&&a(document.body).removeClass(c.cursor),r.off("resize"+j)}),w("Resize"+d,n.resizeImage),n.isLowIE&&w("AfterChange",n.resizeImage)},resizeImage:function(){var a=n.currItem;if(!a||!a.img)return;if(n.st.image.verticalFit){var b=0;n.isLowIE&&(b=parseInt(a.img.css("padding-top"),10)+parseInt(a.img.css("padding-bottom"),10)),a.img.css("max-height",n.wH-b)}},_onImageHasSize:function(a){a.img&&(a.hasSize=!0,H&&clearInterval(H),a.isCheckingImgSize=!1,y("ImageHasSize",a),a.imgHidden&&(n.content&&n.content.removeClass("mfp-loading"),a.imgHidden=!1))},findImageSize:function(a){var b=0,c=a.img[0],d=function(e){H&&clearInterval(H),H=setInterval(function(){if(c.naturalWidth>0){n._onImageHasSize(a);return}b>200&&clearInterval(H),b++,b===3?d(10):b===40?d(50):b===100&&d(500)},e)};d(1)},getImage:function(b,c){var d=0,e=function(){b&&(b.img[0].complete?(b.img.off(".mfploader"),b===n.currItem&&(n._onImageHasSize(b),n.updateStatus("ready")),b.hasSize=!0,b.loaded=!0,y("ImageLoadComplete")):(d++,d<200?setTimeout(e,100):f()))},f=function(){b&&(b.img.off(".mfploader"),b===n.currItem&&(n._onImageHasSize(b),n.updateStatus("error",g.tError.replace("%url%",b.src))),b.hasSize=!0,b.loaded=!0,b.loadError=!0)},g=n.st.image,h=c.find(".mfp-img");if(h.length){var i=document.createElement("img");i.className="mfp-img",b.el&&b.el.find("img").length&&(i.alt=b.el.find("img").attr("alt")),b.img=a(i).on("load.mfploader",e).on("error.mfploader",f),i.src=b.src,h.is("img")&&(b.img=b.img.clone()),i=b.img[0],i.naturalWidth>0?b.hasSize=!0:i.width||(b.hasSize=!1)}return n._parseMarkup(c,{title:I(b),img_replaceWith:b.img},b),n.resizeImage(),b.hasSize?(H&&clearInterval(H),b.loadError?(c.addClass("mfp-loading"),n.updateStatus("error",g.tError.replace("%url%",b.src))):(c.removeClass("mfp-loading"),n.updateStatus("ready")),c):(n.updateStatus("loading"),b.loading=!0,b.hasSize||(b.imgHidden=!0,c.addClass("mfp-loading"),n.findImageSize(b)),c)}}});var J,K=function(){return J===undefined&&(J=document.createElement("p").style.MozTransform!==undefined),J};a.magnificPopup.registerModule("zoom",{options:{enabled:!1,easing:"ease-in-out",duration:300,opener:function(a){return a.is("img")?a:a.find("img")}},proto:{initZoom:function(){var a=n.st.zoom,d=".zoom",e;if(!a.enabled||!n.supportsTransition)return;var f=a.duration,g=function(b){var c=b.clone().removeAttr("style").removeAttr("class").addClass("mfp-animated-image"),d="all "+a.duration/1e3+"s "+a.easing,e={position:"fixed",zIndex:9999,left:0,top:0,"-webkit-backface-visibility":"hidden"},f="transition";return e["-webkit-"+f]=e["-moz-"+f]=e["-o-"+f]=e[f]=d,c.css(e),c},h=function(){n.content.css("visibility","visible")},i,j;w("BuildControls"+d,function(){if(n._allowZoom()){clearTimeout(i),n.content.css("visibility","hidden"),e=n._getItemToZoom();if(!e){h();return}j=g(e),j.css(n._getOffset()),n.wrap.append(j),i=setTimeout(function(){j.css(n._getOffset(!0)),i=setTimeout(function(){h(),setTimeout(function(){j.remove(),e=j=null,y("ZoomAnimationEnded")},16)},f)},16)}}),w(c+d,function(){if(n._allowZoom()){clearTimeout(i),n.st.removalDelay=f;if(!e){e=n._getItemToZoom();if(!e)return;j=g(e)}j.css(n._getOffset(!0)),n.wrap.append(j),n.content.css("visibility","hidden"),setTimeout(function(){j.css(n._getOffset())},16)}}),w(b+d,function(){n._allowZoom()&&(h(),j&&j.remove(),e=null)})},_allowZoom:function(){return n.currItem.type==="image"},_getItemToZoom:function(){return n.currItem.hasSize?n.currItem.img:!1},_getOffset:function(b){var c;b?c=n.currItem.img:c=n.st.zoom.opener(n.currItem.el||n.currItem);var d=c.offset(),e=parseInt(c.css("padding-top"),10),f=parseInt(c.css("padding-bottom"),10);d.top-=a(window).scrollTop()-e;var g={width:c.width(),height:(p?c.innerHeight():c[0].offsetHeight)-f-e};return K()?g["-moz-transform"]=g.transform="translate("+d.left+"px,"+d.top+"px)":(g.left=d.left,g.top=d.top),g}}}),A()})

================================================
File: automate/index.md
================================================
---
title: Automation/Common Tasks
permalink: /automate/
---

## Automation

Use the Keboola Orchestrator component to specify what tasks should be executed in what order and 
configure their automatic execution (specified intervals, specified times of the day, etc.).

The set of [Keboola APIs](/overview/api/) provides full automation of the data warehouse cycle. 
The end-to-end serverless solution automatically enables you to connect data sources, automatically store data 
in the correct format, check for format inconsistencies, and choose different metadata providers based on the
operation you wish to perform on the data. The platform scales the needed resources automatically across various 
types of data (structured, semi-structured, and non-structured) and processes.

The whole environment tracks all the [operational metadata](https://keboola.docs.apiary.io/#reference/events) 
and can be accessed without needing a server via APIs. This is useful when automating development, testing and 
production run of data jobs with automatic controls of [pipelines](https://keboola.docs.apiary.io/#reference/development-branches).

As Storage API is part of the wider Keboola platform, it is an essential element in providing coherent data 
fabric across clouds, users, services, and on premise.


## CI/CD

No matter whether you use Jenkins, CircleCI, AWS CodeBuilder, or Azure DevOps, you can utilise 
the Keboola API within your existing CI/CD pipeline to deploy and manage new versions of your data 
pipeline and data process automation tasks.

## Documentation

You can learn about how to set up our Orchestrator on [help.keboola.com/tutorial/automate/](https://help.keboola.com/tutorial/automate/).

{% comment %} 
  - Load data from your system
  - Trigger orchestrations
  - Send data
  - Copy buckets from different projects


Orchestrator

spusteni jobu
API pro konfiguraci, nepouzivat normalni api
custom joby
{% endcomment %}


================================================
File: automate/run-job.md
================================================
---
title: Run a Job
permalink: /automate/run-job/
---

A [job](https://help.keboola.com/management/jobs/) represents a work being done in Keboola. 
You can create (run) a job from the UI or via scheduled [Orchestrations](https://help.keboola.com/orchestrator/) or Flows. 
A job can also be created manually via the API. The easiest way to get started is to create
a [configuration](https://help.keboola.com/components/) of the component you want to run and run it manually in the UI. 
Once you're satisfied with the result, look at the successful job:

{: .image-popup}
![Screenshot -- Job Parameters](/automate/job-parameters.png)

In the job detail, you can see the parameters required to run the configuration, in this case:

```
mode: run
component: keboola.ex-db-snowflake
config: 493493
```

Then create a [Storage API token](https://help.keboola.com/management/project/tokens/) which you will use to 
run the API requests (if you don't have one already). We recommend to create
as restricted token as possible -- in this case limit it to to the component with ID `keboola.ex-db-snowflake`:

{: .image-popup}
![Screenshot -- Token Settings](/automate/token-settings.png)

Then use the [Create Job API call](https://app.swaggerhub.com/apis-docs/keboola/job-queue-api/1.2.4#/Jobs/createJob) to 
create a job with the same parameters 
(see [example](https://documenter.getpostman.com/view/3086797/77h845D#fd60aa15-485c-4922-8536-c2ba2f27e8ea)):

```bash
curl --location --request POST 'https://queue.keboola.com/jobs' \
--header 'X-StorageApi-Token: YOUR_TOKEN' \
--header 'Content-Type: application/json' \
--data-raw '{
    "mode": "run",
    "component": "keboola.ex-db-snowflake",
    "config": "493493"
}'
```

Take care to use the right endpoint depending on which [Stack](https://help.keboola.com/overview/#stacks) are you using. 
You'll see `Invalid access token` error message if you are using the wrong endpoint or token. Read more about 
the concept of [Jobs](/integrate/jobs/).


================================================
File: automate/run-orchestration.md
================================================
---
title: Run Orchestration
permalink: /automate/run-orchestration/
---

Running an [Orchestration](https://help.keboola.com/orchestrator/) or Flow is in principle same as running 
a [job](/automate/run-job/). 
You can create (run) an orchestration job from the UI. A job can also be created manually via the API. 
The easiest way to get started is to create a configuration of orchestration or flow and run it manually in the UI. 
Once you're satisfied with the result, look at the successful job:

{: .image-popup}
![Screenshot -- Orchestration Parameters](/automate/orchestration-parameters.png)

In the job detail, you can see the parameters required to run the configuration, in this case:

```
mode: run
component: keboola.orchestrator
config: 1496488
```

The difference between running an arbitrary [component job](/automate/run-job/) and an orchestrator job is only in
that the `component` value is always `keboola.orchestrator`. The same component is used for both Orchestrator 
and Flow jobs.

Create a [Storage API token](https://help.keboola.com/management/project/tokens/) which you will use to 
run the API requests (if you don't have one already). We recommend to create a token with **Full Access** to
components. Though you can list the components used in the orchestration, this leads to a fragile setup when
modifying the orchestration may need the modification of the the token too.

Then use the [Create Job API call](https://app.swaggerhub.com/apis-docs/keboola/job-queue-api/1.2.4#/Jobs/createJob) to 
create a job with the same parameters 
(see [example](https://documenter.getpostman.com/view/3086797/77h845D#3e71b131-afd4-44be-9831-6534e581f2e0)):

```bash
curl --location --request POST 'https://queue.keboola.com/jobs' \
--header 'X-StorageApi-Token: YOUR_TOKEN' \
--header 'Content-Type: application/json' \
--data-raw '{
    "mode": "run",
    "component": "keboola.orchestrator",
    "config": "1496488"
}'
```

Take care to use the right endpoint depending on which [Stack](https://help.keboola.com/overview/#stacks) are you using. 
You'll see `Invalid access token` error message if you are using the wrong endpoint or token. Read more about 
the concept of [Jobs](/integrate/jobs/).


================================================
File: automate/set-schedule.md
================================================
---
title: Set Schedule
permalink: /automate/set-schedule/
---

In the UI, you can set a time schedule for [orchestration](https://help.keboola.com/orchestrator/running/#automation).
Via the API you can set a time schedule for any [configuration](https://help.keboola.com/components/) or even multiple 
schedules for a single configuration.

Assuming, you have already setup of any [configuration](https://help.keboola.com/components/)
(including Orchestrator and Flow) and you can successfully run it through the UI or through the 
[API](/automate/run-job/). Look at the successful job:

{: .image-popup}
![Screenshot -- Job Parameters](/automate/job-parameters.png)

In the job detail, you can see the parameters required to run the configuration, in this case:

```
mode: run
component: keboola.ex-db-snowflake
config: 493493
```

To create a schedule, you have to create the schedule configuration first using the 
[Create Configuration API call](https://keboola.docs.apiary.io/#reference/components-and-configurations/component-configurations/create-configuration).
With the contents similar to this:

```json
{
    "schedule": {
        "cronTab": "0 * * * *",
        "timezone": "UTC",
        "state": "enabled"
    },
    "target": {
        "componentId": "keboola.ex-db-snowflake",
        "configurationId": "493493",
        "mode": "run"
    }
}
```

The `cronTab` field defines the schedule in [cronTab expression](https://crontab.guru/#0_*_*_*_*) format. The 
`target` defines which configuration should be run. In the above example we use the same configuration from the
job. To create the configuration itself, use the `keboola.scheduler` component 
(see an [example](https://documenter.getpostman.com/view/3086797/77h845D#b721ecd8-159c-4895-9d0b-8b735880b714)):

```bash
curl --location --request POST 'https://connection.keboola.com/v2/storage/components/keboola.scheduler/configs/' \
--header 'X-StorageApi-Token: YOUR_TOKEN' \
--form 'name="Example Schedule"' \
--form 'configuration="{
    \"schedule\": {
        \"cronTab\": \"0 * * * *\",
        \"timezone\": \"UTC\",
        \"state\": \"enabled\"
    },
    \"target\": {
        \"componentId\": \"keboola.ex-db-snowflake\",
        \"configurationId\": \"493493\",
        \"mode\": \"run\"
    }
}"'
```

Take care to use the right endpoint depending on which [Stack](https://help.keboola.com/overview/#stacks) are you using. 
You'll see `Invalid access token` error message if you are using the wrong endpoint or token.
An example request response will contain:

```json
{
    "id": "10850624",
    "name": "Example Schedule",
    "description": "",
    "created": "2022-01-31T00:00:59+0100",
    "creatorToken": {
        "id": 25144,
        "description": "Run Job"
    },
    "version": 1,
    "changeDescription": "Configuration created",
    "isDisabled": false,
    "isDeleted": false,
    "configuration": {
        "schedule": {
            "cronTab": "0 * * * *",
            "timezone": "UTC",
            "state": "enabled"
        },
        "target": {
            "componentId": "keboola.ex-db-snowflake",
            "configurationId": "493493",
            "mode": "run"
        }
    },
    "state": {},
    "currentVersion": {
        "created": "2022-01-31T00:00:59+0100",
        "creatorToken": {
            "id": 25144,
            "description": "Run Job"
        },
        "changeDescription": "Configuration created"
    }
}
```

The important field is `id` (with value `10850624` in the above example). In the second step, you need to activate 
the schedule via the [Activate Schedule API call](https://app.swaggerhub.com/apis/odinuv/scheduler/1.0.0#/schedules/activate)
with he following body:

```json
{
    "configurationId": "10850624"
}
```

See an [example](https://documenter.getpostman.com/view/3086797/77h845D#130cbfc4-4dd5-4f6d-99c0-2444c48ee551)):

```bash
curl --location --request POST 'https://scheduler.azure.keboola.com/schedules' \
--header 'X-StorageApi-Token: YOUR_TOKEN' \
--header 'Content-Type: application/json' \
--data-raw '{
    "configurationId": "10850624"
}
'
```

Note: You have to use a [Master Token](https://help.keboola.com/management/project/tokens/#master-tokens) to execute the above API call.

## Configure Schedule for Row
If the configuration you're scheduling uses [Configuration rows](https://help.keboola.com/components/#configuration-rows), you can
also schedule individual rows. Assuming you have a job running a single row:

{: .image-popup}
![Screenshot -- Row Parameters](/automate/job-row-parameters.png)

You will see the the following in job parameters:

```
mode: run
component: keboola.ex-db-snowflake
config: 493493
row: 48094
```

Create a new scheduler configuration with the following configuration contents:

```json
{
    "schedule": {
        "cronTab": "10,20,30,40,50 * * * *",
        "timezone": "UTC",
        "state": "enabled"
    },
    "target": {
        "componentId": "keboola.ex-db-snowflake",
        "configurationId": "493493",
        "configurationRowIds": ["48094"],
        "mode": "run"
    }
}
```

See [example](https://documenter.getpostman.com/view/3086797/77h845D#0fadefb7-9352-45b0-8c4e-6f3742feea2a):

```bash
curl --location --request POST 'https://connection.keboola.com/v2/storage/components/keboola.scheduler/configs/' \
--header 'X-StorageApi-Token: YOUR_TOKEN' \
--form 'name="Example Row Schedule"' \
--form 'configuration="{
    \"schedule\": {
        \"cronTab\": \"10,20,30,40,50 * * * *\",
        \"timezone\": \"UTC\",
        \"state\": \"enabled\"
    },
    \"target\": {
        \"componentId\": \"keboola.ex-db-snowflake\",
        \"configurationId\": \"493493\",
        \"configurationRowIds\": [\"48094\"],
        \"mode\": \"run\"
    }
}"'
```

You'll obtain the following example:

```json
{
    "id": "10852379",
    "name": "Example Row Schedule",
    "description": "",
    "created": "2022-01-31T00:42:15+0100",
    "creatorToken": {
        "id": 322,
        "description": "ondrej.popelka@keboola.com"
    },
    "version": 1,
    "changeDescription": "Configuration created",
    "isDisabled": false,
    "isDeleted": false,
    "configuration": {
        "schedule": {
            "cronTab": "10,20,30,40,50 * * * *",
            "timezone": "UTC",
            "state": "enabled"
        },
        "target": {
            "componentId": "keboola.ex-db-snowflake",
            "configurationId": "493493",
            "configurationRowIds": [
                "48094"
            ],
            "mode": "run"
        }
    },
    "state": {},
    "currentVersion": {
        "created": "2022-01-31T00:42:15+0100",
        "creatorToken": {
            "id": 322,
            "description": "ondrej.popelka@keboola.com"
        },
        "changeDescription": "Configuration created"
    }
}
```

The created configuration has id `10852379`. You can now [Activate the Schedule](https://app.swaggerhub.com/apis/odinuv/scheduler/1.0.0#/schedules/activate)
with he following body:

```json
{
    "configurationId": "10852379"
}
```

See an [example](https://documenter.getpostman.com/view/3086797/77h845D#130cbfc4-4dd5-4f6d-99c0-2444c48ee551)):

```bash
curl --location --request POST 'https://scheduler.keboola.com/schedules' \
--header 'X-StorageApi-Token: YOUR_TOKEN' \
--header 'Content-Type: application/json' \
--data-raw '{
    "configurationId": "10852379"
}
'
```

This also demonstrates that you can set multiple schedules for a single configuration. In this case, the configuration 
`10852379` of the `keboola.ex-db-snowflake` will be executed at the beginning of every hour. Then the row `48094` of 
this configuration will also be executed every 10 minutes. To list the schedules use the 
[Get Schedules API call](https://app.swaggerhub.com/apis/odinuv/scheduler/1.0.0#/schedules/get_schedules) --
(see [example](https://documenter.getpostman.com/view/3086797/77h845D#6e0f31b1-9d50-4b51-9570-5334936d569c)). You'll get
a response similar to this:

```json
[
    {
        "id": "743",
        "tokenId": "25147",
        "configurationId": "10850624",
        "configurationVersionId": "1",
        "schedule": {
            "cronTab": "0 * * * *",
            "timezone": "UTC",
            "state": "enabled"
        },
        "target": {
            "componentId": "keboola.ex-db-snowflake",
            "configurationId": "493493",
            "configurationRowIds": [],
            "mode": "run",
            "tag": ""
        },
        "executions": []
    },
    {
        "id": "744",
        "tokenId": "25148",
        "configurationId": "10852379",
        "configurationVersionId": "1",
        "schedule": {
            "cronTab": "10,20,30,40,50 * * * *",
            "timezone": "UTC",
            "state": "enabled"
        },
        "target": {
            "componentId": "keboola.ex-db-snowflake",
            "configurationId": "493493",
            "configurationRowIds": [
                "48094"
            ],
            "mode": "run",
            "tag": ""
        },
        "executions": []
    }
]
```


================================================
File: cli/index.md
================================================
---
title: CLI
permalink: /cli/
---

* TOC
{:toc}

Keboola CLI (Command Line Interface), known also as "Keboola as Code", is a set of commands for operating your cloud data 
pipeline. It is available to install in the Windows, macOS, and Linux environments.

The whole Keboola project is represented by a local [directory structure](/cli/structure/#directory-structure). 
[Component configurations](https://help.keboola.com/components) are represented by [JSON files](/cli/structure/#configurations).

## Use Cases

Keboola CLI can be used, for example, to:
- Pull your entire project to a local directory in seconds. See the [init](/cli/commands/sync/init/) and [pull](/cli/commands/sync/pull/) commands.
- Bulk edit [component configurations](https://help.keboola.com/components) in your IDE.
- Compare the local version with the current project state. See the [diff](/cli/commands/sync/diff/) command.
- Copy a [configuration](https://help.keboola.com/components) as a directory in the project and between projects. See the [persist](/cli/commands/local/persist/) command.
- Apply all changes back to the project in a moment. See the [push](/cli/commands/sync/push/) command.
- Manage project history in a git repository.
- Automate the whole process in a CI/CD pipeline. See [GitHub Integration](/cli/github-integration/).
- Merge and rebase Keboola Branches via Git. Learn more in the [Example Use Cases]() section.
- Distribute a single project definition into multiple projects. See the [Example Use Cases]() section.
- Multi-stage (and multi-project) environment management via Git. See the [Example Use Cases]() section. 
- Locally develop and test your dbt transformation code.

## Subsystems

A brief overview of supported subsystems of the project.

### Configurations

- [Component configurations](https://help.keboola.com/components) and [configuration rows](https://help.keboola.com/components/#configuration-rows) are fully supported.
- This includes all special types of components, such as:
  - [Transformations](/cli/structure/#transformations), [Variables](/cli/structure/#variables), [Shared Codes](/cli/structure/#shared-code), [Schedules](/cli/structure/#schedules) and [Orchestrations](/cli/structure/#orchestrations).   

### Development Branches

- A [branch](https://help.keboola.com/components/branches/)  can be [pulled](/cli/commands/sync/pull/) and then edited or deleted locally. 
- Changes can be [pushed](/cli/commands/sync/push/) back to the project.
- There is one limitation, **a branch cannot be created locally**. 
  - A branch must be created directly in the project, from the `main` branch.
  - See the [Create Branch](/cli/commands/remote/create/branch/) command.

### Storage

At the moment, all [Storage](https://help.keboola.com/storage/) related operations are sub-commands of the [kbc remote](/cli/commands/remote/) command. They operate directly on a project. This means that any changes you make using the CLI are immediately applied to your project. We have plans to add support for managing buckets and tables locally using definition files just like component configurations.


#### Files

- To upload a file, use the [file upload](/cli/commands/remote/file/upload/) command.
- To download a file, use the [file download](/cli/commands/remote/file/download/) command.

#### Buckets and tables

These commands can be used to manage the [buckets](https://help.keboola.com/storage/buckets/) and [tables](https://help.keboola.com/storage/tables/) in your project:
- To create a new bucket, use the [create bucket](/cli/commands/remote/create/bucket/) command. 
- To create a new table, use the [create table](/cli/commands/remote/create/table/) command.

The resulting [tables](https://help.keboola.com/storage/tables/) will be empty, so you may want to use:
- The [table import](/cli/commands/remote/table/import/) command to import data. 
- The [table unload](/cli/commands/remote/table/unload/) command can be used to take data out of a table and store it in a file.

For convenience, you can use combined commands:
- The [table upload](/cli/commands/remote/table/upload/) command combines the [file upload](/cli/commands/remote/file/upload/) + [table import](/cli/commands/remote/table/import/) operations.
- The [table download](/cli/commands/remote/table/download/) command combines the [table unload](/cli/commands/remote/table/unload/) + [file download](/cli/commands/remote/file/download/) operations.

These commands may be a little heavy if you are dealing with a lot of data.
- If you just want a quick sample, use the [table preview](/cli/commands/remote/table/preview/) command.

## Next Steps

- [Installation](/cli/installation/)
- [Getting Started](/cli/getting-started/)
- [Directory Structure](/cli/structure/)
- [Commands](/cli/commands/)


================================================
File: cli/commands/index.md
================================================
---
title: Commands
permalink: /cli/commands/
---

* TOC
{:toc}


Run `help` to list all available commands.
```
kbc help
```

You can also get details of any command.
```
kbc help <command>
kbc help local create row
```

## Available Commands

|---
| Command | Description
|-|-|-
| [kbc help](/cli/commands/help/) | Show help for any command. |
| [kbc status](/cli/commands/status/) | Show information about a working directory. |
| | |
| **[kbc sync](/cli/commands/sync/)** | **Synchronization between a [local directory](/cli/structure/) and a [project](/cli/#subsystems).** |
| [kbc sync init](/cli/commands/sync/init/) | Initialize a new local directory and run `kbc sync pull`. |
| [kbc sync pull](/cli/commands/sync/pull/) | Sync a project to the local directory. |
| [kbc sync push](/cli/commands/sync/push/) | Sync a local directory to the project. |
| [kbc sync diff](/cli/commands/sync/diff/) | Show differences between a local directory and a project. |
| | |
| **[kbc ci](/cli/commands/ci/)** | **Manage the CI/CD pipeline.** |
| [kbc ci workflows](/cli/commands/ci/workflows/) | Generate workflows for [GitHub Actions integration](/cli/github-integration/). |
| | |
| **[kbc local](/cli/commands/local/)** | **Operations in the [local directory](/cli/structure/) don't affect the project.** |
| [kbc local create](/cli/commands/local/create/) | Create an object in the local directory. |
| [kbc local create config](/cli/commands/local/create/config/) | Create an empty [configuration](https://help.keboola.com/components/). |
| [kbc local create row](/cli/commands/local/create/row/) | Create an empty [configuration row](https://help.keboola.com/components/#configuration-rows). |
| [kbc local persist](/cli/commands/local/persist/) | Detect new directories with a [configuration](https://help.keboola.com/components/) or a [configuration row](https://help.keboola.com/components/#configuration-rows). |
| [kbc local encrypt](/cli/commands/local/encrypt/) | Encrypt all [unencrypted secrets](/overview/encryption/#encrypting-data-with-api). |
| [kbc local validate](/cli/commands/local/validate/) | Validate the local directory. |
| [kbc local validate config](/cli/commands/local/validate/config/) | Validate a configuration JSON file. |
| [kbc local validate row](/cli/commands/local/validate/row/) | Validate a configuration row JSON file. |
| [kbc local validate schema](/cli/commands/local/validate/schema/) | Validate a configuration/row JSON file by a JSON schema file. |
| [kbc local fix-paths](/cli/commands/local/fix-paths/) | Ensure that all local paths match [configured naming](/cli/structure/#naming). |
| | |
| **[kbc remote](/cli/commands/remote/)** | **Operations directly in the [project](/cli/#subsystems).** |
| [kbc remote create](/cli/commands/remote/create/) | Create an object in the project. |
| [kbc remote create branch](/cli/commands/remote/create/branch/) | Create a new [branch](https://help.keboola.com/components/branches/) from the `main` branch. |
| [kbc remote create bucket](/cli/commands/remote/create/bucket/) | Create a new [bucket](https://help.keboola.com/storage/buckets/). |
| [kbc remote file](/cli/commands/remote/file/) | Manage [files](https://help.keboola.com/storage/files/) in Storage. |
| [kbc remote file download](/cli/commands/remote/file/download/) | Download a [file](https://help.keboola.com/storage/files/) from Storage. |
| [kbc remote file upload](/cli/commands/remote/file/upload/) | Upload a [file](https://help.keboola.com/storage/files/) to Storage. |
| [kbc remote job](/cli/commands/remote/job/) | Manage [jobs](https://help.keboola.com/management/jobs/) in the project. |
| [kbc remote job run](/cli/commands/remote/job/run/) | Run one or more [jobs](https://help.keboola.com/management/jobs/). |
| [kbc remote table](/cli/commands/remote/table/) | Manage [tables](https://help.keboola.com/storage/tables/) in the project. |
| [kbc remote table create](/cli/commands/remote/table/create/) | Create a new [table](https://help.keboola.com/storage/tables/). |
| [kbc remote table upload](/cli/commands/remote/table/upload/) | Upload a CSV file to a [table](https://help.keboola.com/storage/tables/). |
| [kbc remote table download](/cli/commands/remote/table/download/) | Download data from a [table](https://help.keboola.com/storage/tables/). |
| [kbc remote table preview](/cli/commands/remote/table/preview/) | Preview up to 1000 rows from a [table](https://help.keboola.com/storage/tables/). |
| [kbc remote table detail](/cli/commands/remote/table/detail/) | Print [table](https://help.keboola.com/storage/tables/) details. |
| [kbc remote table import](/cli/commands/remote/table/import/) | Import data to a [table](https://help.keboola.com/storage/tables/) from a [file](https://help.keboola.com/storage/files/). |
| [kbc remote table unload](/cli/commands/remote/table/unload/) | Unload a [table](https://help.keboola.com/storage/tables/) into a [file](https://help.keboola.com/storage/files/). |
| [kbc remote workspace](/cli/commands/remote/create/) | Manage workspaces in the project. |
| [kbc remote workspace create](/cli/commands/remote/workspace/create/) | Create a workspace in the project. |
| [kbc remote workspace delete](/cli/commands/remote/workspace/delete/) | Delete a workspace in the project. |
| [kbc remote workspace detail](/cli/commands/remote/workspace/detail/) | Print workspace details and credentials. |
| [kbc remote workspace list](/cli/commands/remote/workspace/list/) | List workspaces in the project. |
| | |
| **[kbc local template](/cli/commands/local/template/)** | **Manage [template](/cli/templates/structure/#template) instances in the [project directory](/cli/structure/).** |
| [kbc local template delete](/cli/commands/local/template/delete/) | Delete a template instance from the local directory. |
| [kbc local template list](/cli/commands/local/template/list/) | List template instances used in the project. |
| [kbc local template use](/cli/commands/local/template/use/) | Use the template in the project directory. |
| | |
| **[kbc template](/cli/commands/template/)** | **Manage [templates](/cli/templates/structure/#template) in the [template repository](/cli/templates/structure/#repository).** |
| [kbc template create](/cli/commands/template/create/) | Create a template in the repository directory. |
| [kbc template describe](/cli/commands/template/describe/) | Describe a template and its inputs. |
| [kbc template list](/cli/commands/template/list/) | List templates in the repository. |
| [kbc template repository init](/cli/commands/template/repository/init/) | Initialize a new repository directory. |
| [kbc template test](/cli/commands/template/test/) | Manage template tests. |
| [kbc template test create](/cli/commands/template/test/create/) | Create template tests. |
| [kbc template test run](/cli/commands/template/test/run/) | Run template tests. |
| | |
| **[kbc dbt](/cli/commands/dbt/)** | **Work with dbt inside your repository.** |
| [kbc dbt init](/cli/commands/dbt/init/) | Initialize profiles, sources, and environment variables for use with dbt. |
| [kbc dbt generate](/cli/commands/dbt/generate/) | Generate profiles, sources, and environment variables for use with dbt. |
| [kbc dbt generate profile](/cli/commands/dbt/generate/profile/) | Generate profiles for use with dbt. |
| [kbc dbt generate sources](/cli/commands/dbt/generate/sources/) | Generate sources for use with dbt. |
| [kbc dbt generate env](/cli/commands/dbt/generate/env/) | Generate environment variables for use with dbt. |

## Aliases

The most used commands have their shorter aliases.

For example, you can use `kbc c` instead of `kbc local create`.

|---
| Full Command | Aliases
|-|-|-
| `kbc sync init`      |  `kbc init`, `kbc i`
| `kbc sync diff`      |  `kbc diff`, `kbc d`
| `kbc sync pull`      |  `kbc pull`, `kbc pl` 
| `kbc sync push`      |  `kbc push`, `kbc ph`
| `kbc local validate` |  `kbc validate`, `kbc v`
| `kbc local persist`  |  `kbc persist`, `kbc pt`
| `kbc local create`   |  `kbc create`, `kbc c`
| `kbc local encrypt`  |  `kbc encrypt`, `kbc e`

## Options 

Options are a way to modify the behavior of a command, they can be:
- **[Global](#global-options)**, for all commands, see below.
- **Local**, only for a specific command, see the command help.

#### Command-line flags

- Entered as part of the CLI command.
- One-letter flags start with `-`, for example `-v`.
- Longer flags start with `--`, for example `--verbose`.
- **Flags take precedence over environment variables.**


#### Environment variables

- Each flag can be defined via an environment variable.
- Variable name is based on the flag name, and starts with `KBC_`.
- All letters are changed to uppercase and dashes to underscores.
- For example, flag `--log-file` can be defined by the `KBC_LOG_FILE` environment variable.
- Sources and priority of the environment variables:
    1. From the OS environment.
    2. From environment files in the working directory.
    3. From environment files in the project directory.

All found environment files are automatically loaded.  
Variables are merged together according to the following priority.

|---
| Environment File | Environment | Priority
|-|-|-
| `.env.development.local`  | Development | The highest |  
| `.env.test.local`         | Test |  |
| `.env.production.local`   | Production |  |
| `.env.local`              | Wherever the file is |  |
| `.env.development`        | Development|  |
| `.env.test`               | Test|  |
| `.env.production`         | Production|  |
| `.env`                    | All | The lowest  |

*Note: All `.*local` environment files should be part of the `.gitignore` file, if used.*

### Global Options

`-h, --help`
: Show help for the command

`-l, --log-file <string>`
: Path to a log file to store the details in

`-t, --storage-api-token <string>`
: Storage API token to the project

`-v, --verbose`
: Increase output verbosity

`--verbose-api`
: Log each API request and its response

`-V, --version`
: Show the version

`-d, --working-dir <string>`
: Use another working directory

## Next Steps

- [Installation](/cli/installation/)
- [Getting Started](/cli/getting-started/)
- [Directory Structure](/cli/structure/)
- [GitHub Integration](/cli/github-integration/)


================================================
File: cli/commands/ci/index.md
================================================
---
title: CI Command
permalink: /cli/commands/ci/
---

* TOC
{:toc}

Commands to manage the CI/CD pipeline.

```
kbc ci [command]
```

|---
| Command | Description
|-|-|-
| [kbc ci workflows](/cli/commands/ci/workflows/) | Generate workflows for [GitHub Actions integration](/cli/github-integration/). |


================================================
File: cli/commands/ci/workflows/index.md
================================================
---
title: Workflows
permalink: /cli/commands/ci/workflows/
---

* TOC
{:toc}

**Generate workflows for [GitHub Actions integration](/cli/github-integration/).**

```
kbc ci workflows [flags]
```

You will be prompted to choose which workflows you want to generate:
- `validate` - validates all branches on change
- `push` - pushes each change in the main branch to the project
- `pull` - pulls the main branch from the project every five minutes

## Options

`--ci-main-branch <string>`
: Name of the main branch for push/pull workflows (default "main")

`--ci-pull <bool>`
: Create a workflow to sync the main branch from the project every five minutes (default true)

`--ci-push <bool>`
: Create a workflow to push changes in the main branch to the project (default true)

`--ci-validate <bool>`
: Create a workflow to validate all branches on change to a GitHub branch (default true)

[Global Options](/cli/commands/#global-options)

## Example

```
➜ kbc workflows

Please confirm the GitHub Actions you want to generate.

? Generate "validate" workflow?
All GitHub branches will be validated on change. Yes

? Generate "push" workflow?
Each change in the main GitHub branch will be pushed to the project. Yes

? Generate "pull" workflow?
The main GitHub branch will be synchronized every five minutes.
If a change is found, a new commit is created and pushed. Yes

? Please select the main GitHub branch name: main

Generating CI workflows ...
Created file ".github/actions/install/action.yml".
Created file ".github/workflows/validate.yml".
Created file ".github/workflows/push.yml".
Created file ".github/workflows/pull.yml".

CI workflows have been generated.
Feel free to modify them.

Please set the secret KBC_STORAGE_API_TOKEN in the GitHub settings.
See: https://docs.github.com/en/actions/reference/encrypted-secrets
```

## Next Steps

- [All Commands](/cli/commands/)
- [GitHub Integration](/cli/github-integration/)


================================================
File: cli/commands/dbt/index.md
================================================
---
title: dbt Command
permalink: /cli/commands/dbt/
---

* TOC
{:toc}

**Work with dbt inside your repository.**

The commands must be run in a directory with a dbt project (i.e. containing `dbt_project.yml`) or its subdirectory.

See the [introduction to dbt support](/cli/dbt/) for more information.

```
kbc dbt [command]
```

|---
| Command | Description
|-|-|-
| [kbc dbt init](/cli/commands/dbt/init/) | Initialize profiles, sources, and environment variables for use with dbt. |
| [kbc dbt generate](/cli/commands/dbt/generate/) | Generate profiles, sources, or environment variables for use with dbt. |
| [kbc dbt generate profile](/cli/commands/dbt/generate/profile/) | Generate profiles for use with dbt. |
| [kbc dbt generate sources](/cli/commands/dbt/generate/sources/) | Generate sources for use with dbt. |
| [kbc dbt generate env](/cli/commands/dbt/generate/env/) | Generate environment variables for use with dbt. |


================================================
File: cli/commands/dbt/generate/index.md
================================================
---
title: Generate Command
permalink: /cli/commands/dbt/generate/
---

* TOC
{:toc}

**Work with dbt inside your repository.**

The commands must be run in a directory with a dbt project (i.e., containing `dbt_project.yml`) or its subdirectory.

```
kbc dbt generate [command]
```

|---
| Command | Description
|-|-|-
| [kbc dbt generate profile](/cli/commands/dbt/generate/profile/) | Generate profiles for use with dbt. |
| [kbc dbt generate sources](/cli/commands/dbt/generate/sources/) | Generate sources for use with dbt. |
| [kbc dbt generate env](/cli/commands/dbt/generate/env/) | Generate environment variables for use with dbt. |


================================================
File: cli/commands/dbt/generate/env/index.md
================================================
---
title: Generate Env Command
permalink: /cli/commands/dbt/generate/env/
---

* TOC
{:toc}

**Generates sources in the dbt project directory.**

```
kbc dbt generate sources [flags]
```

The command must be run in a directory with a dbt project (i.e., containing `dbt_project.yml`) or its subdirectory.

The command outputs commands to create environment variables from a selected existing Snowflake workspace.

See the [introduction to dbt support](/cli/dbt/) for more information.

## Options

`-H, --storage-api-host <string>`
: Storage API host, e.g., "connection.keboola.com"

`-T, --target-name <string>`
: Target name of the profile

`-W, --workspace-id <string>`
: ID of the workspace to use

[Global Options](/cli/commands/#global-options)

## Examples

```
➜ kbc dbt generate env

Please enter the Keboola Storage API host, e.g., "connection.keboola.com".
? API host: connection.north-europe.azure.keboola.com


Please enter the Keboola Storage API token. The value will be hidden.
? API token: **************************************************


Please enter the target name.
Allowed characters: a-z, A-Z, 0-9, "_".
? Target Name: target1


? Workspace: dbt_workspace (12345678)

Commands to set the environment for the dbt target:
  export DBT_KBC_TARGET1_TYPE=snowflake
  export DBT_KBC_TARGET1_SCHEMA=WORKSPACE_123456
  export DBT_KBC_TARGET1_WAREHOUSE=KEBOOLA_PROD_SMALL
  export DBT_KBC_TARGET1_DATABASE=KEBOOLA_1234
  export DBT_KBC_TARGET1_ACCOUNT=keboola.west-europe.azure
  export DBT_KBC_TARGET1_USER=KEBOOLA_WORKSPACE_123456
  export DBT_KBC_TARGET1_PASSWORD=abcd123456
```

## Next Steps

- [dbt generate](/cli/commands/dbt/generate/)
- [Introduction to dbt support](/cli/dbt/)


================================================
File: cli/commands/dbt/generate/profile/index.md
================================================
---
title: Generate Profile Command
permalink: /cli/commands/dbt/generate/profile/
---

* TOC
{:toc}

**Generates a profile file in the dbt project directory.**

```
kbc dbt generate profile [flags]
```

The command must be run in a directory with a dbt project (i.e., containing `dbt_project.yml`) or its subdirectory.

The command creates a `profiles.yml` file if it does not exist yet and prepares outputs for the selected target.

See the [introduction to dbt support](/cli/dbt/) for more information.

## Options

`-T, --target-name <string>`
: Target name of the profile

[Global Options](/cli/commands/#global-options)

## Examples

```
➜ kbc dbt generate profile -T target1

Profile stored in "profiles.yml".
```

The generated `profiles.yml`:

{% raw  %}
```yaml
TestProject:
    target: target1
    outputs:
        target1:
            account: '{{ env_var("DBT_KBC_TARGET1_ACCOUNT") }}'
            database: '{{ env_var("DBT_KBC_TARGET1_DATABASE") }}'
            password: '{{ env_var("DBT_KBC_TARGET1_PASSWORD") }}'
            schema: '{{ env_var("DBT_KBC_TARGET1_SCHEMA") }}'
            type: '{{ env_var("DBT_KBC_TARGET1_TYPE") }}'
            user: '{{ env_var("DBT_KBC_TARGET1_USER") }}'
            warehouse: '{{ env_var("DBT_KBC_TARGET1_WAREHOUSE") }}'
send_anonymous_usage_stats: false
```
{% endraw %}

## Next Steps

- [dbt generate](/cli/commands/dbt/generate/)
- [Introduction to dbt support](/cli/dbt/)


================================================
File: cli/commands/dbt/generate/sources/index.md
================================================
---
title: Generate Sources Command
permalink: /cli/commands/dbt/generate/sources/
---

* TOC
{:toc}

**Generates sources in the dbt project directory.**

```
kbc dbt generate sources [flags]
```

The command must be run in a directory with a dbt project (i.e., containing `dbt_project.yml`) or its subdirectory.

The command creates a file for each Storage bucket in the `models/_sources` directory containing a dbt source for every table in the bucket.

See the [introduction to dbt support](/cli/dbt/) for more information.

## Options

`-H, --storage-api-host <string>`
: Storage API host, e.g., "connection.keboola.com"

`-T, --target-name <string>`
: Target name of the profile

[Global Options](/cli/commands/#global-options)

## Examples

```
➜ kbc dbt generate sources

Please enter the Keboola Storage API host, e.g., "connection.keboola.com".
? API host: connection.north-europe.azure.keboola.com


Please enter the Keboola Storage API token. The value will be hidden.
? API token: **************************************************


Please enter the target name.
Allowed characters: a-z, A-Z, 0-9, "_".
? Target Name: target1

Sources stored in the "models/_sources" directory.
```

A generated source file `models/_sources/in.c-test.yml`:

{% raw  %}
```yaml
version: 2
sources:
    - name: in.c-test
      freshness:
        warn_after:
            count: 1
            period: day
      database: '{{ env_var("DBT_KBC_TARGET1_DATABASE") }}'
      schema: in.c-test
      loaded_at_field: '"_timestamp"'
      tables:
        - name: products
          quoting:
            database: true
            schema: true
            identifier: true
          columns: []
```
{% endraw %}

## Next Steps

- [dbt generate](/cli/commands/dbt/generate/)
- [Introduction to dbt support](/cli/dbt/)


================================================
File: cli/commands/dbt/init/index.md
================================================
---
title: dbt Init Command
permalink: /cli/commands/dbt/init/
---

* TOC
{:toc}

**Initialize a new Snowflake workspace, generate profiles, sources, and environment variables to use in your dbt project.**

```
kbc dbt init [flags]
```

The command must be run in a directory with a dbt project (i.e., containing `dbt_project.yml`) or its subdirectory.

See the [introduction to dbt support](/cli/dbt/) for more information.

## Options

`-H, --storage-api-host <string>`
: Storage API host, e.g., "connection.keboola.com"

`-T, --target-name <string>`
: Target name of the profile

`-W, --workspace-name <string>` 
: Name of the workspace to be created

[Global Options](/cli/commands/#global-options)

## Examples

```
➜ kbc dbt init

Please enter the Keboola Storage API host, e.g., "connection.keboola.com".
? API host: connection.north-europe.azure.keboola.com


Please enter the Keboola Storage API token. The value will be hidden.
? API token: **************************************************


Please enter the target name.
Allowed characters: a-z, A-Z, 0-9, "_".
? Target Name: TARGET1


? Enter a name for the workspace to be created: dbt_workspace

Creating a new workspace, please wait.
Created new workspace "dbt_workspace".
Profile stored in "profiles.yml".
Sources stored in "models/_sources" directory.
Commands to set environment for the dbt target:
  export DBT_KBC_TARGET1_TYPE=snowflake
  export DBT_KBC_TARGET1_SCHEMA=WORKSPACE_12345
  export DBT_KBC_TARGET1_WAREHOUSE=KEBOOLA_PROD_SMALL
  export DBT_KBC_TARGET1_DATABASE=KEBOOLA_1234
  export DBT_KBC_TARGET1_ACCOUNT=keboola.west-europe.azure
  export DBT_KBC_TARGET1_USER=KEBOOLA_WORKSPACE_12345
  export DBT_KBC_TARGET1_PASSWORD=abcd1234
```

## Next Steps

- [dbt generate](/cli/commands/dbt/generate/)
- [Introduction to dbt support](/cli/dbt/)


================================================
File: cli/commands/help/index.md
================================================
---
title: Help Command
permalink: /cli/commands/help/
---

* TOC
{:toc}

**Shows help for any command.**

```
kbc help [command] [flags]
```

## Options

[Global Options](/cli/commands/#global-options)

## Example

```
kbc help local create config
```

## Next Steps

- [All Commands](/cli/commands/)
- [Init](/cli/commands/sync/init/)


================================================
File: cli/commands/local/index.md
================================================
---
title: Local Command
permalink: /cli/commands/local/
---

* TOC
{:toc}

**Operations in the [local directory](/cli/structure/) don't affect the project.**

```
kbc local [command]
```

|---
| Command | Description
|-|-|-
| **[kbc local create](/cli/commands/local/create/)** | **Create an object in the local directory.** |
| [kbc local create config](/cli/commands/local/create/config/) | Create an empty [configuration](https://help.keboola.com/components/). |
| [kbc local create row](/cli/commands/local/create/row/) | Create an empty [configuration row](https://help.keboola.com/components/#configuration-rows). |
| | |
| [kbc local persist](/cli/commands/local/persist/) | Detect new directories with a [configuration](https://help.keboola.com/components/) or a [configuration row](https://help.keboola.com/components/#configuration-rows). |
| [kbc local encrypt](/cli/commands/local/encrypt/) | Encrypt all [unencrypted secrets](/overview/encryption/#encrypting-data-with-api). |
| [kbc local validate](/cli/commands/local/validate/) | Validate the local directory. |
| [kbc local fix-paths](/cli/commands/local/fix-paths/) | Ensure that all local paths match [configured naming](/cli/structure/#naming). |
| | |
| **[kbc local template](/cli/commands/local/template/)** | **Manage [templates](/cli/templates/structure/#template) instances in the [project directory](/cli/structure/).** |
| [kbc local template delete](/cli/commands/local/template/delete/) | Delete a template instance from the local directory. |
| [kbc local template list](/cli/commands/local/template/list/) | List templates instances used in the project. |
| [kbc local template upgrade](/cli/commands/local/template/upgrade/) | Upgrade a template instance from the local directory. |
| [kbc local template use](/cli/commands/local/template/use/) | Use the template in the project directory. |


================================================
File: cli/commands/local/create/index.md
================================================
---
title: Create Local Object
permalink: /cli/commands/local/create/
---

* TOC
{:toc}

**Create an object in the [local directory](/cli/structure/).**

```
kbc local create [config/row] [flags]
```

Or shorter:
```
kbc create [config/row] [flags]
kbc c [config/row] [flags]
```

Shows an interactive dialog if you do not enter a sub-command.

|---
| Command | Description
|-|-|-
| [kbc local create config](/cli/commands/local/create/config/) | Create an empty [configuration](https://help.keboola.com/components/). |
| [kbc local create row](/cli/commands/local/create/row/) | Create an empty [configuration row](https://help.keboola.com/components/#configuration-rows). |


================================================
File: cli/commands/local/create/config/index.md
================================================
---
title: Create Configuration
permalink: /cli/commands/local/create/config/
---

* TOC
{:toc}

**Create an empty [configuration](https://help.keboola.com/components/).**

```
kbc local create config [flags]
```

Or shorter:

```
kbc create config [flags]
```

```
kbc c config [flags]
```

Create an empty configuration in your [local directory](/cli/structure/) and assign it a unique ID (i.e., the [persist](/cli/commands/local/persist/) 
command is called automatically). To save it to the project, run the [kbc sync push](/cli/commands/sync/push/) command afterwards. You will 
be prompted for a name, a branch, and a component ID.

Some components have a default content that will be used (if specified by the component author). 
For others, `config.json` will only contain an empty JSON document `{}`.


*Tip: You can create a new configuration by copying an existing one and running the [persist](/cli/commands/local/persist/) 
command.*

### Options

`-b, --branch string <string>`
: Id or name of the branch

`-c, --component-id <string>`
: Id of the component

`-n, --name <string>`
: Name of the new configuration

[Global Options](/cli/commands/#global-options)

### Examples

```
➜ kbc create config

? Enter a name for the new config invoices

? Select the target branch Main (4908)

? Select the target component MySQL extractor (keboola.ex-db-mysql)
Created new config "main/extractor/keboola.ex-db-mysql/invoices"
```

```
➜ kbc create config -n invoices -b main -c keboola.ex-db-mysql
Created new config "main/extractor/keboola.ex-db-mysql/invoices"
```

## Next Steps

- [All Commands](/cli/commands/)
- [Create Configuration Row](/cli/commands/local/create/row/)
- [Create Branch](/cli/commands/remote/create/brabch/)


================================================
File: cli/commands/local/create/row/index.md
================================================
---
title: Create Configuration Row
permalink: /cli/commands/local/create/row/
---

* TOC
{:toc}

**Create an empty [configuration row](https://help.keboola.com/components/#configuration-rows).**

```
kbc local create row [flags]
```

Or shorter:
```
kbc create row [flags]
kbc c row [flags]
```

Create a new configuration row in your [local directory](/cli/structure/) and assign it a unique ID (i.e., the [persist](/cli/commands/local/persist/)
command is called automatically). To save it to the project, run the [kbc sync push](/cli/commands/sync/push/) command afterwards. You will
be prompted for a name, a branch, and a component ID.

Some components have a default content that will be used (if specified by the component author).
For others, `config.json` will only contain an empty JSON document `{}`.

*Tip: You can create a new configuration row by copying an existing one and running the [persist](/cli/commands/local/persist/) command.*

### Options

`-b, --branch string <string>`
: Id or name of the branch

`-c, --config <string>`
: Id or name of the configuration

`-n, --name <string>`
: Name of the new configuration row

[Global Options](/cli/commands/#global-options)

### Examples

```
➜ kbc create row

? Enter a name for the new config row customer

? Select the target branch Main (4908)

? Select the target config invoices (7475544)
Created new config row "main/extractor/keboola.ex-db-mysql/invoices/rows/customer"
```

```
➜ kbc create config -n customer -b main -c invoices
Created new config row "main/extractor/keboola.ex-db-mysql/invoices/rows/customer"
```

## Next Steps

- [All Commands](/cli/commands/)
- [Create Configuration](/cli/commands/local/create/config/)
- [Create Branch](/cli/commands/remote/create/brabch/)


================================================
File: cli/commands/local/encrypt/index.md
================================================
---
title: Encrypt Command
permalink: /cli/commands/local/encrypt/
---

* TOC
{:toc}

Encrypt all [unencrypted secrets](/overview/encryption/#encrypting-data-with-api) in the [local directory](/cli/structure/).

```
kbc local encrypt [flags]
```

Or shorter:
```
kbc e [flags]
```

[Unencrypted secrets](/overview/encryption/#encrypting-data-with-api) are values of properties prefixed by `#` that have not been encrypted 
yet. 

For example, `{"#someSecretProperty": "secret value"}`  
will be transformed into `{"#someSecretProperty": "KBC::ProjectSecure::<encryptedcontent>"}`.

## Options

`--dry-run`
: Preview all values that would be affected

[Global Options](/cli/commands/#global-options)

## Examples

Let's say you create a configuration for the MySQL extractor:

```json
{
  "parameters": {
    "host": "our.mysql.server.dev",
    "user": "keboola",
    "#password": "super-secret"
  }
}
```

The preview will look like this:

```
➜ kbc encrypt --dry-run
Plan for "encrypt" operation:
  C main/extractor/keboola.ex-db-mysql/invoices
    parameters.#password
Dry run, nothing changed.
```

The actual encrypt command: 

```
➜ kbc encrypt
Plan for "encrypt" operation:
  C main/extractor/keboola.ex-db-mysql/invoices
    parameters.#password
Encrypt done.
```

And the configuration now looks like this:

```json
{
  "parameters": {
    "host": "our.mysql.server.dev",
    "user": "keboola",
    "#password": "KBC::ProjectSecureKV::eJxLtDK2qs60MrIutrI0s1K695WJQWmhYOI9j2l/twSJl0/nsf6auv/Fs7n5VWvj+tbwvtyz/PSh30Jz8/Y2B0QyPDwteXK/3d7GN55b/y3rK+BbXLF1ne5sg6/Lja/vfzlT4TbvXfkFIuHL9DU0knh8yvedF0lXss60MgbaZQS0Kz01Tzc1L7mosqAkv8jM0NIgzdTU0NQw1cACpMoEqMrYyEop1cjM0DjZzNzE0tLYxNTQMtEw0dLYKCnN0sDS1DjV3EzJuhYAzUBL0A=="
  }
}
```

## Next Steps

- [All Commands](/cli/commands/)
- [Diff](/cli/commands/sync/diff/)
- [Push](/cli/commands/sync/push/)


================================================
File: cli/commands/local/fix-paths/index.md
================================================
---
title: Fix Paths Command
permalink: /cli/commands/local/fix-paths/
---

* TOC
{:toc}

**Ensure that all local paths match [configured naming](/cli/structure/#naming).**

```
kbc local fix-paths [flags]
```

The command unifies names of configurations, rows, and other directories based on [configured naming](/cli/structure/#naming).
For example, if the configuration name in `meta.json` changes, this command renames the directory by that name.
It is run automatically after [pull](/cli/commands/sync/pull/). 

## Options

`--dry-run`
: Preview all paths that would be affected

[Global Options](/cli/commands/#global-options)

## Examples

When you have a config and rename it in its `meta.json`, run the command afterwards. It will rename the directory:

```
➜ kbc fix-paths --dry-run
Plan for "rename" operation:
  - main/extractor/ex-generic-v2/{wiki-001 -> wiki-2}
Dry run, nothing changed.
Fix paths done.
```

## Next Steps

- [All Commands](/cli/commands/)
- [Persist](/cli/commands/local/persist)


================================================
File: cli/commands/local/persist/index.md
================================================
---
title: Persist Command
permalink: /cli/commands/local/persist/
---

* TOC
{:toc}

**Detect new directories with a [configuration](https://help.keboola.com/components/) or a [configuration row](https://help.keboola.com/components/#configuration-rows) in the [local directory](/cli/structure/).**

```
kbc local persist [flags]
```

Or shorter:
```
kbc p [flags]
```

Propagate changes in the [local directory](/cli/structure/) to the manifest. When you manually create a configuration or a row (e.g., by 
copy & paste of another existing configuration), the command will add its record to the [manifest](/cli/structure/#manifest) and generate a new ID. 
When you delete a configuration/row directory, the command will remove its record from the [manifest](/cli/structure/#manifest). If you want 
to propagate the changes to the project, call the [push](/cli/commands/sync/push/) command afterwards.

## Options

`--dry-run`
: Preview all changes

[Global Options](/cli/commands/#global-options)

## Examples

When you copy & paste a directory of a MySQL extractor configuration, the command will look like this:

```
➜ kbc persist --dry-run
Plan for "persist" operation:
  + C main/extractor/keboola.ex-db-mysql/invoices 2
  + R main/extractor/keboola.ex-db-mysql/invoices 2/rows/customer
Dry run, nothing changed.
Persist done.
```

## Next Steps

- [All Commands](/cli/commands/)
- [Diff](/cli/commands/sync/diff/)
- [Push](/cli/commands/sync/push/)
- [Fix Paths](/cli/commands/local/fix-paths/)


================================================
File: cli/commands/local/template/index.md
================================================
---
title: Manage Template Instances
permalink: /cli/commands/local/template/
---

* TOC
{:toc}

**Commands to manage [template](/cli/templates/structure/#template) instances in the [project directory](/cli/structure/).**

```
kbc local template [command]
```

|---
| Command | Description
|-|-|-
| [kbc local template delete](/cli/commands/local/template/delete/) | Delete a template instance from the local directory. |
| [kbc local template list](/cli/commands/local/template/list/) | List template instances used in the project. |
| [kbc local template upgrade](/cli/commands/local/template/upgrade/) | Upgrade a template instance from the local directory. |
| [kbc local template use](/cli/commands/local/template/use/) | Use the template in the project directory. |


================================================
File: cli/commands/local/template/delete/index.md
================================================
---
title: Delete Template Instance
permalink: /cli/commands/local/template/delete/
---

* TOC
{:toc}

**Delete a [template](/cli/templates/structure/#template) instance from the [local directory](/cli/structure/).**

```
kbc local template delete [flags]
```

Deletes all component configurations that were created from a template.

### Options

`-b, --branch string <string>`
: branch ID or name

`-i, --instance <string>`
: ID of the template instance

`--dry-run`
: Preview the list of configs to be deleted

[Global Options](/cli/commands/#global-options)

### Examples

See [Use Template Tutorial](/cli/templates/tutorial/#use-template).

```
➜ kbc local template delete -b main -i inst1 --dry-run

Plan for "delete-template" operation:
  x C main/extractor/keboola.ex-db-mysql/my-data-source
  x C main/extractor/keboola.ex-db-mysql/my-data-source-2
Dry run, nothing changed.
Delete done.
```

## Next Steps

- [Templates](/cli/templates/)
- [Create Template Tutorial](/cli/templates/tutorial/)
- [Use Template Tutorial](/cli/templates/tutorial/#use-template)


================================================
File: cli/commands/local/template/list/index.md
================================================
---
title: List Template Instances
permalink: /cli/commands/local/template/list/
---

* TOC 
{:toc}

**List [template](/cli/templates/structure/#template) instances used in the project.**

```
kbc local template list [flags]
```

Lists instances of all templates that were used in the project.

### Options

`-b, --branch string <string>`
: branch ID or name

[Global Options](/cli/commands/#global-options)

### Examples

```
➜ kbc local template list -b main
Template ID:          api-demo
Instance ID:          Kr2U26rYqefnpdeZ88qffZCcB
RepositoryName:       keboola
Version:              0.0.1
Name:                 tmpl1
Created:
  Date:               2022-05-02T14:56:32Z
  TokenID:            25254
Updated:
  Date:               2022-05-02T14:56:32Z
  TokenID:            25254
```

## Next Steps

- [Templates](/cli/templates/)
- [Create Template Tutorial](/cli/templates/tutorial/)
- [Use Template Tutorial](/cli/templates/tutorial/#use-template)


================================================
File: cli/commands/local/template/upgrade/index.md
================================================
---
title: Upgrade Template
permalink: /cli/commands/local/template/upgrade/
---

* TOC
{:toc}

**Upgrade a [template](/cli/templates/structure/#template) in the [local directory](/cli/structure/).**

```
kbc local template upgrade [flags]
```

Upgrades the existing [template](/cli/templates/structure/#template) in the [project directory](/cli/structure/).
Changes are made only locally. To save changes to the project, run [kbc sync push](/cli/commands/sync/push/) afterwards.
You will be prompted to select a target branch and provide [user inputs](/cli/templates/structure/inputs/).

### Options

`-b, --branch string <string>`
: target branch ID or name

`--dry-run bool <bool>`
: print what needs to be done

`-f, --inputs-file string <string>`
: JSON file with input values

`-i, --instance string <string>`
: instance ID of the template to upgrade

`-V, --version string <string>`
: target version; the default is the latest stable version

[Global Options](/cli/commands/#global-options)

### Examples


```
➜ kbc local template upgrade

? Select branch:  [Use arrows to move, type to filter]
> Main (997933)

? Select template instance: [Use arrows to move, type to filter]
> data-quality 1.0.0 (06YeEsQLdR66jhn81zmmtqnpQ)

New objects from "my-repository/my-template/v0" template:
   ...
  * R main/_shared/keboola.snowflake-transformation/codes/keboola-test-table-compare-structure
  * R main/_shared/keboola.snowflake-transformation/codes/keboola-test-table-empty
  * R main/_shared/keboola.snowflake-transformation/codes/keboola-test-time-series-complete
  * R main/_shared/keboola.snowflake-transformation/codes/keboola-test-time-series-complete-range
  * C main/other/keboola.orchestrator/data-quality-example
  * C main/transformation/keboola.python-transformation-v2/generate-sample-data
  * C main/transformation/keboola.snowflake-transformation/data-quality-core-abort-fail-example
  * C main/transformation/keboola.snowflake-transformation/data-quality-core-abort-fail-example/variables
  * R main/transformation/keboola.snowflake-transformation/data-quality-core-abort-fail-example/variables/values/default
  * C main/transformation/keboola.snowflake-transformation/data-quality-core-full-example
  * C main/transformation/keboola.snowflake-transformation/data-quality-core-full-example/variables
  * R main/transformation/keboola.snowflake-transformation/data-quality-core-full-example/variables/values/default
Template instance "06YeEsQLdR66jhn81zmmtqnpQ" has been upgraded to "keboola/data-quality/1.0.0".
```

## Next Steps

- [Templates](/cli/templates/)
- [Create Template Tutorial](/cli/templates/tutorial/)
- [Use Template Tutorial](/cli/templates/tutorial/#use-template)


================================================
File: cli/commands/local/template/use/index.md
================================================
---
title: Use Template
permalink: /cli/commands/local/template/use/
---

* TOC
{:toc}

**Use a [template](/cli/templates/structure/#template) in the [local directory](/cli/structure/).**

```
kbc local template use <repository>/<template>/<version> [flags]
```

Applies the [template](/cli/templates/structure/#template) to the [project directory](/cli/structure/).
Changes are made only locally. To save changes to the project, run [kbc sync push](/cli/commands/sync/push/) afterwards.
You will be prompted for a target branch and [user inputs](/cli/templates/structure/inputs/).

### Options

`-b, --branch string <string>`
: target branch ID or name

`-f, --inputs-file <string>`
: JSON file with inputs values

[Global Options](/cli/commands/#global-options)

### Examples

See [Use Template Tutorial](/cli/templates/tutorial/#use-template).

```
➜ kbc local template use my-repository/my-template/v0

? Select target branch:  [Use arrows to move, type to filter]
> Main (251721)

? MySQL Host: my-mysql.com

? MySQL Port: 3306
...

Plan for "encrypt" operation:
  C main/extractor/keboola.ex-db-mysql/my-data-source
    parameters.db.#password
Encrypt done.
New objects from "my-repository/my-template/v0" template:
  + C main/extractor/keboola.ex-db-mysql/my-data-source
  + R main/extractor/keboola.ex-db-mysql/my-data-source/rows/table1
  + R main/extractor/keboola.ex-db-mysql/my-data-source/rows/table2
  + C main/transformation/keboola.snowflake-transformation/my-transformation
Template "my-repository/my-template/v0" has been applied.
```

## Next Steps

- [Templates](/cli/templates/)
- [Create Template Tutorial](/cli/templates/tutorial/)
- [Use Template Tutorial](/cli/templates/tutorial/#use-template)


================================================
File: cli/commands/local/validate/index.md
================================================
---
title: Validate Local Project Command
permalink: /cli/commands/local/validate/
---

* TOC
{:toc}


**Validate the [local project directory](/cli/structure/).**

```
kbc local validate [flags]
```

Or shorter:
```
kbc v [flags]
```

Validate the directory structure and file contents of the local directory. Configurations of components having a JSON schema
will be validated against the schema.

## Options

[Global Options](/cli/commands/#global-options)

## Example

```
➜ kbc validate
Everything is good.
```

## Sub Commands

|---
| Command | Description
|-|-|-
| [kbc local validate config](/cli/commands/local/validate/config/) | Validate a configuration JSON file. |
| [kbc local validate row](/cli/commands/local/validate/row/) | Validate a configuration row JSON file. |
| [kbc local validate schema](/cli/commands/local/validate/schema/) | Validate a configuration/row JSON file by a JSON schema file. |


## Next Steps

- [All Commands](/cli/commands/)
- [Diff](/cli/commands/sync/diff/)
- [Push](/cli/commands/sync/push/)
- [Fix Paths](/cli/commands/local/fix-paths/)


================================================
File: cli/commands/local/validate/config/index.md
================================================
---
title: Validate Config Command
permalink: /cli/commands/local/validate/config/
---

* TOC
{:toc}


**Validate a [configuration JSON file](/extend/common-interface/config-file/).**

```
kbc local validate config component.id config.json [flags]
```

Each [component](/extend/component/) definition optionally contains a **schema of the configuration `parameters` key**.

The command validates the content of the specified JSON file against the schema. 
It can be used both in a project [local directory](/cli/structure/) and also separately.

## Options

[Global Options](/cli/commands/#global-options)

## Example

A successful run, the configuration is valid:
```
➜ kbc local validate config keboola.ex-azure-cost-management config.json
Validation done.
```

A validation error:
```
➜ kbc local validate config keboola.ex-azure-cost-management config.json
Error: missing properties: "subscriptionId"
```

If there is no schema in the component definition, a warning is printed:
```
➜ kbc local validate config ex-generic-v2 config.json
Component "ex-generic-v2" has no configuration JSON schema.
Validation done.
```

## Next Steps

- [All Commands](/cli/commands/)
- [Validate Local Project](/cli/commands/local/validate/)


================================================
File: cli/commands/local/validate/row/index.md
================================================
---
title: Validate Row Command
permalink: /cli/commands/local/validate/row/
---

* TOC
{:toc}


**Validate a [configuration row JSON file](https://help.keboola.com/components/#configuration-rows).**

```
kbc local validate row component.id row.json [flags]
```

Each [component](/extend/component/) definition optionally contains a **schema of the configuration row `parameters` key**.

The command validates the content of the specified JSON file against the schema.
It can be used both in a project [local directory](/cli/structure/) and also separately.

## Options

[Global Options](/cli/commands/#global-options)

## Example

A successful run, the configuration row is valid:
```
➜ kbc local validate row keboola.ex-azure-cost-management row.json
Validation done.
```

A validation error:
```
➜ kbc local validate row keboola.ex-azure-cost-management row.json
Error:
- "export": missing properties: "aggregation"
- "export.groupingDimensions": expected array, but got string
```

If there is no schema in the component definition, a warning is printed:
```
➜ kbc local validate row ex-generic-v2 row.json
Component "ex-generic-v2" has no configuration row JSON schema.
Validation done.
```

## Next Steps

- [All Commands](/cli/commands/)
- [Validate Local Project](/cli/commands/local/validate/)


================================================
File: cli/commands/local/validate/schema/index.md
================================================
---
title: Validate Schema Command
permalink: /cli/commands/local/validate/schema/
---

* TOC
{:toc}


**Validate a [configuration](/extend/common-interface/config-file/)/[row](https://help.keboola.com/components/#configuration-rows) JSON file by a JSON schema file.**

```
kbc local validate schema schema.json config.json [flags]
```

Validate the content of the specified JSON file
against the specified JSON schema file.

The JSON schema should contain a schema for the `parameters` key,
just like the configuration/row schema in a [component](/extend/component/) definition.

The main purpose of this command is to **test 
a new JSON schema before it is changed in a component definition**.
It can be used both in a project [local directory](/cli/structure/) and also separately.

## Options

[Global Options](/cli/commands/#global-options)

## Example

A successful run, the JSON file is valid:
```
➜ kbc local validate schema schema.json config.json
Validation done.
```

A validation error:
```
➜ kbc local validate schema schema.json config.json
Error: missing properties: "subscriptionId"
```

## Next Steps

- [All Commands](/cli/commands/)
- [Validate Local Project](/cli/commands/local/validate/)


================================================
File: cli/commands/remote/index.md
================================================
---
title: Remote Commands
permalink: /cli/commands/remote/
---

* TOC
{:toc}

**Operations directly in the [project](/cli/#subsystems).**

```
kbc remote [command]
```

|---
| Command | Description
|-|-|-
| [kbc remote create](/cli/commands/remote/create/) | Create an object in the project. |
| [kbc remote create branch](/cli/commands/remote/create/branch/) | Create a new [branch](https://help.keboola.com/components/branches/) from the `main` branch. |
| [kbc remote create bucket](/cli/commands/remote/create/bucket/) | Create a new [bucket](https://help.keboola.com/storage/buckets/). |
| [kbc remote file](/cli/commands/remote/file/) | Manage [files](https://help.keboola.com/storage/files/) in Storage. |
| [kbc remote file download](/cli/commands/remote/file/download/) | Download a [file](https://help.keboola.com/storage/files/) from Storage. |
| [kbc remote file upload](/cli/commands/remote/file/upload/) | Upload a [file](https://help.keboola.com/storage/files/) to Storage. |
| [kbc remote job](/cli/commands/remote/job/) | Manage [jobs](https://help.keboola.com/management/jobs/) in the project. |
| [kbc remote job run](/cli/commands/remote/job/run/) | Run one or more [jobs](https://help.keboola.com/management/jobs/). |
| [kbc remote table](/cli/commands/remote/table/) | Manage [tables](https://help.keboola.com/storage/tables/) in the project. |
| [kbc remote table create](/cli/commands/remote/table/create/) | Create a new [table](https://help.keboola.com/storage/tables/). |
| [kbc remote table upload](/cli/commands/remote/table/upload/) | Upload a CSV file to a [table](https://help.keboola.com/storage/tables/). |
| [kbc remote table download](/cli/commands/remote/table/download/) | Download data from a [table](https://help.keboola.com/storage/tables/). |
| [kbc remote table preview](/cli/commands/remote/table/preview/) | Preview up to 1000 rows from a [table](https://help.keboola.com/storage/tables/). |
| [kbc remote table detail](/cli/commands/remote/table/detail/) | Print [table](https://help.keboola.com/storage/tables/) details. |
| [kbc remote table import](/cli/commands/remote/table/import/) | Import data to a [table](https://help.keboola.com/storage/tables/) from a [file](https://help.keboola.com/storage/files/). |
| [kbc remote table unload](/cli/commands/remote/table/unload/) | Unload a [table](https://help.keboola.com/storage/tables/) into a [file](https://help.keboola.com/storage/files/). |
| [kbc remote workspace](/cli/commands/remote/create/) | Manage workspaces in the project. |
| [kbc remote workspace create](/cli/commands/remote/workspace/create/) | Create a workspace in the project. |
| [kbc remote workspace delete](/cli/commands/remote/workspace/delete/) | Delete a workspace in the project. |
| [kbc remote workspace detail](/cli/commands/remote/workspace/detail/) | Print workspace details and credentials. |
| [kbc remote workspace list](/cli/commands/remote/workspace/list/) | List workspaces in the project. |


================================================
File: cli/commands/remote/create/index.md
================================================
---
title: Create Remote Object
permalink: /cli/commands/remote/create/
---

* TOC
{:toc}

**Create an object directly in the [project](/cli/#subsystems).**

```
kbc remote create [command]
```

Shows an interactive dialog if you do not enter a sub-command.

|---
| Command | Description
|-|-|-
| [kbc remote create branch](/cli/commands/remote/create/branch/) | Create a new [branch](https://help.keboola.com/components/branches/) from the `main` branch. |
| [kbc remote create bucket](/cli/commands/remote/create/bucket/) | Create a new [bucket](https://help.keboola.com/storage/buckets/). |


================================================
File: cli/commands/remote/create/branch/index.md
================================================
---
title: Create Branch
permalink: /cli/commands/remote/create/branch/
---

* TOC
{:toc}

**Create a new [branch](https://help.keboola.com/components/branches/) from the `main` branch.**

```
kbc remote create branch [flags]
```

Create a new dev branch as a copy of the main branch in the project and pull its state back to the local directory. 
If you have some local changes of the main branch, push them to the project first. 

**Limitation:**  
A branch cannot be created locally, it must be created directly in the project from the `main` branch.

### Options

`-n, --name <string>`
: Name of the branch to be created

`--output-json <string>`
: Output as a JSON file


[Global Options](/cli/commands/#global-options)

### Examples

```
➜ kbc remote create branch -n try1

The branch was successfully created.
Pulling objects to the local directory.
Plan for "pull" operation:
  * C main/extractor/keboola.ex-google-drive/my-google-drive-data-source | changed: configuration
Pull done.
Created new branch "try1".
```

## Next Steps

- [All Commands](/cli/commands/)
- [Create Configuration](/cli/commands/local/create/config/)
- [Create Configuration Row](/cli/commands/local/create/row/)



================================================
File: cli/commands/remote/create/bucket/index.md
================================================
---
title: Create Bucket
permalink: /cli/commands/remote/create/bucket/
---

* TOC
{:toc}

**Create a new [bucket](https://help.keboola.com/storage/buckets/) in Keboola Storage.**

```
kbc remote create bucket [flags]
```

### Options

`--stage <string>`
: Stage of the bucket, allowed values: `in`, `out`

`--display-name <string>`
: Display name of the bucket for the UI

`--name <string>`
: Name of the bucket

`--description <string>`
: Description of the bucket

[Global Options](/cli/commands/#global-options)

### Examples

```
➜ kbc remote create bucket

? Select a stage for the bucket:  [Use arrows to move, type to filter]
  in
> out
? Select a stage for the bucket: out

Enter a display name for the bucket: Bucket1

Enter a name for the bucket: bucket1

? Enter a description for the bucket: Test description

Created bucket "out.c-bucket1".
```

## Next Steps

- [All Commands](/cli/commands/)
- [Create Configuration](/cli/commands/local/create/config/)
- [Create Configuration Row](/cli/commands/local/create/row/)


================================================
File: cli/commands/remote/file/index.md
================================================
---
title: File Commands
permalink: /cli/commands/remote/file/
---

* TOC
  {:toc}

**Manage [files](https://help.keboola.com/storage/files/) directly in the [project](/cli/#subsystems).**

```
kbc remote file [command]
```

|---
| Command | Description
|-|-|-
| [kbc remote file download](/cli/commands/remote/file/download/) | Download a [file](https://help.keboola.com/storage/files/) from Storage. |
| [kbc remote file upload](/cli/commands/remote/file/upload/) | Upload a [file](https://help.keboola.com/storage/files/) to Storage. |


================================================
File: cli/commands/remote/file/download/index.md
================================================
---
title: File Download
permalink: /cli/commands/remote/file/download/
---

* TOC
{:toc}

**Download a [file](https://help.keboola.com/storage/files/) from [Storage](https://help.keboola.com/storage/).**

```
kbc remote file download [id] [flags]
```

### Options

`-H, --storage-api-host <string>`
: Keboola instance URL, e.g., `connection.keboola.com`

`-o, --output <string>`
: Path and/or name of the destination file (if the file is not sliced) or directory (if the file is sliced). If `-`, output goes to `stdout` without any extra text, so the command is pipeable.

`--allow-sliced`
: Allow sliced files to appear sliced locally. (default false)

  By default, sliced files are stitched together to form a single file.
  If this flag is set when downloading a sliced file, the resulting file will instead be stored as a directory, and each slice will be stored as a separate file in that directory.

[Global Options](/cli/commands/#global-options)

### Examples

```
➜ $ kbc remote file download 1234567 -o name
File "1234567" downloaded to "name.csv".
```

If you don't specify the file ID, the command will let you select a file by name. 
```
➜ $ kbc remote file download
? File: <selection prompt>
? Enter a name for the destination: 

File "1234567" downloaded to "name.csv"
```

If you specify `-` as output, the file will be printed to standard output. 
```
➜ kbc remote file download 1234567 -o -
col1,col2,col3
val1,val2,val3
...
```

## Next Steps

- [All Commands](/cli/commands/)
- [Learn more about Files Storage](https://help.keboola.com/storage/files/)


================================================
File: cli/commands/remote/file/upload/index.md
================================================
---
title: File Upload
permalink: /cli/commands/remote/file/upload/
---

* TOC
{:toc}

**Upload a [file](https://help.keboola.com/storage/files/) to [Storage](https://help.keboola.com/storage/).**

```
kbc remote file upload [flags]
```

### Options

`-H, --storage-api-host <string>`
: Keboola instance URL, e.g., `connection.keboola.com`

`--data <string>`
: Path and/or name of the source file. If `-`, input is expected from standard input, so the command is pipeable.

`--file-name <string>`
: Name of the file to be created

`--file-tags <string>`
: Comma-separated list of tags

[Global Options](/cli/commands/#global-options)

### Examples

```
➜ $ kbc remote file upload --name file1 --data ./name.csv --tags tag1,tag2
File "file1" uploaded with file id "1234567".
```

If you don't specify the options, the command will ask you for them. 
```
➜ $ kbc remote file upload
? Enter a name for the file: file1

Enter a path for the file input or - to read from standard input.
? File: name.csv

Enter a comma-separated list of tags.
? Tags: tag1,tag2

File "file1" uploaded with file id "1234567".
```

If you specify `-` as input, the file will be read from standard input. 
```
➜ cat ./name.csv | kbc remote file upload --file-name file1 --data -
File "file1" uploaded with file id "1234567". 
```

## Next Steps

- [All Commands](/cli/commands/)
- [Learn more about Files Storage](https://help.keboola.com/storage/files/)


================================================
File: cli/commands/remote/job/index.md
================================================
---
title: Job Commands
permalink: /cli/commands/remote/job/
---

* TOC
{:toc}

**Manage [jobs](https://help.keboola.com/management/jobs/) directly in the [project](/cli/#subsystems).**

```
kbc remote job [command]
```

|---
| Command | Description
|-|-|-
| [kbc remote job run](/cli/commands/remote/job/run/) | Run a job. |


================================================
File: cli/commands/remote/job/run/index.md
================================================
---
title: Job Run
permalink: /cli/commands/remote/job/run/
---

* TOC
{:toc}

**Run one or more [jobs](https://help.keboola.com/management/jobs/).**

```
kbc remote job run [branch1/]component1/config1[@tag] [branch2/]component2/config2[@tag] ... [flags]
```

If no `branch` is specified, the `main` branch is used.

If no `@tag` is specified, the default version of the component is used.

### Options

`-H, --storage-api-host <string>`
: Keboola instance URL, e.g., `connection.keboola.com`

`--timeout <string>`
: How long to wait for the job to finish (default `2m`)
  
  Specified as a sequence of decimal numbers with unit suffixes, e.g., `5m10s` or `1.5h`.  
  Available units are `ms`, `s`, `m`, and `h`.

`--async`
: Do not wait for jobs to finish (default false)

[Global Options](/cli/commands/#global-options)

### Examples

Run one configuration and wait:
```
➜ kbc remote job run ex-db-snowflake/978904392
Starting job.
Started job "328904392" using config "ex-db-snowflake/978904392"
Waiting for "328904392"
Waiting for "328904392"
Finished job "328904392"
Finished all jobs.
```

Run multiple configurations and wait; the `branch` and the component version `@tag` are specified:
```
➜ kbc remote job run keboola.ex-db-snowflake/978904392 12345/keboola.ex-db-oracle/947204232@v2.3.4 
Starting 2 jobs.
Started job "328904393" using config "keboola.ex-db-snowflake/978904392"
Started job "328904394" using config "12345/keboola.ex-db-oracle/947204232@v2.3.4"
Waiting for "328904393", "328904394"
Finished job "328904393"
Waiting for "328904394"
Waiting for "328904394"
Finished job "328904394"
Finished all jobs.
```

Run and don't wait; the `--async` flag is used:
```
➜ kbc remote job run keboola.ex-db-snowflake/978904392 keboola.ex-db-oracle/947204232 --async
Starting 2 jobs.
Started job "328904393" using config "keboola.ex-db-snowflake/978904392"
Started job "328904394" using config "keboola.ex-db-oracle/947204232"
Started all jobs.
```

## Next Steps

- [All Commands](/cli/commands/)
- [Learn more about Jobs](https://help.keboola.com/management/jobs/)


================================================
File: cli/commands/remote/table/index.md
================================================
---
title: Table Commands
permalink: /cli/commands/remote/table/
---

* TOC
{:toc}

**Manage [tables](https://help.keboola.com/storage/tables/) directly in the [project](/cli/#subsystems).**

```
kbc remote table [command]
```

|---
| Command | Description
|-|-|-
| [kbc remote table create](/cli/commands/remote/table/create/) | Create a new [table](https://help.keboola.com/storage/tables/). |
| [kbc remote table upload](/cli/commands/remote/table/upload/) | Upload a CSV file to a [table](https://help.keboola.com/storage/tables/). |
| [kbc remote table download](/cli/commands/remote/table/download/) | Download data from a [table](https://help.keboola.com/storage/tables/). |
| [kbc remote table preview](/cli/commands/remote/table/preview/) | Retrieve up to 1000 rows from a table. |
| [kbc remote table detail](/cli/commands/remote/table/detail/) | Print [table](https://help.keboola.com/storage/tables/) details. |
| [kbc remote table import](/cli/commands/remote/table/import/) | Import data to a [table](https://help.keboola.com/storage/tables/) from a [file](https://help.keboola.com/storage/files/). |
| [kbc remote table unload](/cli/commands/remote/table/unload/) | Unload a [table](https://help.keboola.com/storage/tables/) into a [file](https://help.keboola.com/storage/files/). |


================================================
File: cli/commands/remote/table/create/index.md
================================================
---
title: Create Table
permalink: /cli/commands/remote/table/create/
---

* TOC
{:toc}

To create a [table](https://help.keboola.com/storage/tables/) in Keboola Storage directly from the command line interface, use the following command:

```
kbc remote create table [flags]
```

### Options

`--bucket <string>`
: Specifies the bucket ID where the table will be created.

`--columns <string>`
: Defines a comma-separated list of column names for the table.

`--columns-from <string>`
: Indicates the path to the column definition file in json.

`--name <string>`
: Sets the name of the new table.

`--primary-key <string>`
: Determines a comma-separated list of columns to be used as the primary key.

`--options-from <string>`
: The path to the table definition file with backend-specific options.  
: This flag is enabled only for projects with the BigQuery backend and must be combined with a `--columns-from` flag because these settings must have specific column types.

[Global Options](/cli/commands/#global-options)

### Usage Examples

**Creating a table without defining column types:**

```
➜ kbc remote create table

? Select a bucket:  [Use arrows to move, type to filter]
  bucket1 (in.c-bucket1)
> bucket2 (in.c-bucket2)

Enter the table name.
? Table name: my-table

Want to define column types?
? Columns Types Definition: [? for help] (Y/n)
```
If you want to skip defining column types, select `n/N` when prompted and enter the names of the columns.
```
Want to define column types?
? Columns Types Definition: No

Enter a comma-separated list of column names.
? Columns: id,name,age

? Select columns for the primary key:  [Use arrows to move, space to select]
> [x]  id
  [ ]  name
  [ ]  age

Created table "in.c-bucket2.my-table".
```
**Defining column types:**

To define column types, select `y/Y`. Then, start an editor. 

```
Want to define column types?
? Columns Types Definition: Yes

Columns definition from file
? Columns definition from file: [Enter to launch editor]
```
**Edit the YAML file in the editor:**

Edit or replace this part of the text with your definition. Keep the same format. Then save your changes and close the editor.

```
- name: id
  definition:
    type: VARCHAR
    nullable: false
  basetype: STRING
- name: name
  definition:
    type: VARCHAR
    nullable: true
  basetype: STRING
```
```
Columns definition from file
? Columns definition from file: <Received>

? Select columns for the primary key:  [Use arrows to move, space to select]
> [x]  id

Created table "in.c-bucket2.my-table".
```
**Defining column types using a JSON file:**

```
kbc remote create table --columns-from <definition.json> [flags]
```
Example JSON file:
```json
[
    {
      "name": "id",
      "definition": {
        "type": "VARCHAR",
        "nullable": false
      },
      "basetype": "STRING"
    },
    {
      "name": "name",
      "definition": {
        "type": "VARCHAR",
        "nullable": true
      },
      "basetype": "STRING"
    }
]
```
**Writing a JSON file that defines Bigquery settings:**

```
kbc remote create table --columns-from <definition.json> --options-from <options.json> [flags]
```
Example JSON file:
```json
{
  "timePartitioning": {
    "type": "DAY",
    "expirationMs": 864000000,
    "field": "time"
  },
  "clustering": {
    "fields": [
      "id"
    ]
  },
  "rangePartitioning": {
    "field": "id",
    "range": {
      "start": 0,
      "end": 10,
      "interval": 1
    }
  }
}
```



## Next Steps

- [All Commands](/cli/commands/)
- [Create a Bucket](/cli/commands/remote/create/bucket/)
- [Table Upload](/cli/commands/remote/table/upload/)


================================================
File: cli/commands/remote/table/detail/index.md
================================================
---
title: Table Detail
permalink: /cli/commands/remote/table/detail/
---

* TOC
{:toc}

**Print [table](https://help.keboola.com/storage/tables/) details.**

```
kbc remote table detail [table] [flags]
```

### Options

`-H, --storage-api-host <string>`
: Keboola instance URL, e.g., `connection.keboola.com`

[Global Options](/cli/commands/#global-options)

### Examples

Print the details of a table:
```
➜ kbc remote table detail in.c-demo-keboola-ex-google-drive-1234567.account

Table "in.c-demo-keboola-ex-google-drive-1234567.account":
  Name: issues
  Primary key: Id, Name
  Columns: Id, Name, Region, First_Order
  Rows: 7801
  Size: 92 MB
  Created at: 2023-02-01T11:22:05.000Z
  Last import at: 2023-02-01T13:09:19.000Z
  Last changed at: 2023-02-01T13:09:19.000Z
```

Print the details of a table without knowing its ID:
```
➜ kbc remote table detail
? Table:  [Use arrows to move, type to filter]
> in.c-my-bucket.data
  in.c-demo-keboola-ex-google-drive-1234567.account
  in.c-facebook-extractor.uses
  ...

(down arrow pressed)

➜ kbc remote table preview
? Table:  [Use arrows to move, type to filter]
  in.c-my-bucket.data
> in.c-demo-keboola-ex-google-drive-1234567.account
  in.c-facebook-extractor.uses
  ...

(enter pressed)

➜ kbc remote table detail
? Table: in.c-demo-keboola-ex-google-drive-1234567.account

Table "in.c-demo-keboola-ex-google-drive-1234567.account":
  Name: issues
  Primary key: Id, Name
  Columns: Id, Name, Region, First_Order
  Rows: 7801
  Size: 92 MB
  Created at: 2023-02-01T11:22:05.000Z
  Last import at: 2023-02-01T13:09:19.000Z
  Last changed at: 2023-02-01T13:09:19.000Z
```

## Next Steps

- [All Commands](/cli/commands/)
- [Learn more about Tables](https://help.keboola.com/storage/tables/)


================================================
File: cli/commands/remote/table/download/index.md
================================================
---
title: Table Download
permalink: /cli/commands/remote/table/download/
---

* TOC
{:toc}

**Download data from a [table](https://help.keboola.com/storage/tables/).**

```
kbc remote table download [table] [flags]
```

`file`
: Path and/or name of the source file. If `-`, input is expected from standard input, so the command is pipeable.

`table`
: ID of the destination table.

### Options

`-H, --storage-api-host <string>`
: Keboola instance URL, e.g., `connection.keboola.com`

`-o, --output <string>`
: Path and/or name of the destination file (if the file is not sliced) or directory (if the file is sliced). If `-`, output goes to `stdout` without any extra text, so the command is pipeable.

`--changed-since <string>`
: Only export rows imported after this date.

  Date may be written in any format compatible with [strtotime](https://www.php.net/manual/en/function.strtotime.php).

`--changed-until <string>`
: Only export rows imported before this date.

  Date may be written in any format compatible with [strtotime](https://www.php.net/manual/en/function.strtotime.php).

`--columns <string>`
: Comma-separated list of columns to export.

`--format <string>`
: Output format. Supported formats are `json` and `csv`.

  The `json` format is only supported in projects with the Snowflake backend.

`--header`
: First line of the CSV file contains column names.

`--limit <int>`
: Limit the number of exported rows. A value of 0 means no limit. (default 0)

`--order <string>`
: Order the data by one or more columns.

  Accepts a comma-separated list of column+order pairs, such as `First_Name,Last_Name=desc`.
  If the order for a column is not specified, it defaults to ascending, such as `First_Name` in the example above.

`--where <string>`
: Filter the data.

  Accepts a semicolon-separated list of expressions, each of which specifies a column and a comparison to one or more values, such as `First_Name=Ivan,Pavel;Birth_Date>=1990-01-01`

`--allow-sliced`
: Allow sliced files to appear sliced locally. (default false)

  By default, sliced files are stitched together to form a single file.
  If this flag is set when downloading a sliced file, the resulting file will instead be stored as a directory, and each slice will be stored as a separate file in that directory.


[Global Options](/cli/commands/#global-options)

### Examples

Download 2000 rows from a table:
```
➜ kbc remote table download in.c-gdrive.account -o account.csv --limit 2000
Unloading table, please wait.
Table "in.c-gdrive.account" unloaded to file "734370450".
File "734370450" downloaded to "account.csv".
```

## Next Steps

- [All Commands](/cli/commands/)
- [Learn more about Tables](https://help.keboola.com/storage/tables/)


================================================
File: cli/commands/remote/table/import/index.md
================================================
---
title: Table Import
permalink: /cli/commands/remote/table/import/
---

* TOC
{:toc}

Import data to a table from a Storage file. 

```
kbc remote table import [table] [file] [flags]
```

### Options

`-H, --storage-api-host <string>`
: Keboola instance URL, e.g., `connection.keboola.com`

`--columns <string>`
: Comma-separated list of column names. If present, the first row in the CSV file is not treated as a header.

`--incremental-load <bool>`
: Data are either added to existing data in the table or replace the existing data.

`--file-delimiter <string>`
: Delimiter of the CSV file. Default is `,`.

`--file-enclosure <string>`
: Enclosure of the CSV file. Default is `"`.

`--file-escaped-by <string>`
: Escape character of the CSV file. By default, no escaping is used. (Note: You can specify either the `enclosure` or `escapedBy` parameter, but not both.)

`--file-without-headers`
: States if the CSV file contains headers on the first row or not.

[Global Options](/cli/commands/#global-options)

### Examples

Preview a table in the terminal:
```
➜ $ cat my.csv | kbc remote table import in.c-main.products 1234567
File with id "1234567" imported to table "in.c-main.products"
```

```
➜ kbc remote table import
? Table: <selection prompt>
? File: <selection prompt>

File with id "1234567" imported to table "in.c-main.products"
```

## Next Steps

- [All Commands](/cli/commands/)
- [Upload files to Storage](/cli/commands/remote/file/upload/)
- [Learn more about Tables](https://help.keboola.com/storage/tables/)


================================================
File: cli/commands/remote/table/preview/index.md
================================================
---
title: Table Preview
permalink: /cli/commands/remote/table/preview/
---

* TOC
{:toc}

**Preview up to 1000 rows from a [table](https://help.keboola.com/storage/tables/).**

```
kbc remote table preview [table] [flags]
```

### Options

`-H, --storage-api-host <string>`
: Keboola instance URL, e.g., `connection.keboola.com`

`--changed-since <string>`
: Only export rows imported after this date.

  Date may be written in any format compatible with [strtotime](https://www.php.net/manual/en/function.strtotime.php).

`--changed-until <string>`
: Only export rows imported before this date.

  Date may be written in any format compatible with [strtotime](https://www.php.net/manual/en/function.strtotime.php).

`--columns <string>`
: Comma-separated list of columns to export.

`--format <string>`
: Output format. Supported formats are `json`, `csv`, and `pretty`. (default `pretty`)

  `csv` is formatted according to [RFC 4180](https://www.ietf.org/rfc/rfc4180.txt).

  `json` is formatted as follows:
  ```json
  {
    "columns": ["Id", "Name", "Region"],
    "rows": [
      ["Id0", "Name0", "Region0"],
      ["Id1", "Name1", "Region1"],
      ["Id2", "Name2", "Region2"]
    ]
  }
  ```

`-o, --out <string>`
: Write the data to a file. Fails if the file already exists.

`--force`
: When combined with `--out`, the file will be overwritten if it already exists.

`--limit <int>`
: Limit the number of exported rows (maximum 1000, default 100).

`--order <string>`
: Order the data by one or more columns.
  
  Accepts a comma-separated list of column+order pairs, such as `First_Name,Last_Name=desc`.
  If the order for a column is not specified, it defaults to ascending, such as `First_Name` in the example above.

`--where <string>`
: Filter the data.

  Accepts a semicolon-separated list of expressions, each of which specifies a column and a comparison to one or more values, such as `First_Name=Ivan,Pavel;Birth_Date>=1990-01-01`

[Global Options](/cli/commands/#global-options)

### Examples

Preview a table in the terminal:
```
➜ kbc remote table preview in.c-demo-keboola-ex-google-drive-1234567.account
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━┳━━━━━━━━━━━━━━┓
┃ Id                               ┃ Name              ┃ Region  ┃ First_Order  ┃
┣━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╋━━━━━━━━━━━━━━━━━━━╋━━━━━━━━━╋━━━━━━━━━━━━━━┫
┃ f030ed64cbc8babbe50901a26675a2ee ┃ CSK Auto          ┃ US West ┃ 2015-01-23   ┃
┃ 06c0b954b0d2088e3da2132d1ba96f31 ┃ AM/PM Camp        ┃ Global  ┃ 2015-02-04   ┃
┃ fffe0e30b4a34f01063330a4b908fde5 ┃ Super Saver Foods ┃ Global  ┃ 2015-02-06   ┃
┃ 33025ad4a425b6ee832e76beb250ae1c ┃ Netcore           ┃ Global  ┃ 2015-03-02   ┃
┃ ...                              ┃ ...               ┃ ...     ┃ ...          ┃
┗━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┻━━━━━━━━━━━━━━━━━━━┻━━━━━━━━━┻━━━━━━━━━━━━━━┛
```

Preview a table with where filters and ordering, and output the result to a CSV
file:
```
➜ kbc remote table preview in.c-demo-keboola-ex-google-drive-1234567.account \
  --where Age>23 \
  --order Age=asc \
  --limit 1000 \
  --format csv \
  --out accounts-preview.csv
Fetching the data, please wait.
Table "in.c-gdrive.account" preview successfully written to "accounts-preview.csv".
```

Preview a table in the terminal without knowing its ID:
```
➜ kbc remote table preview
? Table:  [Use arrows to move, type to filter]
> in.c-my-bucket.data
  in.c-demo-keboola-ex-google-drive-1234567.account
  in.c-facebook-extractor.uses
  ...

(down arrow pressed)

➜ kbc remote table preview
? Table:  [Use arrows to move, type to filter]
  in.c-my-bucket.data
> in.c-demo-keboola-ex-google-drive-1234567.account
  in.c-facebook-extractor.uses
  ...

(enter pressed)

➜ kbc remote table preview
? Table: in.c-demo-keboola-ex-google-drive-1234567.account
Fetching the data, please wait.
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━┳━━━━━━━━━━━━━━┓
┃ Id                               ┃ Name              ┃ Region  ┃ First_Order  ┃
┣━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╋━━━━━━━━━━━━━━━━━━━╋━━━━━━━━━╋━━━━━━━━━━━━━━┫
┃ f030ed64cbc8babbe50901a26675a2ee ┃ CSK Auto          ┃ US West ┃ 2015-01-23   ┃
┃ 06c0b954b0d2088e3da2132d1ba96f31 ┃ AM/PM Camp        ┃ Global  ┃ 2015-02-04   ┃
┃ fffe0e30b4a34f01063330a4b908fde5 ┃ Super Saver Foods ┃ Global  ┃ 2015-02-06   ┃
┃ 33025ad4a425b6ee832e76beb250ae1c ┃ Netcore           ┃ Global  ┃ 2015-03-02   ┃
┃ ...                              ┃ ...               ┃ ...     ┃ ...          ┃
┗━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┻━━━━━━━━━━━━━━━━━━━┻━━━━━━━━━┻━━━━━━━━━━━━━━┛
```

## Next Steps

- [All Commands](/cli/commands/)
- [Learn more about Tables](https://help.keboola.com/storage/tables/)


================================================
File: cli/commands/remote/table/unload/index.md
================================================
---
title: Table Unload
permalink: /cli/commands/remote/table/unload/
---

* TOC
{:toc}

**Unload a [table](https://help.keboola.com/storage/tables/) into a [file](https://help.keboola.com/storage/files/).**

```
kbc remote table unload [table] [flags]
```

### Options

`-H, --storage-api-host <string>`
: Keboola instance URL, e.g., `connection.keboola.com`

`--changed-since <string>`
: Only export rows imported after this date.

  Date may be written in any format compatible with [strtotime](https://www.php.net/manual/en/function.strtotime.php).

`--changed-until <string>`
: Only export rows imported before this date.

  Date may be written in any format compatible with [strtotime](https://www.php.net/manual/en/function.strtotime.php).

`--columns <string>`
: Comma-separated list of columns to export.

`--format <string>`
: Output format. Supported formats are `json` and `csv`.
  
  The `json` format is only supported in projects with the Snowflake backend.

`--limit <int>`
: Limit the number of exported rows. A value of 0 means no limit. (default 0)

`--order <string>`
: Order the data by one or more columns.
  
  Accepts a comma-separated list of column+order pairs, such as `First_Name,Last_Name=desc`.
  If the order for a column is not specified, it defaults to ascending, such as `First_Name` in the example above.

`--where <string>`
: Filter the data.

  Accepts a semicolon-separated list of expressions, each of which specifies a column and a comparison to one or more values, such as `First_Name=Ivan,Pavel;Birth_Date>=1990-01-01`

`--timeout <string>`
: How long to wait for the storage job to finish (default `2m`)
  
  Specified as a sequence of decimal numbers with unit suffixes, e.g., `5m10s` or `1.5h`.  
  Available units are `ms`, `s`, `m`, and `h`.

`--async`
: Do not wait for the storage job to finish (default false)

[Global Options](/cli/commands/#global-options)

### Examples

Unload a table:
```
➜ kbc remote table unload in.c-gdrive.account
Unloading table, please wait.
Table "in.c-gdrive.account" unloaded to file "734370450".
```

Unload a table with where filters and ordering:
```
➜ kbc remote table unload in.c-gdrive.account \
  --where Age>23 \
  --order Age=asc \
  --limit 1000 \
  --format csv \
Unloading table, please wait.
Table "in.c-gdrive.account" unloaded to file "734370450".
```

Unload a table in the terminal without knowing its ID:
```
➜ kbc remote table unload
? Table:  [Use arrows to move, type to filter]
> in.c-my-bucket.data
  in.c-gdrive.account
  in.c-facebook-extractor.uses
  ...

(down arrow pressed)

➜ kbc remote table unload
? Table:  [Use arrows to move, type to filter]
  in.c-my-bucket.data
> in.c-gdrive.account
  in.c-facebook-extractor.uses
  ...

(enter pressed)

➜ kbc remote table unload
? Table: in.c-gdrive.account
Unloading table, please wait.
Table "in.c-gdrive.account" unloaded to file "734370450".
```

## Next Steps

- [All Commands](/cli/commands/)
- [Learn more about Tables](https://help.keboola.com/storage/tables/)


================================================
File: cli/commands/remote/table/upload/index.md
================================================
---
title: Table Upload
permalink: /cli/commands/remote/table/upload/
---

* TOC
{:toc}

**Upload a CSV file to a [table](https://help.keboola.com/storage/tables/).**

```
kbc remote table upload [table] [file] [flags]
```

`table`
: ID of the destination table.

`file`
: Path and/or name of the source file. If `-`, input is expected from standard input, so the command is pipeable.

### Options

`-H, --storage-api-host <string>`
: Keboola instance URL, e.g., `connection.keboola.com`

`--columns <string>`
: Comma-separated list of column names. If present, the first row in the CSV file is not treated as a header.

`--incremental-load`
: Data are either added to existing data in the table or replace the existing data.

`--primary-key <string>`
: Comma-separated list of columns representing the primary key for the newly created table if the table doesn't exist.

`--file-name <string>`
: Name of the file to be created

`--file-tags <string>`
: Comma-separated list of tags for the uploaded file

`--file-delimiter <string>`
: Delimiter of the CSV file. Default is `,`.

`--file-enclosure <string>`
: Enclosure of the CSV file. Default is `"`.

`--file-escaped-by <string>`
: Escape character of the CSV file. By default, no escaping is used. (***Note:** you can specify either the `enclosure` or `escapedBy` parameter, not both.*)

`--file-without-headers`
: States if the CSV file contains headers on the first row or not.



[Global Options](/cli/commands/#global-options)

### Examples

Create a table from a CSV file:
```
➜ kbc remote table upload in.c-users.accounts accounts.csv \
  --file-name accounts.csv
  --file-tags local-file
  --primary-key Id
File "accounts.csv" uploaded with file id "734370450".
Table "in.c-users.accounts" does not exist, creating it.
Bucket "in.c-users" does not exist, creating it.
Created new table "in.c-users.accounts" from file with id "734370450".
```

## Next Steps

- [All Commands](/cli/commands/)
- [Learn more about Tables](https://help.keboola.com/storage/tables/)


================================================
File: cli/commands/remote/workspace/index.md
================================================
---
title: Workspace Commands
permalink: /cli/commands/remote/workspace/
---

* TOC
{:toc}

**Manage workspaces directly in the [project](/cli/#subsystems).**

```
kbc remote workspace [command]
```

|---
| Command | Description
|-|-|-
| [kbc remote workspace create](/cli/commands/remote/workspace/create/) | Create a workspace in the project. |
| [kbc remote workspace delete](/cli/commands/remote/workspace/delete/) | Delete a workspace in the project. |
| [kbc remote workspace detail](/cli/commands/remote/workspace/detail/) | Print workspace details and credentials. |
| [kbc remote workspace list](/cli/commands/remote/workspace/list/) | List workspaces in the project. |


================================================
File: cli/commands/remote/workspace/create/index.md
================================================
---
title: Create Workspace
permalink: /cli/commands/remote/workspace/create/
---

* TOC
{:toc}

**Create a new [workspace](https://help.keboola.com/transformations/workspace/).**

```
kbc remote workspace create [flags]
```

### Options

`--name <string>`
: Name of the workspace to be created

`--type <string>`
: Type of the workspace to be created

`--size <string>`
: Size of the workspace to be created. It is ignored for database workspaces.

`-H, --storage-api-host <string>` 
: Keboola instance URL, e.g., "connection.keboola.com"

[Global Options](/cli/commands/#global-options)

### Examples

```
➜ kbc remote workspace create --name foo --type snowflake

Creating a new workspace, please wait.
Created the new workspace "foo" (<id>).
Credentials:
  Host: <host>
  User: <user>
  Password: <password>
  Database: <database>
  Schema: <schema>
  Warehouse: <warehouse>
```

## Next Steps

- [All Commands](/cli/commands/)
- [Learn more about Workspaces](https://help.keboola.com/transformations/workspace/)


================================================
File: cli/commands/remote/workspace/delete/index.md
================================================
---
title: Delete Workspace
permalink: /cli/commands/remote/workspace/delete/
---

* TOC
{:toc}

**Delete a [workspace](https://help.keboola.com/transformations/workspace/).**

```
kbc remote workspace delete [flags]
```

### Options

`-W, --workspace-id string`
: ID of the workspace to be deleted. You can find it using the [List Workspaces](/cli/commands/remote/workspace/list/) command.

`-H, --storage-api-host <string>` 
: Keboola instance URL, e.g., "connection.keboola.com"

[Global Options](/cli/commands/#global-options)

### Examples

```
➜ kbc remote workspace delete -W <id>

Deleting the workspace "foo" (<id>), please wait.
Delete done.
```

## Next Steps

- [All Commands](/cli/commands/)
- [Learn more about Workspaces](https://help.keboola.com/transformations/workspace/)


================================================
File: cli/commands/remote/workspace/detail/index.md
================================================
---
title: Workspace Detail
permalink: /cli/commands/remote/workspace/detail/
---

* TOC
{:toc}

**Print the credentials and details of a [workspace](https://help.keboola.com/transformations/workspace/)**

```
kbc remote workspace detail [flags]
```

### Options

`-W, --workspace-id string`
: ID of the workspace to be detailed. You can find it using the [List Workspaces](/cli/commands/remote/workspace/list/) command.

`-H, --storage-api-host <string>` 
: Keboola instance URL, e.g., "connection.keboola.com"

[Global Options](/cli/commands/#global-options)

### Examples

```
➜ kbc remote workspace detail -W <id>

Workspace "foo"
ID: <id>
Type: snowflake
Credentials:
  Host: <host>
  User: <user>
  Password: <password>
  Database: <database>
  Schema: <schema>
  Warehouse: <warehouse>
```

## Next Steps

- [All Commands](/cli/commands/)
- [Learn more about Workspaces](https://help.keboola.com/transformations/workspace/)


================================================
File: cli/commands/remote/workspace/list/index.md
================================================
---
title: List Workspaces
permalink: /cli/commands/remote/workspace/list/
---

* TOC
{:toc}

**Print a list of [workspaces](https://help.keboola.com/transformations/workspace/).**

```
kbc remote workspace list [flags]
```

### Options

`-H, --storage-api-host <string>`
: Keboola instance URL, e.g., "connection.keboola.com"

[Global Options](/cli/commands/#global-options)

### Examples

```
➜ kbc remote workspace list

Loading workspaces, please wait.
Found workspaces:
  foo (ID: <id>, Type: snowflake)
  bar (ID: <id>, Type: snowflake)
  baz (ID: <id>, Type: python, Size: small)
```

## Next Steps

- [All Commands](/cli/commands/)
- [Learn more about Workspaces](https://help.keboola.com/transformations/workspace/)


================================================
File: cli/commands/status/index.md
================================================
---
title: Status Command
permalink: /cli/commands/status/
---

* TOC
{:toc}

**Show information about the current working directory.**

```
kbc status [flags]
```

## Options

[Global Options](/cli/commands/#global-options)

## Examples

Status of a project directory:
```
➜ kbc status
Project directory:  /home/kbc-project
Working directory:  .
Manifest path:      .keboola/manifest.json
```

Status of a template repository directory:
```
➜ kbc status
Repository directory:  /home/kbc-repository
Working directory:     .
Manifest path:         .keboola/repository.json
```

Status of a template directory:
```
➜ kbc status
Template directory:    /home/kbc-repository/my-template/v1
Working directory:     .
Manifest path:         src/manifest.jsonnet
```

Status of an unknown directory:
```
Directory "/home/kbc-test" is not a project or template repository.
```


## Next Steps

- [All Commands](/cli/commands/)
- [Init](/cli/commands/sync/init/)


================================================
File: cli/commands/sync/index.md
================================================
---
title: Sync Command
permalink: /cli/commands/sync/
---

* TOC
{:toc}

**Synchronization between a [local directory](/cli/structure/) and a [project](/cli/#subsystems).**

```
kbc sync [command]
```

|---
| Command | Description
|-|-|-
| [kbc sync init](/cli/commands/sync/init/) | Initialize a new local directory and run `kbc sync pull`. |
| [kbc sync pull](/cli/commands/sync/pull/) | Sync a project to the local directory. |
| [kbc sync push](/cli/commands/sync/push/) | Sync the local directory to the project. |
| [kbc sync diff](/cli/commands/sync/diff/) | Show differences between the local directory and the project. |


================================================
File: cli/commands/sync/diff/index.md
================================================
---
title: Diff Command
permalink: /cli/commands/sync/diff/
---

* TOC
{:toc}

**Show differences between a [local directory](/cli/structure/) and a [project](/cli/#subsystems).**

```
kbc sync diff [flags]
```

Or shorter:
```
kbc diff [flags]
kbc d [flags]
```

## Options

`--details`
: Show changed fields

[Global Options](/cli/commands/#global-options)

## Examples

When you change a configuration option of one component (e.g., an output table for a sheet 
in the [Google Drive extractor](/components/extractors/storage/google-drive/)), the output will look like this:

```
➜ kbc diff
* changed
- remote state
+ local state

Diff:
* R main/extractor/keboola.ex-aws-s3/my-aws-s-3-data-source/rows/share-cities-2 | changed: configuration
+ C main/extractor/keboola.ex-db-mysql/invoices
+ R main/extractor/keboola.ex-db-mysql/invoices/rows/customer

Use --details flag to list the changed fields.
```

If you want more details:

```
➜ kbc diff --details
* changed
- remote state
+ local state

Diff:
* R main/extractor/keboola.ex-aws-s3/my-aws-s-3-data-source/rows/jakubm-share-cities-2
  configuration:
    parameters.key:
      - cities2.csv
      + cities.csv
+ C main/extractor/keboola.ex-db-mysql/invoices
+ R main/extractor/keboola.ex-db-mysql/invoices/rows/customer
```

## Next Steps

- [All Commands](/cli/commands/)
- [Init](/cli/commands/sync/init/)
- [Pull](/cli/commands/sync/pull/)
- [Push](/cli/commands/sync/push/)


================================================
File: cli/commands/sync/init/index.md
================================================
---
title: Init Command
permalink: /cli/commands/sync/init/
---

* TOC
{:toc}

**Initialize a new [local directory](/cli/structure/) and run the first [pull](/cli/commands/sync/pull/).**

```
kbc sync init [flags]
```

Or shorter:
```
kbc init [flags]
kbc i [flags]
```

The command must be run in an empty directory.

If the command is run without options, it will start an interactive dialog asking for:
- URL of the [stack](https://help.keboola.com/overview/#stacks), for example, `connection.keboola.com`.
- [Master token](https://help.keboola.com/management/project/tokens/#master-tokens) to your project.
- Allowed [branches](https://help.keboola.com/tutorial/branches/) to work with.

It will allow you to create GitHub Actions workflows in the directory.

## Options

`--allow-target-env`
: Allow usage of `KBC_PROJECT_ID` and `KBC_BRANCH_ID` environment variables for future operations.  
Sets `true` to the `allowTargetEnv` field in the [manifest.json](/cli/structure/#manifest).

`-b, --branches <string>`
: Comma-separated list of branch IDs or name globs (use "*" for all) for branches you want to work with locally (default "main"); other branches in the project will be ignored.

`--ci-main-branch <string>`
: Name of the main branch for push/pull workflows (default "main")

`--ci-pull <bool>`
: Create a workflow to sync the main branch from the project every 5 minutes (default true)

`--ci-push <bool>`
: Create a workflow to push changes in the main branch to the project (default true)

`--ci-validate <bool>`
: Create a workflow to validate all branches on change (default true)

`-H, --storage-api-host <string>` 
: Keboola instance URL, e.g., "connection.keboola.com"

[Global Options](/cli/commands/#global-options)

## Examples

```
➜ kbc init

Please enter the Keboola Storage API host, e.g., "connection.keboola.com".
? API host connection.north-europe.azure.keboola.com

Please enter the Keboola Storage API token. Its value will be hidden.
? API token ***************************************************

Please select which project's branches you want to use with this CLI.
The other branches will still exist, but they will be invisible in the CLI.
? Allowed project's branches: only main branch

Created metadata directory ".keboola".
Created manifest file ".keboola/manifest.json".
Created file ".env.local" - it contains the API token, keep it local and secret.
Created file ".env.dist" - an ".env.local" template.
Created file ".gitignore" - to keep ".env.local" local.

? Generate workflows files for GitHub Actions? No

Init done. Running pull.
Plan for "pull" operation:
+ B main
+ C main/extractor/ex-generic-v2/empty
+ C main/extractor/keboola.ex-aws-s3/my-aws-s-3-data-source
+ R main/extractor/keboola.ex-aws-s3/my-aws-s-3-data-source/rows/share-cities
+ C main/extractor/keboola.ex-google-drive/my-google-drive-data-source
+ C main/extractor/keboola.ex-google-drive/my-google-drive-data-source/schedules/scheduler-for-7243915
+ C main/other/keboola.orchestrator/daily
+ C main/other/keboola.orchestrator/daily/schedules/scheduler-for-7243915
+ C main/other/keboola.sandboxes/address
+ C main/transformation/keboola.snowflake-transformation/address
+ C main/transformation/keboola.snowflake-transformation/address/variables
+ R main/transformation/keboola.snowflake-transformation/address/variables/values/default
Pull done.
```

## Next Steps

- [All Commands](/cli/commands/)
- [Pull](/cli/commands/sync/pull/)
- [Push](/cli/commands/sync/push/)
- [Diff](/cli/commands/sync/diff/)


================================================
File: cli/commands/sync/pull/index.md
================================================
---
title: Pull Command
permalink: /cli/commands/sync/pull/
---

* TOC 
{:toc}

**Sync a [project](/cli/#subsystems) to the [local directory](/cli/structure/).**

```
kbc sync pull [flags]
```

Or shorter:
```
kbc pull [flags]
kbc pl [flags]
```

Local changes will be overwritten to match the state of the project. 

If your local state is invalid, the command will fail unless you use the `--force` flag.

## Options

`--dry-run`
: Preview all changes

`--force`
: Ignore invalid local state

[Global Options](/cli/commands/#global-options)

## Examples

```
➜ kbc pull --dry-run
Pulling objects to the local directory.
Plan for "pull" operation:
  × C main/extractor/keboola.ex-db-mysql/7511990/invoices
  × R main/extractor/keboola.ex-db-mysql/7511990/invoices/rows/customer
Pull done.
```

## Next Steps

- [All Commands](/cli/commands/)
- [Init](/cli/commands/sync/init/)
- [Push](/cli/commands/sync/push/)
- [Diff](/cli/commands/sync/diff/)


================================================
File: cli/commands/sync/push/index.md
================================================
---
title: Push Command
permalink: /cli/commands/sync/push/
---

* TOC
{:toc}

**Sync a [local directory](/cli/structure/) to the [project](/cli/#subsystems).**

```
kbc sync push [flags]
```

Or shorter:
```
kbc push [flags]
kbc ph [flags]
```

The project state will be overwritten to match the local state.

## Options

`--dry-run`
: Preview all changes

`--encrypt`
: Encrypt unencrypted values before the push

`--force`
: Delete configurations missing in the local directory

[Global Options](/cli/commands/#global-options)

## Example

When you [create a configuration](/cli/commands/local/create/config/) of the MySQL extractor, the command will look like this:

```
➜ kbc push --dry-run

Plan for "push" operation:
  + C main/extractor/keboola.ex-db-mysql/7511990/invoices
  + R main/extractor/keboola.ex-db-mysql/7511990/invoices/rows/customer
Dry run, nothing changed.
Push done.
```

## Next Steps

- [All Commands](/cli/commands/)
- [Init](/cli/commands/sync/init/)
- [Pull](/cli/commands/sync/pull/)
- [Diff](/cli/commands/sync/diff/)


================================================
File: cli/commands/template/index.md
================================================
---
title: Manage Templates
permalink: /cli/commands/template/
---

* TOC
{:toc}

**Manage [templates](/cli/templates/structure/#template) in the [template repository](/cli/templates/structure/#repository).**

```
kbc template [command]
```

|---
| Command | Description
|-|-|-
| [kbc template repository](/cli/commands/template/repository/) | Manage a template [repository directory](/cli/templates/structure/#repository). |
| [kbc template repository init](/cli/commands/template/repository/init/) | Initialize a new [repository directory](/cli/templates/structure/#repository) in an empty directory. |
| [kbc template create](/cli/commands/template/create/) | Create a new template from an existing project. |
| [kbc template describe](/cli/commands/template/describe/) | Describe a template and its inputs. |
| [kbc template list](/cli/commands/template/list/) | List templates in the repository. |
| [kbc template test](/cli/commands/template/test/) | Manage template tests. |
| [kbc template test create](/cli/commands/template/test/create/) | Create template tests. |
| [kbc template test run](/cli/commands/template/test/run/) | Run template tests. |


================================================
File: cli/commands/template/create/index.md
================================================
---
title: Create Template
permalink: /cli/commands/template/create/
---

* TOC
{:toc}

**Create a new [template](/cli/templates/structure/#template) in the [repository directory]((/cli/templates/structure/#repository)) from an existing [project](/cli/#subsystems).**

```
kbc template create [flags]
```

An interactive dialog will start. It will guide you through the process of creating a new template.
See [Create Template Tutorial](/cli/templates/tutorial).


The command must be run in the [repository directory](/cli/templates/structure#repository).

## Options

`-a, --all-configs`
: Use all configs from the branch

`--all-inputs`
: Use all found config/row fields as user inputs

`-b, --branch string`
: Source branch ID or name

`-c, --configs string`
: Comma separated list of {componentId}:{configId}

`--description string`
: Template description

`--id string`
: Template ID

`--name string`
: Template name

`-H, --storage-api-host string`
: Storage API host, e.g., "connection.keboola.com"

[Global Options](/cli/commands/#global-options)

## Examples

See [Create Template Tutorial](/cli/templates/tutorial/#create-template).

## Next Steps

- [All Commands](/cli/commands/)
- [Init](/cli/commands/sync/init/)


================================================
File: cli/commands/template/describe/index.md
================================================
---
title: Describe Template
permalink: /cli/commands/template/describe/
---

* TOC
{:toc}

**Describe the [template](/cli/templates/structure/#template) and its inputs in the [repository directory]((/cli/templates/structure/#repository)).**

```
kbc template describe <template-id> [version] [flags]
```

If you don't provide the `version` parameter, the default version will be used.

The command must be run in the [repository directory](/cli/templates/structure#repository).

## Options

[Global Options](/cli/commands/#global-options)

### Examples

```
➜ kbc template describe

 Template ID:          my-template 
 Name:                 My Template 
 Description:          Full workflow to ... 
  
 Version:              0.0.1 
 Stable:               false 
 Description:          notes 
 Components:
   - keboola.ex-aws-s3
  
 Group ID:             g01 
 Description:          Default Group 
 Required:             all 
  
   Step ID:            g01-s01 
   Name:               Default Step 
   Description:        Default Step 
   Dialog Name:        Default Step 
   Dialog Description: Default Step 
  
     Input ID:         ex-generic-v2-api-base-url 
     Name:             Api BaseUrl 
     Description:      a 
     Type:             string 
     Kind:             input 
     Default:          "https://jsonplaceholder.typicode.com" 
  
     Input ID:         ex-db-mysql-db-host 
     Name:             Db Host 
     Description:      b 
     Type:             string 
     Kind:             input 
     Default:          "mysql.example.com" 
  
     Input ID:         ex-db-mysql-incremental 
     Name:             Incremental 
     Description:      c 
     Type:             bool 
     Kind:             confirm 
     Default:          false 
  
 Group ID:             g02 
 Description:          Group 2 
 Required:             all 
  
   Step ID:            g02-s01 
   Name:               Step 2-1 
   Description:        Step 2-1 
   Dialog Name:        Step 2-1 
   Dialog Description: Step 2-1 
  
     Input ID:         ex-generic-v2-api-base-url-2 
     Name:             Api BaseUrl 
     Description:      a 
     Type:             string 
     Kind:             input 
     Default:          "https://jsonplaceholder.typicode.com" 
```

## Next Steps

- [Templates](/cli/templates/)
- [All Commands](/cli/commands/)


================================================
File: cli/commands/template/list/index.md
================================================
---
title: List Templates
permalink: /cli/commands/template/list/
---

* TOC
{:toc}

**List [templates](/cli/templates/structure/#template) in the [repository directory]((/cli/templates/structure/#repository)).**

```
kbc template list [flags]
```

The command must be run in the [repository directory](/cli/templates/structure#repository).

## Options

[Global Options](/cli/commands/#global-options)

### Examples

```
➜ kbc template list

 Template ID:          my-template 
 Name:                 My Template 
 Description:          Full workflow to ... 
 Default version:      1.0.0 
  
   Version:            1.0.0 
   Stable:             true 
   Description:        notes 
  
   Version:            0.0.1 
   Stable:             false 
   Description:        notes 
  
  
 Template ID:          second-template 
 Name:                 Second Template 
 Description:          Full workflow to ... 
 Default version:      1.0.2 
  
   Version:            1.0.2 
   Stable:             true 
   Description:        notes 
```

## Next Steps

- [Templates](/cli/templates/)
- [All Commands](/cli/commands/)


================================================
File: cli/commands/template/repository/index.md
================================================
---
title: Manage Template Repository
permalink: /cli/commands/template/repository/
---

* TOC
{:toc}

**Manage a [template repository](/cli/templates/structure/#repository).**

```
kbc template repository [command]
```

|---
| Command | Description
|-|-|-
| [kbc template repository init](/cli/commands/template/repository/init/) | Initialize a new [repository directory](/cli/templates/structure/#repository) in an empty directory. |


================================================
File: cli/commands/template/repository/init/index.md
================================================
---
title: Init Template Repository
permalink: /cli/commands/template/repository/init/
---

* TOC
{:toc}

**Initialize a new [repository directory](/cli/templates/structure/#repository) in an empty directory.**

```
kbc template repository init [flags]
```

## Options

[Global Options](/cli/commands/#global-options)

## Examples

See [Create Template Tutorial](/cli/templates/tutorial/).

```
➜ kbc template repository init

Created metadata directory ".keboola".
Created repository manifest file ".keboola/repository.json".
Repository init done.
```

## Next Steps

- [Templates](/cli/templates/)
- [Create Template Tutorial](/cli/templates/tutorial/)
- [Use Template Tutorial](/cli/templates/tutorial/#use-template)



================================================
File: cli/commands/template/test/index.md
================================================
---
title: Template Tests
permalink: /cli/commands/template/test/
---

* TOC
{:toc}

**Manage [template](/cli/templates/structure/#template) tests in the [repository directory]((/cli/templates/structure/#repository)).**

```
kbc template test [command]
```

|---
| Command | Description
|-|-|-
| [kbc template test create](/cli/commands/template/test/create/) | Create template tests. |
| [kbc template test run](/cli/commands/template/test/run/) | Run template tests. |


================================================
File: cli/commands/template/test/create/index.md
================================================
---
title: Create Template Tests
permalink: /cli/commands/template/test/create/
---

* TOC
{:toc}

**Create [template](/cli/templates/structure/#template) tests in the [repository directory]((/cli/templates/structure/#repository)). 
See the [test structure](/cli/templates/tests/) for more details.**

```
kbc template test create [template] [version] [flags]
```

This command creates a test for the specified template.

If you do not provide the `version` parameter, the default version will be used.

This command must be run in the [repository directory](/cli/templates/structure#repository).

It requires at least one existing project in a public Keboola stack, defined in the environment variable `KBC_TEST_PROJECTS_FILE`.

For example:
```
KBC_TEST_PROJECTS_FILE=./projects.json
``` 

Example project file:
```json
[
  {
    "host": "connection.keboola.com",
    "project": 12345,
    "stagingStorage": "s3",
    "backend": "snowflake",
    "token": "XXXX",
    "legacyTransformation": true
  }
]
```

## Options

`--test-name <string>`
: Run only the test with the specified name

`--inputs-file <string>`
: Path to the file containing the template inputs

`--test-projects-file <string>`
: File containing the projects available for templates

`--verbose <bool>`
: Show details (default false)


[Global Options](/cli/commands/#global-options)

### Examples

```
➜ kbc template test create my-template 0.0.1 --test-name one --inputs-file ./inputs.json
New objects from "keboola/my-template/0.0.1" template:
  + C main/extractor/ex-generic-v2/empty
Template "keboola/my-template/0.0.1" has been applied, instance ID: 1234
The test was created in the folder tests/one.
```

## Next Steps

- [Tests](/cli/templates/tests/)
- [Templates](/cli/templates/)
- [All Commands](/cli/commands/)


================================================
File: cli/commands/template/test/run/index.md
================================================
---
title: Run Template Tests
permalink: /cli/commands/template/test/run/
---

* TOC
{:toc}

**Run [template](/cli/templates/structure/#template) tests in the [repository directory]((/cli/templates/structure/#repository)).
See [Test Structure](/cli/templates/tests/) for more details.**

```
kbc template test run [template] [version] [flags]
```

This command runs tests for a specified template or all templates in the repository (if you do not provide the `template` parameter).

If you provide `template` but not the `version` parameter, the default version will be used.

This command must be run in the [repository directory](/cli/templates/structure#repository).

It requires at least one existing project in a public Keboola stack defined in the environment variable `KBC_TEST_PROJECTS_FILE`. 

For example: 
```
KBC_TEST_PROJECTS_FILE=./projects.json
``` 

This is an example of a projects file:
```json
[
  {
    "host": "connection.keboola.com",
    "project": 12345,
    "stagingStorage": "s3",
    "backend": "snowflake",
    "token": "XXXX",
    "legacyTransformation": true
  }
]
```

## Options

`--local-only <bool>`
: Run only local tests (default false)

`--remote-only <bool>`
: Run only remote tests (default false)

`--test-name <string>`
: Run only the test with the specified name

`--test-projects-file <string>`
: File containing the projects available for templates

`--verbose <bool>`
: Show details about running tests (default false)


[Global Options](/cli/commands/#global-options)

### Examples

```
➜ kbc template test run --local-only
PASS keboola/my-template/0.0.1 one local
PASS keboola/template-2/2.0.0 one local
```

## Next Steps

- [Tests](/cli/templates/tests/)
- [Templates](/cli/templates/)
- [All Commands](/cli/commands/)


================================================
File: cli/dbt/index.md
================================================
---
title: dbt
permalink: /cli/dbt/
---

* TOC
{:toc}

Keboola CLI allows you to integrate with your dbt project. The commands must be run in a directory with a dbt project 
(i.e., containing `dbt_project.yml`) or its subdirectory.

[kbc dbt init](/cli/commands/dbt/init/) command creates a Snowflake [workspace](https://help.keboola.com/transformations/workspace/)
in Keboola, configures a dbt target with it, generates source files for every table in Keboola Storage and outputs
commands to create environmental variables so that you don't store Snowflake credentials directly in the dbt configuration files. 

The command output will look like this:

```
➜ kbc dbt init

Please enter the Keboola Storage API host, e.g., "connection.keboola.com".
? API host: connection.north-europe.azure.keboola.com


Please enter the Keboola Storage API token. The value will be hidden.
? API token: **************************************************


Please enter the target name.
Allowed characters: a-z, A-Z, 0-9, "_".
? Target Name: target1


? Enter a name for the workspace to be created: dbt_workspace

Creating a new workspace, please wait.
Created the new workspace "dbt_workspace".
Profile stored in "profiles.yml".
Sources stored in the "models/_sources" directory.
Commands to set the environment for the dbt target:
  export DBT_KBC_TARGET1_TYPE=snowflake
  export DBT_KBC_TARGET1_SCHEMA=WORKSPACE_12345
  export DBT_KBC_TARGET1_WAREHOUSE=KEBOOLA_PROD_SMALL
  export DBT_KBC_TARGET1_DATABASE=KEBOOLA_1234
  export DBT_KBC_TARGET1_ACCOUNT=keboola.west-europe.azure
  export DBT_KBC_TARGET1_USER=KEBOOLA_WORKSPACE_12345
  export DBT_KBC_TARGET1_PASSWORD=abcd1234
```

## Profile

The target name is used for the configuration in the dbt's `profiles.yml` file. See the official documentation for more information: [https://docs.getdbt.com/reference/profiles.yml](https://docs.getdbt.com/reference/profiles.yml).

The created target in `profiles.yml` does not contain any sensitive information, it just references environmental variables. 

{% raw  %}
```yaml
TestProject:
    target: target1
    outputs:
        target1:
            account: '{{ env_var("DBT_KBC_TARGET1_ACCOUNT") }}'
            database: '{{ env_var("DBT_KBC_TARGET1_DATABASE") }}'
            password: '{{ env_var("DBT_KBC_TARGET1_PASSWORD") }}'
            schema: '{{ env_var("DBT_KBC_TARGET1_SCHEMA") }}'
            type: '{{ env_var("DBT_KBC_TARGET1_TYPE") }}'
            user: '{{ env_var("DBT_KBC_TARGET1_USER") }}'
            warehouse: '{{ env_var("DBT_KBC_TARGET1_WAREHOUSE") }}'
send_anonymous_usage_stats: false
```
{% endraw %}

## Sources

The sources are stored in the `models/_sources` directory and the command generates a separate file for every bucket. The directory
can look like this:

```
➜ ls -1 models/_sources

in.c-keboola-ex-facebook-8103426.yml
in.c-keboola-ex-facebook-ads-15044494.yml
in.c-keboola-ex-gcalendar-1279777.yml
in.c-test.yml
in.c-test1647518938917259000.yml
```

Each source file contains the definition for all tables in the specific bucket, like this:

{% raw  %}
```yaml
version: 2
sources:
    - name: in.c-test
      freshness:
        warn_after:
            count: 1
            period: day
      database: '{{ env_var("DBT_KBC_TARGET1_DATABASE") }}'
      schema: in.c-test
      loaded_at_field: '"_timestamp"'
      tables:
        - name: products
          quoting:
            database: true
            schema: true
            identifier: true
          columns: []
```
{% endraw %}

See the official documentation for more information: [https://docs.getdbt.com/docs/build/sources](https://docs.getdbt.com/docs/build/sources).

## Env

The command in the end outputs commands for setting all environment variables you are going to need for the dbt project.

```
  export DBT_KBC_TARGET1_TYPE=snowflake
  export DBT_KBC_TARGET1_SCHEMA=WORKSPACE_12345
  export DBT_KBC_TARGET1_WAREHOUSE=KEBOOLA_PROD_SMALL
  export DBT_KBC_TARGET1_DATABASE=KEBOOLA_1234
  export DBT_KBC_TARGET1_ACCOUNT=keboola.west-europe.azure
  export DBT_KBC_TARGET1_USER=KEBOOLA_WORKSPACE_12345
  export DBT_KBC_TARGET1_PASSWORD=abcd1234
  ```

Single steps in this command can be run separately; see [kbc dbt generate](/cli/commands/dbt/generate/).

## Available Commands

|---
| Command | Description
|-|-|-
| [kbc dbt init](/cli/commands/dbt/init/) | Initialize profiles, sources, and environment variables for use with dbt. |
| [kbc dbt generate](/cli/commands/dbt/generate/) | Generate profiles, sources, or environment variables for use with dbt. |
| [kbc dbt generate profile](/cli/commands/dbt/generate/profile/) | Generate profiles for use with dbt. |
| [kbc dbt generate sources](/cli/commands/dbt/generate/sources/) | Generate sources for use with dbt. |
| [kbc dbt generate env](/cli/commands/dbt/generate/env/) | Generate environment variables for use with dbt. |


================================================
File: cli/devops-use-cases/index.md
================================================
---
title: DevOps Use Cases
permalink: /cli/devops-use-cases/
---

* TOC
{:toc}

Keboola CLI provides a Keboola project representation in
a [directory structure](/cli/structure/#directory-structure) with [JSON files](/cli/structure/#configurations).
The [--allow-target-env](https://developers.keboola.com/cli/commands/sync/init/#:~:text=Options-,%2D%2Dallow%2Dtarget%2Denv,-Allow%20usage%20of)
init mode
enables you to apply a GitOps management framework to all your projects. Here we list several example use cases that are possible
using this mode.

## Git-Based Branch Management

By overriding the destination branch via the `KBC_BRANCH_ID` environment variable, you can
map each Git branch to a particular GUI Dev branch and then use Git to perform the merge or rebase even between different
branches.

{: .image-popup}
![branch_management.png](/cli/devops-use-cases/branch_management.png)

### Tutorial

#### Initialization

1. First, let’s initialize a GitHub repository with a single main branch via the `kbc init --allow-target-env` command.

- Fill in all parameters as usual.
- Select only the main branch in this case.

  {: .image-popup}
  ![init.png](/cli/devops-use-cases/init.png)

2. Initialize the GitHub repository using the `git init` command.

Now, you can perform `kbc push` or `kbc pull` as normal, enabling you to sync the production development branch into main.

#### Creating a new branch

Let’s create a new branch named `new-feature`.

```shell
git checkout -b new-feature
```

Now, you can link the current branch to an actual Keboola development branch:

1. Create a new Keboola Dev Branch named `new-feature`. The following command will create a remote branch off the production
   branch.

    ```shell
    kbc remote create branch -n new-feature --output-json new_branch.json 
    ```

2. Obtain the newly created branch ID.
    The newly created branch ID can be found in the resulting file `new_branch.json`.
    ```json
    {
      "newBranchId": 123
    }
    ```
   
3. Override the destination branch by setting the `KBC_BRANCH_ID` environment variable.
    
    ```shell
    export KBC_BRANCH_ID=123
    ```

4. Run `kbc push` to synchronize the local changes.

Any changes that you perform in the remote branch will be now synchronized back using the `kbc pull` command as long as
the `KBC_BRANCH_ID` variable is set.

#### Merging the changes

Once you are ready, you can commit the changes and compare to the main branch and eventually merge the new branch to
your main.

**WARNING:** Once you switch back to the main branch, do not forget to unset the `KBC_BRANCH_ID` (using
the `unset KBC_BRANCH_ID` command) variable so the `kbc push/pull` commands run against the main branch again.

## Deployment to Multiple Projects

By using the `kbc init --allow-target-env` mode, you can override the destination project. This is, for instance, leveraged in
the Dev/Prod Manager example use case. You can use this, for instance, to distribute a single project (as a
“template”) into multiple ones to start from.

{: .image-popup}
![project_deploy.png](/cli/devops-use-cases/project_deploy.png)

### Tutorial

1. First, let’s **create a GitHub repository** with a single main branch via the `kbc init --allow-target-env` command:

- Fill in all parameters as usual.
- Select only the main branch in this case.

  {: .image-popup}
  ![init.png](/cli/devops-use-cases/init.png)

2. **Obtain the main branch ID**:

   To get the destination project main branch ID, you can use
   the [List Branches API call](https://keboola.docs.apiary.io/#reference/development-branches/branches/list-branches)
   and search for a branch named `main`.

   Alternatively, from any component configuration, go to the Developer Tools (`F12` in Chrome)
   and search for any underlying API call, e.g., `versions`. You will see the branch ID in the URL (
   *xxx/branch/{BRANCH_ID}/xx*).

   {: .image-popup}
   ![devtools.png](/cli/devops-use-cases/devtools.png)

   Now you can perform `kbc push` and the project definition will be transferred into the main branch of the selected
   project.

3. **Change the destination project ID and its main branch:**

```shell
export KBC_PROJECT_ID=1234
export KBC_BRANCH_ID=972851
```

## Multi-Stage (and Multi-Project) Environment Management

Keboola's [native branching environment](https://help.keboola.com/components/branches/) is typically sufficient for small
to medium projects. However, in an enterprise setup, it may
be necessary to have completely separate environments where both data and data pipeline definitions (code) are isolated.
In such setups, administrators may need to define complex “branch protection” rules to closely control who can release
new features into the production environment, as well as how and when these releases occur. In the software engineering
world, this is often achieved with version control systems like Git.

Thanks
to[ Keboola's CLI functionality](https://developers.keboola.com/cli/commands/sync/init/#:~:text=Options-,%2D%2Dallow%2Dtarget%2Denv,-Allow%20usage%20of),
it is possible to define and synchronize separate environments, including the
ones with a [multi-project architecture](https://help.keboola.com/catalog/multi-project/) setup, entirely via Git. This
gives users the freedom to establish deployment rules
according to their needs and allows for the testing of entire pipelines across multiple projects in completely isolated
environments.

{: .image-popup}
![devprod.png](/cli/devops-use-cases/devprod.png)

### High-Level Workflow

To implement the above suggested setup, we need the following tools:
- **Keboola CLI**: sync project representations with an enabled overridden target environment
- **Keboola Variables Vault**: a feature that allows users to define variables and secrets on a project level and reference them in configurations
- **GitHub & Git Actions**: a versioning system to hold the project representations and define deployment rules and validations

{: .image-popup}
![dev_prod_flow.png](/cli/devops-use-cases/dev_prod_flow.png)

We have prepared a sample [Streamlit application](https://github.com/keboola/cli-based-sync-generator) 
that can be deployed as a [Data App](https://help.keboola.com/components/data-apps/#git-repository) in the Keboola environment to assist with the initialization process.

This application includes GitHub actions that allow you to manage this scenario. It is expected that users will modify this flow to their needs.

To learn about the full use case, please refer to [this blog post](https://www.keboola.com/blog/keboola-dev-prod-lifecycle-via-git), where we describe the workflow in depth.


================================================
File: cli/getting-started/index.md
================================================
---
title: Getting Started
permalink: /cli/getting-started/
---

* TOC
{:toc}

## Init the Directory

To manage a project using Keboola CLI, you need to initialize a directory. Create an empty directory, hop into it and run
the init command.

```
mkdir my-kbc-project
cd my-kbc-project
kbc init
```

The command runs interactively by default and asks for the URL of the Keboola instance you want to use and
a [Master token](https://help.keboola.com/management/project/tokens/#master-tokens) to your project. It pulls all 
configurations from the project to the local directory.

```
➜ kbc init

Please enter the Keboola Storage API host, e.g., "connection.keboola.com".
? API host connection.north-europe.azure.keboola.com

Please enter the Keboola Storage API token. Its value will be hidden.
? API token ***************************************************

Please select which project's branches you want to use with this CLI.
The other branches will still exist, but they will be invisible in the CLI.
? Allowed project's branches: only main branch

Created metadata directory ".keboola".
Created manifest file ".keboola/manifest.json".
Created file ".env.local" - it contains the API token, keep it local and secret.
Created file ".env.dist" - an ".env.local" template.
Created file ".gitignore" - to keep ".env.local" local.

? Generate workflows files for GitHub Actions? No

Init done. Running pull.
Plan for "pull" operation:
+ B main
+ C main/extractor/keboola.ex-aws-s3/my-aws-s-3-data-source
+ R main/extractor/keboola.ex-aws-s3/my-aws-s-3-data-source/rows/share-cities
+ C main/extractor/keboola.ex-google-drive/my-config
+ C main/extractor/keboola.ex-google-drive/my-config/schedules/scheduler-for-7241051
+ C main/other/keboola.orchestrator/daily
+ C main/other/keboola.orchestrator/daily/schedules/scheduler-for-7243915
+ C main/other/keboola.sandboxes/address
+ C main/transformation/keboola.snowflake-transformation/address
+ C main/transformation/keboola.snowflake-transformation/address/variables
+ R main/transformation/keboola.snowflake-transformation/address/variables/values/default
Pull done.
```

You could want to version your project in a git repository. Feel free to call `git init` and make an initial commit.
The init command can prepare workflows for GitHub Actions to keep your directory and the project in sync. 

## Push Changes to the Project

When you update your local directory, you can compare the changes with the project:

```
➜ kbc diff --details
* changed
- remote state
+ local state

Diff:
* C main/extractor/keboola.ex-google-drive/my-config | changed: configuration
```

Before pushing the changes to the project, you are able to preview them first:

```
➜ kbc push --dry-run
Plan for "push" operation:
  * C main/extractor/keboola.ex-google-drive/my-config | changed: configuration
Dry run, nothing changed.
Push done.
```

And finally, perform the actual changes to the project:

```
➜ kbc push
Plan for "push" operation:
  * C main/extractor/keboola.ex-google-drive/my-config | changed: configuration
Push done.
```

## Create New Configurations

The configuration can be created in two ways. You can create an empty configuration or copy an existing one.

### Create Empty Configuration
Let's say you want to download some data from Wikipedia. You can run [`kbc create`](/cli/commands/local/create/config/) 
without options and be guided by an interactive dialog, or fill all the options:

```
➜ kbc create config -b main -c ex-generic-v2 -n wiki
Created new config "main/extractor/ex-generic-v2/wiki"
```

Edit file `main/extractor/ex-generic-v2/wiki/config.json` as 
a [Generic Extractor](/extend/generic-extractor/) configuration. A super basic 
configuration could look like this:

```json
{
  "api": {
    "baseUrl": "https://wikipedia.org"
  }
}
```

Now we can push it to the project:

```
➜ kbc push
Plan for "push" operation:
  + C main/extractor/ex-generic-v2/wiki
Push done.
```

### Create Configurations by Copy & Paste

Let's say you want to copy a configuration of your Generic Extractor. Duplicate its directory:

{: .image-popup}
![Screenshot -- Duplicate a configuration directory](/cli/getting-started/configurations-copy-1.jpg)

Run the `persist` command:

```
➜ kbc persist
Plan for "persist" operation:
  + C main/extractor/ex-generic-v2/wiki 2
Persist done.
Plan for "rename" operation:
  - main/extractor/ex-generic-v2/{wiki 2 -> wiki-001}
Rename done.
```

The directory name is fixed and the configuration added to the manifest:

{: .image-popup}
![Screenshot -- Fixed configuration directory](/cli/getting-started/configurations-copy-2.jpg)

## Pull Changes from the Project

When you create or change configurations in the project, you can pull them to the local directory.

Show the changes between the project and the local directory:

```
➜ kbc diff --details
* changed
- remote state
+ local state

Diff:
* C main/extractor/ex-generic-v2/wiki
  configuration:
    api.baseUrl:
      - https://en.wikipedia.org/wiki/Git
      + https://wikipedia.org
```

Preview the pull command without changing anything first:

```
➜ kbc pull --dry-run
Plan for "pull" operation:
  * C main/extractor/ex-generic-v2/wiki | changed: configuration
Dry run, nothing changed.
Pull done.
```

And finally, pull the changes to the local directory. Note that it will override any changes to your local directory:

```
➜ kbc pull
Plan for "pull" operation:
  * C main/extractor/ex-generic-v2/wiki | changed: configuration
Pull done.
```

## Next Steps

- [Directory Structure](/cli/structure/)
- [Commands](/cli/commands/)


================================================
File: cli/github-integration/index.md
================================================
---
title: GitHub Integration
permalink: /cli/github-integration/
---

* TOC
{:toc}

The tool can generate workflows for GitHub Actions within commands [init](/cli/commands/sync/init/) 
and [workflows](/cli/commands/ci/workflows/).

Secret `KBC_STORAGE_API_TOKEN` with your master token needs to be added to the GitHub 
[secrets](https://docs.github.com/en/actions/security-guides/encrypted-secrets#creating-encrypted-secrets-for-a-repository).

{: .image-popup}
![Screenshot -- GitHub Actions](/cli/github-integration/github-actions.jpg)

## Pull

The Pull workflow is set to run automatically every five minutes to [pull](/cli/commands/sync/pull/) the changes from 
the project in Keboola. If it finds any changes, it creates a commit to the repository.

*Note: GitHub does not guarantee periodic running at exact times. The triggers may be delayed a few minutes 
depending on the current GitHub Actions workload.* 

{: .image-popup}
![Screenshot -- A commit by Pull action](/cli/github-integration/pull-commit.jpg)

The commit contains description of the change:

{: .image-popup}
![Screenshot -- A change description by Pull action](/cli/github-integration/pull-description.jpg)

## Push

The Push workflow is triggered by a push to the GitHub repository to [push](/cli/commands/sync/push/) the changes from
the local directory to the project in Keboola.

## Validate

The Validate workflow is triggered by a push to a branch in the GitHub repository to validate and preview its changes by 
a [push --dry-run](/cli/commands/sync/push/).


================================================
File: cli/installation/index.md
================================================
---
title: Installation
permalink: /cli/installation/
---

* TOC
{:toc}

The recommended way to install Keboola CLI is with one of the package managers listed below.
This allows you to easily upgrade to a new version.

Alternatively, you can:
- Download precompiled binaries from [cli-dist.keboola.com](https://cli-dist.keboola.com/?prefix=zip/). 
- Or build binary from [source code](#build-from-source).

Changelog can be found at [github.com/keboola/keboola-as-code/releases](https://github.com/keboola/keboola-as-code/releases).

## macOS

Installation on macOS is managed by Homebrew. If you don't have Homebrew available on your system,
[install it](https://docs.brew.sh/Installation.html) before continuing.

Install:

```bash
brew tap keboola/keboola-cli
brew install keboola-cli
kbc --version
```

Upgrade:

```bash
brew upgrade keboola-cli
```

## Debian / Ubuntu

Install:

```bash
sudo wget -P /etc/apt/trusted.gpg.d https://cli-dist.keboola.com/deb/keboola.gpg
echo "deb https://cli-dist.keboola.com/deb /" | sudo tee /etc/apt/sources.list.d/keboola.list
sudo apt-get update
sudo apt-get install keboola-cli
kbc --version
```

Upgrade:

```bash
sudo apt-get update
sudo apt-get install keboola-cli
```

## Fedora

Install:

```bash
sudo rpm --import https://cli-dist.keboola.com/rpm/keboola.gpg
echo "[keboola]
name=keboola
baseurl=https://cli-dist.keboola.com/rpm
enabled=1
gpgcheck=1
gpgkey=https://cli-dist.keboola.com/rpm/keboola.gpg
" | sudo tee /etc/yum.repos.d/keboola.repo
sudo dnf install keboola-cli
kbc --version
```

Upgrade:

```bash
sudo dnf update keboola-cli
```

## Alpine

Install:

```bash
echo "https://cli-dist.keboola.com/apk" | sudo tee -a /etc/apk/repositories
sudo wget -P /etc/apk/keys/ https://cli-dist.keboola.com/apk/keboola.rsa.pub
sudo apk update
sudo apk add keboola-cli
kbc --version
```

Upgrade:

```bash
apk update
apk add --upgrade keboola-cli
```

## Windows

### WinGet

If you don't have App Installer available on your system, either install it [from the Microsoft Store](https://apps.microsoft.com/store/detail/app-installer) or [download directly](https://winget.run/) before continuing.

Install:

```shell
winget install Keboola.KeboolaCLI
kbc --version
```

Upgrade:

```shell
winget upgrade Keboola.KeboolaCLI
```


### Chocolatey

If you don't have Chocolatey available on your system, [install it](https://chocolatey.org/install) before continuing.

Install:

```shell
choco install keboola-cli
kbc --version
```

Upgrade:

```shell
choco upgrade keboola-cli
```

### Scoop

If you don't have Scoop available on your system, [install it](https://scoop.sh/) before continuing.

Install:

```shell
scoop bucket add keboola https://github.com/keboola/scoop-keboola-cli.git
scoop install keboola/keboola-cli
kbc --version
```

Upgrade:

```shell
scoop update keboola/keboola-cli
```

### Download

Use a [msi installer](https://cli-dist.keboola.com/?prefix=msi/) or a [precompiled binary](https://cli-dist.keboola.com/?prefix=zip/). 

## Build From Source

1. Install the [Go environment](https://golang.org/doc/install) (if you haven't done so already).
2. Clone the source from GitHub:
```
git clone https://github.com/keboola/keboola-as-code
cd keboola-as-code
```

3. Run the build:  
On Linux or macOS:
```
go build -o target/kbc ./cmd/kbc/main.go
```
On Windows:
```
go build -o target/kbc.exe ./cmd/kbc/main.go
```

4. Binary is located in `target/kbc` or `target/kbc.exe`.

## Next Steps

- [Getting Started](/cli/getting-started/)
- [Commands](/cli/commands/)


================================================
File: cli/structure/index.md
================================================
---
title: Project Directory Structure
permalink: /cli/structure/
---

* TOC
{:toc}

The initial configuration of your local directory can be done using the [init command](/cli/commands/sync/init/). This command initializes 
the directory and pulls configurations from the project.

The **Storage API token** for your project is stored in the `.env.local` file under the `KBC_STORAGE_API_TOKEN` directive. 
Currently, you must use a [master token](https://help.keboola.com/management/project/tokens/#master-tokens).
To maintain security, `.env.local` is automatically included in the .gitignore file to prevent it from being committed to your Git repository.

[Manifest - Naming](#naming) defines directory names. Typically, this setting does not need to be changed. 
Each object (branch, configuration, row) is guaranteed to have a unique directory, even if objects share the same name.

Below is an example of a default project directory structure. Some files and directories are specific to the component type. 
For example, transformations are represented by native files. A more detailed description can be found in the chapters below.

<br>

```
🟫 .gitignore                   - excludes ".env.local" from the Git repository
🟫 .env.local                   - contains the Storage API token
🟫 .env.dist                    - template for ".env.local"
📂 .keboola                     - project metadata directory
┣ 🟦 manifest.json              - contains object IDs, paths, naming and other configuration details
┣ 🟦 project.json               - project cache for local commands, including backends and features
┗ 🟫 .kbcignore                 - optional file listing paths to configurations to exclude from CLI sync
🟩 description.md               - project description
📂 [branch-name]                - branch directory (e.g., "main")
┣ 🟦 meta.json                  
┣ 🟩 description.md             
┣ 📂 _shared                    - shared code directory
┃ ┗ 📂 [target-component]       - target component (e.g., "keboola.python-transfomation")
┃   ┗ 📂 codes      
┃     ┗ 📂[code-name]           - shared code directory
┃       ┣ 🟫 code.[ext]         - native file (e.g., ".sql" or ".py")
┃       ┣ 🟦 config.json    
┃       ┣ 🟦 meta.json   
┃       ┗ 🟩 description.md
┗ 📂 [component-type]           - e.g., extractor, app, ...
  ┗ 📂 [component-id]           - e.g., keboola.ex-db-oracle
    ┗ 📂 [config-name]          - configuration directory (e.g., "raw-data")
      ┣ 🟦 config.json           
      ┣ 🟦 meta.json    
      ┣ 🟩 description.md    
      ┣ 📂 rows                 - only if the configuration has some rows
      ┃ ┗ 📂 [row-name]         - configuration row directory (e.g., "prod-fact-table")
      ┃   ┣ 🟦 config.json     
      ┃   ┣ 🟦 meta.json
      ┃   ┗ 🟩 description.md
      ┣ 📂 blocks               - only if the configuration is a transformation
      ┃ ┗ 📂 001-block-1        - block directory
      ┃   ┣ 🟦 meta.json   
      ┃   ┗ 📂 001-code-1       - code directory
      ┃     ┣ 🟫 code.[ext]     - native file (e.g., ".sql" or ".py")
      ┃     ┗ 🟦 meta.json   
      ┣ 📂 phases               - only if the configuration is an orchestration
      ┃ ┗ 📂 001-phase          - phase directory
      ┃   ┣ 🟦 phase.json   
      ┃   ┗ 📂 001-task         - task directory
      ┃     ┗ 🟦 task.json   
      ┣ 📂 schedules            - only if the configuration has some schedules
      ┃ ┗ 📂 [schedule-name]    - schedule directory
      ┃   ┣ 🟦 config.json     
      ┃   ┣ 🟦 meta.json
      ┃   ┗ 🟩 description.md
      ┗ 📂 variables            - only if the configuration has some variables defined
        ┣ 🟦 config.json        - variable definition, name, and type
        ┣ 🟦 meta.json
        ┣ 🟩 description.md
        ┗ 📂 values             - multiple sets of values can be defined
          ┗ 📂 default          - default values directory
            ┣ 🟦 config.json    - default values     
            ┣ 🟦 meta.json
            ┗ 🟩 description.md  
```

## Branches

The tool works with [development branches](/components/branches/) by default. You can specify which branches from the project 
you want to work with locally during the [init](/cli/commands/sync/init/) command. Alternatively, you can ignore the development branches concept and work exclusively
with the main branch. However, note that all configurations will then be stored in the `main` directory.

The main branch directory is simply named `main` and does not include the branch ID. This makes it easily distinguishable from the other branches.

Each branch directory contains:

- `description.md`: Use this file to write a branch description formatted in [Markdown](https://www.markdownguide.org/).
- `meta.json`: Contains the name of the branch and a flag indicating whether it is the default branch.

Example of `meta.json`:
```json
{
  "name": "Main",
  "isDefault": true
}
```

Within the branch directory, configurations are organized into thematic directories: `extractor`, `other`, `transformation`, and `writer`.

Example of a branch folder with components configurations:

{: .image-popup}
![Screenshot -- A configuration directory example](/cli/structure/directory-example.jpg)


## Configurations

Each configuration directory contains the following files:

- `config.json`: Includes parameters specific to the component.
- `description.md`: A description file formatted in [Markdown](https://www.markdownguide.org/).
- `meta.json`: Contains the name of the configuration.

Example of `config.json` for the Generic extractor:
```json
{
  "parameters": {
    "api": {
      "baseUrl": "https://wikipedia.org"
    } 
  }
}
```

Example of `meta.json`:
```json
{
  "name": "Wikipedia"
}
```

Configuration directories can be copied freely within the project and between projects. Their IDs are stored 
in the [manifest](/cli/structure/#manifest). After copying, run the [persist command](/cli/commands/local/persist/) to generate a new ID for the configuration and update it in the manifest.

## Configuration Rows

The directory structure for configuration rows is identical to that of configurations. The component configuration
includes a `rows` directory, which contains a subdirectory for each row. Each row directory includes `config.json`, 
`description.md`, and `meta.json`.

Example of `meta.json`:
```json
{
  "name": "share/cities2",
  "isDisabled": false
}
```

Example of a Google Drive extractor configuration:

{: .image-popup}
![Screenshot -- A configuration rows directory example](/cli/structure/directory-rows-example.jpg)

## Transformations

In addition to standard configurations, transformation directories include a `blocks` directory containing a list of codes.
Codes are stored as native files corresponding to the transformation type. For example, Snowflake transformations store codes
in `.sql` files.

Example of a Snowflake transformation configuration:

{: .image-popup}
![Screenshot -- A transformation directory example](/cli/structure/directory-transformation-example.jpg)

## Variables

The [variables](https://help.keboola.com/transformations/variables/#variables) directory, in addition to the standard 
configuration layout, contains a `values` subdirectory.

For example, suppose you have the following two variables in your transformation:

{: .image-popup}
![Screenshot -- Variables in the UI](/cli/structure/variables-ui.jpg)

When you [pull](/cli/commands/sync/pull/) them to the local directory, the structure will look like this:

{: .image-popup}
![Screenshot -- Configuration directory with the variables](/cli/structure/variables-directory.jpg)

Variables configuration in `variables/config.json`:

```json
{
  "variables": [
    {
      "name": "state",
      "type": "string"
    },
    {
      "name": "city",
      "type": "string"
    }
  ]
}
```

Default values configuration in `variables/values/default/config.json`:

```json
{
  "values": [
    {
      "name": "state",
      "value": "NY"
    },
    {
      "name": "city",
      "value": "Boston"
    }
  ]
}
```

## Shared Code

[Shared code](https://help.keboola.com/transformations/variables/#shared-code) blocks are stored in the branch directory 
under the `_shared` subdirectory, enabling reuse across different configurations.

If you create shared code from a block:

{: .image-popup}
![Screenshot -- Shared code directory](/cli/structure/shared-code-ui.jpg)

It will move to the `_shared` directory:

{: .image-popup}
![Screenshot -- Shared code directory](/cli/structure/shared-code-directory.jpg)

The code in the transformation file `blocks/block-1/join/code.sql` will then be replaced with:

{: .image-popup}
![Screenshot -- Shared code code](/cli/structure/shared-code-code.jpg)


## Schedules

The [Orchestrator](https://help.keboola.com/orchestrator/running) or any other component can have a schedule to run 
automatically and periodically. The schedule configuration is stored within a specific directory.

{: .image-popup}
![Screenshot -- Scheduler directory](/cli/structure/scheduler-directory.jpg)

The `config.json` file for the schedule contains the schedule in [crontab](https://crontab.guru/) format, the timezone, and a flag 
indiciating whether the schedule is enabled. 

For example, the following configuration runs at the 40th minute of every hour:

```json
{
  "schedule": {
    "cronTab": "40 */1 * * *",
    "timezone": "UTC",
    "state": "enabled"
  },
  "target": {
    "mode": "run"
  }
}
```

## Orchestrations

Orchestrator directories include the `phases` directory, which contains a list of tasks for execution.

Example:

{: .image-popup}
![Screenshot -- An orchestration directory](/cli/structure/directory-orchestration-example.png)

Example `phase.json`:

```json
{
  "name": "Transformation",
  "dependsOn": [
    "001-extraction"
  ]
}
```

Example `task.json`:

```json
{
  "name": "keboola.snowflake-transformation-7241628",
  "task": {
    "mode": "run",
    "configPath": "transformation/keboola.snowflake-transformation/address-completion"
  },
  "continueOnFailure": false,
  "enabled": true
}
```

**Using `kbcdir.jsonnet` for different orchestration phases:**  

The `kbcdir.jsonnet` file can be used to specify which directories in the phases folder should be ignored for different project backends. By setting the `isIgnored` value to true in the file, you can exclude specific directories.

Example `kbcdir.jsonnet`:
```jsonnet
{
  "isIgnored":false 
}
```

## Manifest

The local state of the project is stored in the `.keboola/manifest.json` file. It is not recommended to modify
this file manually.

### Basic Manifest Structure

- `version`: Current major version (e.g., `2`)
- `project`: Information about the project
  - `id`: ID of the project
  - `apiHost`: URL of the Keboola instance (e.g., `connection.keboola.com`)
- `allowTargetEnv`: Boolean (default: `false`)
  - If `true`, allows environment variables `KBC_PROJECT_ID` and `KBC_BRANCH_ID` to temporary override the target project and branch without modifying the manifest.
  - The mapping is bidirectional and occurs during the manifest's save and load operations.
  - For more information, see the [--allow-target-env](/cli/commands/sync/init/#options) option in the [kbc sync init](/cli/commands/sync/init/) command.
- `sortBy`: Property name used for sorting configurations (default: `id`)
- `naming`: Rules for directory naming ([see details](/cli/structure/#naming))
- `allowedBranches`: Array of branches to work with
- `ignoredComponents`: Array of components to exclude
- `templates`: 
  - `repositories` (*array*):
    - Local repository:
      - `type` = `dir`
      - `name`: Repository name
      - `url`: Absolute or relative path to a local directory
        - Relative path must be relative to the project directory.
    - Git-based repository:
      - `type` = `git`
      - `name`: Repository name
      - `url`: URL of the Git repository
        - E.g., `https://github.com/keboola/keboola-as-code-templates.git`
      - `ref`: Git `branch` or `tag` (e.g., `main` or `v1.2.3`)
- `branches`: List of used branches
  - `id`: Branch ID
  - `path`: Directory name (e.g., `main`)
- `configurations`: List of component configurations
  - `branchId`: Branch ID
  - `componentId`: Component ID (e.g., `keboola.ex-aws-s3`)
  - `id`: Configuration ID
  - `path`: Path to the configuration in the local directory (e.g., `extractor/keboola.ex-aws-s3/7241111/my-aws-s3-data-source`)
  - `rows`: List of configuration rows (if the component supports rows)
    - `id`: Row ID
    - `path`: Path to the row from the configuration directory (e.g., `rows/cities`)

### Naming

Directory names for configurations follow the rules in the [manifest](/cli/structure/#manifest) under the `naming` section.  
These are the default values:

```json
{
    "branch": "{branch_name}",
    "config": "{component_type}/{component_id}/{config_name}",
    "configRow": "rows/{config_row_name}",
    "schedulerConfig": "schedules/{config_name}",
    "sharedCodeConfig": "_shared/{target_component_id}",
    "sharedCodeConfigRow": "codes/{config_row_name}",
    "variablesConfig": "variables",
    "variablesValuesRow": "values/{config_row_name}"
  }
```

To include object IDs in directory names, use these values:

```json
{
    "branch": "{branch_id}-{branch_name}",
    "config": "{component_type}/{component_id}/{config_id}-{config_name}",
    "configRow": "rows/{config_row_id}-{config_row_name}",
    "schedulerConfig": "schedules/{config_name}",
    "sharedCodeConfig": "_shared/{target_component_id}",
    "sharedCodeConfigRow": "codes/{config_row_name}",
    "variablesConfig": "variables",
    "variablesValuesRow": "values/{config_row_name}"
  }
```

Use the [fix-paths](/cli/commands/local/fix-paths/) command to rebuild the directory structure with updated naming rules.

## Project Cache

The project cache is stored in `.keboola/project.json` and is used by local commands without making authorized requests to the Storage API.

This is its basic structure:

- `backends`: List of project backends
- `features`: List of project features
- `defaultBranchId`: ID of the default branch

Example:

```json
{
  "backends": [
    "snowflake"
  ],
  "features": [
    "workspace-snowflake-dynamic-backend-size",
    "input-mapping-read-only-storage",
    "syrup-jobs-limit-10",
    "oauth-v3"
  ],
  "defaultBranchId": 123
}
```
## .kbcignore

You can exclude specific configurations from the sync process by creating a `.kbcignore` file in the `.keboola` directory.
 
It is a plain text file where each line specifies a path to a configuration or configuration row in the format 
`{component_id}/{configuration_id}/{row_id}`. The `row_id` is optional for [row-based configurations](https://help.keboola.com/components/#configuration-rows).

Example `.kbcignore` file:
    
```
keboola.python-transformation-v2/1197618481
keboola.keboola.wr-db-snowflake/1196309603/1196309605
```

This excludes:

- The configuration of the Python transformation (`keboola.python-transformation-v2`)  with the ID `1197618481`. 
- Row  ID `1196309605` in the configuration of the Snowflake writer (`keboola.keboola.wr-db-snowflake`) with the ID `1196309603`.

As a result, the `kbc sync pull` and `kbc sync push` commands will not synchronize these configurations.

**`kbc push` operation**

The `kbc push` command will skip the excluded configurations and will not push them back to the project, even if they exist or have been modified in the local folder structure. 
The log will display the following message:

```
➜ kbc push
Plan for "push" operation:
  × main/transformation/keboola.python-transformation-v2/dev-l0-sample-data - IGNORED
Skipped remote objects deletion, use "--force" to delete them.
Push done.
```

The log clearly identifies configurations that were ignored, even if they are absent in the local folder structure.

**`kbc pull` operation**

The `kbc pull` command will exclude the matched configurations and not pull them from the project. 

<div class="clearfix"></div><div class="alert alert-warning">
    <p><strong>Warning:</strong><br>
        If the matched configuration is already present locally, it will be deleted from both the filesystem and manifest.json.</p>
</div>


If the configuration was already present locally, the log will indicate its deletion as shown below:

```
➜ kbc pull
Plan for "pull" operation:
  × C main/writer/keboola.wr-db-snowflake/my-snowflake-data-destination
  × R main/writer/keboola.wr-db-snowflake/my-snowflake-data-destination/rows/test-sheet1
Pull done.
```

## Next Steps

- [Commands](/cli/commands/)


================================================
File: cli/templates/index.md
================================================
---
title: Templates
permalink: /cli/templates/
---

* TOC
{:toc}

Keboola CLI allows you to create a template from an existing project and apply it to another project.

See the [tutorial](/cli/templates/tutorial/) on how to create and use a template.

## Available Commands

|---
| Command | Description
|-|-|-
| **[kbc local template](/cli/commands/local/template/)** | Manage template instances in the [project directory](/cli/structure/). |
| [kbc local template delete](/cli/commands/local/template/delete/) | Delete an instance of a template in the project directory. |
| [kbc local template list](/cli/commands/local/template/list/) | List used template instances in the project directory. |
| [kbc local template upgrade](/cli/commands/local/template/upgrade/) | Upgrade an instance of a template in the project directory. |
| [kbc local template use](/cli/commands/local/template/use/) | Use a template in the project directory. |
| | |
| **[kbc template](/cli/commands/template/)** | Manage [templates](/cli/templates/structure/#template) in the [template repository](/cli/templates/structure/#repository). |
| [kbc template repository](/cli/commands/template/repository/) | Manage a template [repository directory](/cli/templates/structure/). |
| [kbc template repository init](/cli/commands/template/repository/init/) | Initialize a new [repository directory](/cli/templates/structure/#repository) in an empty directory. |
| [kbc template create](/cli/commands/template/create/) | Create a new template from an existing project. |
| [kbc template describe](/cli/commands/template/describe/) | Describe the template and its inputs. |
| [kbc template list](/cli/commands/template/list/) | List the templates in the repository. |
| [kbc template test](/cli/commands/template/test/) | Manage template tests. |
| [kbc template test create](/cli/commands/template/test/create/) | Create template tests. |
| [kbc template test run](/cli/commands/template/test/run/) | Run template tests. |



## Next Steps
- [Create Template Tutorial](/cli/templates/tutorial/)
- [Use Template Tutorial](/cli/templates/tutorial/#use-template)
- [Template Structure](/cli/templates/structure/)


================================================
File: cli/templates/structure/index.md
================================================
---
title: Templates Structure
permalink: /cli/templates/structure/
---

* TOC
{:toc}

## Repository

The templates repository is a directory stored in:
- Local filesystem.
- Git repository.
  - It must be a root directory, not a subdirectory.
  - One git repository is one template repository.

The repository contains a manifest and directories with templates.

```
📂 .keboola             - metadata directory
┗ 🟦 repository.json    - manifest, paths and versions
📂 [template]           - template directory, see below
┗ 📂 [template version]
  ┗ ...
...
```

### Repository Manifest

All templates are listed in the repository manifest file `.keboola/repository.json`.

Repository manifest structure:
- `version` - current major version, now `2`
- `author` - repository author
  - `name` - author name
  - `url` - URL to the author's website
- `templates` *(array)* - information about the project
  - `id` - template ID
  - `name` - a human-readable name
  - `description` - short description of the template
  - `requirements` - requirements of the project
    - `backends` - *string[]* - list of project backends, e.g., `["snowflake","bigquery"]`
      - At least one must match the project backends.
    - `components` - *string[]* - list of project components, e.g., `["keboola.wr-db-snowflake"]`
      - All must match the project components.
    - `features` - *string[]* - list of project features, e.g., `["foo","bar"]`
      - All must match the project features.
  - `categories` - *string[]* - list of template categories, e.g., `["Data Extraction", "E-Commerce"]`
    - Optional: If it is not set, the template is in the `Other` category.
  - `deprecated` - *bool* - default `false`
    - A deprecated template is excluded from the list.
    - Metadata of the deprecated template can be obtained for existing instances.
  - `path` - path to the template directory
    - Required if `deprecated=false`.
    - It must not be set for deprecated templates if `deprecated=true`. 
  - `versions` *(array)*
    - `version` - [semantic version](https://semver.org/)
    - `description` - short description of the version
    - `stable` - is the template ready for production use?
    - `path` - path to the template version directory
      - Required if `deprecated=false`.
      - It must not be set for deprecated templates if `deprecated=true`.
    - `components` *(array)* - list of components used by the template

#### Snowflake writer

**Snowflake writer (data destination) component ID differs** on AWS and Azure stacks because staging storage differs.
- Component ID `keboola.wr-db-snowflake` is used for AWS stacks.
- Component ID `keboola.wr-snowflake-blob-storage` is used for Azure stacks.
- Please use:
  - Placeholder `"<keboola.wr-snowflake>"` in the `repository.json` in the `components` list.
  - Jsonnet function `SnowflakeWriterComponentId()` in [Jsonnet Files](/cli/templates/structure/jsonnet-files/).

#### Example

```json
{
  "version": 2,
  "author": {
    "name": "Keboola",
    "url": "https://keboola.com"
  },
  "templates": [
    {
      "id": "my-template",
      "name": "My Template",
      "description": "Full workflow to ...",
      "path": "my-template",
      "versions": [
        {
          "version": "0.0.1",
          "description": "",
          "stable": false,
          "path": "v0"
        },
        {
          "version": "1.2.3",
          "description": "Version notes.",
          "stable": true,
          "path": "v1"
        }
      ]
    }
  ]
}

```

### Git Integration

**Creating template**
- A command to manage a repository works with local directories.
- You can push changes into a git repository in the standard way using the `git` command.

**Using template**
- A template can be used in a project directly from a git repository.
- The repository must be defined in the [project manifest](/cli/structure/#manifest) in `templates.repositories` key.

## Template

A template directory is stored in the [repository](#repository) and contains directories with template [versions](#versioning).

```
📂 [template]
┗ 📂 [template version]
  ┣ 📂 src
  ┃ ┗ 🟪 inputs.jsonnet          - definition of user inputs
  ┃ ┣ 🟪 manifest.jsonnet        - template manifest, object IDs and paths
  ┃ ┣ 🟩 description.md          - description which is displayed on the template detail page
  ┃ ┣ 🟩 README.md               - detailed information, changelog, ...
  ┃ ┗ 📂 [component-type]        
  ┃   ┗ 📂 [component-id]
  ┃     ┗ 📂 [config-name]       - structure is similar to the project structure,
  ┃       ┣ 🟪 config.jsonnet      but instead of JSON files, there are JSONNET templates
  ┃       ┣ 🟪 meta.jsonet    
  ┃       ┣ 🟩 description.md
  ┃       ... 
  ┗ 📂 tests                     -  tests directory
    ┣ 📂 [test name]
    ┃ ┣ 📂 expected-out          - expected structure of the project directory 
    ┃ ┃                            after applying the template in the test 
    ┃ ┗ 🟪 inputs.json           - sample inputs used to apply the template in the test
    ┗ ...
...
```

### Description

There are three types of template descriptions:
- `description` field in the [repository.json](#repository):
  - Short description.
  - It is displayed on the overview of all templates.
- `description.md` file in the template [src directory](#template):
  - Longer description with MarkDown formatting support. 
  - It is displayed on the template detail page.
- `README.md` file in the template [src directory](#template):
  - Detailed information, changelog, data model ...
  - It is, by default, collapsed on the template detail page in the `More Details` section.

### Versioning

A template is identified by `<repository>/<template-id>/<version>`,  e.g., `keboola/my-template/1.2.3`.
Each template version is stored in a separate directory; see the [directory structure](#template).

Templates use [semantic versioning](https://semver.org/):
- Version format is `<major>.<minor>.<patch>`.
- For example, `v1.2.3`; the prefix `v` is optional.
- Versions are defined in the [repository manifest](#manifest).
- Multiple versions of the template may be available at the same time.
- By default, the latest stable version is applied.
- Users don't have to enter the full version. For example:
  - `my-template/v1` references the latest available version `1.x.x`.
  - `my-template/v1.4` references the latest available version `1.4.x`.
- The name of the version directory doesn't matter.
  - It is recommended that the directory be called according to the `<major>` version.
  - For example, for version `3.2.1`, the directory name should be `v3`.

#### New Version


It is recommended that the existing version be updated for **small changes** in the template.
- Increment `<minor>` or `<patch>` part of the version in the [repository manifest](#manifest).
- Changes will be clearly visible in git history because the changes are made in an existing directory.
- The overwritten old version of the template will not be available.
- Users will be able to upgrade to the new version.
- Users will **not** be able to roll back.

For **more significant changes** in the template, it is recommended to create a new `<major>` version.
- Copy the directory with the latest version, e.g., `v3` -> `v4`.
- Make changes and register the new version in the [repository manifest](#manifest), e.g., `4.0.0`.
- Users will be able to upgrade to the new version, e.g., `v3` -> `v4`.
- Users will be able to roll back, e.g., `v4` -> `v3`.

### Manifest

All configurations and configuration rows are defined in the manifest file `manifest.jsonnet`. 
Each template should have a `mainConfig` that can be started in the UI by pressing the **Run** button after the template is used.
This is usually the main orchestration/flow.

Template manifest structure:
- `mainConfig` - main configuration
  - `componentId` - ID of the component
  - `id` - human-readable ID of the configuration defined by [`ConfigId` function](/cli/templates/structure/jsonnet-files/#functions)
- `configurations` - array of component configurations
  - `componentId` - ID of the component
  - `id` - human-readable ID of the configuration defined by [`ConfigId` function](/cli/templates/structure/jsonnet-files/#functions)
  - `path` - path to the configuration from the template version directory
  - `rows` - array of configuration rows (if the component supports rows)
    - `id` - human-readable ID of the row defined by [`ConfigRowId` function](/cli/templates/structure/jsonnet-files/#functions)
    - `path` - path to the row from the configuration directory

#### Example

```jsonnet
{
  mainConfig: {
    componentId: "keboola.orchestrator",
    id: ConfigId("orchestrator"),
  },
  configurations: [
    {
      componentId: "keboola.ex-db-mysql",
      id: ConfigId("country"),
      path: "extractor/keboola.ex-db-mysql/country",
      rows: [
        {
          id: ConfigRowId("people"),
          path: "rows/people",
        },
        {
          id: ConfigRowId("cities"),
          path: "rows/cities",
        },
      ],
    },
  ],
}
```

### Inputs

All user inputs are defined in the `inputs.jsonnet`.

Read more in [Template Inputs](/cli/templates/structure/inputs/).

### Common Directory

Files saved in the `_common` directory in the [repository directory](#repository) can be accessed by every template using the `<common>/` prefix.

#### Example

Use of the `_common` directory in `manifest.jsonnet`:
```jsonnet
{
  configurations: [
    {
      componentId: "ex-generic-v2",
      id: ConfigId("myconfig"),
      path: "<common>/foo/bar/extractor/ex-generic-v2/myconfig",
      rows: [],
    }
  ],
}
```

Use of the `_common` directory in a Jsonnet file (`config.jsonnet`):
```jsonnet
local part1 = import "lib/part1.jsonnet";
local part2 = import "/<common>/foo/bar/extractor/ex-generic-v2/myconfig/lib/part2.jsonnet";
std.mergePatch(part1, part2)
```

### Data Apps

A data app (configuration of the `keboola.data-apps` component) contains the deployment ID, 
which is stored in `parmeters.id` in the configuration.

This ID is not set when the configuration is created. 
It will be set when the data app is deployed.

This ID must be kept during the template upgrade to a new version. 

It happens automatically; no extra work is required.

## Next Steps
- [Jsonnet Files](/cli/templates/structure/jsonnet-files/)
- [User Inputs](/cli/templates/structure/inputs/)
- [Tests](/cli/templates/tests/)


================================================
File: cli/templates/structure/inputs/index.md
================================================
---
title: Templates Inputs
permalink: /cli/templates/structure/inputs/
---

* TOC
{:toc}

All user inputs are defined in  
[repository](/cli/templates/structure/#repository) / 
[template](/cli/templates/structure/#template) / 
[version](/cli/templates/structure/#versioning) / 
`src` / 
`inputs.jsonnet`.

Users must fill in these inputs before the template is applied.
In the template [Jsonnet files](/cli/templates/structure/jsonnet-files/), inputs are referenced using the [Input function](/cli/templates/structure/jsonnet-files/#functions). 

Inputs are divided into steps, and steps are grouped into groups. Each group defines how many steps the user must select. 
A template must contain at least one group with one step. 

## Definition

**Structure of the `inputs.jsonnet` file**:
- `stepsGroups` – an array of step groups
  - `description` string – group description
  - `required` string – define how many steps must be selected by the user 
    - One of: `optional`, `exactlyOne`, `atLeastOne`, `zeroOrOne`, `all`
  - `steps` – an array of steps within the group
    - `icon` – component or common icon, [read more](#icons) 
    - `name` (string) – step name
    - `description` (string) – step description
    - `backend` string (optional) – step backend, used to filter transformations for different backends
    - `dialogName` (string) – name of the step presented to the user in the UI dialog (`name` is used if empty)
    - `dialogDescription` (string) – step description as presented to the user in the UI dialog (`description` is used if empty)
    - `inputs` – an array of input definitions
      - `id` string – input ID
        - Used in [Jsonnet](/cli/templates/structure/jsonnet-files) function `Input`, e.g., `Input("id")`
      - `name` string – input name
      - `description` (string) – input description
      - `type` string – input data type
        - One of: `string`, `int`, `double`, `bool`, `string[]`, `object`
      - `kind` (string) – input visual style, see below
      - `default` – default value (must match `type`)
      - `rules` (string) – comma-separated validation rules, [read more](#rules) about syntax
      - `showIf` (string) – condition for displaying the input, [read more](#show-if) about syntax
      - `options` – an array of selectable options (only for `kind = select/multiselect`)
          - `value` (string) – option value
          - `label` (string) – visible option name
      - `componentId` (string) – ID of the component to be authorized for (allowed only for `kind = oauth`)
      - `oauthInputId` (string) – ID of the linked `kind=oauth` input (allowed only for `kind = oauthAccounts`)

**Allowed combinations of `type` and `kind`**:
- Type `string`
  - Kind `input` – single-line text
  - Kind `hidden` – single-line text with masked characters
  - Kind `textarea` – multi-line text
  - Kind `select` – drop-down list (one option must be selected)
- Type `int`
  - Kind `input` – single-line text
- Type `double`
  - Kind `input` – single-line text
- Type `bool`
  - Kind `confirm` – yes/no prompt 
- Type `string[]`
  - Kind `multiselect` – drop-down list (multiple options can be selected)
- Type `object`
  - Kind `oauth` – OAuth authorization (requires `componentId`)
  - Kind `oauthAccounts` – OAuth account selector (requires `oauthInputId`)


**Example of `inputs.jsonnet`**:
```jsonnet
{
  stepsGroups: [
    {
      description: "Data extraction",
      required: "all",
      steps: [
        {
          name: "Awesome API",
          description: "Data extraction from Awesome API",
          inputs: [
            {
              id: "api-base-url",
              name: "Api Url",
              description: "Please enter URL of your API.",
              type: "string",
              kind: "input",
              default: "https://jsonplaceholder.typicode.com/todos/1",
            },
          ]
        }
      ]
    }
  ]
}
```

### Icons

There are several places where the template author can specify an icon to be displayed in the UI. For security reasons,
it is not possible to load images from external sites.

The icon is defined as a string and can take one of the following forms:

- `component:<component-id>` e.g., `component:keboola.ex-onedrive` (uses the component icon).
- `common:<icon-name>`, e.g., `common:upload` (uses an icon from the predefined set).
  - Supported icons: `upload`, `download`, `settings`, `import`
  
**The Snowflake writer (data destination) component ID differs** accross AWS, Azure, and GCP stacks due to variations in staging storage.

AWS stacks: `keboola.wr-db-snowflake`
Azure stacks: `keboola.wr-snowflake-blob-storage`
GCP stacks (BigQuery backend): `keboola.wr-db-snowflake-gcs`
GCP stacks (Snowflake backend): `keboola.wr-db-snowflake-gcs-s3`
- Use the placeholder `"<keboola.wr-snowflake>"` in `inputs.jsonnet` for the `icon` field.

### Rules

Each user input can have validation `rules`.
- Rules are separated by `,`.
- Rule parameters are separated by `=`.
- Example: The rule `required,min=0` specifies that the value cannot be empty and must be `0` or more.
- Rules are interpreted by the [go-playground/validator](https://pkg.go.dev/github.com/go-playground/validator) library.
- See the full [list of available rules](https://pkg.go.dev/github.com/go-playground/validator/v10#hdr-Required).

### Show If

Each user input can have a `showIf` condition, allowing inputs to be dynamically shown or hidden based on previous values.
- The value of a previous input is referenced by `[<input-id>]`.
- Example: The condition `[some-previous-input] == 'value'` means that the input will only be displayed if `some-previous-input` has the value `value`.
- The condition is interpreted by the [Knetic/govaluate](https://github.com/Knetic/govaluate) library.
- See available [operators and types](https://github.com/Knetic/govaluate/blob/master/MANUAL.md#operators).

## Example Inputs

#### String Input

Definition in `inputs.jsonnet`:
```jsonnet
{
  stepsGroups: [
    {
      description: "Data extraction",
      required: "all",
      steps: [
        {
          name: "Awesome API",
          description: "Data extraction from Awesome API",
          inputs: [
            {
              id: 'my-string',
              name: 'My String',
              description: 'Input Description',
              type: 'string',
              kind: 'input',
              rules: 'required',
              default: 'default value',
              showIf: "[some-previous-input] == 'value'",
            },
          ]
        }
      ]
    }
  ]
}
```

CLI dialog:
```
Input Description
? My String: (default value) foo bar
```

#### String Hidden

Definition in `inputs.jsonnet`:
```jsonnet
{
  stepsGroups: [
    {
      description: "Data extraction",
      required: "all",
      steps: [
        {
          name: "Awesome API",
          description: "Data extraction from Awesome API",
          inputs: [
            {
              id: 'my-string',
              name: 'My String',
              description: 'Input Description',
              type: 'string',
              kind: 'hidden',
              rules: 'required',
              showIf: "[some-previous-input] == 'value'",
            },
          ]
        }
      ]
    }
  ]
}
```

CLI dialog:
```
Input Description
? My String: **********
```

#### String Textarea

Definition in `inputs.jsonnet`:
```jsonnet
{
  stepsGroups: [
    {
      description: "Data extraction",
      required: "all",
      steps: [
        {
          name: "Awesome API",
          description: "Data extraction from Awesome API",
          inputs: [
            {
              id: 'my-string',
              name: 'My String',
              description: 'Input Description',
              type: 'string',
              kind: 'textarea',
              rules: 'required',
              default: 'default value',
              showIf: "[some-previous-input] == 'value'",
            },
          ]
        }
      ]
    }
  ]
}
```

CLI dialog:
```
Input Description
? My String: [Enter to launch editor]
```

The value is edited in the editor defined by the `EDITOR` or `VISUAL` environment variable.

#### String Select

Definition in `inputs.jsonnet`:
```jsonnet
{
  stepsGroups: [
    {
      description: "Data extraction",
      required: "all",
      steps: [
        {
          name: "Awesome API",
          description: "Data extraction from Awesome API",
          inputs: [
            {
              id: 'my-string',
              name: 'My String',
              description: 'Input Description',
              type: 'string',
              kind: 'select',
              rules: 'required',
              default: 'value2',
              showIf: "[some-previous-input] == 'value'",
              options: [
                {
                  value: 'value1',
                  label: 'Name 1',
                },
                {
                  value: 'value2',
                  label: 'Name 2',
                },
                {
                  value: 'value3',
                  label: 'Name 3',
                },
              ],
            },
          ]
        }
      ]
    }
  ]
}
```

CLI dialog:
```
Input Description
? My String:  [Use arrows to move, type to filter]
  Name 1
> Name 2
  Name 3
```

#### Int Input

Definition in `inputs.jsonnet`:
```jsonnet
{
  stepsGroups: [
    {
      description: "Data extraction",
      required: "all",
      steps: [
        {
          name: "Awesome API",
          description: "Data extraction from Awesome API",
          inputs: [
            {
              id: 'my-int',
              name: 'My Int',
              description: 'Input Description',
              type: 'int',
              kind: 'input',
              rules: 'required',
              default: 123,
              showIf: "[some-previous-input] == 456",
            },
          ]
        }
      ]
    }
  ]
}
```

CLI dialog:
```
Input Description
? My Int: (123) 789
```


#### Double Input

Definition in `inputs.jsonnet`:
```jsonnet
{
  stepsGroups: [
    {
      description: "Data extraction",
      required: "all",
      steps: [
        {
          name: "Awesome API",
          description: "Data extraction from Awesome API",
          inputs: [
            {
              id: 'my-double',
              name: 'My Double',
              description: 'Input Description',
              type: 'double',
              kind: 'input',
              rules: 'required',
              default: 123.45,
              showIf: "[some-previous-input] == 456.78",
            },
          ]
        }
      ]
    }
  ]
}
```

CLI dialog:
```
Input Description
? My Double: (123.45) 789.12
```

#### Bool Confirm

Definition in `inputs.jsonnet`:
```jsonnet
{
  stepsGroups: [
    {
      description: "Data extraction",
      required: "all",
      steps: [
        {
          name: "Awesome API",
          description: "Data extraction from Awesome API",
          inputs: [
            {
              id: 'my-bool',
              name: 'My Bool',
              description: 'Input Description',
              type: 'bool',
              kind: 'confirm',
              rules: 'required',
              default: true,
              showIf: "[some-previous-input] == true",
            },
          ]
        }
      ]
    }
  ]
}
```

CLI dialog:
```
Input Description
? My Bool: (Y/n)
```

#### String[] Multiselect

Definition in `inputs.jsonnet`:
```jsonnet
{
  stepsGroups: [
    {
      description: "Data extraction",
      required: "all",
      steps: [
        {
          name: "Awesome API",
          description: "Data extraction from Awesome API",
          inputs: [
            {
              id: 'my-string-array',
              name: 'String Values',
              description: 'Input Description',
              type: 'string[]',
              kind: 'multiselect',
              rules: 'required',
              default: ['value2', 'value3'],
              options: [
                {
                  value: 'value1',
                  label: 'Name 1',
                },
                {
                  value: 'value2',
                  label: 'Name 2',
                },
                {
                  value: 'value3',
                  label: 'Name 3',
                },
              ],
            },
            },
          ]
        }
      ]
    }
  ]
}
```

CLI dialog:
```
Input Description
? String Values:  [Use arrows to move, space to select, <right> to all, <left> to none, type to filter]
> [ ]  Name 1
  [x]  Name 2
  [x]  Name 3
```

#### OAuth authorization

The OAuth authorization input (`kind=oauth`) is fully supported only in the UI.
- It can be used for any component that supports OAuth authorization (see the `componentId` field).
- If a template containing an `oauth` input is used in the CLI, it will leave the value empty.
- Links to configurations that require additional authorization will be printed at the end.

Definition in `inputs.jsonnet`:
```jsonnet
{
  stepsGroups: [
    {
      description: "Data extraction",
      required: "all",
      steps: [
        {
          name: "Awesome API",
          description: "Data extraction from Awesome API",
          inputs: [
            {
              id: 'my-oauth',
              name: 'oAuth',
              description: 'oAuth Authorization',
              type: 'object',
              kind: 'oauth',
              componentId: 'keboola.ex-google-ads'
            },
          ]
        }
      ]
    }
  ]
}
```

Input usage in a `config.jsonnet`:
```jsonnet
{
  authorization: {
    oauth_api: Input("my-oauth"),
  },
}
```

CLI output:
```
Template "keboola/my-template-id/1.2.3" has been applied, instance ID: inst12345

The template generated configurations that need OAuth authorization. Please follow the links and complete the setup:
- https://connection.keboola.com/admin/projects/123/components/ex-generic-v2/456789
```


#### OAuth accounts

The OAuth accounts input (`kind=oauthAccounts`) is fully supported only in the UI.
- In the CLI, it will leave the value empty.
- It is an additional input linked to the `kind=oauth` input via the `oauthInputId` field.
- It allows users to select specific accounts, as an OAuth account may have access to multiple accounts.

Definition in `inputs.jsonnet`:
```jsonnet
{
  stepsGroups: [
    {
      description: "Instagram",
      required: "all",
      steps: [
        {
          name: "Instagram",
          description: "Data extraction from Instagram",
          inputs: [
            {
              {
                id: "my-oauth",
                name: "Instagram oAuth",
                description: "Instagram Authorization",
                type: "object",
                kind: "oauth",
                componentId: "keboola.ex-instagram",
              },
              {
                id: "my-oauth-accounts",
                name: "Instagram Profiles",
                description: "Instagram Profiles",
                type: "object",
                kind: "oauthAccounts",
                oauthInputId: "my-oauth",
              },
          ]
        }
      ]
    }
  ]
}
```

Inputs usage in a `config.jsonnet`:
```jsonnet
{
  authorization: {
    oauth_api: Input("my-oauth"),
  },
  parameters: Input("my-oauth-accounts") + {
    other1: "value1",
    other2: "value2",
  }
}
```


The OAuth accounts input can only be used with the components listed below:

##### keboola.ex-google-analytics-v4

Example value for `profiles` mode:
```json
{
  "profiles": [
    {
      "id": "PROFILE_ID",
      "name": "All Web Site Data",
      "webPropertyId": "WEB_PROPORTY_ID",
      "webPropertyName": "WEB_PROPRTY_NAME",
      "accountId": "ACCOUNT_ID",
      "accountName": "ACCOUNT_NAME"
    }
  ]
}
```

Example value for `properties` mode:
```json
{
  "properties": [
    {
      "accountKey": "accounts/ACCOUNT_ID",
      "accountName": "ACCOUNT_NAME",
      "propertyKey": "properties/PROPERTY_ID",
      "propertyName": "PROPERTY_NAME"
    }
  ]
}
```

##### keboola.ex-google-ads

Example value:
```json
{
  "customerId": ["1234abcd"],
  "onlyEnabledCustomers": true
}
```

##### keboola.ex-facebook-ads

Example value:
```json
{
  "accounts": {
    "act_12345678": {
      "account_id": "12345678",
      "business_name": "",
      "currency": "CZK",
      "id": "act_12345678",
      "name": "Jane Doe"
    }
  }
}
```

##### keboola.ex-facebook

Example value:
```json
{
  "accounts": {
    "123456789101112": {
      "category": "Just for fun",
      "category_list": [
        {
          "id": "9876543210000",
          "name": "Just for fun"
        }
      ],
      "name": "PAGE_NAME",
      "id": "123456789101112",
      "tasks": [
        "ANALYZE",
        "ADVERTISE",
        "MODERATE",
        "CREATE_CONTENT",
        "MANAGE"
      ]
    }
  }
}
```

##### keboola.ex-instagram

Example value:
```json
{
  "accounts": {
    "123456789101112": {
      "category": "Musician/Band",
      "fb_page_id": "9876543210000",
      "id": "123456789101112",
      "name": "Entita"
    }
  }
}
```

## Next Steps
- [Jsonnet Files](/cli/templates/structure/jsonnet-files)
- [Template Structure](/cli/templates/structure)


================================================
File: cli/templates/structure/jsonnet-files/index.md
================================================
---
title: Jsonnet Files
permalink: /cli/templates/structure/jsonnet-files/
---

* TOC
{:toc}

All project [JSON files](/cli/structure/) in a template are defined by [Jsonnet](https://jsonnet.org/) files.
Jsonnet builds on JSON syntax, meaning that valid JSON is also valid Jsonnet.
In addition, Jsonnet offers more language constructs, such as [conditions, cycles, and variables](https://jsonnet.org/learning/tutorial.html).


## Functions

In addition to the [standard Jsonnet functions](https://jsonnet.org/ref/stdlib.html), the following functions are also available: 

--------------------------------------

**`ConfigId(string configId) string`**

- Replaces a human-readable configuration ID with a generated unique ID.
- In a template, each configuration has a human-readable name (e.g., `my-config`).
- When applying a template, the human-readable ID is replaced with a generated unique ID (e.g., `5038695485`).
- This allows a creation of multiple instances of a template.
- The `ConfigId` function is primarily used in the [template manifest](/cli/templates/structure/#repository-manifest) but can also be applied in any Jsonnet file.

Example: 
<br>Composing a bucket ID containing a configuration ID:
```jsonnet
{
 storage: {
  input: {
   tables: [
    {source: "in.c-keboola-ex-aws-s3-" + ConfigId("config-with-output-mapping") + ".table"},
   ],
  },
 },
}
```

--------------------------------------

**`ConfigRowId(string rowId) string`**

- Replaces a human-readable configuration row ID with a generated unique ID.
- Similar to `ConfigId`, but applies to configuration rows.

--------------------------------------

**`Input(string inputId) string`**

- Returns the value of the [user input](/cli/templates/structure/inputs/).
- If the input is hidden because the [showIf](/cli/templates/structure/inputs/#show-if) condition evaluated to `false`:
  - The function returns a default empty value based on the input type (e.g., `0` for `int`, `false` for `bool`, etc.).

Example:
```jsonnet
{
  parameters: {
    api: {
      baseUrl: Input("base-url"),
    },
  },
}
```

--------------------------------------

**`InputIsAvailable(string inputId) string`**

- Returns `true` if the input has been filled by the user.
- Return `false` if the step was skipped or `showIf = false`.

--------------------------------------

**`InstanceId() string`**

- Returns the ID of the current template instance.
- Example: `V1StGXR8IZ5jdHi6BAmyT`
- This function is not supported in the preview endpoint, which is used for simple template configurations that do not have InstanceIDs.

--------------------------------------

**`InstanceIdShort() string`**

- Returns the shortend ID of the current template instance (8 characters).
- Example: `V1StGXR8`
- This function is not supported in the preview endpoint.
  
--------------------------------------

**`ComponentIsAvailable(string componentId) bool`**

- Returns `true` if the component is available, otherwise returns `false`.

--------------------------------------

**`SnowflakeWriterComponentId() string`**

- Returns the component ID of the Snowflake writer based on the stack.
  - AWS: `keboola.wr-db-snowflake`
  - Azure: `keboola.wr-snowflake-blob-storage`
  - GCP stacks (BigQuery backend): `keboola.wr-db-snowflake-gcs`
  - GCP stacks (Snowflake backend): `keboola.wr-db-snowflake-gcs-s3`
- This function is not supported in the `inputs.jsonnet` because project backends are unknown before template loading.
--------------------------------------

**`HasProjectBackend(backend string) bool`**

- Returns `true` if the specified backend is available, otherwise returns `false`.

--------------------------------------

**`RandomID() string`**

- Returns a random ID truncated to 8 characters.
  

## Next Steps
- [User Inputs](/cli/templates/structure/inputs/)
- [Template Structure](/cli/templates/structure/)


================================================
File: cli/templates/tests/index.md
================================================
---
title: Template Tests
permalink: /cli/templates/tests/
---

* TOC
{:toc}

## How the Tests Work

Each test can be run locally, remotely, or both ways. See the [CLI command](/cli/commands/template/test/run/) for more information.

**Local** running of the test prepares a directory with a fake empty project and [applies](/cli/commands/local/template/use/) 
the template to it using the `inputs.json` file for the template inputs. Then the state of the directory is compared 
to the `expected-out` directory of the test.

**Remote** running of the test again [applies](/cli/commands/local/template/use/) the template to a project 
using the `inputs.json` file for the template inputs like the local one but uses a real project in a public Keboola stack 
that you have to provide (see the [CLI command](/cli/commands/template/test/run/) for details). Then it performs a
[push](/cli/commands/sync/push/) to the project and runs the [main config](/cli/templates/structure/#manifest) of the template.
It waits for the result of the job and evaluates if it ended successfully or not. Any other error during the whole process
is considered as the test fail and the command exits with an error.

A template directory contains the directory `tests` that should gather one or more subdirectories with tests for the template.
The directory for each test has to contain the directory `expected-out` and the file `inputs.json`. 

You can have a test generated by a [CLI command](/cli/commands/template/test/create/). 

## Expected Out

The `expected-out` directory looks like a regular [project directory](/cli/structure/) after applying the template. 
Some values in the project manifest cannot be reused freely and are dependent on the project 
(project id, host, and main branch id) or the template instance (instance id). For these values the template test command
supports placeholders in the directory:

- `__PROJECT_ID__` is replaced by a current project id during the test run.
- `__STORAGE_API_HOST__` is replaced by a current Keboola stack host of the project during the test run.
- `__MAIN_BRANCH_ID__` is replaced by a current main branch id of the project during the test run.

Then you can use wildcards for comparison of dynamic values:

- `%e`: Represents a directory separator, for example, `/` on Linux.
- `%s`: One or more of anything (character or white space) except the end-of-line character.
- `%S`: Zero or more of anything (character or white space) except the end-of-line character.
- `%a`: One or more of anything (character or white space) including the end-of-line character.
- `%A`: Zero or more of anything (character or white space) including the end-of-line character.
- `%w`: Zero or more white space characters.
- `%i`: A signed integer value, for example, +3142, -3142.
- `%d`: An unsigned integer value, for example, 123456.
- `%x`: One or more hexadecimal character. That is, characters in the range 0-9, a-f, and A-F.
- `%f`: A floating point number, for example, 3.142, -3.142, 3.142E-10, 3.142e+10.
- `%c`: A single character of any sort.
- `%%`: A literal percent character: %.

Example of `.keboola/manifest.json`:

```json
{
  "version": 2,
  "project": {
    "id": __PROJECT_ID__,
    "apiHost": "__STORAGE_API_HOST__"
  },
  "sortBy": "id",
  "naming": {},
  "allowedBranches": ["*"],
  "ignoredComponents": [],
  "templates": {
    "repositories": [
      {
        "type": "dir",
        "name": "keboola",
        "url": "../repository",
        "ref": "main"
      }
    ]
  },
  "branches": [
    {
      "id": __MAIN_BRANCH_ID__,
      "path": "main",
      "metadata": {
        "KBC.KAC.templates.instances": "%s"
      }
    }
  ],
  "configurations": [
    {
      "branchId": __MAIN_BRANCH_ID__,
      "componentId": "ex-generic-v2",
      "id": "%s",
      "path": "extractor/ex-generic-v2/empty",
      "metadata": {
        "KBC.KAC.templates.configId": "{\"idInTemplate\":\"empty\"}",
        "KBC.KAC.templates.configInputs": "[{\"input\":\"ex-generic-v2-oauth\",\"key\":\"authorization.oauth_api\"},{\"input\":\"ex-generic-v2-api-base-url\",\"key\":\"parameters.api.baseUrl\"}]",
        "KBC.KAC.templates.instanceId": "%s",
        "KBC.KAC.templates.repository": "keboola",
        "KBC.KAC.templates.templateId": "my-template"
      },
      "rows": []
    }
  ]
}

```

## Inputs.json

The `inputs.json` file has to contain values for inputs that the template expects during its application to the project.
It is a one-level key-value store:

```json
{
  "input1": "value 1",
  "input2": 2
}
```

The file supports complex values and can even refer to an OAuth configuration:

```json
{
  "oauthInput": {
    "id": "123",
    "version": 3
  }
}
```

## Environment Placeholders

Environment variables can be referred to using a placeholder encapsulated by `##`.

This snippet means that the configuration `incrementalDays` will get its value from the environmental variable `INC_DAYS`:

```json
{
  "incrementalDays": ##INC_DAYS##
}
```

See [GitHub's documentation](https://docs.github.com/en/actions/learn-github-actions/environment-variables) on how to define environment variables in the Actions workflow.


### Sensitive Values

Sensitive values can be stored in GitHub Secrets and will be passed to the test environmental variables. They need to be prefixed by `KBC_SECRET_`. 

This snippet means that the input `inputToken` will get its value from the GitHub secret `KBC_SECRET_MY_TEMPLATE_TOKEN`:

```json
{
  "inputToken": "##KBC_SECRET_MY_TEMPLATE_TOKEN##"
}
```

See [GitHub's documentation](https://docs.github.com/en/actions/security-guides/encrypted-secrets#creating-encrypted-secrets-for-a-repository) on how to define GitHub secrets.


================================================
File: cli/templates/tutorial/index.md
================================================
---
title: Create Template Tutorial
permalink: /cli/templates/tutorial/
---

* TOC
{:toc}

This tutorial will guide you through the process of creating and using a template.
First, make sure you have the [latest version](https://github.com/keboola/keboola-as-code/releases) of the Keboola CLI.

```sh
kbc --version
```


## Create Repository

Create an empty directory for template repository and enter it:
```sh
mkdir my-repository
cd my-repository
```

Initialize the repository directory, run command:
```sh
kbc template repository init
```

Example output:
```
Created metadata directory ".keboola".
Created repository manifest file ".keboola/repository.json".
Repository init done.
```

Optionally, you can initialize the directory as a git repository.
```
git init
git add -A
git commit -m "Initial commit"
```

## Create Template

The template can be created from any existing project in [Keboola](https://help.keboola.com/overview/).

### Set Editor

First, set an editor that will be used to edit values.
`EDITOR` or `VISUAL` environment variable must be set.

For example, use `nano` console editor.
```sh
export EDITOR="nano"
```

You can also use a GUI editor, for example [Visual Studio Code](https://code.visualstudio.com/).
```sh
export EDITOR="code --new-window --wait"
```

Or [Sublime Text](https://www.sublimetext.com/) editor.
```sh
export EDITOR="subl --new-window --wait"
```

### Source Project

Specify source project by Storage API [host](https://help.keboola.com/overview/#stacks) and [token](https://help.keboola.com/management/project/tokens/).

In the repository directory create `.env.local` file:
```
KBC_STORAGE_API_HOST=connection.keboola.com
KBC_STORAGE_API_TOKEN=...
```

File `.env.local` must be kept locally. Create`.gitignore` file:
```
.env.local
```

Alternatively, if you don't create the `.env.local` file, you will be prompted to enter these values interactively.

### Start Dialog

Start interactive dialog to create template. It will guide you through creating the template step by step.
```sh
kbc template create
```

### ID and Name

Enter template name and ID:
```
Please enter a template public name for users.
For example "Lorem Ipsum Ecommerce".
? Template name: My Template

Please enter a template internal ID.
Allowed characters: a-z, A-Z, 0-9, "-".
For example "lorem-ipsum-ecommerce".
? Template ID: my-template
```

Enter a short description of the template using the [editor](#set-editor):
```
Please enter a short template description.
?  [Enter to launch editor]
```

### Branch and Configurations

Select source branch and configurations to be included in the template:
```
? Select source branch: Main (251718)

? Select configurations to be included in the template:  
[Use arrows to move, space to select, <right> to all, <left> to none, type to filter]
> [x]  My MySQL Data Source (keboola.ex-db-mysql:810414442)
  [ ]  MySQL with demo data (keboola.ex-sample-data:810416777)
  [x]  Test transformation (keboola.snowflake-transformation:810416570)

```

### Configurations IDs

For each configuration and configuration row specify a human-readable ID:
```
Please enter a human readable ID for each config and config row.
?  [Enter to launch editor]
```

Example definition file that opens in the editor:
```md
<!--
Please enter a human-readable ID for each configuration. For example "L0-raw-data-ex".
Allowed characters: a-z, A-Z, 0-9, "-".
These IDs will be used in the template.

Please edit each line below "## Config ..." and "### Row ...".
Do not edit lines starting with "#"!
-->

## Config "My MySQL Data Source" keboola.ex-db-mysql:810414442
my-data-source

### Row "table1" keboola.ex-db-mysql:810414442:48061
table1

### Row "table2" keboola.ex-db-mysql:810414442:12883
table2

## Config "Test transformation" keboola.snowflake-transformation:810416570
my-transformation
```

When you have finished editing, save the file and close the editor.

### Select User Inputs

Potential [user inputs](/cli/templates/structure/inputs/) are detected in the `parameters` fields, in all configurations and configuration rows.

```
Please select which fields in the configurations should be user inputs.
?  [Enter to launch editor]
```

Follow the instructions in the definition file:
1. **Mark which fields should be user inputs.**
    - Encrypted values are automatically pre-marked.
    - User inputs are marked with `[x]`.
    - Ignored fields are marked with`[ ]`.
2. **Modify `<input-id>` if the pre-generated value is not sufficient.**

Example definition file that opens in the editor:
```md
<!--
Please define user inputs for the template.
Edit lines below "## Config ..." and "### Row ...".
Do not edit "<field.path>" and lines starting with "#"!

Line format: <mark> <input-id> <field.path> <example>

1. Mark which fields should be user inputs.
[x] "input-id" "field.path"   <<< this field will be user input
[ ] "input-id" "field.path"   <<< this field will be scalar value

2. Modify "<input-id>" if the pre-generated value is not sufficient.
Allowed characters: a-z, A-Z, 0-9, "-".
-->

## Config "My MySQL Data Source" keboola.ex-db-mysql:810414442
[x] mysql-password            `parameters.db.#password`
[x] mysql-database            `parameters.db.database`    <!-- database -->
[x] mysql-host                `parameters.db.host`        <!-- my-mysql.com -->
[x] mysql-port                `parameters.db.port`        <!-- 3306 -->
[x] mysql-user                `parameters.db.user`        <!-- username -->

### Row "table1" keboola.ex-db-mysql:810414442:48061
[ ] ex-db-mysql-incremental   `parameters.incremental`    <!-- false -->
[ ] ex-db-mysql-output-table  `parameters.outputTable`    <!-- in.c-keboola-ex-db-m... -->
[ ] ex-db-mysql-primary-key   `parameters.primaryKey`
[ ] ex-db-mysql-query         `parameters.query`          <!-- SELECT `id`, `name` ... -->

### Row "table2" keboola.ex-db-mysql:810414442:12883
[ ] ex-db-mysql-incremental   `parameters.incremental`    <!-- false -->
[ ] ex-db-mysql-output-table  `parameters.outputTable`    <!-- in.c-keboola-ex-db-m... -->
[ ] ex-db-mysql-primary-key   `parameters.primaryKey`
[ ] ex-db-mysql-query         `parameters.query`          <!-- SELECT `id`, `name` ... -->
```

When you have finished editing, save the file and close the editor.

### Complete User Inputs

```
Please complete the user inputs specification.
?  [Enter to launch editor]
```

Follow the instructions in the definition file:
1. **Complete the [user inputs](/cli/templates/structure/inputs/).**
2. **Sort the user inputs.**
    - Move text blocks with definitions.
    - Assign the inputs to different steps. A preview of the created steps structure is suggested in the comment.
    - User will be asked for inputs in the specified order.

```md
<!--
Please complete definition ...

Preview of steps and groups you created:
- Group 1: Default Group
  - Step "step-1": Default Step - Description
-->

## Input "mysql-host" (string)
name: MySQL Host
description: 
kind: input
rules: 
showIf: 
default:
step: step-1

## Input "mysql-port" (int)
name: MySQL Port
description: 
kind: input
rules: 
showIf: 
default: 3306
step: step-1

## Input "mysql-user" (string)
name: MySQL User
description: 
kind: input
rules: 
showIf: 
default:
step: step-1

## Input "mysql-password" (string)
name: MySQL Password
description: 
kind: hidden
rules: 
showIf: 
default:
step: step-1

## Input "mysql-database" (string)
name: MySQL Database
description: 
kind: input
rules: 
showIf: 
default:
step: step-1
```

### All Done

After completing all the steps, the template is saved in the repository directory.
You can add detailed information about the template to the `README.md` file.

#### Console output
```
Created template dir "my-template/v0".
Created template manifest file "src/manifest.jsonnet".
Created template inputs file "src/inputs.jsonnet".
Created readme file "README.md".
Plan for "pull" operation:
  + C extractor/keboola.ex-db-mysql/my-data-source
  + R extractor/keboola.ex-db-mysql/my-data-source/rows/table1
  + R extractor/keboola.ex-db-mysql/my-data-source/rows/table2
  + C transformation/keboola.snowflake-transformation/my-transformation
Pull done.
Template "my-template/v0" has been created.
```
#### Resulting directory structure
```
📂 [repository]
┣ 📂 .keboola
┃ ┗ 🟦 repository.json
┗ 📂 my-template
  ┗ 📂 v0
    ┣ 🟩 README.md
    ┗ 📂 src
       ┣ 🟪 inputs.jsonnet
       ┣ 🟪 manifest.jsonnet
       ┣ 📂 extractor
       ┃ ┗ 📂 keboola.ex-db-mysql
       ┃   ┗ 📂 my-data-source
       ┃      ┣ 🟪 config.jsonnet
       ┃      ┣ 🟪 meta.jsonnet
       ┃      ┣ 🟩 description.md
       ┃      ┗ 📂 rows
       ┃        ┣ 📂 table1
       ┃        ┃ ┣ 🟪 config.jsonnet
       ┃        ┃ ┣ 🟪 meta.jsonnet
       ┃        ┃ ┗ 🟩 description.md
       ┃        ┗ 📂 table2
       ┃          ┣ 🟪 config.jsonnet
       ┃          ┣ 🟪 meta.jsonnet
       ┃          ┗ 🟩 description.md
       ┗ 📂 transformation
         ┗ 📂 keboola.snowflake-transformation
           ┗ 📂 my-transformation
              ┣ 🟪 config.jsonnet
              ┣ 🟪 meta.jsonnet
              ┣ 🟩 description.md
              ┗ 📂 blocks
                 ┗ 📂 001-block-1
                    ┣ 🟪 meta.jsonnet
                    ┗ 📂 001-code-1
                       ┣ 🟪 meta.jsonnet
                       ┗ 🟫 code.sql       
```

#### Repository manifest

Template record is added to the `.keboola/repository.json`:
```json
{
  "version": 2,
  "templates": [
    {
      "id": "my-template",
      "name": "My Template",
      "description": "Full workflow to ...",
      "path": "my-template",
      "versions": [
        {
          "version": "0.0.1",
          "description": "",
          "stable": false,
          "path": "v0"
        }
      ]
    }
  ]
}
```

#### Template manifest

IDs and paths are defined in `my-template/v0/src/manifest.jsonnet`:
```jsonnet
{
  configurations: [
    {
      componentId: "keboola.ex-db-mysql",
      id: ConfigId("my-data-source"),
      path: "extractor/keboola.ex-db-mysql/my-data-source",
      rows: [
        {
          id: ConfigRowId("table1"),
          path: "rows/table1",
        },
        {
          id: ConfigRowId("table2"),
          path: "rows/table2",
        },
      ],
    },
    {
      componentId: "keboola.snowflake-transformation",
      id: ConfigId("my-transformation"),
      path: "transformation/keboola.snowflake-transformation/my-transformation",
      rows: [],
    },
  ],
}
```

#### User inputs

User inputs are defined in `my-template/v0/src/inputs.jsonnet`:
```jsonnet
{
  inputs: [
    {
      id: "mysql-host",
      name: "MySQL Host",
      description: "",
      type: "string",
      kind: "input",
    },
    {
      id: "mysql-port",
      name: "MySQL Port",
      description: "",
      type: "int",
      kind: "input",
      default: 3306,
    },
    {
      id: "mysql-user",
      name: "MySQL User",
      description: "",
      type: "string",
      kind: "input",
    },
    {
      id: "mysql-password",
      name: "MySQL Password",
      description: "",
      type: "string",
      kind: "hidden",
    },
    {
      id: "mysql-database",
      name: "MySQL Database",
      description: "",
      type: "string",
      kind: "input",
    },
  ],
}
```

Example configuration with user inputs:
```jsonnet
# my-template/v0/src/extractor/keboola.ex-db-mysql/my-data-source/config.jsonnet
{
  parameters: {
    db: {
      port: Input("mysql-port"),
      host: Input("mysql-host"),
      user: Input("mysql-user"),
      "#password": Input("mysql-password"),
      database: Input("mysql-database"),
    },
  },
}
```

You can further customize the template as needed.

## Use Template

To use template you need a local [project directory](/cli/structure/). 
If you do not have one, use [kbc sync init](/cli/commands/sync/init/) command.
The template is applied locally. Command [kbc sync push](/cli/commands/sync/push/) can be used to push changes to the project.


Template repositories are defined in the [project manifest](/cli/structure/#manifest).
First step is to add our custom repository to the project manifest.
Template repository can be stored in a git repository or in a local directory.


### Add Git Repository

First, push template repository to a public git repository. 
Repository directory must be root directory of the git repository.

Then edit [.keboola/manifest.json](/cli/structure/#manifest) file in the project directory in which you want to use the template.
Add repository definition to `templates.repositories` key.
Key `url` is URL of the public git repository. Key `ref` is `branch` or `tag` used internally by `git checkout`.

Example `.keboola/manifest.json`:
```
....
  "templates": {
    "repositories": [
        "type": "git",
        "name": "my-repository",
        "url": "https://github.com/my-org/my-repository.git",
        "ref": "main"
    ]
  },
....
```

### Add Local Repository

Edit [.keboola/manifest.json](/cli/structure/#manifest) file in the project directory in which you want to use the template.
Add repository definition to `templates.repositories` key.
Key `path` is relative or absolute path to the repository directory. Relative path must be relative to the project directory.

Example `.keboola/manifest.json`:
```
....
  "templates": {
    "repositories": [
      {
        "type": "dir",
        "name": "my-repository",
        "url": "/path/to/repository"
      }
    ]
  },
....
```

### Start Dialog

Use template, run [command](/cli/commands/local/template/use/) in the project directory:
```
kbc local template use my-repository/my-template/v0
```

The last parameter `v0` is the version, it can have different forms, see [versioning](/cli/templates/structure/#versioning).

Select target branch where the template should be applied:
```
? Select target branch:  [Use arrows to move, type to filter]
> Main (251721)
```

Fill in all [user inputs](/cli/templates/structure/inputs/).
```
? MySQL Host: my-mysql.com

? MySQL Port: 3306
...
```

Example console output:
```
Plan for "encrypt" operation:
  C main/extractor/keboola.ex-db-mysql/my-data-source
    parameters.db.#password
Encrypt done.
New objects from "my-repository/my-template/v0" template:
  + C main/extractor/keboola.ex-db-mysql/my-data-source
  + R main/extractor/keboola.ex-db-mysql/my-data-source/rows/table1
  + R main/extractor/keboola.ex-db-mysql/my-data-source/rows/table2
  + C main/transformation/keboola.snowflake-transformation/my-transformation
Template "my-repository/my-template/v0" has been applied.
```

The template can be applied multiple times.

### Push Changes

The template was applied to the local directory only.
You can see the changes with [kbc sync diff](/cli/commands/sync/diff/) command. 


If you are satisfied with the changes, you can push changes to the project and see the new configurations in the UI.
Run command:

```
kbc sync push
```

Example output:
```
Plan for "push" operation:
  + C main/extractor/keboola.ex-db-mysql/my-data-source
  + R main/extractor/keboola.ex-db-mysql/my-data-source/rows/table1
  + R main/extractor/keboola.ex-db-mysql/my-data-source/rows/table2
  + C main/transformation/keboola.snowflake-transformation/test-transformation
  + C main/transformation/keboola.snowflake-transformation/my-transformation
Push done.
```

## Next Steps
- [Template Structure](/cli/templates/structure/)
- [User Inputs](/cli/templates/structure/inputs/)


================================================
File: extend/index.md
================================================
---
title: Extending Keboola
permalink: /extend/
---

As an open system consisting of many built-in, interoperating components,
such as Storage or Extractors, [Keboola](/overview/) can be easily extended.
We encourage you to [**build your own components**](/extend/component/tutorial), whether for
your own use or to be offered to other Keboola users and customers.

* TOC
{:toc}

There are two main options for extending Keboola: (a) creating your own **component** and (b) using **Generic 
Extractor** to build an extractor for a RESTful API.

## Advantages of Extending Keboola

Depending on your role, extending Keboola offers various advantages:

- If you already are a **Keboola customer**: 
    - Create your own component to convert your business problem into cloud. We will take care of the technical arrangements around running it.
    - Create extractors or writers for communicating with your legacy systems, even if they are completely non-standard.
    - Create components to experiment with new business solutions. No need to ask your IT to allocate resources to you. [Fail fast](https://en.wikipedia.org/wiki/Fail-fast#Business).
    - Easily access data from many different sources.
- If you are an **external company**:
    - Create connectors (Extractors/Writers) so that Keboola users can easily connect to your service and broaden your customer base.
    - Create applications containing or using your algorithms and easily "deploy" them to Keboola customers. They won't be exposed to end-users, neither will be the end-user data exposed to you.
	- Easily deliver the data back to your customers.
- If you are a **data scientist**:
    - Create applications for delivering your work to your customer. We will take care of the technical arrangements. No need to rent servers and feed data to them.
    - Make your application or algorithm available to all existing Keboola subscribers and implementation partners.
    - Focus only on areas of your product where you are adding value.
    - Let Keboola be in charge of the billing.

## Component
A [component](/extend/component/) can be used as:

- **Extractor**, allowing customers to get data from new sources. It only processes input tables from external sources (usually API).
- **Application**, further enriching the data or adding value in new ways. It processes input tables stored as CSV files or database tables and generates result tables as CSV files or database tables.
- **Transformation**, allowing customers to modify their data. It is a constrained form of an application.
- **Writer**, pushing data into new systems and consumption methods. It does not generate any data in Keboola projects.
- **Processor**, adjusting the inputs or outputs of other components. It has to be run together with one of the above components.

All components are run using [Docker Runner](/extend/docker-runner/), a component that takes
care of their authentication, starting, stopping, isolation, reading data from and writing it to Keboola Storage. They must adhere to the
[common interface](/extend/common-interface/). Creating components requires an elementary knowledge of [Docker](https://www.docker.com/why-docker).
They can be implemented in virtually any programming language and be fully customized and tailored to anyone's needs.
They also support OAuth authorization. To get started with building a component, see our [**tutorial**](/extend/component/tutorial/).

## Generic Extractor
[Generic Extractor](/extend/generic-extractor/) is a Keboola component acting like a
customizable [HTTP REST client](/extend/generic-extractor/tutorial/rest/). It can be configured to extract data 
from virtually any API and offers a vast amount of configuration options. With Generic Extractor, you can build an 
entirely new extractor for Keboola in less than an hour. 

Components based on Generic Extractor are built using [JSON configuration](/extend/generic-extractor/tutorial/) and a
[published template](/extend/generic-extractor/publish/). They have a predefined UI, require no knowledge of Docker or
other tools, and they use a Keboola owned [repository](https://github.com/keboola/kbc-ui-templates/). To get 
started with Generic Extractor, see our [**tutorial**](/extend/generic-extractor/tutorial/).


================================================
File: extend/common-interface/actions.md
================================================
---
title: Actions
permalink: /extend/common-interface/actions/
---

* TOC
{:toc}

Actions provide a way to execute very quick tasks in a single Component, using a single code base.
The default component's action (`run`) executes as a background, asynchronous job. It is queued, has plenty of
execution time, and there are cases when you might not want to wait for it. Apart from the default `run`, there
can be synchronous actions with limited execution time and you must wait for them. When we refer to
**actions**, we mean *synchronous actions*. Using actions is fully optional.

## Use Case
For example, in our database extractor, the main task (`run` action) is the data extraction itself. But we also want to be
able to test the database credentials and list tables available in the database.
These tasks would be very helpful in the UI. It is not possible to do these things directly in the browser. Setting up a
separate component would bring an overhead of maintaining both the extractor's Docker image and the new component.

## Solution
For each Component, you can specify other actions (apart from the default `run`). These
actions will be executed using the same Docker image, but [Docker Runner](/extend/docker-runner/) will wait for its execution and use
the returned value as the API response. So, these additional actions are executed *synchronously* and have a very
limited execution time (maximum 30 seconds). These actions also cannot access Storage.

![Docker Actions overview](/extend/common-interface/docker-sync-actions.svg)

The [configuration file](/extend/common-interface/config-file/#configuration-file-structure)
contains the `action` property with the name of the currently executed action. Just grab the value and act accordingly.
All actions must be explicitly specified in the component configuration in [Developer Portal](https://components.keboola.com/).

## Running Actions
Actions are available through the [API](https://kebooladocker.docs.apiary.io/#reference/actions/run-custom-component-action).
They do not load the configuration from Storage, so you need to fully specify the whole configuration in the request body.
If any of your parameters are encrypted, they will be decrypted before they are passed to your component.

Do not specify the `action` attribute in the request body, it is already in the URI. Use any of `parameters` and `runtime` inside the `configData` root element as you would when creating an asynchronous job. Using `storage` configuration in actions makes no sense, because actions cannot read or write to Storage. For instance:

{% highlight json %}

{
    "configData": {
        "parameters": {
            "key": "val"
        }
    }
}

{% endhighlight %}

**Important: use https://docker-runner.keboola.com/ for calling this part of the API.**

### Return Values

As the component output is passed back through the API, all output from an action **MUST** be JSON (except for errors).

If your component outputs an invalid JSON on its STDOUT, an application error will be raised.

## Handling User and Application errors

Actions use the same [exit codes](/extend/common-interface/environment/#return-values) as the default `run` action.

If an user or application error is detected, STDERR/STDOUT is handled as the message string and is returned to the user. The message is wrapped into a standardized structure.

For example

{% highlight python %}
print('user error message')
sys.exit(1)
{% endhighlight %}

yields this message on the API (HTTP status code 400)

{% highlight json %}
{
  "status": "error",
  "error": "User error",
  "code": 400,
  "message": "user error message",
  "exceptionId": "docker-7ed4c3b599776e8a2a84a7f185f5f7f2",
  "runId": 0
}
{% endhighlight %}

and

{% highlight python %}
print('application error message')
sys.exit(2)
{% endhighlight %}

yields this message on the API (HTTP status code 500)

{% highlight json %}
{
  "status": "error",
  "error": "Application error",
  "code": 500,
  "message": "Contact support@keboola.com and attach this exception id.",
  "exceptionId": "docker-2a51922e0753cf78297ad6d384200206",
  "runId": 0
}
{% endhighlight %}

## Limits

**Sync actions may not read from or write data to the Storage.**
Otherwise actions share the same limits as the default `run` action, only the execution time is limited to 30 seconds.
This time does not include pulling the Docker image.


================================================
File: extend/common-interface/config-file.md
================================================
---
title: Configuration File Specification
permalink: /extend/common-interface/config-file/
---

* TOC
{:toc}

Configuration files are one of the [possible channels](/extend/common-interface/) for exchanging data
between components and Keboola.

To create a sample configuration file (together with the data directory),
use the [Debug API call](/extend/component/running/#preparing-the-data-folder) via the
[Docker Runner API](https://kebooladocker.docs.apiary.io/#reference/sandbox/input-data).
You will get a zip archive containing all the resources you need in your component.

All configuration files are always stored in `JSON` format.

## Configuration File Structure
Each configuration file has the following root nodes:

- `storage`: Contains both the input and output [mapping](https://help.keboola.com/manipulation/transformations/mappings/) for both files and tables.
This section is important if your component uses a dynamic input/output mapping.
Simple components can be created with a static input/output mapping.
They do not use this configuration section at all (see [Tutorial](/extend/component/tutorial/)).
- `parameters`: Contains arbitrary parameters passed from the UI to the component. This section can be used in any
way you wish. Your component should validate the contents of this section. For passing sensitive
data, use [encryption](/overview/encryption/). This section is not available in Transformations.
- `image_parameters`: See [below](#image-parameters).
- `authorization`: Contains Oauth2 [authorization contents](/extend/common-interface/oauth/) or 
[Workspace credentials](/extend/common-interface/folders/#exchanging-data-via-workspace) .
- `action`: Name of the [action](/extend/common-interface/actions/) to execute; defaults to `run`. All
actions except `run` have a strict execution time limit of 30 seconds.
See [actions](/extend/common-interface/actions/) for more details.

### Validation
Your application should implement validation of the `parameters` section, which is passed without modification from the UI.
Your application might also implement validation of the `storage` section if you have some specific requirements on the
input mapping or output mapping setting (e.g., certain number of tables, certain names). If you chose to do any validation
outside the `parameters` section, it must always be forward compatible -- i.e. benevolent. While we maintain backward compatibility
very carefully, it is possible for new keys to appear in the configuration structure as we introduce new features.

### Image Parameters
The `image_parameters` section contains configuration options, which are the same for every configuration of a component.
They cannot be modified by the end-user. This section is typically used for global component
parameters (such as a token, URL, version of your API) which, for any reason, are not practical to be part of the component image itself.
The `image_parameters` contents are configured in the [component settings](https://components.keboola.com/) in JSON format in two
text fields: **Image Parameters** and **Stack Parameters**.

Both JSONs are merged into the `image_parameters` of the configuration file. The *Stack Parameters* 
provide different values for different [Keboola Stacks](/overview/api/#regions-and-endpoints). Values in
*Stack Parameters* are merged with those in *Image Parameters* with *Stack Parameters* having a higher priority.
*Stack Parameters* are indexed with [Storage URL](/overview/api/#regions-and-endpoints) or the given region.

Given the following *Image Parameters*:

{% highlight json %}
{
    "name": "my-app-name",
    "token": "default"
}
{% endhighlight %}

And the following *Stack Parameters*:

{% highlight json %}
{
    "connection.keboola.com": {
        "url": "https://my-us-api/",
        "token": "abc"
    },
    "connection.eu-central-1.keboola.com": {
        "url": "https://my-eu-api/",
        "token": "def"
    }
}
{% endhighlight %}

The component will receive the following `image_parameters` in the configuration file when run in the **EU region**:
{% highlight json %}
{
    "image_parameters": {
        "name": "my-app-name",
        "url": "https://my-eu-api/",
        "token": "def"
    }
}
{% endhighlight %}

The component will receive the following `image_parameters` in the configuration file when run in the **US region**:
{% highlight json %}
{
    "image_parameters": {
        "name": "my-app-name",
        "url": "https://my-us-api/",
        "token": "abc"
    }
}
{% endhighlight %}

When working with the API, note that the [Developer Portal API](https://kebooladeveloperportal.docs.apiary.io/)
(specifically the [Component Detail API call](https://kebooladeveloperportal.docs.apiary.io/#reference/0/app/get-app-detail))
shows separate `stack_parameters` and `image_parameters`, because the API is region agnostic.

However, when working with the [Storage API](https://keboola.docs.apiary.io/)
(specifically the [Component list API call](https://keboola.docs.apiary.io/#reference/miscellaneous/api-index/component-list)),
the `stack_parameters` and `image_parameters` values are already merged and only those designated for the
current region are visible.

#### Encryption
Both *Image Parameters* and *Stack Parameters* support [encrypted values](/overview/encryption/). In practice, however,
the encrypted values must always be stored in *Stack Parameters*, because ciphers are not transferable between regions
(i.e. an encrypted value is only usable in the region in which it was encrypted).

As with configurations, the encrypted values must be prefixed with the hash sign `#`. However, unlike in Keboola configurations,
you **have to encrypt values manually via the API** -- they will not be encrypted automatically when you store *Stack Parameters*!
When using the [encryption API](https://keboolaencryption.docs.apiary.io/#), provide only the `componentId`
parameter (using `projectId` or `configId` will make the cipher unusable).
Also take care to use the correct [API URL](https://developers.keboola.com/overview/api/#regions-and-endpoints) to obtain
ciphers for each region you need.

## State File
The state file is used to store the component state for the next run. It provides a two-way communication between
Keboola configuration state storage and the component. The state file only works if the API call
references a stored configuration (`config` is used, not `configData`).

The location of the state file is:

- `/data/in/state.json` loaded from a configuration state storage
- `/data/out/state.json` saved to a configuration state storage

The component reads the input state file and writes any content to the output state
file (valid JSON) that
will be available to the next API call. A missing or an empty file will remove the state value.
A state object is saved to configuration storage only when actually running the app
(not in [debug API calls](https://kebooladocker.docs.apiary.io/#reference/debug). The state must be a valid JSON file.
[Encryption](/overview/encryption/#encrypting-data-with-api) is applied to the state the same way it is applied to
configurations, `KBC::ProjectSecure::` ciphers are used. 

### State File Properties
Because the state is stored as part of a
[component configuration](https://keboola.docs.apiary.io/#reference/components-and-configurations),
the value of the state object is somewhat limited (should not generally exceed 1MB). It should not
be used to store large amounts of data.

Also, the end-user cannot easily access the data through the UI.
The data can be, however, modified outside of the component itself using the
[component configuration](https://keboola.docs.apiary.io/#reference/components-and-configurations) API calls.
Note however that the content in the contents of the state file is nested:

I.e., assume that the component generates a state file with the following contents:


{% highlight json %}
{
    "time": {
        "previousStart": 1587980435
    }
}
{% endhighlight %}

If you read the configuration through the Component configuration API call, you'll see:

{% highlight json %}
"state": {
    "component": {
        "time": {
            "previousStart": 1587980435
        }
    },
    "storage": {
      "input": {
        "tables": []
      }
    }
  }
{% endhighlight %}

That means the contents of the state file are nested inside the `component` node. There
is also a `storage` node, which is related to the 
[Automatic incremental processing](https://help.keboola.com/storage/tables/#automatic-incremental-processing).

You need to maintain the above structure when manually changing the configuration via the API.

**Important:** The state file is not thread-safe. If multiple instances of the **same configuration**
are run simultaneously in the **same project**, the one writing data later wins. Use the state file more
as an HTTP cookie than as a database. A typical use for the state file would be saving the last record
loaded from some API to enable incremental loads.

## Usage File

Unlike the state file, the **usage file is one way only** and has a pre-defined structure.
The usage file is used to pass information from the component to Keboola.
Metrics stored are used to determine how much resources the job consumed and translate the usage to Keboola
credits; this is very useful when you need your customers to pay using your component or service.

The usage file is located at `/data/out/usage.json`. It should contain an array of objects
keeping information about the consumed resources. The objects have to contain only two keys, `metric`
and `value`, as in the example bellow:

{% highlight json %}
[
    {
        "metric": "API calls",
        "value": 150
    }
]
{% endhighlight %}

This structure is processed and stored within a job, so it can be analyzed, processed and aggregated later.

To keep track of the consumed resources in the case of a component failure, **it is recommended to
write the usage file regularly** during the component run, not only at the end.

*Note: As the structure of the state file is pre-defined, the content of the usage file is strictly
validated and a wrong format will cause a component failure.*

## Examples
To create an example configuration, use the [Debug API call](/extend/component/running/#preparing-the-data-folder). You will get a
`stage_0.zip` archive in your **Storage** > **File Uploads**, which will contain the `config.json` file.
You can also use these configuration structure to create an API request for
actually [running a component](https://kebooladocker.docs.apiary.io/#reference/run/create-a-job).
If you want to manually pass configuration options in the API request, be sure to wrap it around in the `configData` node.

A sample configuration file might look like this:

{% highlight json %}
{
    "storage": {
        "input": {
            "tables": [
                {
                    "source": "in.c-main.test",
                    "destination": "source.csv",
                    "limit": 50,
                    "columns": [],
                    "where_values": [],
                    "where_operator": "eq"
                },
                {
                    "source": "pokus.snaz.test",
                    "destination": "source1.csv"
                }
            ],
            "files": []
        },
        "output": {
            "tables": [
                {
                    "source": "destination.csv",
                    "destination": "out.c-main.test",
                    "incremental": false,
                    "colummns": [],
                    "primary_key": [],
                    "delete_where": [],
                    "delimiter": ",",
                    "enclosure": "\""
                },
                {
                    "source": "write-alwayss.csv",
                    "destination": "out.c-main.output-even-on-error"
                    "write_always": true
                }
            ],
            "files": []
        }
    },
    "parameters": {
        "multiplier": 2
    },
    "image_parameters": [],
    "action": "run"
}
{% endhighlight %}

### Tables
Tables from the input mapping are mounted to `/data/in/tables`.
Input mapping parameters are similar to the [Storage API export table options](https://keboola.docs.apiary.io/#reference/tables/unload-data-asynchronously).
If `destination` is not set, the CSV file will have the same name as the table (without adding `.csv` suffix).
The tables element in a configuration of the **input mapping** is an array and supports the following attributes:

- `source`
- `destination`
- `days` (internally converted to `changed_since`)
- `columns`
- `column_types`
- `where_column`
- `where_operator`
- `where_values`
- `limit`

The output mapping parameters are similar
to the [Transformation API output mapping ](https://help.keboola.com/manipulation/transformations/).
`destination` is the only required parameter. If `source` is not set, the CSV file is expected to have the same name
as the `destination` table.
The tables element in a configuration of the **output mapping** is an array and supports the following attributes:

  - `source`
  - `destination`
  - `incremental`
  - `columns`
  - `primary_key`
  - `delete_where` - Defines rules for deleting records before loading new data
  - `delete_where_column` - **[DEPRECATED]** Use `delete_where` instead
  - `delete_where_operator` - **[DEPRECATED]** Use `delete_where` instead
  - `delete_where_values` - **[DEPRECATED]** Use `delete_where` instead
  - `delimiter`
  - `enclosure`
  - `write_always`

#### Input mapping --- basic
Download tables `in.c-ex-salesforce.Leads` and `in.c-ex-salesforce.Accounts` to `/data/tables/in/leads.csv`
and `/data/tables/in/accounts.csv`.

{% highlight json %}
{
    "storage": {
        "input": {
            "tables": [
                {
                    "source": "in.c-ex-salesforce.Leads",
                    "destination": "leads.csv"
                },
                {
                    "source": "in.c-ex-salesforce.Accounts",
                    "destination": "accounts.csv"
                }
            ]
        }
    }
}
{% endhighlight %}

In an API request, this would be passed as:

{% highlight json %}
{
    "configData": {
        "storage": {
            "input": {
                "tables": [
                    {
                        "source": "in.c-ex-salesforce.Leads",
                        "destination": "leads.csv"
                    },
                    {
                        "source": "in.c-ex-salesforce.Accounts",
                        "destination": "accounts.csv"
                    }
                ]
            }
        }
    }
}
{% endhighlight %}


#### Input mapping --- incremental load
Download 2 days of data from the `in.c-storage.StoredData` table to `/data/tables/in/in.c-storage.StoredData`.

{% highlight json %}
{
    "storage": {
        "input": {
            "tables": [
                {
                    "source": "in.c-storage.StoredData",
                    "days": "2"
                }
            ]
        }
    }
}
{% endhighlight %}

#### Input mapping --- select columns

{% highlight json %}
{
    "storage": {
        "input": {
            "tables": [
                {
                    "source": "in.c-ex-salesforce.Leads",
                    "columns": ["Id", "Revenue", "Date", "Status"]
                }
            ]
        }
    }
}
{% endhighlight %}

#### Input mapping --- column types
This is applicable only to [workspace mapping](/extend/common-interface/folders/#exchanging-data-via-workspace), for CSV files this setting has no effect. The `column_types` setting maps to [Storage API load options](https://keboola.docs.apiary.io/#reference/workspaces/load-data/load-data). It also acts the same way as `columns` setting allowing you to limit the table columns.
If both `column_types` and `columns` setting are used, then the listed columns must match. If you omit `columns` and use only `column_types` (recommended) then `columns` will be propagated automatically from `column_types`.

{% highlight json %}
{
    "storage": {
        "input": {
            "tables": [
                {
                    "source": "in.c-ex-salesforce.Leads",
                    "column_types": [
                        {
                            "source": "Id",
                            "type": "VARCHAR",
                            "destination": "id",
                            "length": "255",
                            "nullable": false,
                            "convert_empty_values_to_null": false
                        }
                    ]
                }
            ]
        }
    }
}
{% endhighlight %}

#### Input mapping --- filtered table

{% highlight json %}
{
    "storage": {
        "input": {
            "tables": [
                {
                    "source": "in.c-ex-salesforce.Leads",
                    "destination": "closed_leads.csv",
                    "where_column": "Status",
                    "where_values": ["Closed Won", "Closed Lost"],
                    "where_operator": "eq"
                }
            ]
        }
    }
}
{% endhighlight %}

#### Output mapping --- basic
Upload `/data/out/tables/out.c-main.data.csv` to `out.c-main.data`.

{% highlight json %}
{
    "storage": {
        "output": {
            "tables": [
                {
                    "source": "out.c-main.data.csv",
                    "destination": "out.c-main.data"
                }
            ]
        }
    }
}
{% endhighlight %}

#### Output mapping --- headless CSV
Upload `/data/out/tables/data.csv`, a CSV file without headers on its first line, to the table `out.c-main.data`.

{% highlight json %}
{
    "storage": {
        "output": {
            "tables": [
                {
                    "source": "data.csv",
                    "destination": "out.c-main.data",
                    "columns": ["column1", "column2"]
                }
            ]
        }
    }
}
{% endhighlight %}

#### Output mapping --- set additional properties
Incrementally upload `/data/out/tables/data.csv` to `out.c-main.data`
with a compound primary key set on the columns `column1` and `column2`.

{% highlight json %}
{
    "storage": {
        "output": {
            "tables": [
                {
                    "source": "data.csv",
                    "destination": "out.c-main.data",
                    "incremental": true,
                    "primary_key": ["column1", "column2"]
                }
            ]
        }
    }
}
{% endhighlight %}

#### Output mapping --- write even if the job fails
If you have a table that you are updating during the execution of the job 
and you want to output that table even if the job fails then you can use the `write_always` flag 

{% highlight json %}
{
    "storage": {
        "output": {
            "tables": [
                {
                    "source": "always-output.csv",
                    "destination": "out.c-main.always-output",
                    "write_always": true
                }
            ]
        }
    }
}
{% endhighlight %}

#### Output mapping --- delete rows
Delete data from the `destination` table before uploading the CSV file (only makes sense with `incremental: true`).

The `delete_where` parameter provides a flexible way to specify which records should be deleted from the target table before loading new data into it. It supports time-based filters and multiple filter conditions:

{% highlight json %}
{
    "storage": {
        "output": {
            "tables": [
                {
                    "source": "data.csv",
                    "destination": "out.c-main.Leads",
                    "incremental": true,
                    "delete_where": [
                        {
                            "changed_since": "-7 days",
                            "changed_until": "-2 days",
                            "where_filters": [
                                {
                                    "column": "Status",
                                    "operator": "eq",
                                    "values_from_set": ["Closed"]
                                },
                                {
                                    "column": "Status",
                                    "operator": "eq",
                                    "values_from_workspace": {
                                        "workspace_id": "123",
                                        "table": "statuses",
                                        "column": "status_name"
                                    }
                                }
                            ]
                        }
                    ]
                }
            ]
        }
    }
}
{% endhighlight %}

**Parameters:**

- `changed_since` (optional) - Starting point for time-based deletion. Can be specified as:
  - Relative time (e.g., "-2 days", "-1 month")
  - Unix timestamp (e.g., "1360138863")
  - ISO 8601 date (e.g., "2013-02-12T15:19:21+00:00")
- `changed_until` (optional) - End point for time-based deletion. Accepts the same formats as `changed_since`
- `where_filters` (optional) - Array of filter conditions:
  - `column` - Name of the column to filter on
  - `operator` - One of: `eq` (equals), `ne` (not equals)
  - `values_from_set` - Array of specific values to match against
  - `values_from_workspace` - Reference values from a workspace table:
    - `workspace_id` - ID of the workspace. Optional when exchanging data through [database workspace](/extend/common-interface/folders/#exchanging-data-via-database-workspace)
    - `table` - Name of the table in the workspace.
    - `column` - Name of the column containing values. If not specified, the column name from `where_filters.column` will be used

**Note:** For each `where_filters` item, you must use only one method to specify values - either `values_from_set` or `values_from_workspace`. Using multiple value sources in a single filter is not allowed.

You can combine multiple rules and filters to create complex deletion conditions. Each rule in the `delete_where` array is processed independently.

##### Simple Example
Here's a basic example of deleting records with a specific status:

{% highlight json %}
{
    "storage": {
        "output": {
            "tables": [
                {
                    "source": "data.csv",
                    "destination": "out.c-main.Leads",
                    "incremental": true,
                    "delete_where": [
                        {
                            "where_filters": [
                                {
                                    "column": "Status",
                                    "operator": "eq",
                                    "values_from_set": ["Closed", "Cancelled"]
                                }
                            ]
                        }
                    ]
                }
            ]
        }
    }
}
{% endhighlight %}

This configuration performs a DELETE operation equivalent to the following SQL:

```sql
DELETE FROM "out.c-main.Leads"
WHERE "Status" IN ('Closed', 'Cancelled')
```

When using `operator: "ne"` (not equals), the operation will use SQL's NOT IN clause instead of IN. For example, if you specify `values_from_set: ["Active", "Pending"]` with `operator: "ne"`, it will delete all records where the column value is NOT one of the specified values.

##### Multiple Filters
Multiple filters in a single `where_filters` array are combined using AND operator. For example:

{% highlight json %}
{
    "storage": {
        "output": {
            "tables": [
                {
                    "source": "data.csv",
                    "destination": "out.c-main.Leads",
                    "incremental": true,
                    "delete_where": [
                        {
                            "where_filters": [
                                {
                                    "column": "Status",
                                    "operator": "eq",
                                    "values_from_set": ["Closed", "Cancelled"]
                                },
                                {
                                    "column": "Region",
                                    "operator": "ne",
                                    "values_from_set": ["EU"]
                                }
                            ]
                        }
                    ]
                }
            ]
        }
    }
}
{% endhighlight %}

This configuration performs a DELETE operation equivalent to the following SQL:

```sql
DELETE FROM "out.c-main.Leads"
WHERE "Status" IN ('Closed', 'Cancelled')
  AND "Region" NOT IN ('EU')
```

**Important Note:** Multiple rules in the `delete_where` array are processed independently (as separate DELETE statements)

##### Independent Rules Processing
When multiple rules are specified in the `delete_where` array, each rule is processed as a separate DELETE statement. For example:

{% highlight json %}
{
    "storage": {
        "output": {
            "tables": [
                {
                    "source": "data.csv",
                    "destination": "out.c-main.Leads",
                    "incremental": true,
                    "delete_where": [
                        {
                            "where_filters": [
                                {
                                    "column": "Status",
                                    "operator": "eq",
                                    "values_from_set": ["Closed"]
                                }
                            ]
                        },
                        {
                            "where_filters": [
                                {
                                    "column": "Region",
                                    "operator": "eq",
                                    "values_from_set": ["EU"]
                                }
                            ]
                        }
                    ]
                }
            ]
        }
    }
}
{% endhighlight %}

This configuration performs two separate DELETE operations equivalent to:

```sql
DELETE FROM "out.c-main.Leads"
WHERE "Status" IN ('Closed');

DELETE FROM "out.c-main.Leads"
WHERE "Region" IN ('EU');
```

##### Legacy Delete Configuration (Deprecated)
For backward compatibility, the following parameters are still supported but not recommended for new implementations:

{% highlight json %}
{
    "storage": {
        "output": {
            "tables": [
                {
                    "source": "data.csv",
                    "destination": "out.c-main.Leads",
                    "incremental": true,
                    "delete_where_column": "Status",
                    "delete_where_values": ["Closed"],
                    "delete_where_operator": "eq"
                }
            ]
        }
    }
}
{% endhighlight %}

### Files
Another way of downloading files from file uploads is to use an
[Elasticsearch query](https://www.elastic.co/guide/en/elasticsearch/reference/current/query-dsl-query-string-query.html#query-string-syntax)
or filtering with tags. Note that the results of a file mapping are limited to 10 files (to prevent accidental downloads).
If you need more files, use multiple file mappings.

All files matching the search will be downloaded to the `/data/in/files` folder.
The name of each file has the `fileId_fileName` format. Each file will also contain a
[manifest](/extend/common-interface/manifest-files/) with all information about the file.

#### Input mapping --- query

{% highlight json %}
{
    "storage": {
        "input": {
            "files": [
                {
                    "tags": ["docker-demo"],
                    "query": "name:.zip"
                }
            ]
        }
    }
}
{% endhighlight %}

This will download with files with matching `.zip` **and** having the `docker-demo` tag. Depending on the contents of your
**File uploads** in **Storage**, this may produce something like:

    /data/in/files/75807542_fooBar.zip
    /data/in/files/75807542_fooBar.zip.manifest
    /data/in/files/75807657_fooBarBaz.zip
    /data/in/files/75807657_fooBarBaz.zip.manifest

#### Output mapping --- basic
Define additional properties for uploaded files in the output mapping configuration.
If that file is not present in the `/data/out/files` folder, an error will be thrown.

{% highlight json %}
{
    "storage": {
        "output": {
            "files": [
                {
                    "source": "file.csv",
                    "tags": ["processed-file", "csv"]
                },
                {
                    "source": "image.jpg",
                    "is_public": true,
                    "is_permanent": true,
                    "tags": ["image", "pie-chart"]
                }
            ]
        }
    }
}
{% endhighlight %}

#### Incremental processing
Docker containers may be used to process unknown files incrementally. This means that when a container is run,
it will download any files not yet downloaded and process them. To achieve this behavior, it is necessary
to select only the files which have not been processed yet and tag the processed files.
To achieve the former, use a proper
[Elasticsearch query](https://www.elastic.co/guide/en/elasticsearch/reference/current/query-dsl-query-string-query.html#query-string-syntax).
The latter is achieved using the `processed_tags` setting. The `processed_tags` setting is an array of tags
which will be added to the **input** files once they are downloaded. A sample contents of `configData`:

{% highlight json %}
{
    "storage": {
        "input": {
            "files": [
                {
                    "query": "tags: toprocess AND NOT tags: downloaded",
                    "processed_tags": ["downloaded"]
                }
            ]
        }
    }
}
{% endhighlight %}

The above request will download every file with the `toprocess` tag **except** for the files having the `downloaded` tag. 
It will mark each such file with the `downloaded` tag; therefore the query will exclude them on the next run.
This allows you to set up an incremental file processing pipeline.


================================================
File: extend/common-interface/development-branches.md
================================================
---
title: Development branches
permalink: /extend/common-interface/development-branches/
---

* TOC
{:toc}

Development branches are a feature for managing change in Keboola projects. Refer to our [user documentation](https://help.keboola.com/components/branches/) 
to learn more about how development branches function. 

{% include branches-beta-warning.html %}

## Running a Component in a Branch

A component that uses the [Common Interface](/extend/common-interface/) can be run in a branch without any changes to the code. Notable exceptions include 
components that modify external resources (e.g., database writers) and those that use [forwarded Storage tokens](/extend/common-interface/environment/#environment-variables) to interact with the Storage API. 

### Is a Component Executed in a Branch Context?

When the [runner](/extend/docker-runner/) executes a job in a branch, it sets the [`KBC_BRANCHID` environment variable](/extend/common-interface/environment/#environment-variables) to the current branch ID, which is unique accross the stack. 

Typically, the fact that a component is executed in a branch is not very important to the component itself. It behaves the same way, and the Keboola job runner does all the heavy lifting.

The exception is when a component directly interacts with the Storage API using a forwarded Storage token; it must then consider the branch ID. These components are subject to a separate review by Keboola to verify correct implementation.  

### Input and Output Mapping in a Development Branch

#### Write

When writing data to Storage, the bucket name in the [input mapping](/extend/component/tutorial/input-mapping/) is automatically prefixed with the branch's internal ID to ensure that data in the production bucket is not overwritten.

#### Read

A component first checks for a development version of the production bucket when reading data from Storage. If such a bucket exists, it is used; otherwise, the data is read from the production bucket. This prevents the need to duplicate data extraction jobs in development branches.

### Configuration State in a Development Branch

Configuration [states](/integrate/storage/api/configurations/#state) are stored separately for each development branch and are not merged back to the main branch upon merging of the branch itself.

### Components Interacting with External Resources

Extra precautions are necessary for components that interact with external resources to prevent unintended impacts on production data.

For example, in a production environment, a Snowflake writer might write to the PROD_SCHEMA schema in a Snowflake database. Running this writer in a development 
branch without appropriate safeguards could result in writing data intended for development to the production schema. Therefore, operational restrictions apply to 
certain jobs in development branches based on the component’s features:

* **dev-branch-configuration-unsafe**: These components can be run in a development branch if `{configuration:{runtime: {safe: true}}}` is set in their configuration. This can be adjusted via the API or through the *Safe for run in branch* toggle in the configuration detail in the UI. The job runner will verify the safety status before execution. This feature is automatically set for applications and writers. It's not set for extractors. 
* **dev-branch-job-blocked**: These components are not permitted to run in development branches under any circumstances.
* **dev-mapping-allowed**: These components are allowed to use development buckets in their default branch input mappings, which is typically restricted. 

For details on a component’s features, you can consult the [Developer Portal API](https://kebooladeveloperportal.docs.apiary.io/#reference/0/public-api/get-app-detail) or the [Component List in Storage API](https://keboola.docs.apiary.io/#reference/miscellaneous/api-index/component-list). 

To request changes to your component's features, please use the support button in your project to contact our support team. 


================================================
File: extend/common-interface/environment.md
================================================
---
title: Environment Specification
permalink: /extend/common-interface/environment/
---

* TOC
{:toc}

Components use several [channels](/extend/common-interface/) to exchange information with Keboola,
primarily through [structured folders](/extend/common-interface/) and [configuration files](/extend/common-interface/config-file/).
Each component has full access to the external network (network type `bridge`), unless explicitly changed to `none` in the
[Developer Portal](https://components.keboola.com).
Below are the specific aspects of the environment in which your component operates.

## Environment Variables
The following environment variables are injected into the container:

 - `KBC_DATADIR`: Always `/data/` in Keboola; use this variable during component development to create development and testing environments.
 - `KBC_RUNID`: The RunId from Storage; links all events within an API call (useful for logging).
 - `KBC_PROJECTID`: The ID of the project in Keboola within a [Keboola stack](/overview/api/#regions-and-endpoints).
 - `KBC_STACKID`: The ID of the [Keboola stack](/overview/api/#regions-and-endpoints).
 - `KBC_CONFIGID`: The ID of the configuration, or a hash of configuration data if the configuration is not named (e.g., when `configData` is used in an [API call](https://kebooladocker.docs.apiary.io/#reference/run/create-a-job/run-job)).
 - `KBC_CONFIGVERSION`: The version of the configuration, or empty if unnamed (whne `configData` is used in the [API call](https://kebooladocker.docs.apiary.io/#reference/run/create-a-job/run-job)).
 - `KBC_COMPONENTID`: The ID of the component.
 - `KBC_CONFIGROWID`: The ID of the configuration row, if available.
 - `KBC_BRANCHID`: The ID of the [development branch](https://keboola.docs.apiary.io/#reference/development-branches/branches).
 - `KBC_STAGING_FILE_PROVIDER`: Either `aws` or `azure`, depending on the type of [stack](/overview/api/#regions-and-endpoints) the container is running. This value refers to the file storage used during [file import/export operations](https://developers.keboola.com/integrate/storage/api/import-export/).
 - `KBC_PROJECT_FEATURE_GATES`: A comma-separated list of feature gates activated for the current project. Feature gates are considered internal and may change or disappear without notice. We recommend checking with our support team before relying on any feature gates.
 - `KBC_COMPONENT_RUN_MODE`: Either `run` or `debug`. The value `debug` is used when the job is run in debug mode ([learn more](https://developers.keboola.com/extend/component/running/#debugging)). This variable can be helpful, for example, to enable more verbose logging.
 - `KBC_DATA_TYPE_SUPPORT`: Either `authoritative`, `hints`, or `none`:
   - `authoritative`: The component generates columns with data types in the schema node.
   - `hints`: The component generates columns without data types in the schema node.
   - `none`: The component generates only column names in the columns node. 

### Additional Variables for Forwarded Token and Token Details
 
 The following variables are available only if "Forwards token" and "Forwards token details" are
 enabled in the [component configuration](https://components.keboola.com/) (and approved by Keboola):

 - `KBC_PROJECTNAME`: The name of the project in Keboola.
 - `KBC_TOKENID`: The ID of the token running the container.
 - `KBC_TOKENDESC`: A description of the token (e.g., user name or token name).
 - `KBC_TOKEN`: The token itself.
 - `KBC_URL`: The Storage API URL.
 - `KBC_REALUSER`: The user ID provided by [SAML](https://en.wikipedia.org/wiki/Security_Assertion_Markup_Language) authentication.

### Additional Variables for GELF Logger
The following variables are available when the [GELF Logger](/extend/common-interface/logging/#gelf-logger) is enabled in the
[component configuration](https://components.keboola.com/):

- `KBC_LOGGER_ADDR`: The IP address of the GELF server.
- `KBC_LOGGER_PORT`: The port of the GELF server.

## Return Values
The script defined in the Dockerfile's [`ENTRYPOINT` or `CMD`](/extend/component/docker-tutorial/howto/) should provide an exit status. The
following rules apply:

- `exit code = 0`:  The execution is considered successful.
- `exit code = 1`:  The execution fails with a *User Error*.
Both STDOUT and [STDERR](https://en.wikipedia.org/wiki/Standard_streams#Standard_error_.28stderr.29) are sent to Storage API Events.
- `exit code > 1`:  The execution fails with an *Application Error*. Both STDOUT and STDERR are logged internally.

### Modifying Error Behavior
To report all errors as User Errors regardless of the exit code, set `no_application_errors` in the [component configuration](https://components.keboola.com/).
See the [implementation notes](/extend/component/implementation/) for tips on distinguishing between User Errors and Application Errors.


================================================
File: extend/common-interface/folders.md
================================================
---
title: Data Folders Specification
permalink: /extend/common-interface/folders/
---

* TOC
{:toc}

Data folders are one of the [possible channels](/extend/common-interface/) to exchange data between your component and Keboola.

## Root Folder /data/
The `/data/` folder is the root folder for exchanging data.
Your component reads its input from the `/data/in` folder and writes its results to the `/data/out` folder.
Keboola takes care of injecting required tables and files into the input folder and
picking up tables and files generated by your code.
The data folders contain actual data files (tables and files) and metadata.
For each datafile, a [manifest file](/extend/common-interface/manifest-files/) is created.
It contains metadata information (creation time, keys for tables, etc.).

The data folder is always available in the component under the **absolute `/data/` path**. The relative path to the data folder
depends fully on your component code (or Dockerfile). If you want to use a different path (for component development),
**use the [`KBC_DATADIR` environment variable](/extend/common-interface/environment/#environment-variables)**. In production,
this variable will always be set to `/data/`. During development, you can set it to your liking.

To create a data folder sample, use the [Debug API](/extend/component/running/#preparing-the-data-folder) call via the
[Docker Runner API](https://kebooladocker.docs.apiary.io/#reference/debug).
All the resources you need in your component will be provided in a ZIP archive.

The predefined data exchange folder structure is as follows:

    /data/in/tables
    /data/in/files
    /data/out/tables
    /data/out/files

This folder structure is always available to your component.
Do not put arbitrary files in the `/data/` folder as they will be uploaded into the user project
(or cause errors in the output [mapping](https://help.keboola.com/manipulation/transformations/mappings/)).
For working or temporary files, use the `/tmp/` folder. Other directories have 10GB of free space in total.

### Folder /data/in/tables/

The folder contains tables defined in the input [mapping](https://help.keboola.com/manipulation/transformations/mappings/);
they are serialized in the CSV format:

  - string enclosure `"`
  - delimiter `,`
  - no escape character

File names are specified in the input mapping, defaulting to `{tableId}` (a file name can be changed in the UI).
The table metadata is stored in a [manifest file](/extend/common-interface/manifest-files/).

### Folder /data/out/tables/

All output tables from your component must be placed in this folder. The destination table in
[Storage](https://help.keboola.com/storage/) is defined by the following rules (listed in order):

- If `defaultBucket` (see [below](#default-bucket)) is specified, the table will be uploaded to a bucket whose name is created
from the component and configuration names.
- If the output mapping is specified (through the UI, usually) and its **source** matches the physical file name
in the `/data/out/tables` folder, the **destination** is the name of the table in Storage. An output mapping which
cannot be matched to a physical file produces an error (i.e., fulfilling the output mapping is mandatory).
- If a [manifest file](/extend/common-interface/manifest-files/) exists, it can specify the **destination** of
the table in Storage if no output mapping is present.
- If none of the above options are used, the destination is defined by the name of the file
(for example, `out.c-data.my-table.csv` will create a **my-table** table in the **out-c-data** bucket). The file name
must have at least two dots.
- If neither rule can be applied, an error is thrown.

Manifests allow you to process files in the `/data/out` folder without explicitly being defined in the
output mapping. That allows for a flexible and dynamic output mapping where the structure is unknown at the beginning.
Using file names (e.g., `out.c-data.my-table.csv`) for an output mapping is great for saving implementation time
in a simple or POC component.

**Important**: All files in the `/data/out/tables` folder will be uploaded, not only those specified in the output
mapping or manifests.

This is the expected CSV format ([RFC 4180](https://tools.ietf.org/html/rfc4180)):

  - string enclosure `"`
  - delimiter `,`
  - no escape character

A [manifest file](/extend/common-interface/manifest-files/) can specify a different enclosure and delimiter.

#### Default Bucket
If you cannot define a bucket or want to get it automatically, set
the **Default Bucket** for your component in the [Developer Portal](https://components.keboola.com/).

All tables in `/data/out/tables` will then be uploaded to a bucket identified by your
component id (generated when the component was created), configuration id (generated when an end-user adds a new component configuration) and stage (`in` or `out`).
The file name (without the `.csv` suffix) will be used as the table name. The `destination` attributes
in the output mapping and file manifests will be overridden.

**Important**: The `Default Bucket` flag always requires the `config` parameter when creating a job manually using
the API even if the `config` configuration does not exist in Storage.

#### Sliced Tables

Sometimes your component will download the CSV file in slices (chunks). You do not need to manually merge them,
simply put them in a subfolder with the same name you would use for a single file. All files found in the
subfolder are considered slices of the table.

    /data/out/tables/myfile.csv/part01
    /data/out/tables/myfile.csv/part02
    /data/out/tables/myfile.csv.manifest

Sliced files cannot have header rows. They must have their columns specified in the [manifest file](/extend/common-interface/manifest-files/)
or in the output mapping configuration.

The following is an example of specifying columns in the manifest file `/data/out/tables/myfile.csv.manifest`:

    {
        "destination": "in.c-mybucket.table",
        "columns": ["col1", "col2", "col3"]
    }

All files from the folder are uploaded irrespective of their name or extension. They are uploaded
to Storage in parallel and in an undefined order. Use sliced tables in case you want to upload tables [larger than 5GB](https://help.keboola.com/storage/file-uploads/#limits). The slices may be compressed by gzip.
A rule of thumb is that slices are [best around 10-100 MB](https://docs.snowflake.net/manuals/user-guide/data-load-considerations-prepare.html#splitting-large-data-files-before-loading) in size **compressed**.


### Folder /data/in/files/

All files defined in the input mapping are stored in their raw form. File names are numeric and
equal to `{fileId}_{filename}` in Storage. All other information about the files is available
in the [manifest file](/extend/common-interface/manifest-files/).

### Folder /data/out/files/

All files in this folder are uploaded to Storage. File names are preserved, and tags and other upload options
can be specified in the [manifest file](/extend/common-interface/manifest-files/).
Note that all files in the `/data/out/files` folder will be uploaded, not only those specified in the output mapping.

## Exchanging Data via S3
The component may also exchange data with Storage [using Amazon S3](https://docs.aws.amazon.com/s3/index.html).
In this case, the data folders contain only [manifest files](/extend/common-interface/manifest-files/) and
not the actual data. This mode of operation can be enabled by setting the **Staging storage input** option to **AWS S3** in
[component settings](https://components.keboola.com/). If this option is enabled, all the data folders
will contain only manifest files, extended with an additional
[`s3` section](/extend/common-interface/manifest-files/#s3-staging).

**Note**: Exchanging data via S3 is currently only available for input mapping.

## Exchanging Data via ABS
The component may also exchange data with Storage [using Azure Blob Storage](https://azure.microsoft.com/en-us/services/storage/blobs/) (ABS).
In this case, the data folders contain only [manifest files](/extend/common-interface/manifest-files/) and
not the actual data. This mode of operation can be enabled by setting the **Staging storage input** option to **ABS** in
[component settings](https://components.keboola.com/). If this option is enabled, all the data folders
will contain only manifest files, extended with an additional
[`abs` section](/extend/common-interface/manifest-files/#abs-staging).

**Note**: Exchanging data via ABS is currently only available for input mapping.

## Exchanging Data via Database Workspace

*Note: this is a preview feature and may change considerably in the future.*

The component may also exchange data with Storage [using Workspaces](https://keboola.docs.apiary.
io/#reference/workspaces).
This mode of operation can be enabled by setting the **Staging storage input** or **Staging storage output** option
to **Workspace Snowflake**, **Workspace Redshift**, or **Workspace Synapse**. A workspace is an isolated database to 
which data are loaded before the component job is run and unloaded when the job finishes. The workspace is created just before the job starts and is
deleted when the job is terminated.

Using this option will load Storage Tables into the provided storage workspace, but Storage Files will still be 
loaded into the local filesystem like in the standard configuration.

If this option is enabled, the table data folder will contain only manifest files. The actual data will be loaded as
database tables into the workspace database. The `destination` in input and `source` in output refer to database
table names. This mode of operation is useful for components which want to manipulate data using SQL queries.
The component can run arbitrary queries against the database. The database credentials are available in the
[`authorization` section](/extend/common-interface/config-file/#configuration-file-structure) of the configuration file:

{% highlight json %}
{
  "storage": {

  },
  "parameters": {
    ...
  },
  "authorization": {
    "workspace": {
      "host": "database.example.com",
      "warehouse": "test",
      "database": "my-db",
      "schema": "my-schema"
      "user": "john-doe",
      "password": "secret"
    }
  }
}
{% endhighlight %}

Notice that some of the values might be empty for different workspace backends (e.g., Redshift is not using `warehouse`).
They will be always present, though.

When exchanging data via workspace, there are couple of differences to loading data into files:
- Loading to workspaces supports only [storage tables](/storage/tables/), [storage files](/storage/file-uploads/)
are always saved to the directory structure.
- The `days` attribute is not supported for filtering table, use `changed_since` instead.
- [Automatic Incremental Processing](https://help.keboola.com/storage/tables/#automatic-incremental-processing) (also known as Adaptive Input Mapping) is not supported.
- When used for output mapping, the `columns` of the output table **must be** specified, this can be done either in the [output manifest](/extend/common-interface/manifest-files/#dataouttables-manifests) or in the [output mapping](/extend/common-interface/config-file/#output-mapping--headless-csv).

**Note**: Currently only some combinations of input/output staging storage settings are supported:
`local<->local`, `local<->s3`, `workspace-snowflake<->workspace-snowflake`, `workspace-redshift<->workspace-redshift`.

## Exchanging Data via File System Workspace
*Note: this is a preview feature and may change considerably in future.*
*Note: currently only Azure Blob Storage workspaces (abs-workspace) are supported for this type and those only work with Synapse storage backend

The component may also exchange data with a provisioned file workspace (Azure Blob Storage) [using Workspaces](https://keboola.docs.apiary.io/#reference/workspaces).
This mode of operation can be enabled by setting the **Staging storage input** or **Staging storage output** option
to **Workspace ABS**. A filesystem workspace is an isolated file storage to which data are loaded before the component job is run (when staging storage input is set)
and unloaded from when the job finishes (when staging storage output is set).
The workspace is created just before the job starts and is deleted when the job is terminated.

If this option is enabled, the data and the manifests will be loaded to the azure storage blob container under the 
data folder similarly to how it does when using the default [local filesystem](extend/common-interface/folders/#root-folder-data).

### Files
Files are loaded into the workspace as `[file name]/[file ID]`.  For example, if a file 'test.txt' with ID '12345' is in 
the input mapping then the file will appear in the storage blob container with URL `https://[storage_account_name].blob.core.windows.net/[container-name]/data/in/files/test.txt/12345`

### Tables
*Note that this is only available on Synapse storage backend*

Synapse only exports tables as sliced files.
So for example, if you set as table input mapping the table `in.c-main.my-input` as source and `my-input.csv` as 
destination then in the ABS workspace you will find it with the following structure:
- [containerName]/data/in/tables/my-inpupt.csv/[random identifier1].txt
- [containerName]/data/in/tables/my-inpupt.csv/[random identifier2].txt
- [containerName]/data/in/tables/my-inpupt.csv/[random identifier3].txt
  
### Mappings

To sum up, below is a sample storage configuration and where the files are written from and to:

| Direction | Source | Destination |
| --- | --- | --- |
| input | in.c-main.my-table-from-abs-workspace | Many slices like `[abs-workspace-root]/data/in/tables/my-inpupt-table.csv/[random identifier].txt` |
| input | file with tag `my-input-files` named `input-file.txt` | `[abs-workspace-root]/data/in/files/test.txt/12345` |
| output | `[abs-workspace-root]/data/out/tables/my-output-table.csv` | out.c-main.my-table-from-abs-workspace |
| output | `[abs-workspace-root]/data/out/files/my-file.txt` | file `my-file.txt` with tag `uploaded-from-abs-workspace` |

{% highlight json %}
{
  "storage": {
    "input": {
      "tables": [
        {
          "source": "in.c-main.my-table-from-abs-workspace",
          "destination": "my-input-table.csv"
        },
        ...
      ],
      "files": [
        {
          "tags": ["my-input-files"]
        }
      ]
    }
    "output": {
      "tables": [
        {
          "source": "my-output-table.csv",
          "destination": "out.c-main.my-table-from-abs-workspace"
        },
        ...
      ],
      "files": [
        {
          "source": "my-file.txt",
          "tags": ["uploaded-from-abs-workspace"]
        }
      ]
    }
  },
  ...
}
{% endhighlight %}

### Authorization
[`authorization` section](/extend/common-interface/config-file/#configuration-file-structure) of the configuration file:

To connect to the ABS storage workspace you need to use the [SAS connection string](https://docs.microsoft.com/en-us/azure/storage/common/storage-configure-connection-string) which is stored in the authorization section as 
shown below.

{% highlight json %}
{
  "storage": {
    ...
  },
  "parameters": {
    ...
  },
  "authorization": {
    "workspace": {
      "container": "azure-storage-blob-container",
      "connectionString": "azure-storage-blob-SAS-connection-string",
    }
  }
}
{% endhighlight %}


================================================
File: extend/common-interface/index.md
================================================
---
title: Common Interface
permalink: /extend/common-interface/
---

To exchange data between your component and Keboola, use

* a predefined set of input and output [folders](/extend/common-interface/folders) for tables and files,
* a [configuration file](/extend/common-interface/config-file/),
* [environment](/extend/common-interface/environment/) variables and return values.

Optionally, you can use

* [logging](/extend/common-interface/logging),
* [manifest files](/extend/common-interface/manifest-files/) for working with table and file meta-data,
* the [OAuth](/extend/common-interface/oauth/) part of the configuration file, and
* [actions](/extend/common-interface/actions/) for quick synchronous tasks.

In addition to that, [Docker Runner](/extend/docker-runner/) provides tools for
[encryption](/overview/encryption) and [OAuth2 authorization](/extend/common-interface/oauth/).

To quickly get the picture, have a look a [random sample data folder](/extend/data.zip).

### Component Limits
Even though you can define your own limits for your component, all components are also subject to the following service limits:

* Both memory and swap sizes are set to an equal value
* Docker [overlay2](https://docs.docker.com/storage/storagedriver/overlayfs-driver/) size is set to 10 GB

The size allocated for overlay2 is consumed by memory swapping, and all other operations in the component
(for instance, ad hoc module installations); only input and output folders (`/data/`) and `/tmp/` are excluded.
As the swap size cannot be larger than the allocated disk space, we cannot safely increase the memory limit over 8 GB.

If you need more than 8 GB of memory/swap or larger disk space, get in touch with us to discuss possible solutions.


================================================
File: extend/common-interface/logging-development.md
================================================
---
title: Local Development
permalink: /extend/common-interface/logging/development/
---

* TOC
{:toc}

When developing a component which is using GELF logging, you need the GELF server to listen to its messages.
You can use the following two servers:

- Fully fledged official Graylog server - see the [installation guide](http://docs.graylog.org/en/3.1/pages/installation.html); or
- [Mock server](https://github.com/keboola/docs-example-logging-mock-server), based on [PHP server](https://github.com/keboola/gelf-server) or [Node JS Server](https://github.com/wavded/graygelf), for example.

## Using Mock Server with Docker Compose
A convenient way to use the [mock server](https://github.com/keboola/docs-example-logging-mock-server) is using [Docker Compose](https://docs.docker.com/compose/).
That way you can set both your docker image and the log server to run together and set the networking stuff automatically.
Each of our sample repositories mentioned above contains a `docker-compose.yml` sample which you can use to derive your own.
To give an example, the [sample PHP client](https://github.com/keboola/docs-example-logging-php) contains the following
[`docker-compose.yml`](https://github.com/keboola/docs-example-logging-php/blob/master/docker-compose.yml):

{% highlight yaml %}
server:
  image: "quay.io/keboola/docs-example-logging-mock-server:master"
  ports:
    - 12202:12202/tcp
  environment:
    SERVER_TYPE: tcp
client:
  image: "quay.io/keboola/docs-example-logging-php:master"
  links:
    - server:log-server
  environment:
    KBC_LOGGER_ADDR: log-server
    KBC_LOGGER_PORT: 12202
{% endhighlight %}

This instructs docker to create two containers: `server` and `client`. The important part is `links: server:log-server` that links
 the `server` container to the `client` container with the DNS name `log-server`. When you run the above setup (the current
 directory should be the root of the docs-example-logging-php repository) with

    docker compose up

 you will obtain an output like this:

    Creating docsexampleloggingphp_server_1
    Creating docsexampleloggingphp_client_1
    Attaching to docsexampleloggingphp_server_1, docsexampleloggingphp_client_1
    server_1  | array(6) {
    server_1  |   ["version"]=>
    server_1  |   string(3) "1.0"
    server_1  |   ["host"]=>
    server_1  |   string(12) "590227a73319"
    server_1  |   ["short_message"]=>
    server_1  |   string(26) "A sample emergency message"
    server_1  |   ["level"]=>
    server_1  |   int(0)
    server_1  |   ["timestamp"]=>
    server_1  |   float(1464443278.9355)
    server_1  |   ["_some"]=>
    server_1  |   array(1) {
    server_1  |     ["structured"]=>
    server_1  |     string(4) "data"
    server_1  |   }
    server_1  | }
    docsexampleloggingphp_client_1 exited with code 0

This will first start the GELF mock server, then the client. All the example client does is log *A sample emergency message* to the server
and terminate, which is indicated by the message `docsexampleloggingphp_client_1 exited with code 0`. The GELF mock server
just prints every received message to the standard output, so you can see that it indeed received the messages from the client.
The server will keep running until you press CTRL+C and terminate it.

The above setup can be modified simply by changing the `image` of the `client` in the docker-compose.yml so that your own image is used.
Note that the port 12202 in the mock server may be changed by setting `PORT` environment variable in `docker-compose.yml`.

## Using Mock Server Manually
If you want to set things manually, start the [mock server](https://github.com/keboola/docs-example-logging-mock-server) by the following command:

    docker run -e SERVER_TYPE=tcp quay.io/keboola/docs-example-logging-mock-server

This will print

    TCP Server listening on port 12202 .

The command (and server) will keep running. To run your client, you need to know the server's IP address. Therefore run another command line instance and find the container ID with

    docker ps

which will give you

    CONTAINER ID        IMAGE                                              COMMAND                  CREATED             STATUS              PORTS                  NAMES
    6cc7c2af97cb        quay.io/keboola/docs-example-logging-mock-server   "/bin/sh -c ./start.s"   4 seconds ago       Up 2 seconds        12202/tcp, 12202/udp   drunk_hopper

Then find out the IP address of the running container, for instance by running docker inspect

{% raw %}
    docker inspect --format '{{ .NetworkSettings.IPAddress }}' 6cc
{% endraw %}

which will give you, for example:

    172.17.0.2

(Note: use double quotes in the above command when running on Windows)
You can now start your client using that address as `KBC_LOGGER_ADDR` environment variable together with (`KBC_LOGGER_PORT` set to 12202), for example:

    docker run -e KBC_LOGGER_ADDR=172.17.0.2 -e KBC_LOGGER_PORT=12202 quay.io/keboola/docs-example-logging-php:master

You will now see messages printed in the output of your server.


================================================
File: extend/common-interface/logging.md
================================================
---
title: Logging Specification
permalink: /extend/common-interface/logging/
---

* TOC
{:toc}

There are two main, mutually exclusive, ways in which your component can display events Keboola end-users:

1. Using [standard output and standard error](https://en.wikipedia.org/wiki/Standard_streams)
2. Using [Graylog GELF](http://docs.graylog.org/en/3.1/pages/gelf.html) compatible logger

Using the standard output option requires **no extra work** from you or your component.
You just print all informational messages to standard output and all error messages to standard error.
These will be forwarded to Storage Events as informational or error messages. See
[implementation notes](/extend/component/implementation/) for best practices in logging.

Using a [GELF](http://docs.graylog.org/en/3.1/pages/gelf.html) compatible logger requires implementing or including
such a logger in your component. However, it offers much **greater flexibility**: you can send different
kinds of messages (such as error, informational, warning, debug), and they can contain additional
structured information (not only a plain text string).

## Standard Output and Standard Error
By default -- unless you have turned on [GELF logging](/extend/common-interface/logging/#gelf-logger) in the
[component configuration](https://components.keboola.com/),
[Docker Runner](/extend/docker-runner) listens to [STDOUT](https://en.wikipedia.org/wiki/Standard_streams#Standard_output_.28stdout.29)
and [STDERR](https://en.wikipedia.org/wiki/Standard_streams#Standard_error_.28stderr.29)
of the component and forwards the STDOUT content live to [Storage API Events](https://keboola.docs.apiary.io/#reference/events)
(log level `info`). The content of STDERR is collected and added (if not empty) as the last event of the job with level `error`.
The events are displayed in a [Job detail](https://help.keboola.com/management/jobs/).

The entire output from a component is filter for sensitive values. The [Runner](/extend/docker-runner/)
keeps track of all encrypted values and if it encounters them in the component output, it replaces
them by `[hidden]` placeholder. This prevents accidental leaking of sensitive information for
example in exception traces.

## GELF Logger
[GELF](http://docs.graylog.org/en/3.1/pages/gelf.html) is a log format allowing you to
send [structured](http://docs.graylog.org/en/3.1/pages/gelf.html#gelf-payload-specification) event messages.
The messages can be sent over several transports and you can specify whether they will be silenced or displayed based on their level.

*Note: The size of the messages is limited. Sending a message larger than 200KB will cause the component job to fail.*

### Setting Up
If you turn on GELF logging in the [component configuration](https://components.keboola.com/),
our [Docker Runner](/extend/docker-runner/) will listen
for messages on the **transport** you specify ([UDP](https://en.wikipedia.org/wiki/User_Datagram_Protocol),
[TCP](https://en.wikipedia.org/wiki/Transmission_Control_Protocol) and
[HTTP](https://en.wikipedia.org/wiki/Hypertext_Transfer_Protocol) are supported).
We suggest using TCP as it offers a nice compromise between transport overhead and reliability, but the final choice is up to you.
If you choose UDP as a transport, make sure that there is a little delay between your component start
and the first message sent (about 1s) to give the network sockets some time to initialize.

Additionally, you can set the visibility of each event message as follows:

- `none` -- Message is ignored entirely.
- `camouflage` -- Generic error message is shown to the end-user instead of the real message content; the full message is logged internally.
- `normal` -- Event message (GELF `short_message` field) is shown to the end-user; the full message is logged internally.
- `verbose` -- Full message is shown to the user including GELF additional fields.

Default settings for message visibilities:

[Keboola Level](https://github.com/php-fig/fig-standards/blob/master/accepted/PSR-3-logger-interface.md#5-psrlogloglevel) | Gelf Log Method | [Syslog Level](https://en.wikipedia.org/wiki/Syslog#Severity_level) | Default Keboola Verbosity
100 | `debug()` | 7 | none
200 | `info()`  | 6 | normal
250 | `notice()` | 5 | normal
300 | `warning()` | 4 | normal
400 | `error()` | 3 | normal
500 | `critical()` | 2 | camouflage
550 | `alert()` | 1 | camouflage
600 | `emergency()` | 0 | camouflage

### Examples
Since GELF is sort of a standard format for structured logs, there are a [number of libraries](https://marketplace.graylog.org/addons?kind=gelf)
available for client implementation. The following examples show how to use the GELF logger in some common languages.
Always use the `KBC_LOGGER_ADDR` and `KBC_LOGGER_PORT` environment variables in your client,
which will be injected into your component by our Docker Runner.

**Important:** Never rely on the default logger settings.

When developing your component, you may want to use the [GELF server for development](/extend/common-interface/logging/development/) to
test the logging.

#### PHP
For PHP, use the official [GELF client](https://github.com/bzikarsky/gelf-php) library. To install it, use

    composer require graylog2/gelf-php

Then test that logging works with this simple script:


{% highlight php %}
<?php

require("vendor/autoload.php");

$transport = new Gelf\Transport\TcpTransport(getenv('KBC_LOGGER_ADDR'), getenv('KBC_LOGGER_PORT'));
$logger = new \Gelf\Logger($transport);

$logger->emergency("A sample emergency message", ["some" => ["structured" => "data"]]);
{% endhighlight %}

You can see the complete component in
a [sample repository](https://github.com/keboola/docs-example-logging-php). For other transports, use the
`UdpTransport` or `HttpTransport` class (AMQP transport is not supported yet). For additional examples on using the library,
see its [official documentation](https://github.com/bzikarsky/gelf-php).

#### Python
For Python, we strongly suggest using the prepared [Component package](/extend/component/implementation/python/#using-keboola-python-package) which takes care of the setup automatically.

If you want to set a GELF logger yourself, you need to choose from [a number of libraries](https://marketplace.graylog.org/addons?kind=gelf&tag=python) available. For example, the [logging-gelf library](https://pypi.org/project/logging-gelf/). To install it, use

    pip3 install logging_gelf

Then test that logging works with this simple script:

{% highlight python %}
import logging_gelf.handlers
import logging_gelf.formatters
import logging
import os

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger()
logging_gelf_handler = logging_gelf.handlers.GELFTCPSocketHandler(host=os.getenv('KBC_LOGGER_ADDR'), port=int(os.getenv('KBC_LOGGER_PORT')))
logging_gelf_handler.setFormatter(logging_gelf.formatters.GELFFormatter(null_character=True))
logger.addHandler(logging_gelf_handler)

# remove default logging to stdout
logger.removeHandler(logger.handlers[0])

logging.critical('A sample emergency message')
{% endhighlight %}

Due to the nature of Python logging, only [some error levels](https://docs.python.org/3.8/library/logging.html#logging-levels) are
permitted.

#### Node.js
There are a number of libraries available for [NodeJS](https://marketplace.graylog.org/addons?kind=gelf&tag=nodejs).
For example, the [GrayGelf library](https://github.com/wavded/graygelf).

    npm install graygelf

Then test that logging works with this simple script:

{% highlight js %}
var log = require('graygelf')({
  host: process.env.KBC_LOGGER_ADDR,
  port: process.env.KBC_LOGGER_PORT
})

log.info('hello', 'world')
log.info.a('short', 'full', { foo: 'bar' })
{% endhighlight %}

Note that the library supports only the UDP transport.


================================================
File: extend/common-interface/manifest-files.md
================================================
---
title: Manifest Files Specification
permalink: /extend/common-interface/manifest-files/
---

A manifest file contains additional information about tables and files injected to the
[`/data/in` folders](/extend/common-interface/folders/).
It also provides a way to specify options for tables and files transferred back to Storage from `/data/out`
folders. Manifest files have the `.manifest` suffix to the original file.

All files in `/data/in` have the manifest file generated by us. For files generated by your code
in `/data/out`, the manifest file **is recommended**. Also, keep in mind that all manifests have a lower priority
than input and output mapping.

## Format

The format of the manifest file is always *JSON*. The manifest
file always has the `.manifest` extension. This applies to files with multiple extensions as well, so the following
filenames are expected:

| Data File Name | Manifest File Name       |
|----------------|--------------------------|
| myfile         | myfile.manifest          |
| myfile.csv     | myfile.csv.manifest      |
| myfile.csv.gz  | myfile.csv.gz.manifest   |


================================================
File: extend/common-interface/oauth.md
================================================
---
title: OAuth Interface Specification
permalink: /extend/common-interface/oauth/
---

* TOC
{:toc}

[OAuth Broker API](https://oauthapi3.docs.apiary.io) integration provides a safe way to retrieve stored authorizations.

When you are building a component that communicates with a 3rd party API and that API authorizes using OAuth,
Keboola stores the users' credentials/access tokens in the OAuth Broker API. They are revealed and
decrypted only for a target component and project. End-users can be assured that their authorized access will not leak.

*Note: This feature must be enabled by our [support](mailto:support@keboola.com).*

## Initialize
Create a configuration for the given component and project in the OAuth Broker API.
The `OAUTH_API_ID` is the id provided when storing authorization via the OAuth Broker API.
Set `"version": 3` to use the latest OAuth Broker API. The old OAuth V2 API is deprecated but still usable.  

{% highlight json %}
{

    "storage": { ... },
    "parameters": { ... },
    "authorization": {
        "oauth_api": {
            "id": "{OAUTH_API_ID}"
            "version": 3
        }
    }
}
{% endhighlight %}

## Authorize
[Docker Runner](/extend/docker-runner/) then retrieves, decrypts and injects the credentials to the
configuration file in the `authorization.oauth_api.credentials` attribute.

{% highlight json %}
{
    "storage": { ... },
    "parameters": { ... },
    "authorization": {
        "oauth_api": {
            "id": "{OAUTH_API_ID}",
            "version": 3,
            "credentials": {
                "id": "main",
                "authorizedFor": "Myself",
                "creator": {
                    "id": "1234",
                    "description": "me@keboola.com"
                },
                "created": "2016-01-31 00:13:30",
                "oauthVersion": "2.0",
                "appKey": "w51u7j30oghe412",
                "#data": "KBC::Encrypted==ENCODEDSTRING==",
                "#appSecret": "KBC::Encrypted==ENCODEDSTRING=="
            }
        }
    }
}
{% endhighlight %}

The `authorization.oauth_api.credentials.#data` configuration node stores the response from
the authorized API as a raw string. Parse the string accordingly, as OAuth Broker API has intentionally
no knowledge about the authorized APIs.

**Important:** None of the [sandbox API calls](/extend/component/running/)
decrypt the `authorization.oauth_api.credentials.#data` and `authorization.oauth_api.credentials.#appSecret` keys.

## Credentials Injection

If you want to bypass the OAuth Broker API integration, you can paste all required credential parameters in the configuration directly.
Fields requiring encryption will be encrypted and decrypted as usual. That means that you can save the following configuration
via the [configuration API](/integrate/storage/api/configurations/).

{% highlight json %}
{
    "storage": { ... },
    "parameters": { ... },
    "authorization": {
        "oauth_api": {
            "credentials": {
                "#data": "{\"oauth_token\":\"xx\",\"oauth_token_secret\":\"xxx\",\"x_auth_expires\":\"0\"}",
                "appKey": "...",
                "#appSecret": "..."
            }
        }
    }
}
{% endhighlight %}

This comes in very handy for quick component iterations and for testing whether your component works before having the OAuth support enabled.


================================================
File: extend/common-interface/manifest-files/in-files-abs-staging.md
================================================
---
title: ABS Staging
permalink: /extend/common-interface/manifest-files/in-files-abs-staging/
---

When using [Azure Blob Storage for direct data exchange](/extend/common-interface/folders/#exchanging-data-via-abs),
the manifest files in the component’s working directory will contain an additional `abs` section with
credentials for downloading the actual file data.

{% highlight json %}
{
    "id": "in.c-docker-demo.data",
    ...
    "abs": {
        "is_sliced": true,
        "region": "us-east-1",
        "container": "exp-2-export-7647-627703071-in-c-docker-test-test",
        "name": "627703071.csv.gzmanifest",
        "credentials": {
            "sas_connection_string": "BlobEndpoint=https://kbcfsdxcgtsezztoqc.blob.core.windows.net;SharedAccessSignature=sv=2017-11-09&sr=c&st=2020-08-27T08:42:08Z&se=2020-08-27T20:42:08Z&sp=rl&sig=UJW4DPh%2Baaaaaaaaaa",
            "expiration": "2020-08-27T22:42:08+0200"
        }
    }
}
{% endhighlight %}

If the file is sliced and you need to merge it into a single file, read through the guide to
[working with sliced files](/integrate/storage/api/import-export/#working-with-sliced-files).
In that case, the `name` points to another manifest, which contains a list of sliced files.

Note: Exchanging data via Azure ABS is currently available only for input mapping.


================================================
File: extend/common-interface/manifest-files/in-files-manifests.md
================================================
---
title: /data/in/files manifests
permalink: /extend/common-interface/manifest-files/in-files-manifests/
---

#### `/data/in/files` manifests

An input file manifest stores metadata about a downloaded file from Storage Files to the component’s working directory.

{% highlight json %}
{
  "id": 75807657,
  "created": "2015-01-14T00:47:00+0100",
  "is_public": false,
  "is_sliced": false,
  "is_encrypted": true,
  "name": "fooBar.jpg",
  "size_bytes": 563416,
  "tags": [
    "tag1",
    "tag2"
  ],
  "max_age_days": 15
}
{% endhighlight %}

================================================
File: extend/common-interface/manifest-files/in-files-s3-staging.md
================================================
---
title: S3 Staging
permalink: /extend/common-interface/manifest-files/in-files-s3-staging/
---

When using [AWS S3 for direct data exchange](/extend/common-interface/folders/#exchanging-data-via-s3),
the manifest files in the component’s working directory will contain an additional `s3` section with
credentials for downloading the actual file data.

{% highlight json %}
{
    "id": "in.c-docker-demo.data",
    ...
    "s3": {
        "isSliced": true,
        "region": "us-east-1",
        "bucket": "kbc-sapi-files",
        "key": "exp-2/1581/table-exports/in/c-docker-test/test/243100072.csv.gzmanifest",
        "credentials": {
            "access_key_id": "ASI...CDQ",
            "secret_access_key": "tCE..I+T",
            "session_token": "Ago...POP"
        }
    }
}
{% endhighlight %}

If the file is sliced and you need to merge it into a single file, read through the guide to
[working with sliced files](/integrate/storage/api/import-export/#working-with-sliced-files).
In that case, the `key` points to another manifest, which contains a list of sliced files.

Note: Exchanging data via AWS S3 is currently available only for input mapping.


================================================
File: extend/common-interface/manifest-files/in-tables-manifests.md
================================================
---
title: /data/in/tables manifests
permalink: /extend/common-interface/manifest-files/in-tables-manifests/
---

An input table manifest stores metadata about a downloaded table from Storage Tables to the component’s working directory.
For example, a table
with the ID `in.c-docker-demo.data` will be downloaded into
`/in/tables/in.c-docker-demo.data.csv` (unless stated otherwise in the
[input mapping](/extend/common-interface/config-file/) and a manifest file
'/in/tables/in.c-docker-demo.data.csv.manifest' will be created with the following
contents:

{% highlight json %}
{
  "id": "in.c-docker-demo.data",
  "uri": "https://connection.keboola.com//v2/storage/tables/in.c-docker-demo.data",
  "name": "data",
  "primary_key": [],
  "created": "2015-01-25T01:35:14+0100",
  "last_change_date": "2015-01-25T01:35:14+0100",
  "last_import_date": "2015-01-25T01:35:14+0100",
  "table_metadata": {
    "KBC.createdBy.component.id": "keboola.python-transformation",
    "KBC.createdBy.configuration.id": "123456",
  },
  "column_metadata": {
    "id": [],
    "name": [],
    "text": []
  }
}
{% endhighlight %}

The `name` node refers to the name of the component configuration.
The `metadata` and `column_metadata` fields contains
[Metadata](https://keboola.docs.apiary.io/#reference/metadata) for the table and its columns.

================================================
File: extend/common-interface/manifest-files/out-files-manifests.md
================================================
---
title: /data/out/files manifests
permalink: /extend/common-interface/manifest-files/out-files-manifests/
---

#### `/data/out/files` manifests

An output file manifest sets options for transferring a file to Storage. The following example lists available
manifest fields; all of them are optional.

{% highlight json %}
{
  "is_permanent": true,
  "is_encrypted": true,
  "notify": false,
  "tags": [
    "image",
    "pie-chart"
  ]
}
{% endhighlight %}

These parameters can be used (taken from [Storage API File Import](https://keboola.docs.apiary.io/#reference/files/upload-file/create-file-resource)):

- If `is_permanent` is false, the file will be automatically deleted after 15 days.
- When `notify` is true, the members of the project will be notified that a file has been uploaded to the project.


================================================
File: extend/common-interface/manifest-files/out-tables-manifests-native-types.md
================================================
---
title: /data/out/tables manifests with Native Types
permalink: /extend/common-interface/manifest-files/out-tables-manifests-native-types/
---

Native Types provide a structured way for components to define their handling of data types, referred to as “Native Types.”

The level of type handling is specified by the dataTypeSupport property, which can take one of three values:
- Authoritative: The component reliably enforces specific data types.
- Hints: The component provides type suggestions that may not always be reliable.
- None: Represents the legacy state with no explicit type handling.

This design overcomes limitations in current settings, where all components automatically produce typed tables when a project switches to Native Types. For instance, Data Sources that output unreliable type hints (e.g., an int column containing values like N/A) can now explicitly signal their limitations, reducing downstream issues.

An output table manifest sets options for transferring a table to Storage. The following examples list available
manifest fields; **all of them are optional**. The `destination` field overrides the table name generated
from the file name; it can (and commonly is) overridden by the end-user configuration.

{% highlight json %}
{
    "destination": "out.c-main.Leads",
    "incremental": true,
    "delimiter": "\t",
    "enclosure": "\"",
    "manifest_type": "output",
    "has_header": true,
    "description": "Best table",
    "table_metadata": ...
    "schema": ...
}
{% endhighlight %}

The `table_metadata` fields allow you to set
[Metadata](https://keboola.docs.apiary.io/#reference/metadata) for the table.
The `table_metadata` field corresponds to the [Table Metadata API call](https://keboola.docs.apiary.io/#reference/metadata/table-metadata/create-or-update).
The `key` and `value` of the object are passed directly to the API; the `provider` value is
filled by the Id of the running component (e.g., `keboola.ex-db-snowflake`).

{% highlight json %}
{
    ...
    "table_metadata": {
        "something else": "a value"
    }
}
{% endhighlight %}

Additionally, the following options will cause the specified rows to be deleted from the source table before the new
table is imported. See an [example](/extend/common-interface/config-file/#output-mapping---delete-rows).
Using this option makes sense only with [incremental loads](/extend/generic-extractor/incremental/).

{% highlight json %}
{
    ...
    "delete_where": [
        {
            "where_filters": [
                {
                    "column": "column name",
                    "operator": "eq",
                    "values_from_set": ["value1", "value2"]
                }
            ]
        }
    ]
}
{% endhighlight %}

The `schema` [optional] field allow you to create a table with Native Data Types columns.
Each object in the `schema` array represents one column:
- The `name` [required] field specifies the column name.
- The `data_type` [optional] field defines the data type for different [storage backends](https://help.keboola.com/storage/#storage-data), referred to as "Native Types".
  - The `base` [required] type is always required and can have values specified in the [Base Types documentation](https://help.keboola.com/storage/tables/data-types/#base-types). 
  - Other types like Snowflake and BigQuery are optional and allows you to specify settings for a particular database backend.
- The `nullable` [optional] field indicates if the column can be null.
- The `primary_key` [optional] field specifies if the column is a primary key.
- The `description` [optional] field provides a description of the column.
- The `metadata` [optional] field allows setting additional metadata for the column.

{% highlight json %}
{
    "schema": [
        {
            "name": "id",
            "data_type": {
                "base": {
                    "type": "INTEGER",
                    "length": "11",
                    "default": "123"
                },
                "snowflake": {
                    "type": "GEOMETRY",
                    "length": "123,123,4455",
                    "default": "POINT(1 1)"
                },
                "bigquery": {
                    "type": "VARCHAR",
                    "length": "123",
                    "default": null
                }
            },
            "nullable": false,
            "primary_key": true,
            "description": "Optional description of the column",
            "metadata": {
                "KBC.someColumnMetadata": "value1"
                "KBC.someOther": "value2"
            }
        }
    ]
}
{% endhighlight %}

## Base Types
Source data types are mapped to a destination using a **base type**. The current base types are
[`STRING`](#string), [`INTEGER`](#integer), [`NUMERIC`](#numeric), [`FLOAT`](#float), [`BOOLEAN`](#boolean),
[`DATE`](#date), and [`TIMESTAMP`](#timestamp). This means that, for example, a MySQL extractor
may store the value `BIGINT` as a type of column; that type maps to the `INTEGER` base type. When the Snowflake writer consumes this value, it will
read the base type `INTEGER` and choose a corresponding type for Snowflake, which happens to be also `INTEGER`.
This ensures high interoperability between the components. Please take a look at the [conversion table below](#data-type-conversions).

View the extracted data types in the storage tables detail:

{: .image-popup}
![Screenshot - View Column Data Type](/extend/common-interface/manifest-files/column-data-type.png)

You can also override the data type:

{: .image-popup}
![Screenshot - Set Column Data Type](/extend/common-interface/manifest-files/column-data-type-override.png)

When you use the table (e.g., in the Snowflake writer), you'll see the data type you have configured:

{: .image-popup}
![Screenshot - Set Column Data Type](/extend/common-interface/manifest-files/column-data-type-use.png)

The data is converted only when writing or copying (e.g., to a transformation or a writer).
That means that you can extract an *integer* column, mark it as a *timestamp* in storage and write it as
an *integer* into a target database (though you'll be offered to write it as a timestamp).

You access both the source and base data type through the corresponding [API](https://keboola.docs.apiary.io/#reference/tables/manage-tables/table-detail).

## Nullable Conversion
Nullable conversion, which transforms an empty string originating from data into a null value, refers to the process where a textual value consisting solely of an empty string `""` is replaced with the value null.

## Data Type Conversions
As described above, the **source data type** is converted to a **base data type** stored in metadata storage. The base type is then converted to the **target data type**. The following tables show mappings for each base type. The mapping
causes possible information loss (e.g., assigning `SMALLINT` to `INTEGER`). To minimize this, we also keep track of the data type
size and transfer that if possible. For example, a `SMALLINT` column would be stored as base type `INTEGER` with size `2`. If the target database supports integer sizes, you will be offered to set the type in the target database as `INTEGER(2)`.

### STRING
Base type `STRING` represents any textual type; both `CHARACTER VARYING` (or `VARCHAR`) and `TEXT` types are included.
Also, the string base type is used for any other unrecognized type on input. It means that the
*source type* column is **not an exhaustive list** in the following table. It's a list of suitable string types converted to a string. All
other unknown types are converted to a string as well.

<table>
<tr>
    <th>Source</th>
    <th>Source Type</th>
    <th>Base Type</th>
    <th>Target Type</th>
    <th>Target</th>
</tr>
<tr>
    <th rowspan='4'>Generic</th>
    <td>char</td>
    <td rowspan='35'>STRING</td>
    <td rowspan='4' colspan='2'>N/A</td>
</tr>
<tr>
    <td>character varying</td>
</tr>
<tr>
    <td>text</td>
</tr>
<tr>
    <td>varchar</td>
</tr>
<tr>
    <td colspan='2'></td>
    <td>STRING</td>
    <th>Hive</th>
</tr>
<tr>
    <td colspan='2'></td>
    <td>STRING</td>
    <th>Impala</th>
</tr>
<tr>
    <td colspan='2'></td>
    <td>TEXT</td>
    <th>MS SQL Server</th>
</tr>
<tr>
    <th rowspan='3'>MySQL</th>
    <td>CHAR</td>
    <td rowspan='3'>VARCHAR</td>
    <th rowspan='3'>MySQL</th>
</tr>
<tr>
    <td>TEXT</td>
</tr>
<tr>
    <td>VARCHAR</td>
</tr>
<tr>
    <td colspan='2'></td>
    <td>VARCHAR2</td>
    <th>Oracle</th>
</tr>
<tr>
    <td colspan='2'></td>
    <td>VARCHAR</td>
    <th>PostgreSQL</th>
</tr>
<tr>
    <th rowspan='8'>Redshift</th>
    <td>BPCHAR</td>
    <td rowspan='8'>VARCHAR</td>
    <th rowspan='8'>Redshift</th>
</tr>
<tr>
    <td>CHAR</td>
</tr>
<tr>
    <td>CHARACTER</td>
</tr>
<tr>
    <td>CHARACTER VARYING</td>
</tr>
<tr>
    <td>NCHAR</td>
</tr>
<tr>
    <td>NVARCHAR</td>
</tr>
<tr>
    <td>TEXT</td>
</tr>
<tr>
    <td>VARCHAR</td>
</tr>
<tr>
    <td colspan='2'></td>
    <td>VARCHAR</td>
    <th>SiSense</th>
</tr>
<tr>
    <th rowspan='7'>Snowflake</th>
    <td>BINARY</td>
    <td rowspan='7'>VARCHAR</td>
    <th rowspan='7'>Snowflake</th>
</tr>
<tr>
    <td>CHAR</td>
</tr>
<tr>
    <td>CHARACTER</td>
</tr>
<tr>
    <td>STRING</td>
</tr>
<tr>
    <td>TEXT</td>
</tr>
<tr>
    <td>VARBINARY</td>
</tr>
<tr>
    <td>VARCHAR</td>
</tr>
<tr>
    <th rowspan='6'>Synapse</th>
    <td>BINARY</td>
    <td rowspan='6'>NVARCHAR</td>
    <th rowspan='6'>Synapse</th>
</tr>
<tr>
    <td>CHAR</td>
</tr>
<tr>
    <td>NCHAR</td>
</tr>
<tr>
    <td>NVARCHAR</td>
</tr>
<tr>
    <td>VARBINARY</td>
</tr>
<tr>
    <td>VARCHAR</td>
</tr>
<tr>
    <td colspan='2'></td>
    <td>VARCHAR</td>
    <th>Thoughtspot</th>
</tr>
<tr>
    <th>Source</th>
    <th>Source Type</th>
    <th>Base Type</th>
    <th>Target Type</th>
    <th>Target</th>
</tr>
</table>

### INTEGER
The `INTEGER` base type represents data types for whole numbers.

<table>
<tr>
    <th>Source</th>
    <th>Source Type</th>
    <th>Base Type</th>
    <th>Target Type</th>
    <th>Target</th>
</tr>
<tr>
    <th rowspan='12'>Generic</th>
    <td>bigint</td>
    <td rowspan='42'>INTEGER</td>
    <td rowspan='12' colspan='2'></td>    
</tr>
<tr>
    <td>bigserial</td>
</tr>
<tr>
    <td>mediumint</td>
</tr>
<tr>
    <td>smallint</td>
</tr>
<tr>
    <td>int</td>
</tr>
<tr>
    <td>int2</td>
</tr>
<tr>
    <td>int4</td>
</tr>
<tr>
    <td>int64</td>
</tr>
<tr>
    <td>int8</td>
</tr>
<tr>
    <td>integer</td>
</tr>
<tr>
    <td>serial8</td>
</tr>
<tr>
    <td>tinyint</td>
</tr>
<tr>
    <td colspan='2'></td>
    <td>INT</td>
    <th>Hive</th>
</tr>
<tr>
    <td colspan='2'></td>
    <td>INT</td>
    <th>Impala</th>
</tr>
<tr>
    <td colspan='2'></td>
    <td>BIGINT</td>
    <th>MS SQL</th>
</tr>
<tr>
    <th rowspan='6'>MySQL</th>
    <td>BIGINT</td>
    <td rowspan='6'>INTEGER</td>
    <th rowspan='6'>MySQL</th>
</tr>
<tr>
    <td>INT</td>
</tr>
<tr>
    <td>INTEGER</td>
</tr>
<tr>
    <td>MEDIUMINT</td>
</tr>
<tr>
    <td>SMALLINT</td>
</tr>
<tr>
    <td>TINYINT</td>
</tr>
<tr>
    <td colspan='2'></td>
    <td>N/A</td>
    <th>Oracle</th>
</tr>
<tr>
    <td colspan='2'></td>
    <td>INTEGER</td>
    <th>Postgres</th>
</tr>
<tr>
    <th rowspan='7'>Redshift</th>
    <td>BIGINT</td>
    <td rowspan='7'>INTEGER</td>
    <th rowspan='7'>Redshift</th>
</tr>
<tr>
    <td>INT</td>
</tr>
<tr>
    <td>INT2</td>
</tr>
<tr>
    <td>INT4</td>
</tr>
<tr>
    <td>INT8</td>
</tr>
<tr>
    <td>INTEGER</td>
</tr>
<tr>
    <td>SMALLINT</td>
</tr>
<tr>
    <td colspan='2'></td>
    <td>BIGINT</td>
    <th>SiSense</th>
</tr>
<tr>
    <th rowspan='6'>Snowflake</th>
    <td>BIGINT</td>
    <td rowspan='6'>INTEGER</td>
    <th rowspan='6'>Snowflake</th>
</tr>
<tr>
    <td>BYTEINT</td>
</tr>
<tr>
    <td>INT</td>
</tr>
<tr>
    <td>INTEGER</td>
</tr>
<tr>
    <td>SMALLINT</td>
</tr>
<tr>
    <td>TINYINT</td>
</tr>
<tr>
    <th rowspan='4'>Synapse</th>
    <td>BIGINT</td>
    <td rowspan='4'>INT</td>
    <th rowspan='4'>Synapse</th>
</tr>
<tr>
    <td>INT</td>
</tr>
<tr>
    <td>SMALLINT</td>
</tr>
<tr>
    <td>TINYINT</td>
</tr>
<tr>
    <td colspan='2'></td>
    <td>INT</td>
    <th>Thoughtspot</th>
</tr>
<tr>
    <th>Source</th>
    <th>Source Type</th>
    <th>Base Type</th>
    <th>Target Type</th>
    <th>Target</th>
</tr>
</table>

### NUMERIC
The `NUMERIC` base type represents [fixed-point](https://en.wikipedia.org/wiki/Fixed-point_arithmetic) fractional numbers
(`real`, `numeric` or `decimal` data types).

<table>
<tr>
    <th>Source</th>
    <th>Source Type</th>
    <th>Base Type</th>
    <th>Target Type</th>
    <th>Target</th>
</tr>
<tr>
    <th rowspan='7'>Generic</th>
    <td>dec</td>
    <td rowspan='25'>NUMERIC</td>
    <td rowspan='7' colspan='2'></td>    
</tr>
<tr>
    <td>decimal</td>
</tr>
<tr>
    <td>fixed</td>
</tr>
<tr>
    <td>money</td>
</tr>
<tr>
    <td>number</td>
</tr>
<tr>
    <td>numeric</td>
</tr>
<tr>
    <td>smallmoney</td>
</tr>
<tr>
    <td colspan='2'></td>
    <td>DECIMAL</td>
    <th>Hive</th>
</tr>
<tr>
    <td colspan='2'></td>
    <td>DECIMAL</td>
    <th>Impala</th>
</tr>
<tr>
    <td colspan='2'></td>
    <td>DECIMAL</td>
    <th>MS SQL Server</th>
</tr>
<tr>
    <th rowspan='4'>MySQL</th>
    <td>DEC</td>
    <td rowspan='4'>NUMERIC</td>
    <th rowspan='4'>MySQL</th>
</tr>
<tr>
    <td>DECIMAL</td>
</tr>
<tr>
    <td>FIXED</td>
</tr>
<tr>
    <td>NUMERIC</td>
</tr>
<tr>
    <td colspan='2'></td>
    <td>NUMBER</td>
    <th>Oracle</th>
</tr>
<tr>
    <td colspan='2'></td>
    <td>NUMERIC</td>
    <th>PostgreSQL</th>
</tr>
<tr>
    <th rowspan='2'>Redshift</th>
    <td>DECIMAL</td>
    <td rowspan='2'>NUMERIC</td>
    <th rowspan='2'>Redshift</th>
</tr>
<tr>
    <td>NUMERIC</td>
</tr>
<tr>
    <td colspan='2'></td>
    <td>DECIMAL</td>
    <th>SiSense</th>
</tr>
<tr>
    <th rowspan='3'>Snowflake</th>
    <td>DECIMAL</td>
    <td rowspan='3'>NUMBER</td>
    <th rowspan='3'>Snowflake</th>
</tr>
<tr>
    <td>NUMBER</td>
</tr>
<tr>
    <td>NUMERIC</td>
</tr>
<tr>
    <th rowspan='2'>Synapse</th>
    <td>NUMERIC</td>
    <td rowspan='2'>NUMERIC</td>
    <th rowspan='2'>Synapse</th>
</tr>
<tr>
    <td>DECIMAL</td>
</tr>
<tr>
    <td colspan='2'></td>
    <td>N/A</td>
    <th>Thoughtspot</th>
</tr>
<tr>
    <th>Source</th>
    <th>Source Type</th>
    <th>Base Type</th>
    <th>Target Type</th>
    <th>Target</th>
</tr>
</table>

### FLOAT
The `FLOAT` base type represents [floating-point](https://en.wikipedia.org/wiki/Floating_point) fractional numbers
(`float` or `double` data types).

<table>
<tr>
    <th>Source</th>
    <th>Source Type</th>
    <th>Base Type</th>
    <th>Target Type</th>
    <th>Target</th>
</tr>
<tr>
    <th rowspan='10'>Generic</th>
    <td>binary_double</td>
    <td rowspan='34'>FLOAT</td>
    <td rowspan='10' colspan='2'></td>    
</tr>
<tr>
    <td>binary_float</td>
</tr>
<tr>
    <td>double</td>
</tr>
<tr>
    <td>double precision</td>
</tr>
<tr>
    <td>d_float</td>
</tr>
<tr>
    <td>float</td>
</tr>
<tr>
    <td>float4</td>
</tr>
<tr>
    <td>float8</td>
</tr>
<tr>
    <td>quad</td>
</tr>
<tr>
    <td>real</td>
</tr>
<tr>
    <td colspan='2'></td>
    <td>FLOAT</td>
    <th>Hive</th>
</tr>
<tr>
    <td colspan='2'></td>
    <td>FLOAT</td>
    <th>Impala</th>
</tr>
<tr>
    <td colspan='2'></td>
    <td>FLOAT</td>
    <th>MS SQL Server</th>
</tr>
<tr>
    <th rowspan='4'>MySQL</th>
    <td>DOUBLE</td>
    <td rowspan='4'>FLOAT</td>
    <th rowspan='4'>MySQL</th>
</tr>
<tr>
    <td>DOUBLE PRECISION</td>
</tr>
<tr>
    <td>FLOAT</td>
</tr>
<tr>
    <td>REAL</td>
</tr>
<tr>
    <td colspan='2'></td>
    <td>N/A</td>
    <th>Oracle</th>
</tr>
<tr>
    <td colspan='2'></td>
    <td>REAL</td>
    <th>PostgreSQL</th>
</tr>
<tr>
    <th rowspan='5'>Redshift</th>
    <td>DOUBLE PRECISION</td>
    <td rowspan='5'>FLOAT</td>
    <th rowspan='5'>Redshift</th>
</tr>
<tr>
    <td>FLOAT</td>
</tr>
<tr>
    <td>FLOAT4</td>
</tr>
<tr>
    <td>FLOAT8</td>
</tr>
<tr>
    <td>REAL</td>
</tr>
<tr>
    <td colspan='2'></td>
    <td>FLOAT</td>
    <th>SiSense</th>
</tr>
<tr>
    <th rowspan='6'>Snowflake</th>
    <td rowspan='6'>FLOAT</td>
    <td>DOUBLE</td>
    <th rowspan='6'>Snowflake</th>
</tr>
<tr>
    <td>DOUBLE PRECISION</td>
</tr>
<tr>
    <td>FLOAT</td>
</tr>
<tr>
    <td>FLOAT4</td>
</tr>
<tr>
    <td>FLOAT8</td>
</tr>
<tr>
    <td>REAL</td>
</tr>
<tr>
    <th rowspan='2'>Synapse</th>
    <td>FLOAT</td>
    <td rowspan='2'>FLOAT</td>
    <th rowspan='2'>Synapse</th>
</tr>
<tr>
    <td>REAL</td>
</tr>
<tr>
    <td colspan='2'></td>
    <td>FLOAT</td>
    <th>Thoughtspot</th>
</tr>
<tr>
    <th>Source</th>
    <th>Source Type</th>
    <th>Base Type</th>
    <th>Target Type</th>
    <th>Target</th>
</tr>
</table>

### BOOLEAN
The `BOOLEAN` base type represents a true or false value.

<table>
<tr>
    <th>Source</th>
    <th>Source Type</th>
    <th>Base Type</th>
    <th>Target Type</th>
    <th>Target</th>
</tr>
<tr>
    <th rowspan='2'>Generic</th>
    <td>bool</td>
    <td rowspan='14'>BOOLEAN</td>
    <td rowspan='2' colspan='2'></td>    
</tr>
<tr>
    <td>boolean</td>
</tr>
<tr>
    <td colspan='2'></td>
    <td>BOOLEAN</td>
    <th>Hive</th>
</tr>
<tr>
    <td colspan='2'></td>
    <td>BOOLEAN</td>
    <th>Impala</th>
</tr>
<tr>
    <td colspan='2'></td>
    <td>BIT</td>
    <th>MS SQL Server</th>
</tr>
<tr>
    <td>N/A</td>
    <th>MySQL</th>
</tr>
<tr>
    <td colspan='2'></td>
    <td>N/A</td>
    <th>Oracle</th>
</tr>
<tr>
    <td colspan='2'></td>
    <td>BOOLEAN</td>
    <th>PostgreSQL</th>
</tr>
<tr>
    <th rowspan='2'>Redshift</th>
    <td>BOOL</td>
    <td rowspan='2'>BOOLEAN</td>
    <th rowspan='2'>Redshift</th>
</tr>
<tr>
    <td>BOOLEAN</td>
</tr>
<tr>
    <td colspan='2'></td>
    <td>BIT</td>
    <th>SiSense</th>
</tr>
<tr>
    <th>Snowflake</th>
    <td>BOOLEAN</td>
    <td>BOOLEAN</td>
    <th>Snowflake</th>
</tr>
<tr>
    <th>Synapse</th>
    <td>BIT</td>
    <td>BIT</td>
    <th>Synapse</th>
</tr>
<tr>
    <td colspan='2'></td>
    <td>BOOL</td>
    <th>Thoughtspot</th>
</tr>
<tr>
    <th>Source</th>
    <th>Source Type</th>
    <th>Base Type</th>
    <th>Target Type</th>
    <th>Target</th>
</tr>
</table>

### DATE
The `DATE` base type represents a date value without a time portion.

<table>
<tr>
    <th>Source</th>
    <th>Source Type</th>
    <th>Base Type</th>
    <th>Target Type</th>
    <th>Target</th>
</tr>
<tr>
    <th>Generic</th>
    <td>date</td>
    <td rowspan='12'>DATE</td>
    <td>DATE</td>
    <td colspan='2'></td>
</tr>
<tr>
    <td colspan='2'></td>
    <td>N/A</td>
    <th>Hive</th>
</tr>
<tr>
    <td colspan='2'></td>
    <td>N/A</td>
    <th>Impala</th>
</tr>
<tr>
    <td colspan='2'></td>
    <td>DATE</td>
    <th>MS SQL Server</th>
</tr>
<tr>
    <th>MySQL</th>
    <td>DATE</td>
    <td>DATE</td>
    <th>MySQL</th>
</tr>
<tr>
    <td colspan='2'></td>
    <td>DATE</td>
    <th>Oracle</th>
</tr>
<tr>
    <td colspan='2'></td>
    <td>DATE</td>
    <th>PostgreSQL</th>
</tr>
<tr>
    <th>Redshift</th>
    <td>DATE</td>
    <td>DATE</td>
    <th>Redshift</th>
</tr>
<tr>
    <td colspan='2'></td>
    <td>DATE</td>
    <th>SiSense</th>
</tr>
<tr>
    <th>Snowflake</th>
    <td>DATE</td>
    <td>DATE</td>
    <th>Snowflake</th>
</tr>
<tr>
    <th>Synapse</th>
    <td>DATE</td>
    <td>DATE</td>
    <th>Synapse</th>
</tr>
<tr>
    <td colspan='2'></td>
    <td>DATE</td>
    <th>Thoughtspot</th>
</tr>
<tr>
    <th>Source</th>
    <th>Source Type</th>
    <th>Base Type</th>
    <th>Target Type</th>
    <th>Target</th>
</tr>
</table>

### TIMESTAMP
The `TIMESTAMP` base type represents a date value with a time portion.

<table>
<tr>
    <th>Source</th>
    <th>Source Type</th>
    <th>Base Type</th>
    <th>Target Type</th>
    <th>Target</th>
</tr>
<tr>
    <th rowspan='12'>Generic</th>
    <td>datetime</td>
    <td rowspan='35'>TIMESTAMP</td>
    <td rowspan='12' colspan='2'></td>    
</tr>
<tr>
    <td>datetime2</td>
</tr>
<tr>
    <td>datetimeoffset</td>
</tr>
<tr>
    <td>smalldatetime</td>
</tr>
<tr>
    <td>timestamp</td>
</tr>
<tr>
    <td>timestamptz</td>
</tr>
<tr>
    <td>timestamp_LTZ</td>
</tr>
<tr>
    <td>timestamp_NTZ</td>
</tr>
<tr>
    <td>TIMESTAMP_TZ</td>
</tr>
<tr>
    <td>timestamp with local time zone</td>
</tr>
<tr>
    <td>timestamp with time zone</td>
</tr>
<tr>
    <td>timestamp without time zone</td>
</tr>
<tr>
    <td colspan='2'></td>
    <td>TIMESTAMP</td>
    <th>Hive</th>
</tr>
<tr>
    <td colspan='2'></td>
    <td>TIMESTAMP</td>
    <th>Impala</th>
</tr>
<tr>
    <td colspan='2'></td>
    <td>DATETIME2</td>
    <th>MS SQL Server</th>
</tr>
<tr>
    <th rowspan='2'>MySQL</th>
    <td>DATETIME</td>
    <td rowspan='2'>TIMESTAMP</td>
    <th rowspan='2'>MySQL</th>
</tr>
<tr>
    <td>TIMESTAMP</td>
</tr>
<tr>
    <td colspan='2'></td>
    <td>TIMESTAMP</td>
    <th>Oracle</th>
</tr>
<tr>
    <td colspan='2'></td>
    <td>TIMESTAMP</td>
    <th>PostgreSQL</th>
</tr>
<tr>
    <th rowspan='4'>Redshift</th>
    <td>TIMESTAMP</td>
    <td rowspan='4'>TIMESTAMP</td>
    <th rowspan='4'>Redshift</th>
</tr>
<tr>
    <td>TIMESTAMPTZ</td>
</tr>
<tr>
    <td>TIMESTAMP WITH TIME ZONE</td>
</tr>
<tr>
    <td>TIMESTAMP WITHOUT TIME ZONE</td>
</tr>
<tr>
    <td colspan='2'></td>
    <td>N/A</td>
    <th>SiSense</th>
</tr>
<tr>
    <th rowspan='5'>Snowflake</th>
    <td>DATETIME</td>
    <td rowspan='5'>TIMESTAMP</td>
    <th rowspan='5'>Snowflake</th>
</tr>
<tr>
    <td>TIMESTAMP</td>
</tr>
<tr>
    <td>TIMESTAMP_NTZ</td>
</tr>
<tr>
    <td>TIMESTAMP_LTZ</td>
</tr>
<tr>
    <td>TIMESTAMP_TZ</td>
</tr>
<tr>
    <th rowspan='5'>Synapse</th>
    <td>DATETIMEOFFSET</td>
    <td rowspan='5'>DATETIMEOFFSET</td>
    <th rowspan='5'>Synapse</th>
</tr>
<tr>
    <td>DATETIME</td>
</tr>
<tr>
    <td>DATETIME2</td>
</tr>
<tr>
    <td>SMALLDATETIME</td>
</tr>
<tr>
    <td>TIME</td>
</tr>
<tr>
    <td colspan='2'></td>
    <td>TIMESTAMP</td>
    <th>Thoughtspot</th>
</tr>
<tr>
    <th>Source</th>
    <th>Source Type</th>
    <th>Base Type</th>
    <th>Target Type</th>
    <th>Target</th>
</tr>
</table>


================================================
File: extend/common-interface/manifest-files/out-tables-manifests.md
================================================
---
title: /data/out/tables manifests
permalink: /extend/common-interface/manifest-files/out-tables-manifests/
---

An output table manifest sets options for transferring a table to Storage. The following examples list available
manifest fields; **all of them are optional**. The `destination` field overrides the table name generated
from the file name; it can (and commonly is) overridden by the end-user configuration. The `columns` option defines
the columns of the imported table. If the `columns` option is provided, then the CSV files are **assumed to be headless**.
If you the component is producing [Sliced tables](/extend/common-interface/folders/#sliced-tables), then they are always
assumed to be headless and you *have to* use the `columns` option.

{% highlight json %}
{
  "destination": "out.c-main.Leads",
  "columns": ["column1", "column2", "column3"],
  "incremental": true,
  "primary_key": ["column1", "column2"],
  "delimiter": "\t",
  "enclosure": "\"",
  "metadata": ...,
  "column_metadata": ...
}
{% endhighlight %}

Additionally, the following options can be specified:

{% highlight json %}
{
  ...
  "delete_where": [
    {
      "where_filters": [
        {
          "column": "column name",
          "operator": "eq",
          "values_from_set": ["value1", "value2"]
        }
      ]
    }
  ]
}
{% endhighlight %}

The options will cause the specified rows to be deleted from the source table before the new
table is imported. See an [example](/extend/common-interface/config-file/#output-mapping---delete-rows).
Using this option makes sense only with [incremental loads](/extend/generic-extractor/incremental/).

The `metadata` and `column_metadata` fields allow you to set
[Metadata](https://keboola.docs.apiary.io/#reference/metadata) for the table and its columns.
The `metadata` field corresponds to the [Table Metadata API call](https://keboola.docs.apiary.io/#reference/metadata/table-metadata/create-or-update).
The `column_metadata` field corresponds to the [Column Metadata API call](https://keboola.docs.apiary.io/#reference/metadata/column-metadata/create-or-update).
In both cases, the `key` and `value` are passed directly to the API; the `provider` value is
filled by the Id of the running component (e.g., `keboola.ex-db-snowflake`).

{% highlight json %}
{
  ...,
  "metadata": [
    {
      "key": "an.arbitrary.key",
      "value": "Some value"
    },
    {
      "key": "another.arbitrary.key",
      "value": "A different value"
    }
  ],
  "column_metadata": {
    "column1": [
      {
        "key": "yet.another.key",
        "value": "Some other value"
      }
    ]
  }
}
{% endhighlight %}


================================================
File: extend/component/index.md
================================================
---
title: Components
permalink: /extend/component/
redirect_from:
    - /extend/docker/
    - /extend/custom-science/
    - /extend/custom-science/development/

---

* TOC
{:toc}

Components allow you to [extend](/extend/) Keboola.
The data interface to components is very similar to [Transformations](https://help.keboola.com/manipulation/transformations/) --- data is exchanged as
CSV files in [designated directories](/extend/common-interface/).

### Intro to Component Creation
As a developer, you implement the application logic in a language of your choice and store it in a
git repository. The component must adhere to our [common interface](/extend/common-interface/).
To start quickly, use our [component generator](https://github.com/keboola/component-generator) that can generate a skeleton of the component for you. We also provide libraries to help you with implementation in
[R](https://github.com/keboola/r-docker-application),
[Python](https://github.com/keboola/python-component), and
[PHP](https://github.com/keboola/php-docker-application).
Check our example component in [PHP](https://github.com/keboola/docker-demo-app).

The main part of the [common interface](/extend/common-interface/) is the specification how 
[CSV files and designated folders](/extend/common-interface/folders/) are used to exchange data between Keboola and components:

- Applications process input tables stored in CSV files and generate result tables in CSV files.
- Extractors write results in the same way as applications, but instead of reading their
input from Keboola tables, they get it from an external source (usually an API).
- Writers, on the other hand, access their input tables in the same way as applications, but push their results into external systems and do not generate any Keboola tables.


Apart from this basic usage, the common interface offers many more features:

- Passing parameters
- Error control
- Working with metadata
- OAuth support
- Working with non-CSV files
- Logging configuration
- Etc.

Our [Docker Runner component](/extend/docker-runner/) makes sure that the common interface is honoured
from our side. It also takes care of executing your component in its own [isolated environment](/extend/docker-runner/).

## Requirements
Before you start developing a new component, you should

- have a [Keboola project](/#development-project) where you can test your code.
- get yourself acquainted with [Docker](/extend/component/docker-tutorial/). You should be
able to [run `docker`](/extend/component/docker-tutorial/setup/) commands. Strictly speaking, you can get away
with not using them, but it will certainly speed things up for you.
- be able to send API requests. Although you can use the [Apiary](https://apiary.io/) client console, we
recommend using [Postman](https://www.getpostman.com/) as it is
more convenient. A list of [sample requests](https://documenter.getpostman.com/view/3086797/kbc-samples/77h845D?version=latest)
is available.
- have a git repository ([Github](https://github.com/) or [Bitbucket](https://bitbucket.org/) are recommended, 
although any other host should work as well).

You can work with your component in your Keboola projects immediately as soon as you
[create it](/extend/component/tutorial/). However, to make the component publicly available to all users,
it must be [published](/extend/publish/).

## Component Types
The following component types are currently allowed:

- **Extractor** -- a component designed to bring data into Keboola Storage
- **Writer** -- a component designed to bring data to an external system
- **Application** -- another arbitrary component
- **Processor** -- a [processor](/extend/component/processors/)
- **Code Pattern** -- a [code pattern](/extend/component/code-patterns/)
- Transformation -- a special type of component for transformations
- Other -- a completely special component

The type of a component has no effect on the component internals -- i.e., all components regardless of their type 
share the identical features of the [common interface](/extend/common-interface/). The component type just tells 
the end-user what behavior to expect from a given component. For example, an extractor is expected to extract data 
from an external system. Nothing prevents it from processing data from Storage 
(e.g., [Geocoding](https://help.keboola.com/components/extractors/other/geocoding-augmentation/) does that), 
but its primary reason of existence is to bring data into Storage.

The expected behavior of the above component types can be described in more detail as follows: 

- **Extractor** -- extracts data from an external system into Storage, uses no Storage tables on input, has a UI.
- **Writer** -- loads data from Storage into an external system, generates no Storage tables on output, has a UI.
- **Application** -- processes data in Storage, either something like a wrapped transformation or using an external service. Or, it does not work with data in Storage at all. This component has a UI.
- **Processor** -- is designed for post-processing or pre-processing data of other components. It is not designed to run alone and has no UI.
- **Code Pattern** -- generates code for the transformation's component. This component has a UI.
- Transformation -- represents a transformation engine. The UI treats these components specially and expects that they have similar capabilities
and configuration options. These are created by Keboola. If you wish to bring your own, please contact us first.
- Other -- this component type has a special role in the UI, it has no standard component UI. Notable "other" components are:
    - `orchestrator` -- [Orchestrator service](https://help.keboola.com/orchestrator/) configurations. To work with either configurations or jobs, use the [dedicated API](https://keboolaorchestratorv2api.docs.apiary.io/#).
    - `transformation` -- [Transformation service](https://help.keboola.com/transformations/) configurations. To work with configurations, use the standard [configurations API](https://keboola.docs.apiary.io/#reference/components-and-configurations). To work with jobs, 
    use the [dedicated API](https://keboolatransformationapi.docs.apiary.io/#).    
    - `provisioning` -- [Sandbox provisioning service](https://help.keboola.com/transformations/sandbox/). No configurations can be made. 
    To work with jobs, use the [dedicated API](https://provisioningapi.docs.apiary.io/#).
    - `keboola.oauth-v2` -- [OAuth integration service](/extend/common-interface/oauth/). Neither configurations nor jobs can be made. Use the [dedicated API](https://provisioningapi.docs.apiary.io/#) to work with the service.
    - `keboola.variables` -- Component for storing [variables](/integrate/variables/) configurations. Use the standard [configurations API](https://keboola.docs.apiary.io/#reference/components-and-configurations). No jobs can be made.
    - `keboola.storage` -- Placeholder component for actions from Storage service. Neither configurations nor jobs can be made. Use the
    [dedicated API](https://keboola.docs.apiary.io/) to work with Storage.

## Next Steps
- Create a [developer account](/extend/component/tutorial/#before-you-start) so that you can create your own components.
- Follow our [tutorial](/extend/component/tutorial/) to build a "Hello, World!" component in 10 minutes.
- If new to Docker, follow a [quick introduction](/extend/component/docker-tutorial/),
along with a [guide to setting up Docker](/extend/component/docker-tutorial/setup/) and a
[guide to building dockerized applications](/extend/component/docker-tutorial/howto/).
- Follow the [next steps](/extend/component/tutorial/input-mapping/) of the tutorial to understand how your component interacts with Keboola.
- See more about [testing and debugging of components](/extend/component/tutorial/debugging/) in the Keboola environment.
- Request [publication](/extend/publish/) of your component. 


================================================
File: extend/component/processors.md
================================================
---
title: Processors
permalink: /extend/component/processors/
redirect_from:
    - /integrate/docker-runner/processors/
    - /extend/docker-runner/processors/
---

* TOC
{:toc}

Processors are additional components which may be used **before or after** running an arbitrary component
(extractor, writer, etc.). 

When [Docker Runner](/extend/docker-runner/) runs a Docker image (a container is created), a processor
may be used to **pre-process the inputs** (files or tables) supplied to that container, or it may be used to **post-process
the container outputs**. For example, if an extractor extracts CSV data in a non-UTF8 encoding, you can use the
[`iconv` processor](https://github.com/keboola/processor-iconv/blob/master/README.md) as a post-processor to
convert the CSV to UTF-8 as expected by [Storage](https://help.keboola.com/storage/). See the
[tutorial](/extend/component/tutorial/configuration/) for a quick example of using processors.

Processors are technically supported in any configuration of any component. However, as an **advanced feature**, they have little to no 
[support in the UI](/extend/component/ui-options/#genericdockerui-processors). To manually configure processors, 
you have to use the [Component Configuration API](https://keboola.docs.apiary.io/#reference/components-and-configurations).
See the respective part of our [documentation](/integrate/storage/api/configurations/) for
examples of working with the [Component Configuration API](/integrate/storage/api/configurations/).
If you want to implement your own processor, see our [implementation notes](/extend/component/implementation/#implementing-processors).

If the component does not contain the [respective configuration field](/extend/component/ui-options/#genericdockerui-processors) or
an [advanced configuration mode](https://help.keboola.com/extractors/other/aws-s3/#advanced), processors are
completely **invisible in the UI**. In such case, modifying the configuration through the UI may delete the processor configuration
(though you can always [rollback](https://keboola.docs.apiary.io/#reference/components-and-configurations/rollback-configuration-version/rollback-version)).
Therefore be sure to add an **appropriate warning** to the configuration description.

## Configuration
By running the
[Get Configuration Detail](https://keboola.docs.apiary.io/#reference/components-and-configurations/manage-configurations/configuration-detail)
request for a specific component ID and configuration ID, you obtain the actual configuration contents.
You can see [an example request](https://documenter.getpostman.com/view/3086797/kbc-samples/77h845D?version=latest#9b9f3e7b-de3b-4c90-bad6-a8760e3852eb)
for getting a configuration with ID `365111648` for the component called Email Attachments extractor (ID `keboola.ex-email-attachments`):

{% highlight json %}
{
    "id": "365111648",
    "name": "Processor test",
    "description": "",
    "created": "2018-03-10T08:13:08+0100",
    "creatorToken": {
        "id": 27865,
        "description": "ondrej.popelka@keboola.com"
    },
    "version": 3,
    "changeDescription": "Update name",
    "isDeleted": false,
    "configuration": {
        "parameters": {
            "email": "572-365111648-5aa3858e91ed1@import.keboola.com",
            "delimiter": ",",
            "enclosure": "\"",
            "primaryKey": [],
            "incremental": false
        }
    },
    "rowsSortOrder": [],
    "rows": [],
    "state": {
        "lastDownloadedFileTimestamp": "1520666119"
    },
    "currentVersion": {
        "created": "2018-03-10T08:16:54+0100",
        "creatorToken": {
            "id": 27865,
            "description": "ondrej.popelka@keboola.com"
        },
        "changeDescription": "Update name"
    }
}
{% endhighlight %}

From this, the actual configuration is the **contents** of the `configuration` node. Therefore:

{% highlight json %}
{
    "parameters": {
        "email": "572-365111648-5aa3858e91ed1@import.keboola.com",
        "delimiter": ",",
        "enclosure": "\"",
        "primaryKey": [],
        "incremental": false
    }
}
{% endhighlight %}

## Adding Processor
Processors are configured in the `processors` section in the `before` array or the `after` array (rarely both).
For example, you might want to configure the [`processor-skip-lines`](https://github.com/keboola/processor-skip-lines):

{% highlight json %}
{
    "parameters": {
        "email": "572-365111648-5aa3858e91ed1@import.keboola.com",
        "delimiter": ",",
        "enclosure": "\"",
        "primaryKey": [],
        "incremental": false
    },
    "processors": {
        "after": [
            {
                "definition": {
                    "component": "keboola.processor-skip-lines"
                },
                "parameters": {
                    "lines": 1,
                    "direction_from": "top"
                }
            }
        ]
    }
}
{% endhighlight %}

The configuration parameters of a processor are always described in [its documentation](https://github.com/keboola/processor-skip-lines).
The above configuration defines that a `keboola.processor-skip-lines` (which removes a certain number of lines from the file)
will run **after** this particular configuration of the Email Attachment extractor is finished,
but **before** its results are loaded into Storage. When the processor is finished, its outputs are loaded
into Storage as if they were the outputs of the extractor itself.

### Specifying Processor Version

You can specify a particular version of the processor by adding an optional `tag` parameter in the `definition`. This parameter allows you to select a specific version:

{% highlight json %}
{
    "definition": {
        "component": "keboola.processor-skip-lines",
        "tag": "1.0.0"
    }
}
{% endhighlight %}

If the tag parameter is omitted, the processor will automatically use the latest released version.

To save the configuration, use the [Update Configuration API call](https://keboola.docs.apiary.io/#reference/components-and-configurations/manage-configurations/update-configuration).
When updating the configuration, you must provide `componentId`, `configurationId`, and the actual contents of
the configuration in the `configuration` form field. Make sure to supply only the **contents** of the `configuration`
node and to properly escape the form data.

See our [configuration documentation](/integrate/storage/api/configurations/#modifying-a-configuration) for
a more thorough description and the *Add processor to Email Attachments Extractor Configuration* example
in our [collection](https://documenter.getpostman.com/view/3086797/kbc-samples/77h845D?version=latest#9b9f3e7b-de3b-4c90-bad6-a8760e3852eb).
Remember, the processors can be [chained](/extend/component/tutorial/processors/#chaining-processors) to
achieve more advanced processing.

### Available Processors
You can obtain a list of available processors using the
[Developer Portal UI](https://components.keboola.com/components) or the [List Components Public API](https://kebooladeveloperportal.docs.apiary.io/#reference/0/public-api/list-published-apps)
of the Developer Portal. The important parts are `id`, which is required for configuration,
and `documentationUrl`, which describes additional parameters of the processor.

### Configuring Parameters
A processor may allow (or require) parameters. These are entered in the `parameters` section.
The below configuration sets values for two parameters --- `lines` and `direction_from`:

{% highlight json %}
{
    "processors": {
        "after": [
            {
                "definition": {
                    "component": "keboola.processor-skip-lines"
                },
                "parameters": {
                    "lines": 1,
                    "direction_from": "top"
                }
            }
        ]
    }
}
{% endhighlight %}

The names and allowed values of the parameters are fully up to the processor interpretation and validation
and are described in the respective processor documentation.

### Using Processors with Configuration Rows
If the configuration uses [Configuration Rows](/integrate/storage/api/configurations/#configuration-rows),
you have to use the [Update Configuration Row](https://keboola.docs.apiary.io/#reference/components-and-configurations/manage-configuration-rows/update-row)
API call to set the processors.

Provide `componentId`, `configurationId`, `rowId` and the contents of the configuration in
the same manner as when [adding a processor to configuration](#adding-a-processor).

See an example *Add processor to S3 Extractor configuration Row* in
[our collection](https://documenter.getpostman.com/view/3086797/kbc-samples/77h845D?version=latest#9b9f3e7b-de3b-4c90-bad6-a8760e3852eb).
It shows how to set a processor for the configuration row with ID `364481153` in configuration `364479526` of
the AWS S3 extractor (component ID `keboola.ex-aws-s3`). The configuration is the following:

{% highlight json %}
{
    "parameters": {
        "bucket": "travis-php-db-import-tests-s3filesbucket-vm9zhtm5jd7s",
        "key": "tw_accounts.csv",
        "saveAs": "first-table",
        "includeSubfolders": false,
        "newFilesOnly": true
    },
    "processors": {
        "after": [
            {
                "definition": {
                    "component": "keboola.processor-skip-lines"
                },
                "parameters": {
                    "lines": 1
                }
            }
        ]
    }
}
{% endhighlight %}

## Chaining Processors
Remember, processors can be [chained](/extend/component/tutorial/processors/#chaining-processors) and therefore
should be as simple as possible. For example, a processor reading tables in CSV should assume that these are
available in the [standard format](https://help.keboola.com/storage/tables/csv-files/#output-csv-format) and that the
table manifests are available.

### Extractor Example
For example, assume that you have a component which extracts the following data:

    Dump from ACME Anvil CRM
    SLA: 24h
    Day|AnvilsDelivered
    2050-12-10|100|5|4|4
    2050-12-11|56|1|2
    2050-12-12|131|9|7|3

First apply the [processor-skip-lines](https://github.com/keboola/processor-skip-lines) to obtain something
resembling a CSV file:

    Day|AnvilsDelivered
    2050-12-10|100|5|4|4
    2050-12-11|56|1|2
    2050-12-12|131|9|7|3

Then apply the [processor-create-manifest](https://github.com/keboola/processor-create-manifest) to
set the delimiter and enclosure in the file manifest.

After that, use the [processor-format-csv](https://github.com/keboola/processor-format-csv) to convert the file
from the format specified in the manifest to the standard format:

    "Day","AnvilsDelivered"
    "2050-12-10","100","5","4","4"
    "2050-12-11","56","1","2"
    "2050-12-12","131","9","7","3"

Finally, you can use the [processor-headers](https://github.com/keboola/processor-headers) to make the data orthogonal:

    "Day","AnvilsDelivered","col1","col2","col3"
    "2050-12-10","100","5","4","4"
    "2050-12-11","56","1","2",""
    "2050-12-12","131","9","7","3"

### Writer Example
A chain similar to the above can be used for a writer too. Assume that you need to send the following data to
the very special ACME Anvil CRM:

    Import: CRM
    ImportFormat: AnvilPSV
    Date: 2018-10-01
    Type: MANF-DLVR-PLAN

    Day|AnvilManufacturingPlan|AnvilDeliveryPlan
    2050-12-10|100|533
    2050-12-11|100|695
    2050-12-12|100|923

The data exported from Storage will be in the following format:

    "Day","AnvilManufacturingPlan","AnvilDeliveryPlan"
    "2050-12-10","100","533"
    "2050-12-11","100","695"
    "2050-12-12","100","923"

Then apply the [processor-format-csv](https://github.com/keboola/processor-format-csv) to convert the file
from the standard format to the format required by the Anvil CRM writer:

    Day|AnvilManufacturingPlan|AnvilDeliveryPlan
    2050-12-10|100|533
    2050-12-11|100|695
    2050-12-12|100|923

Create a custom processor to put the header in:

    Import: CRM
    ImportFormat: AnvilPSV
    Date: 2018-10-01
    Type: MANF-DLVR-PLAN

    Day|AnvilManufacturingPlan|AnvilDeliveryPlan
    2050-12-10|100|533
    2050-12-11|100|695
    2050-12-12|100|923

Finally, the Anvil CRM writer can send the result to the CRM system. Or you can have the header function be part of the
writer itself. That decision should be made depending on whether the header must always be present (part of the writer) or is optional (processor).


================================================
File: extend/component/code-patterns/index.md
================================================
---
title: Code Patterns
permalink: /extend/component/code-patterns/
---

* TOC
{:toc}

Code Patterns are a special type of [component](/extend/component/). They
 
- **generate code** for [transformations](https://help.keboola.com/transformations/#new-transformations),
- implement the [generate action](/extend/component/code-patterns/interface#generate-action), and
- use the [configuration format](/extend/component/code-patterns/interface#configuration-format).

The generated code is written in a specific [output format](/extend/component/code-patterns/interface#output-format).

## Next Steps

- To see code patterns from users' perspective, go to [Code Patterns Help](https://help.keboola.com/transformations/code-patterns/).
- To learn how code patterns work internally, go to [Interface](/extend/component/code-patterns/interface).
- To implement your first code pattern, see this [tutorial](/extend/component/code-patterns/tutorial).


================================================
File: extend/component/code-patterns/interface.md
================================================
---
title: Code Pattern Interface
permalink: /extend/component/code-patterns/interface/
---

* TOC
{:toc}

This page describes how code patterns work internally as part of Keboola.

## Common Interface
Code pattern is a special type of [component](/extend/component/), therefore the common interface applies to it. 
To integrate your own components into Keboola, use the following links:

- [Component common interface](/extend/common-interface/) 
- [Environment](/extend/common-interface/environment/)
- [Implementation notes](/extend/component/implementation/)

It's important to know that 

- the component code is wrapped in a [Docker](/extend/component/docker-tutorial/) image.
- each component gets a [configuration file](#configuration).
- the correct exit code must be used; read about [return values](/extend/common-interface/environment/#return-values) and
    [how to handle user and application errors](/extend/common-interface/actions/#handling-user-and-application-errors).
- the [Storage API token](https://help.keboola.com/management/project/tokens/) can be forwarded to the `KBC_TOKEN` environment variable.
    - For example, if you need to know the details about the table in the input mapping.
    - It must be enabled and approved by us.
    - Read more in [Environment](/extend/common-interface/environment/).

## Code Generation Process
This section shows how the code generation process works from start to end:

- First, there must be a [published](/extend/publish/) code pattern component, for example, `keboola.example-pattern`.
- The component must have [supported transformations](#supported-components) configured.
    - For instance, it supports `keboola.snowflake-transformation`.
- [Create a transformation with the code pattern](https://help.keboola.com/transformations/code-patterns/#new-transformation-with-code-pattern) in the user interface.
- Click the **Generate Code** button.
- User interface calls the [generate action](#generate-action) on the `keboola.example-pattern` component.
- The action finishes with the correct exit code:
    - If **successful**: `exit code = 0`
        - The component `stdout` contains JSON in the [output format](#output-format). 
        - The code blocks in the [parameters](#output-format) are stored to the transformation.
    - If **failed**: `exit code = 1 or 2`
        - The error is processed according to the [exit code](/extend/common-interface/environment/#return-values).
        - The previous version of the generated code remains in the transformation.
- The generated code is displayed read-only in the user interface.

## Generate Action
There are two types of component actions: 

- [Asynchronous, background](/integrate/jobs/) **run** actions
- [Synchronous actions](/extend/common-interface/actions/) with limited execution time

Code patterns do not implement the **run** action. They only implement the **generate** [synchronous action](/extend/common-interface/actions/).

The expected behavior of the **generate** action:

- The action is started by the [Run Component Action](https://kebooladocker.docs.apiary.io/#reference/actions/run-custom-component-action/) API call.
- The `CMD` process defined in the `Dockerfile` is [started in the container](/extend/component/docker-tutorial/#running-docker-images-in-kbc).
- The component generates a transformation code based on the [configuration](#configuration).
- The result is written in the [output format](#output-format) to `stdout`.
- The process will end successfully with `exit code = 0` (or with another [return value](/extend/common-interface/environment/#return-values) if an error occurs).
- API returns the result of the action.
- The user interface modifies the transformation's configuration and saves it. 

### Configuration
The [configuration file](/extend/common-interface/config-file/) `config.json` in the `KBC_DATADIR` contains:

- **`action`** key set to the `generate` value as a name of the [action](/extend/common-interface/actions/) to execute
- **`storage`** key – contains the current input and output mapping from the transformation.
    - Go to [Configuration File - Tables](/extend/common-interface/config-file/#tables) for a schema description and examples.
    - Go to [Overview - Input and Output Mapping](https://help.keboola.com/transformations/code-patterns/#input-and-output-mapping) for an exemplary user interface.
- **`parameters`** key – modifies the generated code.
    - **`_componentId`** key contains the ID of the target transformation component.
        - For example, `keboola.snowflake-transformation`
        - Based on this, it is possible to customize the generated code, e.g., for various SQL dialects.
    - The other keys come from the [parameters form](https://help.keboola.com/transformations/code-patterns/#parameters-form), filled in by the user.
        - The schema of the form is defined in the [configuration schema](#configuration-schema).
        - The values should be [validated](/extend/common-interface/config-file/#validation) in the component's code.
    
**Note**: [Learn more](/extend/common-interface/environment/) about the `KBC_DATADIR` environment variable.

An example configuration (examples of the `storage` key can be found [here](/extend/common-interface/config-file/#tables)):

```json
{ 
  "action": "generate",
  "storage": {
    "input": {
      "tables": ["..."]
     },
     "output": {
       "tables": ["..."]
     }
  },
  "parameters": {
    "_componentId": "keboola.snowflake-transformation",
    "form_parameter_1": "value 1",
    "form_parameter_2": "value 2"
  }
}
```

### Output Format
The component must write the generated code to `stdout` in the following JSON format:

- **`storage`** key contains the new transformation's input and output mapping.
    - It is optional. If absent, the mapping remains unchanged.
    - It is copied into the transformation's configuration `storage` key.
    - A schema and examples can be found in [Configuration File - Tables](/extend/common-interface/config-file/#tables).
- **`parameters`** key with the generated code
    - It is copied into the transformation's configuration `parameters` key.
    - [Schema](https://help.keboola.com/transformations/#writing-scripts) `blocks` -> `codes` -> `script` must be used. See below.
    - Each statement must be a separate item in the `script` array.

An example configuration (examples of the `storage` key can be found [here](/extend/common-interface/config-file/#tables)):

```json
{
  "storage": {
    "input": {
      "tables": ["..."]
     },
     "output": {
       "tables": ["..."]
     }
  },
  "parameters": {
    "blocks": [
      {
        "name": "Generated block",
        "codes": [
          {
            "name": "Generated code",
            "script": [
              "CREATE TABLE table1;",
              "SELECT foo1, foo2 FROM table2 INTO bar;"
            ]
          }
        ]
      }
    ]   
  }
}
```

## Developer Portal
Each newly created component must be registered in the [Keboola Developer Portal](https://components.keboola.com/).

Start with creating a simple [“Hello, World!”](/extend/component/tutorial/) component. To create 
a code pattern component, you must take the following **additional steps**:

First, create a component with the `Code Pattern` type.

{: .image-popup}
![Screenshot -- Add component](/extend/component/code-patterns/interface-1-add-component.png)

Open the component edit page, and modify the settings described in the following sections.

{: .image-popup}
![Screenshot -- Edit component page](/extend/component/code-patterns/interface-5-edit-component.png)

### Configuration Schema
- [Parameters form](https://help.keboola.com/transformations/code-patterns/#parameters-form) in the user interface
is generated from the [configuration schema](/extend/component/ui-options/configuration-schema/).
- Click the **Preview** button to see the preview of the form. 

{: .image-popup}
![Screenshot -- Configuration schema](/extend/component/code-patterns/interface-2-schema.png)

### Supported Components
Each code pattern can generate a code for one or more transformation component types.
They are specified in the [configuration schema](/extend/component/ui-options/configuration-schema/) in
the root-level `supported_components` key, as an array of component IDs. 

{: .image-popup}
![Screenshot -- List of the supported components](/extend/component/code-patterns/interface-3-supported-list.png)

When creating one of the listed transformation components, the [published](/extend/publish/) code pattern will be 
available in the select box.

{: .image-popup}
![Screenshot -- Create a new transformation](/extend/component/code-patterns/interface-4-new-transformation.png)

The code pattern's [configuration](/extend/component/code-patterns/interface#configuration) contains 
the `parameters._componentId` key, so it is possible to distinguish for which transformation component the code is generated.

## Next Steps
- [Tutorial](/extend/component/code-patterns/tutorial) helps you to implement your first code pattern.
- [Code Patterns Help](https://help.keboola.com/transformations/code-patterns/) shows the code patterns from the user's point of view.

================================================
File: extend/component/code-patterns/tutorial.md
================================================
---
title: Code Pattern Quick Start
permalink: /extend/component/code-patterns/tutorial/
---

* TOC
{:toc}

Code patterns are a special type of [component](/extend/component/). 
Their behavior is specified in their  [interface](/extend/component/code-patterns/interface).

The instructions below refer to the general [component quick start](/extend/component/tutorial/), 
highlighting the steps specific to code patterns.

## Creating Component
First, follow the common steps for [creating a component](/extend/component/tutorial/):

- [Before you start](/extend/component/tutorial/#before-you-start) 
- [Create a component](/extend/component/tutorial/#creating-component)
- [Create a deployment account](/extend/component/tutorial/#creating-deployment-account)

Select `Code Pattern` as the type.

{: .image-popup}
![Screenshot -- Add component](/extend/component/code-patterns/tutorial-1-add-component.png)

Modify the settings described in [Interface - Developer Portal](/extend/component/code-patterns/interface#developer-portal).

## Implementation
Go on following the [component quick start](/extend/component/tutorial/):

- [Initialize a component](/extend/component/tutorial/#initializing-component) 
- [Build a component](/extend/component/tutorial/#building-component)

Learn how the whole [code generation process](/extend/component/code-patterns/interface#code-generation-process) works.

**Implement the Generate action** as specified in [Interface - Generate Action](/extend/component/code-patterns/interface#generate-action):

- First, load the [configuration](/extend/component/code-patterns/interface#configuration).
- Validate the configuration, `action = generate` is expected.
- Do not implement other actions (not even `run`).
- In case of an error, use the correct [return value](/extend/common-interface/environment/#return-values).
- Generate code based on the configuration.
- Write the result in the standard [output format](/extend/component/code-patterns/interface#output-format) to `stdout`.
- Exit with the `exit code = 0` if successful.

## Running Component
Unlike other components, the code pattern component [**cannot be run**](/extend/component/tutorial/#running-component),
and will be **invisible in the user interface until it is [published](#publishing-component)**.

However, there are two other ways to try it as a component, as described below.

### Run via API
The first option is to call the [generate action](/extend/component/code-patterns/interface#generate-action) via the API:

- You can test that the component returns the desired results based on the specified inputs.
- Use the [Run Component Action](https://kebooladocker.docs.apiary.io/#reference/actions/run-custom-component-action/process-action) API call.
- An [API token](https://help.keboola.com/management/project/tokens/) is needed.

### Modify Transformation via API
The second option is to modify the transformation to use an unpublished code pattern.

#### Create empty transformation
First, click **Transformations** on the project menu. Then click **New Transformation** to create a new transformation.

{: .image-popup}
![Screenshot -- Transformations page](/extend/component/code-patterns/tutorial-2-project.png)

In the modal, click on the selected **type of the transformation**.

{: .image-popup}
![Screenshot -- Add new transformation modal](/extend/component/code-patterns/tutorial-3-modal.png)

Fill in the **name** and, optionally, the **description**. Do not select any code pattern.

{: .image-popup}
![Screenshot -- Net transformation](/extend/component/code-patterns/tutorial-4-new-transformation.png)

You have created an empty transformation.

#### Set code pattern to transformation

**Make note of the component and configuration ID from the URL.** You will need them in the API calls.

```
/admin/projects/{PROJECT_ID}/transformations-v2/{COMPONENT_ID}/{CONFIGURATION_ID}
```

**Set the code pattern to the transformation via [Storage API](/overview/api/).**

Load the configuration in the JSON format via the [Configuration Detail](https://keboola.docs.apiary.io/#reference/components-and-configurations/manage-configurations/configuration-detail) API call.

```
curl \ 
  --include \
  --header "X-StorageApi-Token: {API_TOKEN}" \
'{STORAGE API}/v2/storage/components/{COMPONENT_ID}/configs/{CONFIGURATION_ID}'
```

This is an example response, some keys are omitted.

```json
{
  "id": "1234",
  "name": "API test",
  "configuration": {}
}
```

It is necessary to set the **ID of the code pattern component** to the configuration.

```json
{
  "configuration": {
    "runtime": {
      "codePattern": {
        "componentId": "keboola.example-pattern"
      }
    }
  }
}
```

Update the configuration via the [Update Configuration](https://keboola.docs.apiary.io/#reference/components-and-configurations/manage-configurations/update-configuration) API call. 
JSON must be url-encoded.

```
curl 
 --include \
 --request PUT \
 --header "X-StorageApi-Token: {API_TOKEN}" \
 --header "Content-Type: application/x-www-form-urlencoded" \
 --data-binary "configuration=%7B%22runtime%22%3A%7B%22codePattern%22%3A%7B%22componentId%22%3A%22keboola.example-pattern%22%7D%7D%7D" \
'{STORAGE API}/v2/storage/components/{COMPONENT_ID}/configs/{CONFIGURATION_ID}'
```

This is an example response, some keys are omitted.

``` json
{
  "id": "1234",
  "name": "API test",
  "configuration": {
    "runtime": {
      "codePattern": {
        "componentId": "keboola.example-pattern"
        }
      }
   }
}
```

The transformation now uses the code pattern, and you can **test it in the [user interface](https://help.keboola.com/transformations/code-patterns/#configuration)**.

## Publishing Component
Make sure the component is set up according to [Interface - Developer Portal](/extend/component/code-patterns/interface#developer-portal).
Then follow the tutorial [Publish Component](/extend/publish/).

## Next Steps
- [Interface](/extend/component/code-patterns/interface) describes how the code patterns work internally.
- [Code Patterns Help](https://help.keboola.com/transformations/code-patterns/) shows the code patterns from the user's point of view.


================================================
File: extend/component/deployment/index.md
================================================
---
title: Deployment
permalink: /extend/component/deployment/
redirect_from:
  - /extend/docker/tutorial/automated-build/
  - /extend/registration/deployment/
---

* TOC
{:toc}

If you created your component according to the [tutorial](/extend/component/tutorial/), you already have
a deployment pipeline set up. This article explains in more detail how the pipeline works. It also describes
alternative set ups. Assuming your component is similar to the [example component](https://github.com/keboola/ex-docs-tutorial)
created in the [tutorial](/extend/component/tutorial/), you see the following behavior:

- Every commit & push to the git repository triggers a build on [Travis](https://docs.travis-ci.com/).
- Every new tag pushes the built image into our [AWS ECR registry](https://aws.amazon.com/ecr/).
- Every [normal version tag](https://semver.org/#spec-item-2) (x.y.z) updates the image tag in the [Developer Portal](https://components.keboola.com/) and subsequently makes the image available in Keboola.

We highly recommend the above setup (or a similar one) as it imposes very little extra work on the developer, yet
it deploys new versions of the component in a controlled and traceable manner.

## How It Works
The following text explains the default setup in detail so that you know what to do if something
breaks or how to set up the pipeline manually.

### Integration
The first step is the integration between GitHub and Travis. This is best set from the Travis side
by enabling the repository:

{: .image-popup}
![Screenshot -- Add Repository](/extend/component/deployment/deploy-config-1.png)

Enable builds for the repository. If you don't see the repository, use the **Sync account** button:

{: .image-popup}
![Screenshot -- Enable Travis Repository](/extend/component/deployment/deploy-config-2.png)

This causes Travis to trigger a build on every GitHub commit & push.

### Build Setting
What the Travis build does is defined in the
[`.travis.yml`](https://github.com/keboola/component-generator/blob/master/templates-common/.travis.yml) file in
your repository. You should have something similar to this:

{% highlight yaml %}
sudo: required
language: bash
services:
  - docker

before_script:
  - export APP_IMAGE=keboola-component
  - docker build . --tag=$APP_IMAGE

after_success:
  - docker images

deploy:
  provider: script
  skip_cleanup: true
  script: ./deploy.sh
  on:
    tags: true
{% endhighlight %}

The `.travis.yml` file offers a vast number of [configuration options](https://docs.travis-ci.com/user/customizing-the-build/).
We only need a few of them though. The options `sudo`, `language` and `services` define that all we need is Docker.
The `before_script` section executes a single shell command which
[builds the image](/extend/component/tutorial/debugging/#step-2--build-the-image) and tags it `keboola-component`. The
tag is completely arbitrary at this moment, but we'll need it later. The `after_success` section simply lists the
built images in the log.

The `deploy` section defines when a deploy will be triggered (`on tags`) and what should be done `deploy.sh`. This means that
when Travis encounters a tagged commit, it triggers the `deploy.sh` shell script (after everything else was done).

### Deploy Script
In your repository, you should have a [deploy script](https://github.com/keboola/component-generator/blob/master/templates-common/deploy.sh)
similar to the one below:

{% highlight bash %}
#!/bin/bash
set -e

# Obtain the component repository and log in
docker pull quay.io/keboola/developer-portal-cli-v2:latest
export REPOSITORY=`docker run --rm  \
    -e KBC_DEVELOPERPORTAL_USERNAME \
    -e KBC_DEVELOPERPORTAL_PASSWORD \
    quay.io/keboola/developer-portal-cli-v2:latest \
    ecr:get-repository ${KBC_DEVELOPERPORTAL_VENDOR} ${KBC_DEVELOPERPORTAL_APP}`
eval $(docker run --rm \
    -e KBC_DEVELOPERPORTAL_USERNAME \
    -e KBC_DEVELOPERPORTAL_PASSWORD \
    quay.io/keboola/developer-portal-cli-v2:latest \
    ecr:get-login ${KBC_DEVELOPERPORTAL_VENDOR} ${KBC_DEVELOPERPORTAL_APP})

# Push to the repository
docker tag ${APP_IMAGE}:latest ${REPOSITORY}:${TRAVIS_TAG}
docker tag ${APP_IMAGE}:latest ${REPOSITORY}:latest
docker push ${REPOSITORY}:${TRAVIS_TAG}
docker push ${REPOSITORY}:latest

# Update the tag in Keboola Developer Portal -> Deploy to Keboola
if echo ${TRAVIS_TAG} | grep -c '^v\?[0-9]\+\.[0-9]\+\.[0-9]\+$'
then
    docker run --rm \
        -e KBC_DEVELOPERPORTAL_USERNAME \
        -e KBC_DEVELOPERPORTAL_PASSWORD \
        quay.io/keboola/developer-portal-cli-v2:latest \
        update-app-repository ${KBC_DEVELOPERPORTAL_VENDOR} ${KBC_DEVELOPERPORTAL_APP} ${TRAVIS_TAG} ecr ${REPOSITORY}
else
    echo "Skipping deployment to KBC, tag ${TRAVIS_TAG} is not allowed."
fi
{% endhighlight %}

The script uses our [Developer Portal CLI tool](https://github.com/keboola/developer-portal-cli-v2) to communicate with
the [Developer Portal API](https://kebooladeveloperportal.docs.apiary.io/#). The tool itself is provided as a Docker
image `quay.io/keboola/developer-portal-cli-v2`. The entire script uses the following environment variables:

- `KBC_DEVELOPERPORTAL_USERNAME` -- Service account user name
- `KBC_DEVELOPERPORTAL_PASSWORD` -- Service account password
- `KBC_DEVELOPERPORTAL_VENDOR` -- Vendor ID
- `KBC_DEVELOPERPORTAL_APP` -- Component ID

You can read more about using the Developer Portal CLI in the [chapter about running components](/extend/component/running/#running-a-component).
The deploy script first pulls the image and then calls the `ecr:get-repository` command (while passing in the
`KBC_DEVELOPERPORTAL_USERNAME` and `KBC_DEVELOPERPORTAL_PASSWORD` variables). The result of that command is stored in the `REPOSITORY`
variable. After that the `ecr:get-login` command is called; it returns
a command line to authorize against our AWS ECR registry (e.g `docker login -u AWS -p ey...ODAzOH0=
147946154733.dkr.ecr.us-east-1.amazonaws.com`). The return value is `eval`ed -- i.e., the login command is executed.

Then there are two `docker tag` and `docker push` commands which tag the image build as `keboola-component` with the `latest` tag
and the git commit tag (stored in `TRAVIS_TAG` variable). Push the two resulting images into the AWS ECR registry.

The last part of the script begins with a check that the commit tag (`TRAVIS_TAG`) is a [normal version tag](https://semver.org/#spec-item-2)
(`x.y.z`). If not, the component is not updated in the Developer Portal. However, at this stage the image was already pushed into the registry
so it can be used by [running it explicitly](/extend/component/tutorial/debugging/#running-specific-tags). If the git tag
is a normal version tag, the component is updated in the Developer Portal using the `update-app-repository` command.
This means that the new version of the component is immediately deployed into Keboola. Keep in mind that it takes a couple of minutes
to propagate the change to all Keboola instances.

When modifying the deploy script, make sure the `deploy.sh` file line ending is set to **Unix (LF)**. Also make sure that the file is executable,
i.e., by executing `git update-index --chmod=+x deploy.sh`. If the script is not executable, you'll get the following error message:

	Script failed with status 127

or

  bash: ./deploy.sh: Permission denied


### Deploy Configuration
The above deploy script requires four environment variables to be set. Set the following environment variables in the repository configuration:

 - `KBC_DEVELOPERPORTAL_APP` the component ID -- e.g.: `keboola-test.ex-docs-tutorial`
 - `KBC_DEVELOPERPORTAL_PASSWORD` with the [**Service Account**](/extend/component/tutorial/#creating-a-deployment-account) password
 - `KBC_DEVELOPERPORTAL_USERNAME` with the [**Service Account**](/extend/component/tutorial/#creating-a-deployment-account) login
 - `KBC_DEVELOPERPORTAL_VENDOR` with the vendor of the component -- e.g.: `keboola-test`

{: .image-popup}
![Screenshot -- Repository Configuration](/extend/component/deployment/deploy-config-3.png)

### Trigger Build
Commit and push anything to the repository to trigger the build. In Travis, you should see an output similar to this:

{: .image-popup}
![Screenshot -- Build Log](/extend/component/deployment/deploy-log-1.png)

Now push a tag to the repository (we recommend using [Semantic Versioning](http://semver.org/)):

    git tag 0.0.6
    git push origin --tags

In Travis, you should see an output similar to this:

{: .image-popup}
![Screenshot -- Build and Deploy Log](/extend/component/deployment/deploy-log-2.png)

If no errors occurred, the component is now deployed into Keboola. In the Developer Portal, you can verify that the
component repository and tag were automatically set:

{: .image-popup}
![Screenshot -- Deploy Verification](/extend/component/deployment/deploy-final.png)

The component is now runnable in Keboola. You can view all settings in our
[example repository](https://github.com/keboola/ex-docs-tutorial). You can also
review [Travis Configuration](https://travis-ci.org/keboola/ex-docs-tutorial/).

*Note that it takes up to **5 minutes** before the changes in the Developer Portal propagate to all Keboola instances in all regions.*

## Bitbucket Integration
The [development tutorial](/extend/component/tutorial/) as well as the above description assume you're using
Travis CI Service for building and deploying the image. Travis integrates very well with [GitHub](https://github.com/), but not with
[Bitbucket](https://bitbucket.org/). However, Bitbucket has its own continuous integration service --
[Bitbucket Pipelines](https://bitbucket.org/product/features/pipelines).

You have to enable Bitbucket Pipelines in your repository:

{: .image-popup}
![Screenshot -- Bitbucket Pipelines](/extend/component/deployment/bitbucket-1.png)

Note that only the owner of the repository can enable pipelines. Then set the environment variables in settings:

{: .image-popup}
![Screenshot -- Bitbucket Environment Variables](/extend/component/deployment/bitbucket-2.png)

Add the following [`bitbucket-pipelines.yml`](https://github.com/keboola/component-generator/blob/master/templates/bitbucket-deploy/bitbucket-pipelines.yml) file to your repository:

{% highlight yaml %}
options:
  docker: true

pipelines:
  default:
    - step:
        script:
          - export APP_IMAGE=keboola-component
          - docker build . --tag=$APP_IMAGE
          - docker images

  tags:
    '*':
      - step:
          script:
          - export APP_IMAGE=keboola-component
          - docker build . --tag=$APP_IMAGE
          - docker images
          - ./deploy.sh
{% endhighlight %}

Also add the [`deploy.sh` script](https://github.com/keboola/component-generator/blob/master/templates/bitbucket-deploy/deploy.sh),
which is modified to use the [`BITBUCKET_TAG`](https://confluence.atlassian.com/bitbucket/environment-variables-794502608.html) variable (instead of `TRAVIS_TAG`). When done, commit and push; a build will automatically appear in the **Pipelines** section:

{: .image-popup}
![Screenshot -- Bitbucket Build](/extend/component/deployment/bitbucket-3.png)

With the above settings, the Bitbucket Pipelines will behave in exactly the same way as the Travis configuration described above.
You can also have a look at a [10 minute video](https://www.youtube.com/watch?v=Pf_hfM_zNyU) showing the Bitbucket setup on a new component.

## GitLab Integration
The [development tutorial](/extend/component/tutorial/) as well as the above description assume you're using
Travis CI Service for building and deploying the image. Travis integrates very well with [GitHub](https://github.com/), but not with
[GitLab](https://about.gitlab.com/). However, GitLab has its own continuous integration service --
[CI Pipelines](https://docs.gitlab.com/ee/ci/pipelines.html).

You have to set the environment variables in settings:

{: .image-popup}
![Screenshot -- GitLab Environment Variables](/extend/component/deployment/gitlab-1.png)

Then add the following [`.gitlab-ci.yml`](https://github.com/keboola/component-generator/blob/master/templates/gitlab-deploy/.gitlab-ci.yml) file to your repository:

{% highlight yaml %}
image: docker:latest

variables:
  DOCKER_DRIVER: overlay2
  APP_IMAGE: keboola-component

services:
- docker:dind

before_script:
- docker info

build-component:
  stage: build
  script:
    - docker build . --tag=$APP_IMAGE

deploy-component:
  stage: deploy
  script:
    - docker build . --tag=$APP_IMAGE
    - pwd
    - ls -la
    - export
    - ./deploy.sh
  only:
    - tags
{% endhighlight %}

Also add the [`deploy.sh` script](https://github.com/keboola/component-generator/blob/master/templates/gitlab-deploy/deploy.sh),
which is modified to use the [`CI_COMMIT_TAG`](https://docs.gitlab.com/ce/ci/variables/README.html) (instead of `TRAVIS_TAG`) and use `sh` shell (instead of `bash`). When done, commit and push; a build will automatically appear in the **Pipelines** section:

{: .image-popup}
![Screenshot -- GitLab Build](/extend/component/deployment/gitlab-2.png)

With the above settings, the GitLab CI Pipelines will behave in exactly the same way as the Travis configuration described above.
You can also have a look at a [10 minute video](https://www.youtube.com/watch?v=TC-tN-zYgEw) showing the GitLab setup on a new component.

## Manual Deployment
If you want to use another continuous integration setting or deploy to the repository manually, you can do so without limitations.
As in the [above script](/extend/component/deployment/#deploy-script),
we recommend using the [Developer Portal CLI client](https://github.com/keboola/developer-portal-cli-v2). This CLI tool (runnable in Docker or PHP)
allows you to obtain the repository for a component and push credentials to that repository. See the chapter about
[running components](/extend/component/running/#running-a-component), for example, how to obtain the AWS registry credentials.
If you want to get even more low level, you can use the [Developer Portal API](https://kebooladeveloperportal.docs.apiary.io/#) directly.
It also allows you to [generate credentials for a service account](https://kebooladeveloperportal.docs.apiary.io/#reference/0/vendor/create-service-account)
programmatically. Apart from our AWS ECR registry, we also support running images stored in [Quay.io](https://quay.io/repository/)
and [Docker Hub](https://hub.docker.com/) registries.

## Test Live Configurations
Testing your component can be simply added as part of the script in `.travis.yml` file. See an example in
[Python](https://github.com/keboola/component-generator/blob/master/templates/python-tests/.travis.yml) or
[PHP](https://github.com/keboola/component-generator/blob/master/templates/php-component/.travis.yml).

However, you may want to test the component on some 'real' configurations
in your project. You can do this by extending the build script and adding certain environment variables to
Travis with an appropriate [Storage token](https://help.keboola.com/storage/tokens/)
and configuration ID. It is highly recommended to create a dedicated token for this task.

The commands will need two extra environment variables apart from the
[ones listed above](/extend/component/deployment/#deploy-configuration):

- `KBC_STORAGE_TOKEN` --- the Storage token that the test(s) will run under
- `KBC_APP_TEST_CONFIG` --- the ID of the configuration to test

{: .image-popup}
![Screenshot -- Sample Configurations](/extend/component/deployment/configuration-sample.png)

If you are still using our [sample component code](https://github.com/keboola/ex-docs-tutorial),
create a configuration and set an arbitrary table on input.

The following extended `.travis.yml` will do the trick:

{% highlight yaml %}
sudo: false

services:
  - docker

before_script:
  - export APP_IMAGE=keboola-component
  - docker build -t $APP_IMAGE .
  - docker run $APP_IMAGE flake8
  - docker run $APP_IMAGE python -m unittest discover
  # push test image to ECR
  - docker pull quay.io/keboola/developer-portal-cli-v2:latest
  - export REPOSITORY=`docker run --rm -e KBC_DEVELOPERPORTAL_USERNAME -e KBC_DEVELOPERPORTAL_PASSWORD -e KBC_DEVELOPERPORTAL_URL quay.io/keboola/developer-portal-cli-v2:latest ecr:get-repository $KBC_DEVELOPERPORTAL_VENDOR $KBC_DEVELOPERPORTAL_APP`
  - docker tag $APP_IMAGE:latest $REPOSITORY:test
  - eval $(docker run --rm -e KBC_DEVELOPERPORTAL_USERNAME -e KBC_DEVELOPERPORTAL_PASSWORD -e KBC_DEVELOPERPORTAL_URL quay.io/keboola/developer-portal-cli-v2:latest ecr:get-login $KBC_DEVELOPERPORTAL_VENDOR $KBC_DEVELOPERPORTAL_APP)
  - docker push $REPOSITORY:test
  - docker pull quay.io/keboola/syrup-cli:latest

script:
  - docker run --rm -e KBC_STORAGE_TOKEN quay.io/keboola/syrup-cli:latest run-job $KBC_DEVELOPERPORTAL_APP $KBC_APP_TEST_CONFIG test

after_success:
  - docker images

deploy:
  provider: script
  skip_cleanup: true
  script: "./deploy.sh"
  on:
    tags: true
{% endhighlight %}

The commands above

- build the component image and tag it `keboola-component`.
- run the [flake8](http://flake8.pycqa.org/en/latest/) code style check.
- run [unittest](https://docs.python.org/3.6/library/unittest.html) tests.
- pull the [Developer Portal CLI client](https://github.com/keboola/developer-portal-cli-v2).
- get the component's Keboola registry from the Developer Portal and store it in the `REPOSITORY` variable.
- tag the image as `test`.
- get the command to login to the registry (`ecr:get-login`) and execute it (i.e., log in).
- push the image to the registry.
- pull the job runner CLI client ([Syrup PHP CLI](https://github.com/keboola/syrup-php-cli)).
- run the specified test job on Keboola using the `/{component}/{config}/run/tag/{tag}` -- [Keboola Docker API](https://kebooladocker.docs.apiary.io/#reference/run/create-a-job-with-image/run-job). The tag used is `test`.

If you want to run multiple test jobs, simply repeat the command with the different configuration IDs
that you would like to test.

When you commit to the component repository, the Docker image will be built, and using a `test` tag, it will be tested in production Keboola.
However, it will not be deployed to production! To get it into production, create a new normal version tag (`x.y.z`) in the repository.
The Docker image will be built and tested using the `test` tag, and if all succeeds, it will be deployed
with the `x.y.z` tag into Keboola --- a new version will be available in production.
You can see the [Python code](https://github.com/keboola/component-generator/tree/master/templates/python-tests) or
[PHP code](https://github.com/keboola/component-generator/tree/master/templates/php-component/) in our
[Templates repository](https://github.com/keboola/component-generator/tree/master/templates)
or in our [Docker Demo App](https://github.com/keboola/docker-demo-app) GitHub repository.


================================================
File: extend/component/docker-tutorial/howto.md
================================================
---
title: How to Create Dockerized Application
permalink: /extend/component/docker-tutorial/howto/
redirect_from:
    - /extend/docker/tutorial/howto/
---

* TOC
{:toc}

The following are the basic steps for developing Keboola Docker Images. There is no need to know everything about the
Docker stack since this is a very limited set of Docker features.
The official [tutorial](https://docs.docker.com/get-started/) is not being replaced here.
Before you start, make sure you have [Docker installed](/extend/component/docker-tutorial/setup/).

The code discussed below is available in our [sample repository](https://github.com/keboola/docs-docker-example-image).

## Creating Your Own Image
To create your own image, create a [Dockerfile](https://docs.docker.com/engine/reference/builder/).
A Dockerfile is a set of shell instructions leading to a configured OS environment. You can think of it as a
bash shell script with some specifics. Each Dockerfile should be placed in its own folder because the folder
becomes a **Build Context** of the Docker image. The build context contains files which can be injected into the
image. There is no other way to inject arbitrary files into the image other than through the build
context or via downloading them from the Internet.

Useful Dockerfile instructions:

- [`FROM`](https://docs.docker.com/engine/reference/builder/#from): State the base image to start with.
- [`RUN`](https://docs.docker.com/engine/reference/builder/#run): Execute an arbitrary shell command.
- [`ENTRYPOINT`](https://docs.docker.com/engine/reference/builder/#entrypoint): Set the command which
will be executed when the image is run; this is the command that will actually run inside a container.
When the command finishes, the container finishes too.
- [`ENV`](https://docs.docker.com/engine/reference/builder/#env): Set an environment variable, use this instead of `export`.
- [`WORKDIR`](https://docs.docker.com/engine/reference/builder/#workdir): Set the current working folder.
- [`COPY`](https://docs.docker.com/engine/reference/builder/#copy): Copy files from the build context into the image.

Note that in Dockerfile, each instruction is executed in its own shell. Therefore, the
`ENV` and `WORKDIR` instructions **MUST** be used to set environment variables and the current folder.

### Sample Image
Create an empty folder. Then create a Dockerfile with the following contents inside the folder.

{% highlight dockerfile %}
FROM alpine
ENTRYPOINT ping -c 2 example.com
{% endhighlight %}

The `FROM` instruction means you start with the [Alpine Linux image](https://hub.docker.com/_/alpine/).
The second instruction means that when you run the image, it will ping _example.com_ twice and exit.
When you run

    docker build .

you should see an output like this:

    Sending build context to Docker daemon  2.048kB
    Step 1/2 : FROM alpine
    ---> 37eec16f1872
    Step 2/2 : ENTRYPOINT ping -c 2 example.com
    ---> Running in 8339a4e2e1c2
    ---> ad16195c696d
    Removing intermediate container 8339a4e2e1c2
    Successfully built ad16195c696d

The `ad16195c696d` is a volatile image hash which is used to refer to the image and can be abbreviated to first three
characters (`ad1` in this case).
Additionally, you can name the image by passing the `--tag` option, e.g.,

    docker build --tag=my-image .

After the image has been built, run it using `docker run ad1` or

    docker run my-image .

You should see an output like this:

    docker run my-image .
    PING example.com (93.184.216.34): 56 data bytes
    64 bytes from 93.184.216.34: seq=0 ttl=37 time=137.057 ms
    64 bytes from 93.184.216.34: seq=1 ttl=37 time=145.279 ms

    --- example.com ping statistics ---
    2 packets transmitted, 2 packets received, 0% packet loss
    round-trip min/avg/max = 137.057/141.168/145.279 ms

### Inspecting Image
When building your own image, the ability to run arbitrary commands in the image is very useful. Override the entrypoint using the `--entrypoint`
option (which means that your application will not execute, and you will have to run it manually). The `-i` and `-t`
options open **i**nteractive **t**erminal:

    docker run -i -t --entrypoint=/bin/sh my-image

The option `--entrypoint` overrides the `ENTRYPOINT` specified in the `Dockerfile`. This ensures that a
sh shell is run instead of your application. You then have to run the `ping` command, previously defined in the entrypoint, manually.

It is also possible to inspect a running container. Assume you have the following `Dockerfile`:

{% highlight dockerfile %}
FROM alpine
ENTRYPOINT ping example.com
{% endhighlight %}

When you build it using:

    docker build --tag=my-image .

Then run the image (create a new container and run the image entrypoint in it):

    docker run my-image

Open a new command line window and run:

    docker ps

This will show you a list of running containers --- something like:

    CONTAINER ID  IMAGE     COMMAND                  CREATED          STATUS         NAMES
    f7def769a470  my-image  "/bin/sh -c 'ping ..."   16 seconds ago   Up 13 seconds  sharp_ptolemy

The important part is the **container ID**. You can then run an arbitrary command in the running container with
the following command:

    docker exec *container_id* *command*

For example:

    docker exec -i -t f7d /bin/sh

will execute **i**nteractive **t**erminal with the shell in the container **daf** (container ID can
be shortened to first 3 letters). Verify that `ping` is still running by:

    ps -A

which will give you something like:

    PID  USER   TIME   COMMAND
    1    root   0:00   /bin/sh -c ping example.com .
    5    root   0:00   ping example.com
    11   root   0:00   /bin/sh
    15   root   0:00   /bin/sh
    19   root   0:00   ps -A

### Installing Things
Chances are that your application requires something special. You can install whatever you need
using standard commands. You can create Dockerfile:

{% highlight dockerfile %}
FROM debian
RUN apt-get update
RUN apt-get install -y php-cli
ENTRYPOINT php -r "echo 'Hello world from PHP';"
{% endhighlight %}

The `RUN` commands will install the specified `php-cli` package. Build the image with:

    docker build --tag=my-image .

and then run the image (and create a new container):

    docker run my-image

You should see the following output:

    Hello world from PHP


### Loading Files into Image
When you need to add files into your image, use the **build context** (which is simply
the folder in which the **Dockerfile** is and in which you are building the image). Create a `test.php`
file in the same folder as the **Dockerfile** with the following contents:

{% highlight php %}
<?php

echo "Hello world from PHP file";
{% endhighlight %}

Then change the Dockerfile to:

{% highlight dockerfile %}
FROM debian
RUN apt-get update
RUN apt-get install -y php-cli
COPY . /code/
ENTRYPOINT php /code/test.php
{% endhighlight %}

The `COPY` command copies the entire contents of the folder with Dockerfile into the `/code/`
folder inside the image. The `ENTRYPOINT` command then simply executes the file when the image
is run. When you `docker build` and `docker run` the image, you will receive:

    Hello world from PHP file

## Dockerfile Gotchas
- Make absolutely sure that the **Dockerfile** script requires no interaction.
- Each Dockerfile instruction runs in its own shell, and there is no state maintained between them.
This means that, for instance, having `RUN export foo=bar` makes no sense. Use `ENV foo=bar` instruction
to create environment variables.
- When you look at the [existing Dockerfiles](https://github.com/keboola/docker-custom-python/blob/master/Dockerfile),
you will realize that commands are squashed together
to a [single instruction](https://github.com/keboola/docker-custom-python/blob/master/Dockerfile#L6). This is
because each instruction creates a **layer** and there is a limited number of layers (layers are counted for the base
images too). However, this approach makes debugging more complicated. So, you better start with having

{% highlight dockerfile %}
RUN instruction1
RUN instruction2
{% endhighlight %}

and only once you are sure the image builds correctly and you are happy with the result, change this to:

{% highlight dockerfile %}
RUN instruction1 \
    && instruction2
{% endhighlight %}

- When you refer to files on the Internet, make sure they are available publicly, so that the image can be
rebuilt by a Docker registry.
- Be careful about storing private things in the image (like credentials or keys); they will remain in
the image unless you delete them.
- Be sure to delete temporary files, as they bloat the image. That's why we add `rm -rf /var/lib/apt/lists/*` everywhere.
- Consult
the [Dockerfile Best Practices](https://docs.docker.com/engine/userguide/eng-image/dockerfile_best-practices/)
for more detailed information.

Now that you are able to create dockerized applications, get yourself familiar with the
[Docker registry](/extend/component/docker-tutorial/registry/).


================================================
File: extend/component/docker-tutorial/index.md
================================================
---
title: About Docker
permalink: /extend/component/docker-tutorial/
redirect_from:
    - /extend/docker/tutorial/
---

* TOC
{:toc}

Docker is a technology stack for running things in virtualized environments. In Keboola, we use a limited set of Docker features.
Their description follows. For a full technical description of Docker, consult its
[official documentation](https://docs.docker.com/).

## What Docker Is
At first sight, Docker is similar to other virtualization technologies (such as VMware or VirtualBox).
However, there are some [fundamental differences](https://docs.docker.com/engine/understanding-docker/),
the main one being that Docker runs only virtualized applications, not the entire OS.

Docker has **Docker Images** and **Docker Containers**. To create a Docker image, create a **Dockerfile**.
Dockerfiles contain instructions on how the Docker image should be built, and this represents the environment
(OS + modifications) in which an application runs.

A Docker image contains everything required to run an application. It usually has an **entrypoint**, which is
a single command executed when the image is run.

When you run an image (start an application in it), a **Docker container** is created. The container is a sandbox
isolated from the image itself and cannot make permanent changes to it. Maybe somewhat surprising, this is very important.
When you run the image again (and create a new container), it won't be affected in any way by the previous
container. The Docker image is therefore stateless and acts as a template. The state is stored only in the container.

## Docker Images
Docker Images are created by executing the instructions written in a **Dockerfile**. It is a simple text
file consisting mostly of shell commands which must be executed to prepare the application for running.
Docker images can be based on other images. So if
you need minor modification to a system, you do not have to build the whole thing from scratch. If you want Images to be
reused, *push* your Dockerfile to a **Docker registry**. The registries ([Dockerhub](https://hub.docker.com/),
[Quay](https://quay.io/)) will build the image; anyone interested in using it can download it.
[AWS ECR](https://aws.amazon.com/ecr/) is a private repository and has no build triggers. You need to push the images manually or
using a [deploy script](/extend/component/deployment/) in your CI pipeline.

Docker image names are based on the following scheme: `registry-name/account-name/image-name:tag` where _registry-name_
and _account-name_ can sometimes be omitted. For example, you can refer to a Docker _hello-world_ image as: `hello-world`
or as `docker.io/library/hello-world:latest`
where the `docker.io` refers to the [Docker Hub](https://hub.docker.com/) registry,
the `library` refers to _account_ (common library is default), `hello-world` refers to the _image name_,
and `latest` refers to the _tag_.

Image tags work similarly to Git tags as they refer to a specific build of the image. However, Docker tags can be moved
easily, so they do not always need to refer to the same build. The general convention is that the *latest*
tag points to the same (latest) build and is movable.

## Running Docker Images in Keboola
We have wrapped Docker in our [Docker Runner component](/extend/docker-runner/). The component
runs [components](/extend/component/) Docker images. Docker Runner
has an [API](/extend/docker-runner/#api)
which allows to run Docker Images and encrypt arbitrary values.
[Docker Runner](/extend/docker-runner/) takes
care of injecting the right data, creating, running, and terminating the container, and uploading
the result data to Keboola Storage. All images to be run in Keboola must have an `ENTRYPOINT` or `CMD`.

Before you run components in Keboola, make sure to
[set up your Docker environment](/extend/component/docker-tutorial/setup/).
Before you develop a dockerized component for Keboola, you should be able to
[create and run dockerized applications](/extend/component/docker-tutorial/howto/) in your own environment.

If you are already familiar with Docker, jump straight into [component development tutorial](/extend/component/tutorial/)
or explore our sample component code [in PHP](https://github.com/keboola/docker-demo-app).
The demo component itself starts with a single
[`/src/run.php`](https://github.com/keboola/docker-demo-app/blob/master/run.php) script,
can exist independently (without Docker), and contains unit and functional tests.
The repository includes also the Docker image definition in the
[**Dockerfile**](https://github.com/keboola/docker-demo-app/blob/master/Dockerfile). The Docker environment including the component
is prepared by the Docker image definition. The [Travis CI](https://docs.travis-ci.com/) service is used to builds Docker image automatically on every commit and
[deploy it to Keboola](/extend/component/deployment/) and public registries.
A similar component is also available [in Python](https://github.com/keboola/python-custom-application-text-splitter).


================================================
File: extend/component/docker-tutorial/registry.md
================================================
---
title: Docker Registry
permalink: /extend/component/docker-tutorial/registry/
redirect_from:
    - /extend/docker/tutorial/automated-build/
    - /extend/docker/tutorial/registry/
---

* TOC
{:toc}

An important part of the Docker ecosystem is a **Docker registry**. It acts as a folder of images, taking
care of their storing and building.
[Docker Hub](https://hub.docker.com/) is the official Docker registry.

For reliability reasons, we strongly recommend to use the [Amazon AWS ECR](https://aws.amazon.com/ecr/)
[provisioned by the **Keboola Developer Portal**](/extend/component/deployment/).
We also support Docker Hub and [Quay](https://quay.io/), both public and private repositories.

## Working with Registry
In order to run an image, **pull** (`docker pull`) the image to your machine. The `docker run`
command does that automatically for you. So, when you do:

    docker run -i quay.io/keboola/docker-custom-php

you will see something like this:

    Unable to find image 'quay.io/keboola/docker-custom-php:latest' locally
    latest: Pulling from keboola/docker-custom-php
    ad74af05f5a2: Pull complete
    8fa9669af8ec: Pull complete
    Digest: sha256:ff21e0f0e58614aa5d8104d9f263552e583e6ddeb6215e83cae181d5169a150a
    Status: Downloaded newer image for quay.io/keboola/docker-custom-php:latest
    Interactive shell

When you build an image locally, **push** (`docker push`) it to the Docker registry. Then the
image can be shared with anyone (if public), or with your organization (if private).

Because the image is defined only by the Dockerfile instructions (and optionally **build context**), you can take
a shortcut and give the registry only the Dockerfile. The registry will then build the image on its own
infrastructure. This is best done by setting up an [automated deploy script](/extend/component/deployment/) or
by linking a git repository containing the Dockerfile (and usually the application code) with the registry.

## Setting Up Repository on Quay
This may get slightly confusing because we will create a new **Image Repository** and link
that to an existing **Github Repository**. Use the
[sample repository](https://github.com/keboola/docs-docker-example-basic)
created in our [tutorial](/extend/component/docker-tutorial/howto/).

Create an account and organization, and then **create a new repository**:

{: .image-popup}
![Create Repository](/extend/component/docker-tutorial/quay-intro.png)

In the repository configuration, select **Link to a Github Repository Push**:

{: .image-popup}
![Repository configuration](/extend/component/docker-tutorial/quay-new-repository.png)

Then link the image repository to a Github repository. You can use
our [sample repository](https://github.com/keboola/docs-docker-example-basic):

{: .image-popup}
![Link repositories](/extend/component/docker-tutorial/quay-link-repository.png)

After that, configure the build trigger. The easiest way to do that is setting the trigger to
`All Branches and Tags`.
It will trigger an image rebuild on every commit to the repository.
You can also set the build trigger only to a specific branch, for example, `head/master`:

{: .image-popup}
![Configure build trigger for branch](/extend/component/docker-tutorial/quay-build-trigger-master.png)

An alternative option is to configure the trigger to a specific tag. For Semantic versioning,
the following regular expression `^tags/[0-9]+\.[0-9]+\.[0-9]+$` ensures the image is rebuilt only
when you create a new tag.

{: .image-popup}
![Configure build trigger for tag](/extend/component/docker-tutorial/quay-build-trigger-tag.png)

Regardless of your chosen approach, finish setting up the trigger by completing the wizard:

{: .image-popup}
![Configure build trigger](/extend/component/docker-tutorial/quay-build-trigger.png)

Pushing a new commit into a git repository or creating a new tag (depending on the trigger setting) will now
trigger a new build of the Docker image. Also note that the image automatically inherits the git repository tag
or branch name. So, when you push a commit to the `master` branch, you will get an image with a tag `master` (which
will move away from any older image builds). When creating a `1.0.0` tag, you will get an image with a `1.0.0` tag.

When using images in Keboola, we **highly recommend to use our [ECR repository](/extend/component/deployment/)**.


================================================
File: extend/component/docker-tutorial/setup.md
================================================
---
title: Installation and Running
permalink: /extend/component/docker-tutorial/setup/
redirect_from:
    - /extend/docker/tutorial/setup/
---

* TOC
{:toc}

To work with Docker, you need to have it installed. If you do not have a computer with a Docker machine, you can obtain a
cheap [hosted server](https://marketplace.digitalocean.com/apps/docker). You can also
run everything locally. To install a Docker machine on Win/Mac,
use [Docker Community Edition](https://hub.docker.com/search?type=edition&offering=community). For
other systems, see the [documentation](https://docs.docker.com/install/).

## Getting Started
To test that everything is running correctly, start with an example
from the Docker [documentation](https://docs.docker.com/get-started/).
Run the following commands on the command line:

    docker run hello-world


or

    docker run docker.io/library/hello-world:latest

If this works, use any image published in any Docker
registry, e.g. [Docker Hub](https://hub.docker.com/), [Quay](https://quay.io/) or [AWS ECR](https://aws.amazon.com/ecr/).
Note that in some configurations, you may need to use `sudo` to run `docker`. If you run into problems, consult the
official troubleshooting ([Windows](https://docs.docker.com/docker-for-windows/troubleshoot/), [Mac](https://docs.docker.com/docker-for-mac/troubleshoot/)).

## Generally Useful Commands
- [`docker run`](https://docs.docker.com/engine/reference/run/): Run an
image (create a container and run the command in `ENTRYPOINT` or `CMD` section of **Dockerfile**).
- [`docker build`](https://docs.docker.com/engine/reference/commandline/build/): Build
an image (execute instructions in **Dockerfile** and create a runnable image).
- [`docker pull`](https://docs.docker.com/engine/reference/commandline/pull/): Pull
a newer version of an image (force update of the cached copy).

## Sharing Files
Sharing files between the host OS and the container is done using the `--volume` parameter of the `docker run` command:

    docker run --volume=/hostPath/:/containerPath/ imageName

Do not use any spaces around `:`. The details of file sharing are somewhat
[dependent on the host OS](https://docs.docker.com/storage/volumes/) you are using.
There is a very
useful [guide for Rocker image](https://github.com/rocker-org/rocker/wiki/Sharing-files-with-host-machine), which
describes all the sharing options in great detail.

On Linux systems, where Docker runs natively, there is really not much to think about. The only things that can bite
you are file and directory permissions. Keep in mind that files created within the running Docker container on
a mounted host volume will be created with the permissions of users of that container (not the host OS).

On Mac OS, follow the [official example](https://docs.docker.com/docker-for-mac/osxfs/).
The limitation is that your host path must be in a shared directory (e.g., `/Users/`).

On Windows, follow the [official example](https://docs.docker.com/docker-for-windows/#shared-drives).
The limitation is that you must use absolute paths with `docker run`.


================================================
File: extend/component/implementation/index.md
================================================
---
title: Implementation Notes
permalink: /extend/component/implementation/
redirect_from:
    - /extend/docker/images/
---

* TOC
{:toc}

Here are some good practices in developing component code. They're best to be followed
across all components, especially if you want your component to be published. We also recommend
that you check our [component templates](https://github.com/keboola/component-generator).

Developing a component is a challenging task. To maximize your efficiency, follow these basic rules:

- **Do not repeat the functions of existing components.** For example, if you want to download data from Google Drive and transpose the
table, you do not have to create a component for that -- just load the table using the existing extractor and transpose it using
the existing R Transpose Table application.
- **Every component should do only one thing.** For example, if you want to extract data from an API and compute some metrics on them,
make two components -- one for extracting the data and a second one for computing the metrics.
- **Do as little data processing as possible.** As in the above example, having the processing tied to extraction makes it hard to
identify errors in data -- was it extracted incorrectly, or was it processed incorrectly? It also allows the end user to split the
task into smaller ones and have better control over their execution.
- **Avoid optional data modification.** For example, if you have a component which sometimes extracts data in ISO8892 encoding and sometimes
in UTF8 encoding, you do not need to implement this conversion in the component. You can let the end user configure
[processors](/extend/component/processors/) to load the incompatible data.
- **Avoid iterations.** For example, your component is downloading multiple files from a system and converts them to CSV files
for Storage import. You do not need to implement the loop around the files, you can use
[configuration rows](/integrate/storage/api/configurations/#configuration-rows) and implement processing of only a single table.

Before you create any complex components, be sure to read about
[configurations](/integrate/storage/api/configurations/) and [processors](/extend/component/processors/)
as they can substantially simplify your component code. We also recommend that you use our
[common interface](/extend/common-interface/) library, which is available for
[Python](/extend/component/implementation/python/#using-the-kbc-package),
[R](/extend/component/implementation/r/#using-the-kbc-package),
and [PHP](/extend/component/implementation/php/#using-the-kbc-package).

## Docker
You may use any Docker image you see fit. We recommend to base your images on those from an [official repository](https://hub.docker.com/search?q=&type=image)
because they are the most stable ones.

We publicly provide images for transformations and sandboxes.
They both share the same common ancestor image with a couple
of pre-installed packages (that saves a lot of time when building the image yourself).
This means that the images for R and Python share the same common code base and always use the
exact same version of R and Python respectively.

Ancestor images:

- docker-custom-r:
[Quay](https://quay.io/repository/keboola/docker-custom-r),
[Dockerfile](https://github.com/keboola/docker-custom-r) --
Custom R Image
- docker-custom-python:
[Quay](https://quay.io/repository/keboola/docker-custom-python),
[Dockerfile](https://github.com/keboola/docker-custom-python) --
Custom Python Image

Transformations:

- python-transformation:
[Quay](https://quay.io/repository/keboola/python-transformation),
[Dockerfile](https://github.com/keboola/python-transformation) --
Image for Python transformations
- r-transformation:
[Quay](https://quay.io/repository/keboola/r-transformation),
[Dockerfile](https://github.com/keboola/r-transformation) --
Image for R transformations

Sandboxes:

- docker-jupyter:
[Quay](https://quay.io/repository/keboola/docker-jupyter),
[Dockerfile](https://github.com/keboola/docker-jupyter) --
Image for Python Jupyter Sandbox
- docker-rstudio:
[Quay](https://quay.io/repository/keboola/docker-rstudio),
[Dockerfile](https://github.com/keboola/docker-rstudio) --
Image for RStudio Sandbox

All of the repositories use [Semantic versioning](http://semver.org/) tags. These are always fixed to a specific image build.
Additionally, the `latest` tag is available and always points to the latest tagged build. That means that the `latest` tag
can be used safely (though it refers to different versions over time).

## Memory
Keboola [components](/extend/component/) can be used to process substantial amounts of data (i.e., dozens of gigabytes), which are not
going to fit into memory. Every component should therefore be written so that it processes data in chunks of
a limited size (typically rows of a table). Many of the Keboola components run with less than 100MB memory.
While the Keboola platform is capable of running jobs with ~8GB of memory without problems, we are not particularly
happy to allow it, and we certainly do not want to allow components where the amount of used memory
depends on the size of the processed data.

## Error Handling
Depending on the component [exit code](/extend/common-interface/environment/#return-values), the component job is marked as
successful or failed.

- `exit code = 0`  The job is considered **successful**.
- `exit code = 1`  The job fails with a **user error**.
- `exit code > 1`  The job fails with an **application error**.

During a component execution, all the output sent to STDOUT is captured and sent live to job events.
The output to [STDERR](https://en.wikipedia.org/wiki/Standard_streams#Standard_error_.28stderr.29) is captured too, and
in case the job is successful or fails with a user error, it is displayed as the last event of the job. In case the
job ends with an application error, the entire contents of STDERR is hidden from the end user and sent only to
vendor internal logs. The end user will see only a canned response ('An application error occurred') with
the option to contact our support.

This means that you do not have to worry about the internals of your component leaking to the end user provided that
the component exit code is correct. On the other hand, the user error is supposed to be solvable by the end user. When creating an error message, stick by the following rules:

- Avoid **nonsense** messages. For example: 'Banana Error: Exceeding trifling witling' or only numeric errors.
- Avoid **errors users cannot solve**. For example: 'An outdated OpenSSL library, update to OpenSSL 1.0.2'.
- Provide **guidance** on what the user should do. For example: 'The input table is missing; make sure the output mapping destination is set to `items.csv`'.
- Avoid deliberate **leaking** sensitive information. For example: credentials, tokens. The output of each component is [filtered](/extend/common-interface/logging/#standard-output-and-standard-error) to prevent *accidental* leaks of sensitive information. That means you don't need to implement filtering for example for exception messages.

Also keep in mind that the output of the components (job events) serve to pass only informational and error messages; **no data** can be passed through.
The event message size is limited (about 64KB). If the limit is exceeded, the message will be trimmed. If the component produces
obscene amount (dozens of MBs) of output in a very short time, it may be terminated with an internal error.
Also make sure your component does not use any [output buffering](#language-specific-notes), otherwise all events will be cached after the application finishes.

## Implementing Processors
[Processors](/extend/component/processors/)
allow the end user to customize the input to the component and the output from it. That means
that many custom requirements can be solved by processors, keeping the component
code general.

Choosing whether to implement a specific feature as a processor or as part of your
component may be difficult. A processor might be a good solution if the following are true:

- The feature is **optional** (not all end users are interested in it).
- The feature is **simple** (one operation, contains no internal logic).
- The feature is **universal** (it is always applied to all input/output or none).

The first condition is especially important. Another way to read it is that a processor must never supply a function expected from the component.
In other words: **Each component should be able to consume/generate a valid input/output without any processors.** For example, if an extractor can
produce tables without any further processing, good, let it be tables, but if can not, it should output only files and processors should do the rest.
If processors are used together with [configuration rows](/integrate/storage/api/configurations/#configuration-rows),
the last condition is weakened, because a different set of processors may be applied to each configuration row.

### Design
Implementing a processor is in principle the same as implementing any other
[component](/extend/component/). However, processors are designed to be
[single responsibility](https://en.wikipedia.org/wiki/Single_responsibility_principle) components. This
means, for example, that processors should require no or very little configuration, should not communicate
over a network and should be fast.

Processors take data from the `in` [data folders](/extend/common-interface/folders/) and
store it in the `out` [data folders](/extend/common-interface/folders/) as any other components. Keep in mind, however,
that any files not copied to the `out` folders will be ignored (i.e., lost). That means if a processor is supposed to
"not touch" something, it actually has to copy that something to the `out` folder.

The processors should be aware of [manifest files](/extend/common-interface/manifest-files/). This means that
the processor:

- Must exclude manifests from processing (they are not data files).
- If the processor changes something stored in the manifest, it must process it (read the manifests in `in` folder, modify and store it in the `out` folder). Typical example is modification of table columns which must be reflected in the manifest.
- If the processor is doing change unrelated to manifest, it should copy the manifest from `in` to `out`.
- If the processor is not doing a 1:1 operation (e.g merges multiple tables into one), it should not do anything about the manifest, which means that it will be discarded.

Keep in mind that processors can be [chained](/extend/component/processors/#chaining-processors);
you can, for example, rely on

- the table CSV files being in [standard format](https://help.keboola.com/storage/tables/csv-files/#output-csv-format).
- table manifest always present.
- the CSV file being orthogonal.

If the above conditions are not met, then another processor should be added before yours. I.e. you should keep the
processor simple and delegate the assumptions to other processors (and [**document** them](#publishing-a-processor)). If possible the
processor should also assume that the CSV files are headless and stored in arbitrary sub-folders. When implemented with this assumption
the processor will support [sliced tables](/extend/common-interface/folders/#sliced-tables).

### Publishing Processor
The process of processor registration is the same as [publishing any other component](/extend/publish/).
However, many of the fields do not apply, because processors have no UI.
The following fields are important:

- Vendor
- Component name and component type (`processor`)
- Short and full description
- Component documentation (`documentationUrl`)
    - must be public
    - must state whether the processor is capable of working with [sliced tables](/extend/common-interface/folders/#sliced-tables)
    - whether it requires/processes manifests


================================================
File: extend/component/implementation/php.md
================================================
---
title: PHP Implementation Notes
permalink: /extend/component/implementation/php/
redirect_from:
    - /extend/custom-science/php/
---

* TOC
{:toc}

## Docker
Use the [official images](https://hub.docker.com/_/php/) if possible. Usually, the `alpine` versions are sufficient and are the
smallest and fastest. If you need Composer, use its [official image](https://hub.docker.com/_/composer/) or
[our templates](https://github.com/keboola/component-generator/blob/master/templates/).

## Working with CSV Files
We recommend using our [CSV library](https://github.com/keboola/php-csv), which provides a convenience wrapper
around the build-in [CSV functions](https://www.php.net/manual/en/function.fgetcsv.php). However, the functions work well on their own too.
If you are using bare PHP functions, the following code illustrates their use:

{% highlight php %}
<?php
$fhIn = fopen('/data/in/tables/source.csv', 'r');
$fhOut = fopen('/data/out/tables/destination.csv', 'w');
$header = fgetcsv($fhIn);
$numberIndex = array_search('number', $header);
fputcsv($fhOut, array_merge($header, ['double_number']));
while ($row = fgetcsv($fhIn)) {
	$row[] = $row[$numberIndex] * 2;
	fputcsv($fhOut, $row);
}
fclose($fhIn);
fclose($fhOut);
echo "All done";
{% endhighlight %}

Note that we open both the input and output files simultaneously; as soon as a row is processed,
it is immediately written to the destination file. This approach keeps only a single row of data in the memory and is
generally very efficient. It is recommended to implement the processing in this way because data files
coming from Keboola can be quite large.

The same can be achieved via the [CSV library](https://github.com/keboola/php-csv). Install the
package with `composer require keboola/csv`. The following
piece of code uses it and reads the [configuration file](/extend/common-interface/config-file/).

{% highlight php %}
<?php

require "vendor/autoload.php";

// read the configuration file
$dataDir = getenv('KBC_DATADIR') . DIRECTORY_SEPARATOR;
$configFile = $dataDir . 'config.json';
$config = json_decode(file_get_contents($configFile), true);

$multiplier = $config['parameters']['multiplier'];

// create output file and write header
$outFile = new \Keboola\Csv\CsvFile(
    $dataDir . 'out' . DIRECTORY_SEPARATOR . 'tables' . DIRECTORY_SEPARATOR . 'destination.csv'
);
$outFile->writeRow(['number', 'someText', 'double_number']);

// read input file and write rows of output file
$inFile = new Keboola\Csv\CsvFile($dataDir . 'in' . DIRECTORY_SEPARATOR . 'tables' . DIRECTORY_SEPARATOR . 'source.csv');
foreach ($inFile as $rowNum => $row) {
    if ($rowNum == 0) {
        // skip header
        continue;
    }
    $outFile->writeRow([
        $row[0],
        $row[1],
        $row[0] * $multiplier
    ]);
}
{% endhighlight %}

## Using Keboola Package
Keboola's [PHP component package](https://github.com/keboola/php-component) provides functions to

- read and parse the configuration file and parameters: 
	`getConfig` method or `getConfig()->getParameters()` methods.
- list input files and tables: `getConfig()->getInputFiles()`, `getConfig()->getInputTables()` methods.
- work with manifests containing table and file metadata: `getManifestManager()->getTableManifest()`, `getManifestManager()->writeTableManifest()`, `getManifestManager()->getFileManifest()`, `getManifestManager()->writeFileManifest()` methods.
- list expected outputs: `getConfig()->getExpectedOutputFiles()` or `getConfig()->getExpectedOutputTables()` methods.

You can go through the [generated docs](https://keboola.github.io/php-component/master/classes.html) of all available methods and classes.
The package can be installed by [Composer](https://getcomposer.org/):

    composer require keboola/php-component

The package can be used standalone (good for existing code), or you can inherit your own component from it (good for new components).
When inheriting from the package, see the [GitHub repository](https://github.com/keboola/php-component) for examples, or
our [component template](https://github.com/keboola/component-generator/tree/master/templates).
Using the package as a standalone class does not require anything else than creating its instance:

{% highlight php %}
<?php

require "vendor/autoload.php";

$component = new \Keboola\Component\BaseComponent();
$parameters = $component->getConfig()->getValue(['parameters']);
var_export($parameters);

$inputTables = $component->getConfig()->getInputTables();
var_export($inputTables);
{% endhighlight %}

The configuration is read from the [data folder](/extend/common-interface/config-file/) specified by the
[KBC_DATADIR environment variable](https://developers.keboola.com/extend/common-interface/environment/).
Given the following `config.json` file:

{% highlight json %}
{
    "storage": {
        "input": {
            "tables": [
                {
                    "source": "in.c-main.sample",
                    "destination": "source.csv"
                }
            ],
            "files": []
        }
    },
    "parameters": {
        "myParameter": "myValue",
        "repeat": 2
    }
}
{% endhighlight %}

The above PHP code would output:

{% highlight php %}
array (
  'myParameter' => 'myValue',
  'repeat' => 2,
)array (
  0 =>
  array (
    'source' => 'in.c-main.sample',
    'destination' => 'source.csv',
  ),
)
{% endhighlight %}

### Dynamic Input/Output Mapping
In the [tutorial](/extend/component/tutorial/) and the above examples, we show
applications which have names of their input/output tables hard-coded.
The following example shows how to read an input and output mapping specified by the end user,
which is accessible in the [configuration file](/extend/common-interface/config-file/). It demonstrates
how to read and write tables and table manifests. File manifests are handled the same way. For a full authoritative list
of items returned in table list and manifest contents, see [the specification](/extend/common-interface/config-file/).

Note that the `destination` label in the script refers to the destination from the
[mapper](/extend/component/tutorial/input-mapping/) perspective.
The input mapper takes `source` tables from the user's storage and produces `destination` tables that become
the input of your component. The output tables of your component are consumed by the output mapper
whose `destination` are the resulting tables in Storage.

The following piece of code reads an arbitrary number of tables and adds an auto-generated primary key
to them. The name of the added column is configured in parameters (`primaryKeyName`). Also, the
step of the generator is configured in parameters (`primaryKeyStep`). The end of the code writes
a table [manifest file](/extend/common-interface/manifest-files/) which stores the configuration of
the primary key and optional table metadata.

{% highlight php %}
<?php

require "vendor/autoload.php";

$component = new \Keboola\Component\BaseComponent();
$inputTables = $component->getConfig()->getInputTables();

$j = 0;
foreach ($inputTables as $inputTable) {
    // get csv file name
    $inFileName = $component->getDataDir() . '/in/tables/' . $inputTable['destination'];

    // get file name from output mapping
    $outFileName = $component->getDataDir() . '/out/tables/' .
        $component->getConfig()->getExpectedOutputTables()[$j]['destination'];

    // read table manifest
    $manifest = $component->getManifestManager()->getTableManifest($inFileName);

    // open input and output files
    $inFile = new \Keboola\Csv\CsvFile($inFileName);
    $outFile = new \Keboola\Csv\CsvFile($outFileName);
    // get value of `primaryKeyName` parameter
    $columnName = $component->getConfig()->getParameters()['primaryKeyName'];

    // process table data
    $header = $inFile->getHeader();
    array_push($header, $columnName);
    $outFile->writeRow($header);
    $i = 0;
    foreach ($inFile as $row) {
        // skip the first line with header
        if ($i != 0) {
            // add generated primary key
            array_push($row, $i);
            $outFile->writeRow($row);
        }
        // get value of `primaryKeyStep` parameter (different approach to `primaryKeyName` above)
        $i = $i + $component->getConfig()->getValue(['parameters', 'primaryKeyStep']);
    }

    // store table metadata
    $metadata = $manifest['metadata'];
    array_push($metadata, [["key" => "sample", "value" => "metadata"]]);

    // create table manifest with primary ket and metadata
    $component->getManifestManager()->writeTableManifestFromArray(
        $outFileName,
        [
            'primary_key' => [$columnName],
            'metadata' => $metadata,
        ]
    );
    $j++;
}
{% endhighlight %}

## Logging
For simple applications, printing with `echo` or `print` is enough. To print to STDERR, you have to use
e.g., `fwrite(STDERR, "Hello, world!" . PHP_EOL);`. The best option is to use the [Monolog package](https://github.com/Seldaek/monolog).
The following is a useful initialization:

{% highlight php %}
$formatter = new LineFormatter("%message%\n");
$errHandler = new StreamHandler('php://stderr', Logger::NOTICE, false);
$errHandler->setFormatter($formatter);
$handler = new StreamHandler('php://stdout', Logger::INFO);
$handler->setFormatter($formatter);
$logger = new Logger('main', [$errHandler, $handler]);
{% endhighlight %}

This means that a log with the [NOTICE level](https://github.com/Seldaek/monolog/blob/master/doc/01-usage.md#log-levels) and above
will go to STDERR, and the INFO level will go to STDOUT. The formatter removes unnecessary fields like `timestamp` and `context`.

## Error Handling
The following [piece of code](https://github.com/keboola/component-generator/blob/master/templates/php-component/src/run.php) is a good entry point:

{% highlight php %}
$logger = new Logger();
try {
    $app = new Component($logger);
    $app->execute();
    exit(0);
} catch (UserException $e) {
    $logger->error($e->getMessage());
    exit(1);
} catch (\Throwable $e) {
    $logger->critical(
        get_class($e) . ':' . $e->getMessage(),
        [
            'errFile' => $e->getFile(),
            'errLine' => $e->getLine(),
            'errCode' => $e->getCode(),
            'errTrace' => $e->getTraceAsString(),
            'errPrevious' => $e->getPrevious() ? get_class($e->getPrevious()) : '',
        ]
    );
    exit(2);
}
{% endhighlight %}

In this case, we consider everything derived from `UserException` to be an error which should be shown to the end user.
You have to create that exception class in your component. Every other error will lead to a generic message; only
the developer will see the details, and the code will follow the [general error handling rules](#error-handling).
Here we use the [`Throwable`](https://www.php.net/manual/en/class.throwable.php) ancestor, which also catches PHP errors. You can, of
course, modify this logic to your liking.


================================================
File: extend/component/implementation/python.md
================================================
---
title: Python Implementation Notes
permalink: /extend/component/implementation/python/
redirect_from:
    - /extend/custom-science/python/
---

* TOC
{:toc}

## Docker
Use the [official images](https://hub.docker.com/_/python/) if possible. Usually, the `alpine` versions are sufficient and are the
smallest and fastest. We recommend using [our templates](https://github.com/keboola/component-generator/tree/master/templates).

## Working with CSV Files
We advise you to follow the guidelines for the [Python transformation](https://help.keboola.com/manipulation/transformations/python/#development-tutorial).

The build-in CSV functions for Python work well except when the data in the CSV file contain a null character. This is
[usually fixed](https://stackoverflow.com/questions/4166070/python-csv-error-line-contains-null-byte) by
adding `lazy_lines = (line.replace('\0', '') for line in in_file)`. The expression
is a [generator](https://wiki.python.org/moin/Generators) which makes sure that
[null characters](https://en.wikipedia.org/wiki/Null_character) are properly handled.
It is also important to use `encoding='utf-8'` when reading and writing files.

{% highlight python %}
import csv

csvlt = '\n'
csvdel = ','
csvquo = '"'
with open('in/tables/source.csv', mode='rt', encoding='utf-8') as in_file, open('out/tables/destination.csv', mode='wt', encoding='utf-8') as out_file:
    writer = csv.DictWriter(out_file, fieldnames=['col1', 'col2'], lineterminator=csvlt, delimiter=csvdel, quotechar=csvquo)
    writer.writeheader()

    lazy_lines = (line.replace('\0', '') for line in in_file)
    reader = csv.DictReader(lazy_lines, lineterminator=csvlt, delimiter=csvdel, quotechar=csvquo)
    for row in reader:
        # do something and write row

        writer.writerow({'col1': row['first'] + 'ping', 'col2': int(row['second']) * 42})
{% endhighlight %}

Note that we open both the input and output files simultaneously; as soon as a row is processed,
it is immediately written to the output file. This approach keeps only a single row of data in the memory and is
generally very efficient. It is recommended to implement the processing in this way because data files
coming from Keboola can be quite large (i.e., dozens of gigabytes).

## Using Keboola Python Package
The [Python component package](https://github.com/keboola/python-component) provides a Python wrapper over the
[Keboola Common Interface](https://developers.keboola.com/extend/common-interface/). It simplifies all tasks related
 to the communication of the [component](https://developers.keboola.com/extend/component/) with 
 Keboola that is defined by the Common Interface. Such tasks are config manipulation, validation, 
 component state, I/O handling, I/O metadata and manifest files, logging, etc.
 
 **NOTE:** That this package is a replacement for the previous legacy [Python docker application](https://github.com/keboola/python-docker-application)

The `CommonInterface` class provides following methods:

- read and parse the configuration file and parameters: `configuration` object and `configuration.parameters` properties.
- list input files and tables represented by Python objects for easier manipulation: 
- work with [manifests](/extend/common-interface/manifest-files/) containing table and file metadata: `get_table_manifest()`, `get_file_manifest()`, `write_table_manifest()`, `write_file_manifest()` methods.
- list expected outputs: `configuration.files_input_mapping`, `configuration.tables_input_mapping` properties.

The library is a standard Python package that is available by default in the production environment.
It is a public PYPI project [keboola.component](https://pypi.org/project/keboola.component/), so it can be installed
locally with `pip3 install keboola.component`.

A generated [API documentation](https://htmlpreview.github.io/?https://raw.githubusercontent.com/keboola/python-component/main/docs/api-html/component/interface.html)
is available for the package, and an actual working example can be found in our
[Python template](https://bitbucket.org/kds_consulting_team/kbc-python-template/src/master/src/component.py).

### Initialization

The core class is `keboola.component.interface.CommonInterface`, upon its initialization the environment is 
created. e.g.

- data folder initialized (either from the [Environment Variable](/extend/common-interface/environment/#environment-variables) or manually)
- [Configuration file](/extend/common-interface/config-file/) is loaded
- All Environment variables are loaded

The optional parameter `data_folder_path` of the constructor is the path to the data directory.
If not provided, [`KBC_DATADIR` environment variable](/extend/common-interface/environment/#environment-variables) will be used.

The class can be either extended or just instantiated and manipulated like object. 
The `CommonInterface` class is exposed in the `keboola.component` namespace:

```python
from keboola.component import CommonInterface
# init the interface
# A ValueError error is raised if the KBC_DATADIR does not exist or contains non-existent path.
ci = CommonInterface()
```

### Loading configuration parameters

The below example loads initializes the common interface class and automatically loading config.json from the 
[data folder](https://developers.keboola.com/extend/common-interface/folders/) 
 
 **NOTE:** The `configuration` object is initialized upon access and a ValueError is thrown if the `config.json` does not exist 
 in the data folder. E.g., `cfg = ci.configuration` may throw a ValueError even though the data folder exists and ci (CommonInterface) 
 is properly initialized.

```python
from keboola.component import CommonInterface
# Logger is automatically set up based on the component setup (GELF or STDOUT)
import logging

SOME_PARAMETER = 'myParameter'
REQUIRED_PARAMETERS = [SOME_PARAMETER]

# init the interface
# A ValueError error is raised if the KBC_DATADIR does not exist or contains non-existent path.
ci = CommonInterface()

# A ValueError error is raised if the config.json file does not exists in the data dir.
# Checks for required parameters and throws ValueError if any is missing.
ci.validate_configuration(REQUIRED_PARAMETERS)

# print Keboola Project ID from the environment variable if present:
logging.info(ci.environment_variables.project_id)

# load particular configuration parameter
logging.info(ci.configuration.parameters[SOME_PARAMETER])
```


The above would read the `somemyParameter_user_parameter` parameter from the user-supplied configuration:

{% highlight json %}
{
    "myParameter": "myValue"
}
{% endhighlight %}

The following piece of code shows how to read parameters:

{% highlight python %}
import csv
from keboola.component import CommonInterface

# initialize the library and read parameter 'multiplier'
ci = CommonInterface()
multiplier = ci.configuration.parameters['multiplier']

# open the input and output files
with open('in/tables/source.csv', mode='rt', encoding='utf-8') as in_file, open('out/tables/destination.csv', mode='wt', encoding='utf-8') as out_file:
    # write output file header
    writer = csv.DictWriter(out_file, fieldnames=['number', 'someText', 'double_number'], dialect='kbc')
    writer.writeheader()

    # read input file line-by-line
    lazy_lines = (line.replace('\0', '') for line in in_file)
    csv_reader = csv.DictReader(lazy_lines, dialect='kbc')
    for row in csv_reader:
        # do something and write row
        writer.writerow({'number': row['number'], 'someText': row['someText'], 'double_number': int(row['number']) * multiplier})
{% endhighlight %}

Note that we have also simplified reading and writing of the CSV files using the `dialect='kbc'` option. The dialect is
registered automatically when the `CommonInterface` class is initialized.

### Processing input tables -- Manifest vs I/O mapping

Input and output tables specified by the user are listed in the [configuration file](/extend/common-interface/config-file/). 
Apart from that, all input tables provided by user also include manifest file with additional metadata.

Tables and their manifest files are represented by the `keboola.component.dao.TableDefinition` object and may be loaded 
using the convenience method `get_input_tables_definitions()`. The result object contains all metadata about the table,
such as [manifest file](/extend/common-interface/manifest-files/#dataintables-manifests) representations (if present), system path and name.

#### Manifest & input folder content

```python
from keboola.component import CommonInterface
import logging

# init the interface
ci = CommonInterface()

input_tables = ci.get_input_tables_definitions()

# print path of the first table (random order)
first_table = input_tables[0]
logging.info(f'The first table named: "{first_table.name}" is at path: {first_table.full_path}')

# get information from table manifest
logging.info(f'The first table has following columns defined in the manifest {first_table.column_names}')

```

#### Get input table by name

```python
from keboola.component import CommonInterface

# init the interface
ci = CommonInterface()
table_def = ci.get_input_table_definition_by_name('input.csv')
```

#### Using I/O mapping

```python
import csv
from keboola.component import CommonInterface

# initialize the library
ci = CommonInterface()

# get list of input tables from the input mapping ()
tables = ci.configuration.tables_input_mapping
j = 0
for table in tables:
    # get csv file name
    inName = table.destination
    
    # read input table manifest and get its physical representation
    table_def = ci.get_input_table_definition_by_name(table.destination)

    # get csv file name with full path from output mapping
    outName = ci.configuration.tables_output_mapping[j].full_path

    # get file name from output mapping
    outDestination = ci.configuration.tables_output_mapping[j]['destination']
```

### Output tables - manifest files and processing results

The component may define output [manifest files](https://developers.keboola.com/extend/common-interface/manifest-files/#dataouttables-manifests) 
that define options on storing the results back to the Keboola Storage. This library provides methods that simplifies 
the manifest file creation and allows defining the export options.

`TableDefinition` object serves as a result container containing all the information needed to store the Table into the Storage. 
It contains the manifest file representation and initializes all attributes available in the manifest.
This object represents both Input and Output manifests. All output manifest attributes are exposed in the class.

There are convenience method for manifest creation `CommonInterface.write_tabledef_manifest()`. 
Also it is possible to create the container for the output table using the `CommonInterface.create_out_table_definition()`
(useful particularly when working with [sliced tables](/extend/common-interface/folders/#sliced-tables)).

```python
from keboola.component import CommonInterface
from keboola.component.dao import ColumnDefinition, DataType, SupportedDataTypes, BaseType

# init the interface
ci = CommonInterface(data_folder_path='data')

# create container for the result
out = ci.create_out_table_definition("testDef",
                                     schema=['foo', 'bar'],
                                     destination='some-destination',
                                     primary_key=['foo'],
                                     incremental=True,
                                     delete_where={'column': 'lilly',
                                                   'values': ['a', 'b'],
                                                   'operator': 'eq'})

# update column
out.update_column('foo',
                  ColumnDefinition(data_types=BaseType(dtype=SupportedDataTypes.INTEGER, length='20')))

# add new columns
out.add_column('note', ColumnDefinition(nullable=False))
out.add_column('test1')
out.add_columns(['test2', 'test3', 'test4'])

# add new typed column
out.add_column('id', ColumnDefinition(primary_key=True,
                                      data_types={'snowflake': DataType(dtype="INTEGER", length='200')})
               )

out.add_columns({
    'phone': ColumnDefinition(primary_key=True,
                              data_types={'snowflake': DataType(dtype="INTEGER", length='200'),
                                          'bigquery': DataType(dtype="BIGINT")}),
    'new2': ColumnDefinition(data_types={'snowflake': DataType(dtype="INTEGER", length='200')}),
                 })

# delete columns
out.delete_column('bar')
out.delete_columns(['test2', 'test3'])


# write some content
with open(out.full_path, 'w') as result:
    result.write('line')
    
# write manifest
ci.write_manifest(out)
```


### Processing input files

Similarly as tables, [files and their manifest files](/extend/common-interface/folders/#folder-datainfiles) are represented by the `keboola.component.dao.FileDefinition` object and may be loaded 
using the convenience method `get_input_files_definitions()`. The result object contains all metadata about the file,
such as manifest file representations, system path and name.

The `get_input_files_definitions()` supports filter parameters to filter only files with a specific tag or retrieve only the latest file of each. 
This is especially useful because the Keboola input mapping will by default include all versions of files matching specific tag. By default, the method 
returns only the latest file of each.

```python
from keboola.component import CommonInterface
import logging

# init the interface
ci = CommonInterface()

input_files = ci.get_input_files_definitions(tags= ['my_tag'], only_latest_files=True)

# print path of the first file (random order) matching the criteria
first_file = input_files[0]
logging.info(f'The first file named: "{input_files.name}" is at path: {input_files.full_path}')
```


When working with files it may be useful to retrieve them in a dictionary structure grouped either by name or a tag group. 
For this there are convenience methods `get_input_file_definitions_grouped_by_tag_group()` and `get_input_file_definitions_grouped_by_name()`


```python
from keboola.component import CommonInterface
import logging

# init the interface
ci = CommonInterface()

# group by tag
input_files_by_tag = ci.get_input_file_definitions_grouped_by_tag_group(only_latest_files=True)

# print list of files matching specific tag
logging.info(input_files_by_tag['my_tag']) 

# group by name
input_files_by_name = ci.get_input_file_definitions_grouped_by_name(only_latest_files=True)

# print list of files matching specific name
logging.info(input_files_by_name['image.jpg'])

```

#### Processing state files

[State files](/extend/common-interface/config-file/#state-file) can be easily loaded and written 
using the `get_state_file()` and `write_state_file()` methods:
 
```python
from keboola.component import CommonInterface
from datetime import datetime
import logging

# init the interface
ci = CommonInterface()

last_state = ci.get_state_file()

# print last_updated if exists
logging.info(f'Previous job stored following last_updated value: {last_state.get("last_updated","")})')

# store new state file
ci.write_state_file({"last_updated": datetime.now().isoformat()})
```

### Logging

The library automatically initializes STDOUT or GELF logger based on the presence of the `KBC_LOGGER_PORT/HOST` environment variables 
upon the `CommonInterface` initialization. To use the GELF logger just enable the logger for your application in the 
[Developer Portal](https://components.keboola.com/). 
More details about logging options are available in a [dedicated article](/extend/common-interface/logging/#examples).

With either setting, you can log your messages using the logging library:

```python
from keboola.component import CommonInterface
from datetime import datetime
import logging

# init the interface
ci = CommonInterface()

logging.info("Info message")
```

To fully leverage the benefits of the GELF logger such as outputting the `Stack Trace` into the log event detail (available by clicking on the log event) 
log exceptions using `logger.exception(ex)`.

**TIP:** When the logger verbosity is set to `verbose` you may leverage `extra` fields to log the detailed message 
in the detail of the log event by adding extra fields to you messages:

```python
logging.error(f'{error}. See log detail for full query. ',
                         extra={"failed_query": json.dumps(query)})
```


If you use STDOUT logging note that in Python components, the output is buffered. The buffering may 
be [switched off](https://stackoverflow.com/questions/107705/disable-output-buffering). The easiest solution is to run your script
with the `-u` option: you would use `CMD python -u ./main.py` in your `Dockerfile`.

## Error Handling
The following [piece of code](https://github.com/keboola/component-generator/blob/master/templates/python-tests/src/main.py) is a good entry point:

{% highlight python %}
import my_component
import os
import sys
import traceback

try:
    datadir = os.environ.get('KBC_DATADIR') or '/data/'
    my_component.run(datadir)
except ValueError as err:
    print(err, file=sys.stderr)
    sys.exit(1)
except Exception as err:
    print(err, file=sys.stderr)
    traceback.print_exc(file=sys.stderr)
    sys.exit(2)
{% endhighlight %}

In this case, we consider everything derived from `ValueError` to be an error which should be shown to the end user.
Every other error will lead to a generic message, and only developers will see the details.
If you maintain that any user error is a `ValueError`, then whatever happens in the `my_component.run` will follow
the [general error handling rules](#error-handling).
You can, of course, modify this logic to your liking.


================================================
File: extend/component/implementation/r.md
================================================
---
title: R Implementation Notes
permalink: /extend/component/implementation/r/
redirect_from:
    - /extend/custom-science/r/
---

* TOC
{:toc}

## Docker
We recommend using the [Rocker version-stable](https://github.com/rocker-org/rocker-versioned) [images](https://hub.docker.com/r/rocker/r-ver/).
The [R base image](https://hub.docker.com/r/rocker/r-base/) does not keep older R versions, so the upgrades are not under your control.
If you want to use the same environment as in transformations, use [our image](#docker).

## Working with CSV Files
We recommend that you follow the guidelines for the [R transformation](https://help.keboola.com/manipulation/transformations/r/#development-tutorial).
The standard R functions for CSV files work without problems:

{% highlight R %}
data <- read.csv(file = "in/tables/source.csv");

df <- data.frame(
  col1 = paste0(data$first, 'ping'),
  col2 = data$second * 42
)
write.csv(df, file = "out/tables/result.csv", row.names = FALSE)
{% endhighlight %}

You can also use the `write_csv` function from the [readr packages](https://cran.r-project.org/web/packages/readr/readr.pdf). It is faster.

## Using Keboola Package
Keboola's [R component package](https://github.com/keboola/r-docker-application) provides functions to

- read and parse the configuration file and parameters: `configData` property and `getParameters()` method.
- list input files and tables: `getInputFiles()`, `getInputTables()` methods.
- work with manifests containing table and file metadata: `getTableManifest()`, `getFileManifest()`, `writeTableManifest()`, `writeFileManifest()` methods.
- list expected outputs: `getExpectedOutputFiles()` and `getExpectedOutputTables()` methods.

The library is a standard R package that is available by default in the production environment.
[Ready for use on GitHub](https://github.com/keboola/r-docker-application), it can be installed locally with `devtools::install_github('keboola/r-docker-application', ref = 'master')`.

Use the library to read a user-supplied configuration parameter 'myParameter':

{% highlight r %}
library(keboola.r.docker.application)
# initialize library
app <- keboola.r.docker.application::DockerApplication$new()
app$readConfig()

# access the supplied value of 'myParameter'
app$getParameters()$myParameter
{% endhighlight %}

The library contains a single [RC class](http://adv-r.had.co.nz/OO-essentials.html#rc) `DockerApplication`; the parameter of the constructor is the path to the data directory.
After that you can call `readConfig()` to actually read and parse the configuration file, and then read the `myParameter` parameter from the user-supplied configuration:

{% highlight json %}
{
    "myParameter": "myValue"
}
{% endhighlight %}

When the application is initialized `app <- keboola.r.docker.application::DockerApplication$new()`, it read the configuration file from the constructor
argument, if no argument is provided, the [`KBC_DATADIR` environment variable](/extend/common-interface/environment/#environment-variables) is used.
You can obtain inline help and the list of library functions by running the `?DockerApplication` command.

### Dynamic Input/Output Mapping
In our [tutorial](/extend/component/tutorial/), we show components which have names of their input/output tables hard-coded.
The following example shows how to read the input and output mapping specified by the end user,
which is accessible in the [configuration file](/extend/common-interface/config-file/). It demonstrates
how to read and write tables and table manifests. File manifests are handled the same way. For a full authoritative list
of items returned in table list and manifest contents, see [the specification](/extend/common-interface/config-file/).

Note that the `destination` label in the script refers to the destination from the
[mapper perspective](/extend/component/tutorial/input-mapping/). The input mapper takes `source` tables
from the user's storage and produces `destination` tables that become the input of the component. The output tables
of the component are consumed by the output mapper whose `destination` are the resulting tables in Storage.

{% highlight r %}
# initialize library
app <- DockerApplication$new()
app$readConfig()

# get list of input tables
tables <- app$getInputTables()
for (i in 1:nrow(tables)) {
    # get csv file name
    name <- tables[i, 'destination']

    # get csv full path and read table data
    data <- read.csv(tables[i, 'full_path'])

    # read table metadata
    manifest <- app$getTableManifest(name)
    if ((length(manifest$primary_key) == 0) && (nrow(data) > 0)) {
        # no primary key present, create one
        data[['primary_key']] <- seq(1, nrow(data))
    } else {
        data[['primary_key']] <- NULL
    }


    # do something clever
    names(data) <- paste0('batman_', names(data))

    # get csv file name with full path from output mapping
    outName <- app$getExpectedOutputTables()[i, 'full_path']
    # get file name from output mapping
    outDestination <- app$getExpectedOutputTables()[i, 'destination']

    # write output data
    write.csv(data, file = outName, row.names = FALSE)

    # write table metadata - set new primary key
    app$writeTableManifest(outName, destination = outDestination, primaryKey = c('batman_primary_key'))
}
{% endhighlight %}

To test the code, set an arbitrary number of input/output mapping tables. Keep in mind to set the same number
of inputs and outputs. The names of the CSV files are arbitrary.

{: .image-popup}
![Dynamic mapping screenshot](/extend/component/dynamic-mapping.png)

## Logging
In R components, the outputs printed in rapid succession are sometimes joined into a single event;
this is a known behavior of R and it has no workaround. See a [dedicated article](/extend/common-interface/logging/#examples) if you want to
implement a GELF logger.


================================================
File: extend/component/running/index.md
================================================
---
title: Running Components
permalink: /extend/component/running/
redirect_from:
    - /extend/docker/running/
    - /extend/common-interface/sandbox/
---

* TOC
{:toc}

One of the great advantages of dockerized components is that the components always run in the
same environment defined by the Docker image. When running in Keboola, there are, however, some outside
environment bindings for you to take care of.

Before you start, make sure you have [Docker set up correctly](/extend/component/docker-tutorial/setup/),
particularly that you know your **host path** for [sharing files](/extend/component/docker-tutorial/setup#sharing-files)
and that you understand the basic concepts of creating a [Dockerized application](/extend/component/docker-tutorial/howto/).
In this guide, we will use `/user/johndoe/data/` as the **host path** containing the
[data folder](/extend/common-interface/folders/).

You can also run your component in your own environment. In that case, set the `KBC_DATADIR` environment
variable to point to the data folder. With this approach, you loose the advantage of the properly defined
environment, but in some cases, it may be a nice shortcut.

For more details on how to develop a component, see the corresponding [tutorial](/extend/component/tutorial/),
especially the part on [debugging](/extend/component/tutorial/debugging/).

## Basic Run
The basic run command we use (assuming that we want to run the
[`keboola-test.ex-docs-tutorial`](https://github.com/keboola/ex-docs-tutorial) component) is as follows:

    docker run --volume=/user/johndoe/data/:/data --memory=4000m --net=bridge -e KBC_RUNID=123456789 -e KBC_PROJECTID=123 -e KBC_DATADIR=/data/ -e KBC_CONFIGID=test-123 quay.io/keboola/keboola-test.ex-docs-tutorial

The `--volume` parameter ensures the `/data/` folder will be mounted into the image. This is used
to inject the input data and configuration into the image. Make sure not to put any spaces around the `:` character.

The `--memory` and `--net` parameters are component limits and are specified in the [Developer Portal](https://components.keboola.com/).

The `-e` parameters define [environment variables](/extend/common-interface/environment/). When entering
environment variables on the command line, do **not** put any spaces around the `=` character.

### Test
Download our [sample data folder](/extend/data.zip), extract it into your **host folder**, and run this command:

    docker run --volume=/user/johndoe/data/:/data --memory=4000m --net=bridge -e KBC_RUNID=123456789 -e KBC_PROJECTID=123 -e KBC_DATADIR=/data/ -e KBC_CONFIGID=test-123 quay.io/keboola/keboola-test.ex-docs-tutorial

You should see the following output:

    All done

    Environment variables:
    KBC_RUNID: 123456789
    KBC_PROJECTID: 123
    KBC_DATADIR: /data/
    KBC_CONFIGID: test-123

In addition, the `destination.csv` file will be created in your **host folder** in the `data/out/tables/` folder, with the following contents:

    number,someText,double_number
    10,ab,20
    20,cd,40
    25,ed,50
    26,fg,52
    30,ij,60

If you encounter any errors, you can run the image interactively:

    docker run --volume=/user/johndoe/data/:/data --memory=4000m --net=bridge -e KBC_RUNID=123456789 -e KBC_PROJECTID=123 -e KBC_DATADIR=/data/ -e KBC_CONFIGID=test-123 -i -t --entrypoint=/bin/bash quay.io/keboola/keboola-test.ex-docs-tutorial

Then you can inspect the container with standard OS (CentOS) commands and/or run the script manually with
`php /home/main.php`.

After you have mastered this step, you can run any Docker component on your machine.

## Debugging
There are two API calls available for debugging purposes:

  - [Debug](https://kebooladocker.docs.apiary.io/#reference/debug/debug-component/create-a-debug-job)
  - [Run Tag](https://kebooladocker.docs.apiary.io/#reference/run/create-a-job-with-image/create-a-dry-run-job)

The [Debug](https://kebooladocker.docs.apiary.io/#reference/debug) API call is useful for obtaining an
environment configuration for a component. It will create a snapshot of the
[data folder](/extend/common-interface/folders/)
(including input mapping and configuration files) and then it will upload the snapshot to the [Files section](https://help.keboola.com/storage/file-uploads/)
of Storage. Then the component will be run and another snapshot will be created with the resulting contents of the data directory.
This gives you snapshots of the data directory before and after a component is run. The debug
API call does not write any tables or files (other than the archive) to the Keboola project, so it is very safe to run. Note however that
any side effects of the component are still performed (e.g. writers still write data to their destination).

The [Run Tag](https://kebooladocker.docs.apiary.io/#reference/run/create-a-job-with-image/create-a-dry-run-job)
API call allows you to run a job in the production environment but using a specific tag of the Docker image.
This means you can test your unreleased image on real configurations in real projects without affecting
any users using that component. See the [tutorial](/extend/component/tutorial/debugging/#running-specific-tags)
for instructions.

## Preparing Data folder
In order to run and debug a Keboola component (including [R](https://help.keboola.com/manipulation/transformations/r/) and [Python](https://help.keboola.com/manipulation/transformations/python/) Transformations)
on your own computer, you need to manually supply the component with
a [data folder and configuration file](/extend/common-interface/). The above mentioned
[Debug API call](https://kebooladocker.docs.apiary.io/#reference/debug/debug-component/create-a-debug-job)
is designed to do that.

We recommend that you use [Apiary or Postman](/overview/api/) to call the API.
A [collection of examples](https://documenter.getpostman.com/view/3086797/kbc-samples/77h845D?version=latest#9b9f3e7b-de3b-4c90-bad6-a8760e3852eb) of the
Debug API calls is available in Postman Docs.

### Prepare
[Create a table](https://help.keboola.com/tutorial/load/) in Keboola Storage.
In the following example, the table is stored in the `in.c-main` bucket and is called `sample`. The table ID is
therefore `in.c-main.sample`. You also need a [Storage API token](https://help.keboola.com/storage/tokens/).

{: .image-popup}
![Storage Screenshot](/extend/component/running/sandbox-data.png)

### Running without Configuration
In the [collection of sample requests](https://documenter.getpostman.com/view/3086797/kbc-samples/77h845D?version=latest#9b9f3e7b-de3b-4c90-bad6-a8760e3852eb),
there is a **Run without Configuration** example with the following JSON in its body:

{% highlight json %}
{
	"configData": {
		"storage": {
			"input": {
				"tables": [
					{
						"source": "in.c-main.sample",
						"destination": "source.csv"
					}
				]
			}
		},
		"parameters": {
			"sound": "Moo",
			"repeat": 2
		}
	}
}
{% endhighlight %}

The node `configData.storage.input.tables.source` refers to the existing table ID (the table created
in the previous step) in Storage. The `configData.storage.input.tables.destination` node refers to the
destination to which the table will be downloaded for the component; it will therefore be the
**source** for the component.

The entire `configData.storage` node is generated by the UI. The node `parameters` contains arbitrary
parameters which are passed to the component. The URL of the request
is `https://syrup.keboola.com/docker/{{componentId}}/input` (in the [US Region](/overview/api/#regions-and-endpoints)).
The request body is in JSON. Replace the `componentId` by the ID of the component for which you
want to generate the config file (e.g., `keboola-test.ex-docs-tutorial`). Enter your Storage API token
into **X-StorageAPI-Token** header and run the request.

### Running with Configuration
In the [collection of sample requests](https://documenter.getpostman.com/view/3086797/kbc-samples/77h845D?version=latest#9b9f3e7b-de3b-4c90-bad6-a8760e3852eb),
there is a **Run with Configuration** example with the the following JSON in its body:

{% highlight json %}
{
    "config": "328831433"
}
{% endhighlight %}

When you create a configuration in Keboola, it is assigned a configuration ID --- `328831433` --- in our example.
Use this ID instead of manually crafting the request body. You need to replace `328831433` with your own
configuration ID. The request URL is as follows:

{: .image-popup}
![Configuration screenshot](/extend/component/running/input-configuration.png)

You can create a configuration for non-public components by visiting the direct URL:

    https://connection.keboola.com/admin/projects/{PROJECT_ID}/extractors/{COMPONENT_ID}

In this case replace `COMPONENT_ID` with `keboola-test.ex-docs-tutorial` and PROJECT_ID with the id of your testing project.

**Important**: If you actually want to **run** the above 328831433 configuration, you also need
to set the output mapping from `destination.csv` to a table.

### Getting Result
When running the request with valid parameters, you should receive a response similar to this:

{% highlight json %}
{
    "id": "176883685",
    "url": "https://syrup.keboola.com/queue/job/176883685",
    "status": "waiting"
}
{% endhighlight %}

This means that an [asynchronous job](/integrate/jobs/) which will prepare the archive of the data folder has been created.
If curious, view the job progress under **Jobs** in Keboola:

{: .image-popup}
![Job progress screenshot](/extend/component/running/sandbox-progress.png)

The job will usually take slightly longer than the normal run job. When finished go to **Storage** --- **Files** in
Keboola. There you will find a `stage_0.zip` file with the data folder before the component was run and `stage_output.zip` before
the component output mapping was supposed to be done. You can now use this folder from `stage_0.zip` to run
the component locally. You should now be able to run the component with it:

    docker run --volume=/user/johndoe/data/:/data --memory=4000m --net=bridge -e KBC_RUNID=123456789 -e KBC_PROJECTID=123 -e KBC_DATADIR=/data/ -e KBC_CONFIGID=test-123 -i -t --entrypoint=/bin/bash quay.io/keboola/keboola-test.ex-docs-tutorial


## Running Component
If you want to run a component during development, it is the easiest to build it locally and
[run the built version](/extend/component/tutorial/debugging/). If you want to run a production code component, you
need to do a couple of things. Let's assume you want to run the `keboola-test.ex-docs-tutorial` component and you have
already [prepared the data directory](#preparing-the-data-folder).

The next step is to obtain the repository settings and credentials from the
[Developer Portal](https://components.keboola.com/). You can either use the [API](https://kebooladeveloperportal.docs.apiary.io/#) or
the [CLI](https://github.com/keboola/developer-portal-cli-v2). The CLI is easier to use. First set your service account credentials
in the environment:

    export KBC_DEVELOPERPORTAL_USERNAME=keboola-test+ex_docs_tutorial_travis
    export KBC_DEVELOPERPORTAL_PASSWORD=RFlYs3HnDkbzyXIUkdPFRMubiCK-FTjy5-tNXrdzRX3qEBLvDQjnxFtAJGzg6UO.

or

    SET KBC_DEVELOPERPORTAL_USERNAME=keboola-test+ex_docs_tutorial_travis
    SET KBC_DEVELOPERPORTAL_PASSWORD=RFlYs3HnDkbzyXIUkdPFRMubiCK-FTjy5-tNXrdzRX3qEBLvDQjnxFtAJGzg6UO.

on Windows. Then run the command to obtain the component repository:

    docker run --rm  -e KBC_DEVELOPERPORTAL_USERNAME -e KBC_DEVELOPERPORTAL_PASSWORD quay.io/keboola/developer-portal-cli-v2 ecr:get-repository vendor component-id

for example:

    docker run --rm  -e KBC_DEVELOPERPORTAL_USERNAME -e KBC_DEVELOPERPORTAL_PASSWORD quay.io/keboola/developer-portal-cli-v2 ecr:get-repository keboola-test keboola-test.ex-docs-tutorial

You will receive the repository URI, e.g.:

    147946154733.dkr.ecr.us-east-1.amazonaws.com/developer-portal-v2/keboola-test.ex-docs-tutorial

Then call a command to obtain credentials for the component repository:

    docker run --rm -e KBC_DEVELOPERPORTAL_USERNAME -e KBC_DEVELOPERPORTAL_PASSWORD quay.io/keboola/developer-portal-cli-v2 ecr:get-login vendor component-id

for example:

    docker run --rm -e KBC_DEVELOPERPORTAL_USERNAME -e KBC_DEVELOPERPORTAL_PASSWORD quay.io/keboola/developer-portal-cli-v2 ecr:get-login keboola-test keboola-test.ex-docs-tutorial

You will receive a `docker login` command which will authorize you to fetch the repository:

    docker login -u AWS -p ey...ODAzOH0= 147946154733.dkr.ecr.us-east-1.amazonaws.com

Then pull the image from the registry:

    docker pull 147946154733.dkr.ecr.us-east-1.amazonaws.com/developer-portal-v2/keboola-test.ex-docs-tutorial

Or run it directly:

    docker run --volume=/user/johndoe/data/:/data --memory=4000m --net=bridge -e KBC_RUNID=123456789 -e KBC_PROJECTID=123 -e KBC_DATADIR=/data/ -e KBC_CONFIGID=test-123 147946154733.dkr.ecr.us-east-1.amazonaws.com/developer-portal-v2/keboola-test.ex-docs-tutorial

The `/user/johndoe/data/` path refers to the contents of the data folder.

**Note for Windows users:**
If you receive the error `The stub received bad data.`, you have to modify the `%userprofile%\.docker\config.json` to e.g.:
{% highlight json %}
{
	"auths": {
		"https://index.docker.io/v1/": {
			"email": "email@example.com"
		}
	}
}
{% endhighlight %}

This is a known [bug in Docker](https://github.com/docker/for-win/issues/1306), see [the workaround](https://github.com/Azure/azure-cli/issues/4843).

## Running Transformations
Both R and Python transformations are implemented as Docker components. They can be run
locally as well. Use the [Debug API](/extend/component/running/#preparing-the-data-folder) call to obtain the data directory.
In the [API call](https://kebooladocker.docs.apiary.io/#reference/debug/debug-component/create-a-debug-job), specify the full
configuration (using the `configData` node). See [examples](https://documenter.getpostman.com/view/3086797/kbc-samples/77h845D?version=latest#9b9f3e7b-de3b-4c90-bad6-a8760e3852eb)
for both R and Python transformations.

To run R transformations, use:

    docker run --volume=/user/johndoe/data/:/data --memory=4000m --net=bridge -e KBC_RUNID=123456789 -e KBC_PROJECTID=123 -e KBC_DATADIR=/data/ -e KBC_CONFIGID=test-123 [quay.io/keboola/r-transformation](https://quay.io/repository/keboola/r-transformation):latest

To run [Python transformations](https://quay.io/repository/keboola/python-transformation), use:

    docker run --volume=/user/johndoe/data/:/data --memory=4000m --net=bridge -e KBC_RUNID=123456789 -e KBC_PROJECTID=123 -e KBC_DATADIR=/data/ -e KBC_CONFIGID=test-123 quay.io/keboola/python-transformation:latest

The transformation will run automatically and produce results. If you want to get into
the container interactively, use the [`--entrypoint`](/extend/component/docker-tutorial/howto/) parameter.


================================================
File: extend/component/tutorial/configuration.md
================================================
---
title: Configuration
permalink: /extend/component/tutorial/configuration/
---

* TOC
{:toc}

In this part of the [tutorial](/extend/component/tutorial/), you will see how to pass
arbitrary configuration parameters to your component. By this time, you probably noticed
that your component has a configuration field:

{: .image-popup}
![Screenshot -- Configuration Empty](/extend/component/tutorial/configuration-1.png)

You can use this field to pass arbitrary configuration parameters to your component.
The parameters will be available in the [/data/config.json](/extend/common-interface/config-file/) file provided to the
component when it is [run](/extend/docker-runner/).

Note: if you don't want to hard-code the [`/data/` directory](/extend/common-interface/folders/#root-folder-data) use the [`KBC_DATADIR`](/extend/common-interface/environment/#environment-variables) environment variable.

Let's assume you want to make the [sample component](/extend/component/tutorial/output-mapping/)
add a given sound to each row a given number of times. For that you'll need two parameters: `sound` and `repeat`.

## Modifying Source Code
To implement the above, you can change the [sample component](/extend/component/tutorial/output-mapping/) to:

```python
import csv
import os

# Load the Component library to process the config file
from keboola.component import CommonInterface

# Rely on the KBC_DATADIR environment variable by default,
# alternatively provide a data folder path in the constructor (CommonInterface('data'))
ci = CommonInterface()
params = ci.configuration.parameters

print("Hello world from python")

csvlt = '\n'
csvdel = ','
csvquo = '"'

# get input table definition by name
in_table = ci.get_input_table_definition_by_name('source.csv')

with open(in_table.full_path, mode='rt', encoding='utf-8') as in_file, \
        open(os.path.join(ci.tables_out_path, 'odd.csv'), mode='wt', encoding='utf-8') as odd_file, \
        open(os.path.join(ci.tables_out_path, 'even.csv'), mode='wt', encoding='utf-8') as even_file:
    lazy_lines = (line.replace('\0', '') for line in in_file)
    reader = csv.DictReader(lazy_lines, lineterminator=csvlt, delimiter=csvdel,
                            quotechar=csvquo)

    odd_writer = csv.DictWriter(odd_file, fieldnames=reader.fieldnames,
                                lineterminator=csvlt, delimiter=csvdel,
                                quotechar=csvquo)
    odd_writer.writeheader()

    even_writer = csv.DictWriter(even_file, fieldnames=reader.fieldnames,
                                 lineterminator=csvlt, delimiter=csvdel,
                                 quotechar=csvquo)
    even_writer.writeheader()
    i = 0
    for row in reader:
        if i % 2 == 0:
            even_writer.writerow(row)
        else:
            newRow = {}
            for key in reader.fieldnames:
                newRow[key] = row[key] + ''.join([params['sound']] * params['repeat'])
            odd_writer.writerow(newRow)
        i = i + 1


```

At the beginning, the [Keboola Python Component library](https://github.com/keboola/python-component) is imported and
initialized by reading the `data` directory (`CommonInterface()`). Its property `configuration.parameters` will provide the
configuration parameters as a dictionary. Apart from that the [Python library](https://github.com/keboola/python-component)
 provides methods to handle input / output files and many more (see [here](/extend/component/implementation/python/) for more information). 

Similar library is currently available also for the [R language](https://github.com/keboola/r-docker-application). 
It does no magic or rocket science, so you can read the [config file](/extend/common-interface/config-file/) directly if you wish.

Commit and push the code in your repository and tag it with a [normal version tag](https://semver.org/#spec-item-2).
This will trigger a [build on Travis CI](https://docs.travis-ci.com/) and automatically
deploy the new version into Keboola. Keep in mind that after the deployment, it may take up to 5 minutes for the update to propagate to all Keboola instances.

## Verifying
To verify that the parameters work, simply edit the component configuration in Keboola and paste in, for example:

{% highlight json %}
{
    "sound": "Moo",
    "repeat": 2
}
{% endhighlight %}

{: .image-popup}
![Screenshot -- Configuration Filled](/extend/component/tutorial/configuration-2.png)

Run the component and examine the job results. In the `odd` result table, you should see that `Moo` was added twice to every value.

{: .image-popup}
![Screenshot -- Table Results](/extend/component/tutorial/configuration-3.png)

## Creating UI
Entering configuration parameters using JSON data is quite low-level. Therefore you should
provide a UI for the end user. The easiest option is to take advantage of the
[JSON editor](https://github.com/jdorn/json-editor) based on the
[configuration schema](/extend/component/ui-options/configuration-schema/). For the above
configuration, the following schema can be created:

{% highlight json %}
{
    "title": "Person",
    "type": "object",
    "properties": {
        "sound": {
            "type": "string",
            "title": "Sound:",
            "default": "Boo",
            "description": "The sound to make."
        },
        "repeat": {
            "type": "integer",
            "title": "Repeat sound:",
            "description": "Number of times to repeat the sound.",
            "default": 2,
            "minimum": 0,
            "maximum": 10
        }
    },
    "required": ["sound", "repeat"]
}
{% endhighlight %}

In the schema the two properties `sound` and `repeat` are declared along with the specification
of their form input fields.
You can test the above schema [online](http://jeremydorn.com/json-editor/) ([alternative](https://mozilla-services.github.io/react-jsonschema-form/)) and verify that the
form generated from it produces the desired JSON structure. Once satisfied with the result,
simply paste the schema into the **Configuration schema** in your component properties in the
[Developer Portal](https://components.keboola.com/).

Once the change propagates to your Keboola instance, you should see the form in the UI:

{: .image-popup}
![Screenshot -- Configuration Form](/extend/component/tutorial/configuration-4.png)

The end user can now configure your component without writing the JSON with parameters. For a very complex UI, the
JSON schema editor is not really suitable; contact us about available options.

## Summary
Your component can now successfully read configuration parameters provided by the end user. You can read more about all the features of the
[configuration file](/extend/common-interface/config-file/).
Keep in mind that the code presented above is simplified as it does not use any validation of
end user parameters. The next part of the tutorial will show you
how to [configure processors](/extend/component/tutorial/processors/).


================================================
File: extend/component/tutorial/debugging.md
================================================
---
title: Debugging
permalink: /extend/component/tutorial/debugging/
---

* TOC
{:toc}

Because all components [run in an isolated environment](/extend/docker-runner/), it may be harder to debug them. There is no way to
examine the component while it is running. However, there are some options how the production environment can be
replicated locally, so that you can analyze what is happening if something is not right.

## Checking Errors and Version
There are two [types of errors](/extend/common-interface/environment/#return-values). In the case of
application errors, you (or any other end user) will only see a generic error message in the job result:

    Internal Error Something is broken. Our developers were notified about this error and will let you know what went wrong.

At the same moment, you should get a full error message on your vendor [channel for receiving errors](/extend/component/tutorial/#before-you-start) (typically a Slack
or email message). If you have not received a message or you don't have a channel for receiving errors, contact us to set it up.

Also, if the component is misbehaving, please double check that you are running the correct version. This can be done in
the job detail in the section **Parameters & Results**, where you can see the tag used to execute the job:

{: .image-popup}
![Screenshot -- Job Tags](/extend/component/tutorial/debug-1.png)

You should be able to trace the tag to a specific version of your source code.

## Running Locally

### Step 1 -- Obtain Sample Data and Configuration
Data between Keboola and your Docker image are exchanged using [CSV files](/extend/common-interface/) in
designated [directories](/extend/common-interface/folders/); they will be
injected into the image when you [run it](/extend/docker-runner/). To simulate this, download an archive containing the data files
and [configuration](/extend/common-interface/config-file/) in the exact same format you get in the production environment.

Use the [Debug API call](https://kebooladocker.docs.apiary.io/#reference/debug/debug-component/create-a-debug-job).
You can see it in our [API request collection](https://documenter.getpostman.com/view/3086797/kbc-samples/77h845D?version=latest#9b9f3e7b-de3b-4c90-bad6-a8760e3852eb).
In the [API call](https://kebooladocker.docs.apiary.io/#reference/debug/debug-component/create-a-debug-job), either specify the
full configuration (using the `configData` node) or refer to an existing configuration
of the component (using the `config` node). See an [example](https://documenter.getpostman.com/view/3086797/kbc-samples/77h845D?version=latest#9b9f3e7b-de3b-4c90-bad6-a8760e3852eb).

The Debug API call will prepare the data folder for the component, put it inside an archive and upload it to Keboola Storage.
When running the request with valid parameters, you should receive a response similar to this:

{% highlight json %}
{
    "id": "176883685",
    "url": "https://syrup.keboola.com/queue/job/176883685",
    "status": "waiting"
}
{% endhighlight %}

This means an [asynchronous job](/integrate/jobs/) for preparing the archive has been created.
If curious, view the job progress under **Jobs** in Keboola.
When the job finishes, you'll see a `stage_0.zip` file uploaded to your project.

{: .image-popup}
![Screenshot -- Job Tags](/extend/component/tutorial/debug-2.png)

You can send the Debug API call with a reference to an existing configuration id, or you can also supply the configuration directly in
the API request. In such case, use the `configData` attribute in the request body, e.g.:

{% highlight json %}
{
    "config": "my-test-config",
    "configData": {
        "storage": {
            "input": {
                "tables": [
                    {
                        "source": "in.c-main.test",
                        "destination": "source.csv"
                    }
                ]
            },
            "output": {
                "tables": [
                    {
                        "source": "destination.csv",
                        "destination": "out.c-main.test"
                    }
                ]
            }
        },
        "parameters": {
        }
    }
}
{% endhighlight %}

The above request corresponds to the following setting in the UI:

{: .image-popup}
![Configuration Screenshot](/extend/component/tutorial/configuration-sample.png)

### Step 2 -- Build Image
Then you can build your component code locally:

    docker build path/to/component/code --tag=my-component

or

    docker build . --tag=my-component

in the component directory. It should produce an output similar to the one below:

{: .image-popup}
![Screenshot -- Building](/extend/component/tutorial/debug-3.png)

### Step 3 -- Run Component with Sample Data
Once you have prepared the data folder with sample data and configuration, inject it into the Docker image.
In addition to the options shown in the example, there are many [other options](/extend/common-interface/config-file/) available.

When you run an image, a **container** is created in which the component is running isolated.
Use the following command to run the image:

    docker run --volume=physicalhostpath:/data/ imageTag

An image tag is the tag you supplied in the `--tag` parameter for `docker build` (`my-component` in the above example).
The physical host path depends on the system you are running. If in doubt,
see [Setting Up Docker](/extend/component/docker-tutorial/setup/#sharing-files). In our example image with default Windows
installation of Docker, this would be:

    docker run --volume=C:\Users\JohnDoe\data\:/data/ my-component

Where the contents of the sample data folder are put in the user's home directory. If you have set everything correctly,
you should see **Hello world from python**, and a `destination.csv` file will appear in the `data/out/tables/` folder.

{: .image-popup}
![Screenshot -- Running](/extend/component/tutorial/debug-4.png)

You can then examine what the component did and what files it produced in the `data/out` folder. You can
also read more in-depth information about [running images](/extend/component/running/).

### Step 4 -- Debug
Chances are that you received an ugly error message or warning. In that case, you might want to check the
contents of the image; specifically, if all the files are where you expect
them to be.

To work with the component container interactively, use the following command:

    docker run --volume=physicalhostpath:/data/ -i -t --entrypoint=/bin/bash imageTag

For instance:

    docker run --volume=C:\Users\JohnDoe\data\:/data/ -i -t --entrypoint=/bin/bash my-component

This will override the default command specified in the `Dockerfile` -- `CMD ["python", "-u", "/code/main.py"]`
to launch [Bash](https://en.wikipedia.org/wiki/Bash_(Unix_shell)) instead. The [`-i` and `-t` flags](https://docs.docker.com/engine/reference/commandline/run/)
ensure that the container runs in an interactive mode.
You can then inspect the container contents: 'ls /data/'. For more details, see [Howto](/extend/component/docker-tutorial/howto/).

### Step 4 -- Modify
Chances are that you want to modify the component code often. If you modify the component code, you have to rebuild the
docker image. To avoid the slow and tedious work, run the image with the following command:

    docker run --volume=physicalhostpathtodata:/data/ --volume=physicalhostpathtocode:/code/ -i -t my-component

For instance:

    docker run --volume=C:\Users\JohnDoe\data\:/data/ --volume=D:\wwwroot\ex-docs-tutorial\:/code/ -i -t my-component

This means that the directory with the component code will shadow the one inside the image (defined by the `COPY . /code/`
instruction in `Dockerfile`) and you will run the current code in the image environment.

## Running Specific Tags
The Debug API call is very powerful but it always runs the production version of component. There are cases where you might want to
run a test or development version of a component. In such situations, an alternative may be to run a specific image tag.

Let's say that you need to list all files on input for some reason. Following the
[example component](/extend/component/tutorial/), you would have to add something like this
to the component code:

{% highlight python %}
from os import listdir

mypath = '/data/in/tables'
onlyfiles = [f for f in listdir(mypath)]
print(onlyfiles)
{% endhighlight %}

Since you are debugging, it is not wise to add this for all customers. Therefore you can commit
the code and tag it with a **non-**[normal version tag](https://semver.org/#spec-item-2), for example, `0.0.7-test`.
Such a tag will be deployed as a Docker image, but it won't (automatically) update in the
Developer Portal. That means the previous tag will be still used for all jobs. However, you can
run the new tag manually, using the [Run Tag API call](https://kebooladocker.docs.apiary.io/#reference/run/create-a-job-with-image/run-job). Again, feel free to use our [collection](https://documenter.getpostman.com/view/3086797/kbc-samples/77h845D?version=latest#9b9f3e7b-de3b-4c90-bad6-a8760e3852eb).

If you added the above debug code to the component `keboola-test.ex-docs-tutorial` and
tagged the release `0.0.7-test`, you can run the configuration `354678919` by issuing the
following API call:

    curl -X POST \
    https://syrup.keboola.com/docker/keboola-test.ex-docs-tutorial/run/tag/0.0.7-test \
    -H 'Content-Type: application/json' \
    -H 'X-StorageApi-Token: your-token' \
    -d '{
    "config": "354678919"
    }'

In the job detail -- under **Parameters & Results**, , you'll see that a specific tag was requested. In the job events, you can then
see that it was indeed used and that the script printed out all files in the `/data/in/tables/` folder.

{: .image-popup}
![Screenshot -- Image Results](/extend/component/tutorial/debug-4.png)

## Summary
You can find more information about running components in the corresponding part of the [documentation](/extend/component/running/).

This concludes our development tutorial on the most important aspects of creating Keboola components. However, our platform offers a
lot more; we encourage you to read about other features in our documentation:

- exchanging data in [data folders](/extend/common-interface/folders/)
- [manifest files](/extend/common-interface/manifest-files/)
- [OAuth support](/extend/common-interface/oauth/)
- or general information about the [common interface](/extend/common-interface/)
- [deployment settings](/extend/component/deployment/)
- [UI settings](/extend/component/ui-options/)
- [Running components locally](/extend/component/running/)


================================================
File: extend/component/tutorial/index.md
================================================
---
title: Component Quick Start
permalink: /extend/component/tutorial/
redirect_from:
    - /extend/docker/quick-start/
    - /extend/custom-science/quick-start/
---

* TOC
{:toc}

In this tutorial, you will create a simple "Hello, World!" component which runs in
Keboola.

## Before You Start
You need to have a computer with working [Docker](https://www.docker.com/why-docker) to develop the Keboola component code.
To be able to create new components, you also need to have an account in the [Keboola Developer Portal](https://components.keboola.com/),
which manages the list of components available in Keboola.

The Developer Portal uses different credentials than Keboola. [Creating an account](https://components.keboola.com/auth/create-account) is free; it requires a working email address
(to which a confirmation email will be sent) and a mobile phone for a mandatory two-factor authorization.

When you log in to the Developer Portal, you have to join a **vendor** --- an organization of
developers. Every Keboola component has to have a vendor assigned. If you join an existing vendor, a
vendor administrator has to approve your request. If you do not work for a company, create a
vendor with your name (even a single developer has to be assigned to a vendor). When you join or create a vendor
you should also receive access to a development Keboola project.

{: .image-popup}
![Screenshot -- Join a vendor](/extend/component/tutorial/join-vendor.png)

In order to create a **new vendor**, a Keboola administrator has to approve your request, and you will
receive a [development project](/#development-project) in Keboola. In addition to that, you need to provide us
with a channel for receiving internal errors from your components. Anything supported
by [Papertrail notifications](https://help.papertrailapp.com/kb/how-it-works/alerts#supported-services)
is available, though e-mail or a Slack channel is most commonly used.

When you are confirmed as a member of a vendor, you may proceed to creating your own component.
The example component is written in the Python language, but no knowledge of Python is required.
Before you continue with this tutorial, make sure you

- can log in to the [Developer Portal](https://components.keboola.com/).
- can log in to one of the Keboola [stacks](https://help.keboola.com/overview/#stacks)
- have a [Github](https://github.com/) account.

*Note: Even though the tutorial assumes using [GitHub](https://github.com/) + [Travis](https://travis-ci.org/) services, they are not required for extending Keboola.
We use them because we like them the most. The [deployment documentation](/extend/component/deployment/) shows how to configure,
for example, [Bitbucket](/extend/component/deployment/#bitbucket-integration) and [GitLab](/extend/component/deployment/#gitlab-integration)
integrations.*

## Creating Component
To add a component, use the **Add a component** button on the main page, and fill in the component name and type:

{: .image-popup}
![Screenshot -- Create component](/extend/component/tutorial/create-component-2.png)

**Important:** Do **not** use the words 'extractor', 'writer', or 'application' in the component name.

Choose the appropriate [component type](/extend/component/#component-types):

- `extractor` -- brings data into Keboola
- `writer` -- sends data out of Keboola
- `transformation` -- does some transformation of the data, [read more](https://help.keboola.com/transformations/#new-transformations)
- `code pattern` -- generates code for transformation's component, [read more](/extend/component/code-patterns)
- `application` -- another arbitrary component

The above does not mean technically that, for example, an extractor cannot send data out of Keboola
or an application cannot bring new data into Keboola. It is a matter of user perception,
so use your judgement to select the correct type.

When you fill the form in, you will obtain a **component ID** (in the
form `vendor-id.component-name`, for instance, `keboola-test.ex-docs-tutorial`). Make a **note** of the ID.

## Creating Deployment Account
To be able to deploy the component to Keboola, you will need **service credentials**. For security
reasons, we strongly advice against using your own credentials in any deployment service. To create
new deployment credentials, click the **Create a service account** button on the **Service accounts** page.

{: .image-popup}
![Screenshot -- Create account](/extend/component/tutorial/service-account-1.png)

Fill in a name (e.g., `ex_docs_tutorial_travis`) and description (e.g., `Travis deployment credentials`) and confirm:

{: .image-popup}
![Screenshot -- Account details](/extend/component/tutorial/service-account-2.png)

Take a note of the **username** and **password**.

{: .image-popup}
![Screenshot -- Account credentials](/extend/component/tutorial/service-account-3.png)

## Initializing Component
Once you have the **component ID** and the service account **username** and **password**,
you can use our [component generator tool](https://github.com/keboola/component-generator) to create a component skeleton for you in your favorite programming language.

Create an empty [Github](https://github.com/) repository. The name of the repository is
arbitrary, but using the component is probably a good idea to avoid confusion.

{: .image-popup}
![Screenshot -- Github Repository](/extend/component/tutorial/github-repository.png)

Checkout the repository on your local computer and execute the following from the command line:

	docker run -i -t --volume=/path/to/repository/:/code/ quay.io/keboola/component-generator

Replace `/path/to/repository/` with an absolute local path to your empty repository. Follow
the on-screen instructions:

{: .image-popup}
![Screenshot -- Component Generator](/extend/component/tutorial/component-generator.png)

When done, you will have an initialized repository with a "Hello, World!" component.
In the above example, we chose the `simple-python` template, which contains the following:

- template.md -- description of the template files
- main.py -- a "Hello, World!" Python script
- Dockerfile -- a [Dockerfile](/extend/component/docker-tutorial/) defining the environment in which the script runs
- deploy.sh -- a Bash script to deploy the component to Keboola

For Travis CI template contain:
- .travis.yml -- a configuration file for [Travis CI](https://docs.travis-ci.com/) to automate the deployment

For GitHub Actions CI template contain:
- .github/workflows/push.yml -- a configuration file for [GitHub Actions CI](https://github.com/features/actions) to automate the deploy

## Building Component
When done exploring, push to the repository.
This will automatically trigger a build on the Travis or GitHub Actions services; you can view the build
progress by visiting the provided link. In fact, two builds will be triggered: one
for the `master` branch, and one for the `0.1.0` tag.

Travis:

{: .image-popup}
![Screenshot -- Travis Build](/extend/component/tutorial/travis-build-1.png)

GitHub Actions:

{: .image-popup}
![Screenshot -- GitHub Actions Build](/extend/component/tutorial/gh-build-1.png)

We are more interested in the latter because that is going to trigger the deployment to Keboola.

Travis:

{: .image-popup}
![Screenshot -- Travis Build Detail](/extend/component/tutorial/travis-build-2.png)

GitHub Actions:

{: .image-popup}
![Screenshot -- GitHub Actions Build Detail](/extend/component/tutorial/gh-build-2.png)

If the deployment passes without errors, the component will become available in Keboola. You
can verify that in the component details (action Edit) in the Developer Portal:

{: .image-popup}
![Screenshot -- Component Deployed](/extend/component/tutorial/component-deployed.png)

This means that the component deployment is fully automated. If you change the component
source code, all you need to do is push the changes to the git repository and tag them
with the [normal version tag](https://semver.org/#spec-item-2).

## Running Component
Once the component is deployed, it becomes available in Keboola. Note that it
takes **up to 5 minutes** for the changes to propagate to all Keboola instances. After that,
you can configure the component by visiting the following URL:

    https://connection.keboola.com/admin/projects/{DEFINED PROJECT_ID}/extractors/{YOUR COMPONENT_ID}

On this URL, you can create a configuration and run it without any settings.

{: .image-popup}
![Screenshot -- Component Configuration](/extend/component/tutorial/component-configuration.png)

And you should see the "Hello, World" message in the events:

{: .image-popup}
![Screenshot -- Component Events](/extend/component/tutorial/hello-world.png)

When you create a component, it will have assigned a memory limit of **256MB** and
run timeout of **1 hour**. If you need to change those limits, please
[contact our support](mailto:support@keboola.com).

## Component Repository
The component repository is a crucial part of the component setting because it
actually defines what [Docker image](/extend/component/docker-tutorial/) will be used when running the component.
We offer free hosting of your Docker images in the **[Amazon Container Registry (AWS ECR)](https://aws.amazon.com/ecr/)** under our own account.
All repositories in AWS ECR are private. When you create your component using the method shown above, we
have just provisioned you with the Docker image hosting and you do not need to worry about it any more.

We also support the DockerHub and Quay.io registries, both public and private. However, as they are more prone to
outages and beyond our control, we recommend using our reliable AWS ECR. Use DockerHub or Quay.io only if you,
for instance, want the image to be public.

## Summary
You have just created your own Keboola component. Although it does not do much, it shows the easiest path
to bringing your own application logic to Keboola. You can now continue with other parts of the tutorial:

 - using [input](/extend/component/tutorial/input-mapping/) and
   [output mapping](/extend/component/tutorial/output-mapping/)
 - using [configuration parameters](/extend/component/tutorial/configuration/)
 - [configuring a processor](/extend/component/tutorial/processors/)
 - [debugging a component](/extend/component/tutorial/debugging/)
 - [implementation notes](/extend/component/implementation/) for specific languages

Although you rarely need all of the above parts (e.g., you do not need input mapping when building an extractor),
we suggest you go through all of them to gain a general overview of the available options. You can also read
all the details in the respective parts of the documentation:

- general information about the [common interface](/extend/common-interface/)
- exchanging data in [data folders](/extend/common-interface/folders/)
- [manifest files](/extend/common-interface/manifest-files/)
- [OAuth support](/extend/common-interface/oauth/)
- [deployment settings](/extend/component/deployment/) (including [Bitbucket integration](/extend/component/deployment/#bitbucket-integration))
- [UI settings](/extend/component/ui-options/)



================================================
File: extend/component/tutorial/input-mapping.md
================================================
---
title: Input Mapping
permalink: /extend/component/tutorial/input-mapping/
---

* TOC
{:toc}

In this part of the [tutorial](/extend/component/tutorial/), you will see how to use **input mapping**. Input mapping
defines what data your component receives from the end users' project. A component never
operates on data in a project's [Storage](https://help.keboola.com/storage/),
it always receives a copy of the selected data.

Input mapping is therefore used when your component needs to read data from the customer
project -- these are typically **writers** and **applications**. Implementing the input mapping requires three steps:

- adding input mapping to the component UI
- adding input mapping to the component source code
- verifying

## Adding Input Mapping to UI
Adding the input mapping to the component UI is very simple. In the [Developer Portal](https://components.keboola.com/), edit the component
and add `genericDockerUI-tableInput` or `genericDockerUI-fileInput` (or both) [UI options](/extend/component/ui-options/).

{: .image-popup}
![Screenshot -- Input Mapping Configuration](/extend/component/tutorial/input-mapping-1.png)

Save the changes, and the corresponding UI elements will appear in your component configuration. Keep in mind that the changes
take up to 5 minutes to propagate to all Keboola instances.

## Modifying Source Code
You also need to modify the source code so that it works with the input data. The data from input mapping will be available in the
[`/data/in/tables/`](/extend/common-interface/folders/#folder-dataintables) and
[`/data/in/files`](/extend/common-interface/folders/#folder-datainfiles) folders when the component is
[run](/extend/docker-runner/). This is almost identical to writing
[Transformation code](https://help.keboola.com/manipulation/transformations/) -- the only difference is that you need to
use absolute paths (or the [`KBC_DATADIR`](/extend/common-interface/environment/#environment-variables) environment variable).

Therefore you can modify the [example component](/extend/component/tutorial/) code to, for instance, the
[following one](https://github.com/keboola/ex-docs-tutorial), which works with table input mapping.

{% highlight python %}
import csv

print("Hello, World! from python")

csvlt = '\n'
csvdel = ','
csvquo = '"'
with open('/data/in/tables/source.csv', mode='rt', encoding='utf-8') as in_file:
    lazy_lines = (line.replace('\0', '') for line in in_file)
    reader = csv.DictReader(lazy_lines, lineterminator=csvlt, delimiter=csvdel, quotechar=csvquo)
    for row in reader:
        # do something
        print("The first row is ", row)
        # we don't want to print the entire file to the output
        exit()

{% endhighlight %}

Commit and push the code in your repository, and tag it with a [normal version tag](https://semver.org/#spec-item-2).
This will trigger a [build on Travis CI](https://docs.travis-ci.com/) and automatically
deploy the new version into Keboola. Keep in mind that after the deployment, it may take up to 5 minutes for the update to propagate to all Keboola instances.

## Verifying
If you configured the UI correctly, you should see the corresponding control in the component
configuration page.

{: .image-popup}
![Screenshot -- Component Configuration](/extend/component/tutorial/input-mapping-2.png)

Add a **New Table Input**, select an arbitrary table from the project, and make sure to set **Destination** to `source.csv`
so that the final path matches `/data/in/tables/source.csv`, which is what you are expecting in the code.

{: .image-popup}
![Screenshot -- Input Mapping Detail](/extend/component/tutorial/input-mapping-3.png)

Now run the component and you should see the proper message in job events.

{: .image-popup}
![Screenshot -- Input Mapping Events](/extend/component/tutorial/input-mapping-4.png)

## Summary
Your component can now successfully read a provided table. You can learn
more about other input mapping options in the
[data folder specification](/extend/common-interface/folders/). Also, the
[manifest files](/extend/common-interface/manifest-files/) contain metadata which
might be useful in your component. The next part of the tutorial will show you
how to create [output mapping](/extend/component/tutorial/output-mapping/).


================================================
File: extend/component/tutorial/output-mapping.md
================================================
---
title: Output Mapping
permalink: /extend/component/tutorial/output-mapping/
---

* TOC
{:toc}

In this part of the [tutorial](/extend/component/tutorial/), you will see how to use **output mapping**.
Similarly to [input mapping](/extend/component/tutorial/input-mapping/), the output mapping
defines what data your component produces in the end users' project. A component cannot directly
write data to the project [Storage](https://help.keboola.com/storage/);
the produced data are stored in the end users' project when the component [finishes](/extend/docker-runner/).

Output mapping is therefore used when your application needs to send data to the customer
project -- these are typically **extractors** and **applications**. Implementing the input mapping requires three steps:

- turning on the default bucket option (or adding output mapping to the component UI)
- adding output mapping to the component source code
- verifying

Unlike [input mapping](/extend/component/tutorial/input-mapping/), the output mapping is fully optional. That means that
it can be configured similarly to the input mapping (using the [`genericDockerUI-tableOutput`](/extend/component/ui-options/) flag) or
using the [Default bucket](/extend/common-interface/folders/#default-bucket) option. The latter means that all tables produced in the
`/data/out/tables/` folder will be uploaded to a [Storage bucket](https://help.keboola.com/storage/buckets/) with a generated name.
This is almost identical to writing
[Transformation code](https://help.keboola.com/manipulation/transformations/) -- the only difference is that you need to
use absolute paths (or the [`KBC_DATADIR`](/extend/common-interface/environment/#environment-variables) environment variable).

## Configuring Default Bucket
Using the default bucket is the preferred option as it allows simpler configuration of the component.
To enable the default bucket for your component, simply go the [Developer Portal](https://components.keboola.com/) and tick the respective
checkbox. You also need to select the [stage](https://help.keboola.com/storage/buckets/) of the bucket. We recommend using `in` for
extractors and `out` for other components.

{: .image-popup}
![Screenshot -- Default Bucket Configuration](/extend/component/tutorial/output-mapping-1.png)

## Modifying Source Code
You can modify the [sample component](/extend/component/tutorial/) code to, for example, the one below.
The code takes a single arbitrary table on input and produces two tables -- one with
even rows and one with odd rows.

{% highlight python %}
import csv

print("Hello world from python")

csvlt = '\n'
csvdel = ','
csvquo = '"'
with open('/data/in/tables/source.csv', mode='rt', encoding='utf-8') as in_file, \
        open('/data/out/tables/odd.csv', mode='wt', encoding='utf-8') as odd_file, \
        open('/data/out/tables/even.csv', mode='wt', encoding='utf-8') as even_file:
    lazy_lines = (line.replace('\0', '') for line in in_file)
    reader = csv.DictReader(lazy_lines, lineterminator=csvlt, delimiter=csvdel,
                            quotechar=csvquo)

    even_writer = csv.DictWriter(odd_file, fieldnames=reader.fieldnames,
                                 lineterminator=csvlt, delimiter=csvdel,
                                 quotechar=csvquo)
    even_writer.writeheader()

    odd_writer = csv.DictWriter(even_file, fieldnames=reader.fieldnames,
                                lineterminator=csvlt, delimiter=csvdel,
                                quotechar=csvquo)
    odd_writer.writeheader()
    i = 0
    for row in reader:
        if i % 2 == 0:
            even_writer.writerow(row)
        else:
            odd_writer.writerow(row)
        i = i + 1
{% endhighlight %}

This script reads a CSV file line by line and checks whether it is odd or even.
Finally, the result is written to either `odd.csv` or `even.csv`.

Commit and push the code in your repository and tag it with a [normal version tag](https://semver.org/#spec-item-2).
This will trigger a [build on Travis CI](/extend/component/tutorial/#building-the-component) and automatically
deploy the new version into Keboola. Keep in mind that after the deployment, it may take up to 5 minutes for the update to propagate to all Keboola instances.

## Verifying
If you configured the default bucket option, nothing changes in the UI. If you followed the
[previous part of our tutorial](/extend/component/tutorial/input-mapping/#verifying), you don't have to do anything.
Just run the component and you should see that two tables were produced.

{: .image-popup}
![Screenshot -- Output Mapping result](/extend/component/tutorial/output-mapping-2.png)

If you happen to see the following error message:

    CSV file 'odd' file name is not a valid table identifier, either set output mapping for 'odd.csv' or make sure that the file name is a valid Storage table identifier.

It means that you have not set the default bucket properly (thus no bucket is generated for the component, and we don't know where to put 'odd').

## Summary
Your component can now successfully write tables to a Keboola project. You can read
more about other output mapping options in the
[data folder specification](/extend/common-interface/folders/). Also, the
[manifest files](/extend/common-interface/manifest-files/) contain metadata which
you might want to set (e.g., primary key). The next part of the tutorial will show you
how to work with [configuration parameters](/extend/component/tutorial/configuration/).


================================================
File: extend/component/tutorial/processors.md
================================================
---
title: Processors
permalink: /extend/component/tutorial/processors/
---

* TOC
{:toc}

[Processors](/extend/component/processors/) are an optional part of a component configuration.
While they are **not at all necessary** in the development of new components for Keboola, we think that you
should know about them; they can save you a lot of time in some cases.
To get a list of currently available processors, see the
[official component list](https://components.keboola.com/components).

## Configuration
To be able to configure the processors in the Keboola UI, go to the
[Developer Portal](https://components.keboola.com/) and add the UI
flag `genericDockerUI-processors` to your component. You'll then see
a new UI element in the component configuration in Keboola:

{: .image-popup}
![Screenshot -- Processors Empty](/extend/component/tutorial/processors-1.png)

Taking the [example component](/extend/component/tutorial/), you might want to use the
**Add Row Number Column** processor in your component to add a sequential number to every
row of the table imported into Keboola. From the
[processor documentation](https://github.com/keboola/processor-add-row-number-column/blob/master/README.md#usage)
you can see that the processor is configured as:

{% highlight json %}
{
    "definition": {
        "component": "keboola.processor-add-row-number-column"
    }
}
{% endhighlight %}

You want the processor to execute on the output of your component; it means that the
above should be inserted into the `after` (after your component runs) section:

{% highlight json %}
{
    "before": [],
    "after": [
        {
            "definition": {
                "component": "keboola.processor-add-row-number-column"
            }
        }
    ]
}
{% endhighlight %}

## Chaining Processors
If you run the above configuration, you'll receive an error:

    Table odd.csv does not have a manifest file.

This is expected because the [Add Row Number Column processor documentation](https://github.com/keboola/processor-add-row-number-column/blob/master/README.md#prerequisites)
clearly states that the processed CSV files must have
[manifests](/extend/common-interface/manifest-files/) and not headers. Since the example component is very simple and does
not generate manifests (or header-less CSV files), you have to add other processors to do that
for you:

{% highlight json %}
{
    "before": [],
    "after": [
        {
            "definition": {
                "component": "keboola.processor-create-manifest"
            },
            "parameters": {
                "columns_from": "header"
            }
        },
        {
            "definition": {
                "component": "keboola.processor-skip-lines"
            },
            "parameters": {
                "lines": 1
            }
        },
        {
            "definition": {
                "component": "keboola.processor-add-row-number-column"
            }
        }
    ]
}
{% endhighlight %}

The `after` configuration is an array of three processors. The first one creates
[manifest files](/extend/common-interface/manifest-files/) for whatever data files were produced by your component. The manifest
files will contain a header read from the data files. The second processor removes the header
from the data files. The third processor adds the row number column.

## Summary
Configuring processors is not part of the component development. However, processors
allow the end user to customize the input to the component and the output from it. That means
that they can be used to implement specific customer requests while keeping the component
code general.

Choosing whether to implement a specific feature as a processor or as part of your
component may be difficult. A processor might be a good solution if the feature is 

- simple (one operation, contains no internal logic),
- optional (not all end users are interested in it), or
- universal (it is always applied to all input/output or none).

Keep in mind, however, that the processors must be configured by the end user. You can read more about
[processors](/extend/component/processors/) or continue with the next part of the tutorial; 
it will show you some [debugging tips](/extend/component/tutorial/debugging/).


================================================
File: extend/component/ui-options/configuration-schema.md
================================================
---
title: Configuration Schema
permalink: /extend/component/ui-options/configuration-schema/
redirect_from:
    - /extend/registration/configuration-schema/
---

The default input for a component configuration is a JSON text area.

{: .image-popup}
![Generic configuration screenshot](/extend/component/ui-options/configuration.png)

If you define a JSON schema, we are able to display a nice form and
let the user to fill the JSON using a set of defined inputs.

{: .image-popup}
![Configuration schema](/extend/component/ui-options/configuration-schema-1.png)

Using the configuration schema also allows us to validate the user input on frontend.

## Creating Schema

JSON schemas are well documented on the [json-schema.org](https://json-schema.org/) website.

We use [JSON Editor](https://github.com/json-editor/json-editor) for displaying a schema.
The supported formatting options for
the editor are available in the [official editor documentation](https://github.com/json-editor/json-editor#format).

For developing and testing,
use, for example, JSON Editor available [on-line](http://jeremydorn.com/json-editor/), or the
[JSON-Editor Interactive Playground](https://pmk65.github.io/jedemov2/dist/demo.html).

### Example
Let's assume your component accepts the following configuration:

{% highlight json %}

{
    "username": "foo",
    "#password": "baz",
    "dateFrom": "yesterday",
    "dateTo": "today"
}

{% endhighlight %}

This looks like an appropriate form:

{: .image-popup}
![Configuration form](/extend/component/ui-options/form.png)

The form above can be created using this JSON Schema:

{% highlight json %}
{
    "title": "Parameters",
    "type": "object",
    "required": [
        "dateFrom",
        "dateTo",
        "username",
        "#password"
    ],
    "properties": {
        "username": {
            "title": "Username",
            "type": "string",
            "minLength": 1,
            "default": "",
            "propertyOrder": 1
        },
        "#password": {
            "title": "Password",
            "type": "string",
            "format": "password",
            "minLength": 1,
            "default": "",
            "propertyOrder": 2
        },
        "dateFrom": {
            "title": "Date from",
            "type": "string",
            "description": "Any date accepted by strtotime (https://www.php.net/manual/en/function.strtotime.php) function",
            "minLength": 1,
            "default": "",
            "propertyOrder": 3
        },
        "dateTo": {
            "title": "Date to",
            "type": "string",
            "description": "Any date accepted by strtotime (https://www.php.net/manual/en/function.strtotime.php) function",
            "minLength": 1,
            "default": "",
            "propertyOrder": 4
        }
    }
}
{% endhighlight %}

### Links Example
If you want to provide links to external resources, keep in mind that the configuration schema does not support markdown, 
but it has a `links` feature. The above example can be modified so that the links are clickable:

{% highlight json %}
{
    "title": "Parameters",
    "type": "object",
    "required": [
        "dateFrom",
        "dateTo",
        "username",
        "#password"
    ],
    "properties": {
        "username": {
            "title": "Username",
            "type": "string",
            "minLength": 1,
            "default": "",
            "propertyOrder": 1
        },
        "#password": {
            "title": "Password",
            "type": "string",
            "format": "password",
            "minLength": 1,
            "default": "",
            "propertyOrder": 2
        },
        "dateFrom": {
            "title": "Date from",
            "type": "string",
            "description": "Any date accepted by the strtotime function",            
            "minLength": 1,
            "default": "",
            "propertyOrder": 3,
            "links": [
                {
                    "rel": "strtotime Documentation",
                    "href": "https://www.php.net/manual/en/function.strtotime.php"
                }
            ]
        },
        "dateTo": {
            "title": "Date to",
            "type": "string",
            "description": "Any date accepted by the strtotime function",
            "minLength": 1,
            "default": "",
            "propertyOrder": 4,
            "links": [
                {
                    "rel": "strtotime Documentation",
                    "href": "https://www.php.net/manual/en/function.strtotime.php"
                }
            ]
        }
    }
}
{% endhighlight %}

Which renders like this:

{: .image-popup}
![Configuration Schema with links](/extend/component/ui-options/configuration-schema-2.png)


================================================
File: extend/component/ui-options/index.md
================================================
---
title: UI Options
permalink: /extend/component/ui-options/
---

* TOC
{:toc}

Each component needs to specify how its user interface (UI) will look. Otherwise the component cannot
be configured via the UI (it can still be configured using the API though).

The most basic UI configuration is `genericDockerUI`. The generic UI will always show a text field for entering the
component configuration in JSON format. Other parts of the UI are turned on using other [UI options](/extend/component/ui-options/)
(for example, `genericDockerUI-tableInput`, `genericDockerUI-tableOutput`). All of the [UI options](/extend/component/ui-options/) may be combined freely.

## genericDockerUI
This provides a basic text area for setting component parameters as a JSON; the text area has
JSON validation and syntax highlighting.

{: .image-popup}
![Generic configuration screenshot](/extend/component/ui-options/configuration.png)

The configuration provided in this input is available in the `parameters` section of the
[configuration file](/extend/common-interface/config-file/#configuration-file-structure).
Defining a [configuration schema](/extend/component/ui-options/configuration-schema/) will replace the JSON text area with a form.

## genericDockerUI-tableInput
This flag provides a UI for setting the table input [mapping](https://help.keboola.com/manipulation/transformations/mappings/).
You can set the following options:

- *Source* --- the name of the table in Storage
- Destination *file name* --- the name of the .csv file passed to the component
- *Columns* --- select only some columns of the source table
- *Days* --- load only rows modified in the specified number of days; useful for incremental loads; set to 0 to load all data
- *Data filter* --- a simple filter for selecting specified rows only

{: .image-popup}
![Table input screenshot](/extend/component/ui-options/table-input-0.png)

{: .image-popup}
![Table input detail screenshot](/extend/component/ui-options/table-input-1.png)

{: .image-popup}
![Table input result screenshot](/extend/component/ui-options/table-input-2.png)

The configuration provided in this input is available in the `storage.input` section of the
[configuration file](/extend/common-interface/config-file/#configuration-file-structure).

## genericDockerUI-tableOutput
This flag provides a UI for setting the table output [mapping](https://help.keboola.com/manipulation/transformations/mappings/). This UI part **should not be used**
if the component is using the [default bucket](/extend/common-interface/folders/#default-bucket) setting.

With this UI, you can set the following options:

- *Source* --- the name of the .csv file retrieved from the component
- *Destination* --- the name of the table in Storage, the destination bucket should exist already
- *Incremental* --- if checked, the loaded data will be appended to the contents of the destination table
- *Primary key* --- set the primary key for your destination table --- multiple columns are allowed
- *Delete rows* --- delete some rows from the destination table using a simple filter

{: .image-popup}
![Table output screenshot](/extend/component/ui-options/table-output-0.png)

{: .image-popup}
![Table output detail screenshot](/extend/component/ui-options/table-output-1.png)

{: .image-popup}
![Table output result screenshot](/extend/component/ui-options/table-output-2.png)

The configuration provided in this input is available in the `storage.output` section of the
[configuration file](/extend/common-interface/config-file/#configuration-file-structure).

## genericDockerUI-processors
This flag provides a UI for the [processor configuration](/extend/component/processors/).
It offers a basic text area for setting the processors and their parameters as a JSON; the text area has
JSON validation and syntax highlighting.

{: .image-popup}
![Processors screenshot](/extend/component/ui-options/processors.png)

## genericDockerUI-fileInput
This flag provides a UI for setting the file input mapping. You can set the following options:

- *File tags* --- select files by the file tags listed in **File Uploads**
- *Query* --- [ElasticSearch query](https://www.elastic.co/guide/en/elasticsearch/reference/current/query-dsl-query-string-query.html#query-string-syntax)
to select files from **File Uploads**
- *Processed tags* --- used for [incremental processing](/extend/common-interface/config-file/#incremental-processing)

{: .image-popup}
![File input screenshot](/extend/component/ui-options/file-input-0.png)

{: .image-popup}
![File input detail screenshot](/extend/component/ui-options/file-input-1.png)

{: .image-popup}
![File input result screenshot](/extend/component/ui-options/file-input-2.png)

The configuration provided in this input is available in the `storage.input` section of the
[configuration file](/extend/common-interface/config-file/#configuration-file-structure).

## genericDockerUI-fileOutput
This flag provides a UI for setting the file output mapping. You can set the following options:

- *Source* --- the name of the file produced by the component
- *File tags* --- the file tags assigned to the produced file
- *Is public* --- the file is accessible to anyone knowing its URL
- *Is permanent* --- the file will not be deleted after 15 days

{: .image-popup}
![File output screenshot](/extend/component/ui-options/file-output-0.png)

{: .image-popup}
![File output detail screenshot](/extend/component/ui-options/file-output-1.png)

{: .image-popup}
![File output result screenshot](/extend/component/ui-options/file-output-2.png)

The configuration provided in this input is available in the `storage.output` section of the
[configuration file](/extend/common-interface/config-file/#configuration-file-structure).

## genericDockerUI-authorization
This flag provides a UI for setting [OAuth2 Authorization](/extend/common-interface/oauth/). However, to
actually activate OAuth for your component, you have to [contact our support](mailto:support@keboola.com).

{: .image-popup}
![Authorization screenshot](/extend/component/ui-options/auth-0.png)

{: .image-popup}
![Authorization detail screenshot](/extend/component/ui-options/auth-1.png)

The configuration provided in this input is available in the `authorization` section of the
[configuration file](/extend/common-interface/config-file/#configuration-file-structure).

## genericTemplatesUI
This flag is used to provide a UI for components based on the [Generic Extractor](/extend/generic-extractor/). It allows the end user to select a
[Generic Extractor template](/extend/generic-extractor/publish/).


================================================
File: extend/component/ui-options/default-configuration/index.md
================================================
---
title: Default Configuration
permalink: /extend/component/ui-options/default-configuration/
---

* TOC
{:toc}

To make configuring a component easier for users, you can provide a default configuration for it. 
This can be done by defining either *Default Configuration* or *Default Row Configuration* 
in [Keboola Developer Portal](https://components.keboola.com/): 

{: .image-popup}
![Setting Default Configuration in Developer Portal](/extend/component/ui-options/default-configuration/developer-portal-01.png)

## Default Configuration

If you define *Default Configuration* for your component, all new configurations
will be created with this configuration.

Let's assume your component has the following JSON set as *Default Configuration*:

{% highlight json %}

{
    "parameters": {
        "debug": true
    }
}

{% endhighlight %}

Once the new configuration is created, the configuration JSON will look like this:

{% highlight json %}

{
    "changeDescription": "Configuration created",
    "configuration": {
        "parameters": {
            "debug": true
        }
    },
    "created": "2021-06-17T12:14:50+0200",
    "description": "",
    "id": "719629255",
    "name": "My DynamoDB Data Source",
    "state": {},
    "version": 1
}

{% endhighlight %}

## Default Row Configuration

The same also applies to rows. If a component has *Default Row Configuration*
defined, e.g., like this:

{% highlight json %}

{
    "parameters": {
        "verbose": false
    }
}

{% endhighlight %}

Then adding a new row to the configuration will use the default values too, and the final configuration
will look like this:

{% highlight json %}

{
    "changeDescription": "Configuration created",
    "configuration": {
        "parameters": {
            "debug": true
        }
    },
    "created": "2021-06-17T12:14:50+0200",
    "description": "",
    "id": "719629255",
    "name": "My DynamoDB Data Source",
    "state": {},
    "version": 2,
    "rowsSortOrder": [],
    "rows": [
        {
            "id": "30645",
            "name": "Test",
            "description": "",
            "isDisabled": false,
            "version": 1,
            "created": "2021-06-17T12:22:19+0200",
            "changeDescription": "Create query Test",
            "state": {},
            "configuration": {
                "parameters": {
                    "verbose": false
                }
            }
        }
    ]
}

{% endhighlight %}


================================================
File: extend/component/ui-options/ui-examples/configuration-schema-examples.md
================================================
---
title: UI Element Examples
permalink: /extend/component/ui-options/configuration-schema/examples/

---

* TOC
{:toc}

[JSON schema](https://json-schema.org/) allows for design of some advanced UI elements. Some of these are often reused 
in many components. This page contains a list of the commonly used UI elements and some advanced tips for UI design.

### API Token & Secret Values

Always prefix private parameters like passwords with `#` character. These will be automatically hashed and hidden from the view. 
Use a textual input field with `"format":"password"` in the JsonSchema for these values to hide the content also during the typing.

```json
{
    "#api_token": {
        "type": "string",
        "title": "API token",
        "format": "password",
        "propertyOrder": 1
    }
}
```

The above code will create the following user interface:

{: .image-popup}
![Password Screenshot](/extend/component/ui-options/ui-examples/password.png)


### Checkboxes

```json
{
    "campaigns": {
        "type": "boolean",
        "title": "Download Campaigns",
        "default": false,
        "format": "checkbox",
        "propertyOrder": 30
    },
    "segments": {
        "type": "boolean",
        "title": "Download Segments",
        "default": false,
        "format": "checkbox",
        "propertyOrder": 40
    }
}
```

The above code will create the following user interface:

{: .image-popup}
![Checkboxes screenshot](/extend/component/ui-options/ui-examples/checkbox.png)


### Multi Selection

```json
{
    "types": {
        "type": "array",
        "title": "Types",
        "description": "Activity types",
        "items": {
            "enum": [
                "page",
                "event",
                "attribute_change",
                "failed_attribute_change",
                "stripe_event",
                "drafted_email",
                "failed_email",
                "dropped_email",
                "sent_email",
                "spammed_email",
                "bounced_email",
                "delivered_email",
                "triggered_email",
                "opened_email"
            ],
            "type": "string"
        },
        "format": "select",
        "uniqueItems": true,
        "propertyOrder": 360
    }
}
```

The above code will create the following user interface:

{: .image-popup}
![multiselect](/extend/component/ui-options/ui-examples/multi_select.png)


### Creatable Multi Select

Multi select with user creatable values

```json
{
  "test_creatable_multi_select": {
    "propertyOrder": 50,
    "type": "array",
    "items": {
      "type": "string"
    },
    "format": "select",
    "options": {
      "tags": true
    },
    "description": "Multi-select element with no enum => user creates arbitrary values. Comma-separated values are supported.",
    "uniqueItems": true
  }
}
```

The above code will create the following element:

{: .image-popup}
![multiselect](/extend/component/ui-options/ui-examples/creatable_select.gif)


### Codemirror (json/sql/python..) Editor

Allow inject Codemirror editor to a JSON schema based UI. 
Allowed options: mode, placeholder, autofocus, lineNumbers lint
Available modes: `text/x-sfsql`, `text/x-sql`, `text/x-plsql`, `text/x-python`, `text/x-julia`, `text/x-rsrc`, `application/json`
JSON mode supports encryption. Default mode is `application/json` . You should set type base on mode (string or object).

**JsonSchema examples:**

```json
{
  "token": {
    "type": "object",
    "format": "editor"
  }
}
```

```json
{
  "sql": {
    "type": "string",
    "format": "editor",
    "options": {
      "editor": {
        "mode": "text/x-sql"
      }
    }
  }
}
```

```json
{
  "json_properties": {
      "type": "object",
      "title": "User Parameters",
      "format": "editor",
      "default": {
        "debug": false
      },
      "options": {
        "editor": {
          "lint": true,
          "mode": "application/json",
          "lineNumbers": true,
          "input_height": "100px"
        }
      },
      "description": "User parameters accessible, the result will be injected in standard data/config.json parameters property as in any other component",
      "propertyOrder": 1
    }
}
```

The above code will create the following element:

{: .image-popup}
![multiselect](/extend/component/ui-options/ui-examples/code_editor.png)


### Trimmed String

Works only for simple string inputs. Value is trimmed before save.

**JsonSchema example:**

```json
"token": {
  "type": "string",
  "format": "trim"
}
```



### Date Range

When a date range is applicable, it should be bounded by two parameters: *From Date* and *To Date*. 
These should be the text fields that accept a particular date in a specified format or a string defining a relative 
interval in [strtotime](https://www.php.net/manual/en/function.strtotime.php) manner. 

**Tip:** A convenient Python function for parsing such values and conversion to date can be found in the Keboola python-utils library 
([parse_datetime_interval](https://github.com/keboola/python-utils#getting-converted-date-period-from-string)).

```json
{
    "date_from": {
        "propertyOrder": 5,
        "type": "string",
        "title": "From date [inclusive]",
        "description": "Date from. Date in YYYY-MM-DD format or a string i.e. 5 days ago, 1 month ago, yesterday, etc. If left empty, all records are downloaded."
    },
    "date_to": {
        "propertyOrder": 7,
        "type": "string",
        "title": "To date [exclusive]",
        "default": "now",
        "description": "Date to. Date in YYYY-MM-DD format or a string i.e. 5 days ago, 1 month ago, yesterday, etc. If left empty, all records are downloaded."
    }
}
```

The above code will create the following user interface:

{: .image-popup}
![Date period](/extend/component/ui-options/ui-examples/det_period.png)


### Loading Options (Incremental vs Full)

This may be combined in [loading options block](/extend/component/ui-options/configuration-schema/examples/#example-1---object-blocks-loading-options).

```json
{
    "incremental_output": {
        "type": "number",
        "enum": [
            0,
            1
        ],
        "options": {
            "enum_titles": [
                "Full Load",
                "Incremental Update"
            ]
        },
        "default": 1,
        "title": "Load type",
        "description": "If set to Incremental update, the result tables will be updated based on the primary key. Full load overwrites the destination table each time. NOTE: If you wish to remove deleted records, this needs to be set to Full load and the Period from attribute empty.",
        "propertyOrder": 365
    }
}
```

The above code will create the following user interface:

{: .image-popup}
![Date period](/extend/component/ui-options/ui-examples/load_type.png)

### Visual Separation of Sections

It often happens that the configuration can be split into multiple sections. 
It is advisable to split these visually using JSON Schema objects or arrays to achieve it using the generic UI.

#### Example 1 – Object blocks (loading options)

Loading options block:

```json
{
    "loading_options": {
        "type": "object",
        "title": "Loading Options",
        "propertyOrder": 400,
        "format": "grid",
        "required": [
            "incremental_output",
            "date_since",
            "date_to"
        ],
        "properties": {
            "date_since": {
                "type": "string",
                "title": "Period from date [including].",
                "default": "1 week ago",
                "description": " Date in YYYY-MM-DD format or dateparser string, i.e., 5 days ago, 1 month ago, yesterday, etc. If left empty, all records are downloaded.",
                "propertyOrder": 300
            },
            "date_to": {
                "type": "string",
                "title": "Period to date [excluding].",
                "default": "now",
                "description": " Date in YYYY-MM-DD format or dateparser string, i.e., 5 days ago, 1 month ago, yesterday, etc. If left empty, all records are downloaded.",
                "propertyOrder": 400
            },
            "incremental_output": {
                "type": "number",
                "enum": [
                    0,
                    1
                ],
                "options": {
                    "enum_titles": [
                        "Full Load",
                        "Incremental Update"
                    ]
                },
                "default": 1,
                "title": "Load type",
                "description": "If set to Incremental update, the result tables will be updated based on the primary key. Full load overwrites the destination table each time. NOTE: If you wish to remove deleted records, this needs to be set to Full load and the Period from attribute empty.",
                "propertyOrder": 450
            }
        }
    }
}
```

The above code will create the following user interface:

{: .image-popup}
![loading options block](/extend/component/ui-options/ui-examples/loading_options_block.png)

#### Example 2 – Optional blocks using arrays

Create an array with parameter `"maxItems": 1` to create optional blocks.

```json
{
    "customers": {
        "type": "array",
        "title": "Customers",
        "description": "Download Customers.",
        "propertyOrder": 4000,
        "maxItems": 1,
        "items": {
            "type": "object",
            "title": "Setup",
            "required": [
                "filters",
                "attributes"
            ],
            "properties": {
                "filters": {
                    "type": "string",
                    "title": "Filter",
                    "description": "Optional JSON filter, as defined in https://customer.io/docs/api-triggered-data-format#general-syntax. Example value: {\"and\":[{\"segment\":{\"id\":7}},{\"segment\":{\"id\":5}}]} If left empty, all users are downloaded",
                    "format": "textarea",
                    "propertyOrder": 1
                },
                "attributes": {
                    "type": "string",
                    "title": "Attributes",
                    "format": "textarea",
                    "options": {
                        "input_height": "100px"
                    },
                    "description": "Comma-separated list of required customer attributes. Each customer may have different set of columns, this is to limit only to attributes you need. All attributes are downloaded if left empty.",
                    "uniqueItems": true,
                    "propertyOrder": 700
                }
            }
        }
    }
}
```

The above code will create the following user interface:

{: .image-popup}
![optional block](/extend/component/ui-options/ui-examples/optional_block_array.gif)


### Changing Set of Options Dynamically Based on Selection

In some cases, a different set of options is available for different types of the same object, e.g., Report type. 
JSON Schema allows to define different schemas based on selection. 
This may be useful in the configuration rows scenario, where each row could represent a different type of Report, Endpoint, etc.

This can be achieved via [dependencies](https://github.com/json-editor/json-editor#dependencies).* 


```json
{
  "type": "object",
  "title": "extractor configuration",
  "required": [
    "download_attachments"

  ],
  "properties": {
    "download_attachments": {
      "type": "boolean",
      "format": "checkbox",
      "title": "Download Attachments",
      "description": "When set to true, also the attachments will be downloaded. By default into the File Storage. Use processors to control the behaviour.",
      "default": false,
      "propertyOrder": 300
    },
    "attachment_pattern": {
      "type": "string",
      "title": "Attachment Pattern",
      "description": "Regex pattern to filter particular attachments, e.g., to retrieve only pdf file types use: .+\\.pdf If left empty, all attachments are downloaded.",
      "default": ".+\\.csv",
      "options": {
        "dependencies": {
          "download_attachments": true
        }
      },
      "propertyOrder": 400
    }
  }
}
```

The above code will create the following user interface:

{: .image-popup}
![dynamic selection](/extend/component/ui-options/ui-examples/dynamic_sel.gif)

You can also react on multiple array values or on multiple elements at the same time.:

```json
"options": {
  "dependencies": {
    "endpoint": [
      "analytics_data_breakdown_by_content", "analytics_data_breakdown_by_object"
    ],
    "filtered": false
  }
}
```


================================================
File: extend/component/ui-options/ui-examples/sync-action-examples.md
================================================
---
title: Sync Action UI Elements Examples
permalink: /extend/component/ui-options/configuration-schema/sync-action-examples/

---

* TOC
{:toc}

Some UI elements use [sync actions](https://developers.keboola.com/extend/common-interface/actions/) to get some values dynamically 
from the component code. This section provides a list of the elements currently supported. 

Each element specifies the `action` attribute, which relates to the name of the sync action registered in the Developer Portal.

***Note:** Support for these elements is also abstracted in the official [Python Component library](https://github.com/keboola/python-component#framework-support).*

### Dynamically Loaded Dropdowns

Drop-down lists (values and labels) can be loaded by the component sync action. 

The sync action code has to return the following stdout:

```
[
 { label: 'Joe', value: 'joe' },
 { label: 'Doe', value: 'doe },
 { label: 'Jane', value: 'jane' }
]
```

The `label` value is optional. 

When used in Python, you can use the [SelectElement](https://github.com/keboola/python-component#selectelement) class as a return value.

#### Dynamically loaded multi select

```json
{
    "test_columns": {
      "type": "array",
      "propertyOrder": 10,
      "description": "Element loaded by an arbitrary sync action.",
      "items": {
        "enum": [],
        "type": "string"
      },
      "format": "select",
      "options": {
        "async": {
          "label": "Re-load test columns",
          "action": "testColumns"
        }
      },
      "uniqueItems": true
    }
}
```

The above code will create the following element, which triggers an action named `testColumns`:

{: .image-popup}
![Screenshot](/extend/component/ui-options/ui-examples/dynamic_dropdown_multi.gif)


#### Dynamically loaded single select

```json
{
  "test_columns_single": {
    "propertyOrder": 40,
    "type": "string",
    "description": "Element loaded by an arbitrary sync action (single).",
    "enum": [],
    "format": "select",
    "options": {
      "async": {
        "label": "Re-load test columns",
        "action": "testColumns"
      }
    }
  }
}
```

The above code will create the following element, which triggers the `testColumns` action:

{: .image-popup}
![ Screenshot](/extend/component/ui-options/ui-examples/single-drop.gif)



### Generic Validation Button

This button can be used to return feedback from the component. The output supports Markdown.

Example use cases are query testing, testing connection, report validation, etc.

The sync action code has to return the following stdout (JSON string):

```json
{
  "message": "###This is display text. \n\n It can contain **Markdown** notation. ",
  "type": "info", //possible values: success, info, warning, danger
  "status": "success" // this is required and will never be other value than "success"
}
```


When used in Python, you can use the [ValidationResult](https://github.com/keboola/python-component#validationresult) class as a return value.

#### Example

```json
{
  "validation_button": {
    "type": "button",
    "format": "sync-action",
    "propertyOrder": 10,
    "options": {
      "async": {
        "label": "Validate",
        "action": "validate_report"
      }
    }
  }
}
```

The above code will create the following element, which triggers the `validate_report` action:

{: .image-popup}
![screenshot](/extend/component/ui-options/ui-examples/generic-button.gif)


### Test Connection

This button can be used for simple connection tests. 

The sync action code has to return the following stdout (JSON string) or error (exit code >0):

```json
{
  "status": "success" // this is required and will never be other value than "success"
}
```

The name of this sync action **always has to be `testConnection`.**

When used in Python, the method does not need to return anything, or it can just throw an exception.

#### Example

```json
{
    "test_connection": {
      "type": "button",
      "format": "sync-action",
      "propertyOrder": 30,
      "options": {
        "async": {
          "label": "TEST CONNECTION",
          "action": "validate_connection"
        }
      }
    }
}
```

The above code will create the following element, which triggers the `testConnection` action:

{: .image-popup}
![multiselect](/extend/component/ui-options/ui-examples/test_connection.png)


### Autoload

All sync action types (buttons, select, and multi-selects) can automatically trigger the sync action if not defined on the UI page load. 

#### Example

```json
{
  "endpoint": {
    "type": "string",
    "title": "Endpoint",
    "description": "Use the sync action to get a list of available endpoints.",
    "propertyOrder": 1,
    "options": {
      "async": {
        "label": "List Endpoints",
        "action": "listEndpoints",
        "autoload": []
      }
    },
    "items": {
      "enum": [],
      "type": "string"
    },
    "enum": []
  }
}
```

Additionally, a watch element can be set in an autoload array, which, when defined or changed, will trigger the sync action.

#### Example

```json
{
  "field_names": {
    "type": "array",
    "format": "select",
    "title": "Fields (optional)",
    "description": "List of field names to be downloaded",
    "propertyOrder": 2,
    "options": {
      "async": {
        "label": "List Fields",
        "action": "listFields",
        "autoload": [
          "parameters.endpoint"
        ]
      }
    },
    "items": {
      "enum": [],
      "type": "string"
    },
    "uniqueItems": true
  }
}
```

The autoload option also enables caching loaded values by default, which can be disabled by setting the `autoload.cache` to false.

#### Example

```json
{
  "endpoint": {
    "type": "string",
    "title": "Endpoint",
    "description": "Use a sync action to get a list of available endpoints.",
    "propertyOrder": 1,
    "options": {
      "async": {
        "label": "List Endpoints",
        "action": "listEndpoints",
        "autoload": [],
        "cache": false
      }
    },
    "items": {
      "enum": [],
      "type": "string"
    },
    "enum": []
  }
}
```


================================================
File: extend/docker-runner/index.md
================================================
---
title: Docker Runner
permalink: /extend/docker-runner/
redirect_from:
    - /integrate/docker-bundle/
    - /integrate/docker-runner/
---

* TOC
{:toc}

Docker Runner is a core [Keboola component](/overview/#important-components), which
provides an interface for running other Keboola components. Every component in Keboola is
represented by a [Docker image](/extend/component/docker-tutorial/).
Running a component means creating and executing an [asynchronous job](/integrate/jobs/).

Developing functionality in [Docker](https://www.docker.com/) allows you to focus only on the application logic; all communication
with the [Storage API](https://keboola.docs.apiary.io/#) will be handled by Docker Runner. You can encapsulate any application into a Docker image
following a set of rules that will allow you to integrate the application into Keboola.

There is a [predefined interface](/extend/common-interface/) with Docker Runner, consisting
mainly of a [folder structure](/extend/common-interface/folders/) and a [serialized configuration file](/extend/common-interface/config-file/).
All [components](/extend/component/), including our internal R and Python Transformations, are run using Docker Runner.

## Workflow
The Docker Runner functionality can be described in the following steps:

- Download and build the specified Docker image.
- Download all [tables](/extend/common-interface/folders/#dataintables-folder) and [files](/extend/common-interface/folders/#datainfiles-folder) specified in the input mapping from Storage.
- Create a [configuration file](/extend/common-interface/config-file/).
- Run [before processors](/extend/component/processors/) if there are any.
- Run the Docker image (create a Docker container).
- Run [after processors](/extend/component/processors/) if there are any.
- Upload all [tables](/extend/common-interface/folders/#dataouttables-folder) and
[files](/extend/common-interface/folders/#dataoutfiles-folder) in the output mapping to Storage.
- Delete the container and all temporary files.

When the component execution is finished, Docker Runner automatically collects the exit code and the content of STDOUT and STDERR.
The following schema illustrates the workflow of running a dockerized component.

![Docker Workflow](/extend/docker-runner/docker-runner.svg)

### Features
The component is responsible for these processes:

- Reading the configuration and source tables in CSV format and files (if specified)
- Writing the results to the predefined folders and files
- Proper handling of success/error results by setting an appropriate exit code

Docker Runner is responsible for the following processes:

- **Authentication:** Docker Runner makes sure the component is run by authorized users/tokens.
It is not possible to run a component anonymously. The component does not have an access to the Keboola token
itself, and it receives only limited information about the project and the end-user.
- **Starting and stopping** the component: Docker Runner will boot a Docker container which contains the
component. This ensures the component runs in a precisely defined environment, which is guaranteed to
be the same for each component run. No component state is preserved (with the exception of the
[state file](/extend/common-interface/config-file/#state-file).
- **Reading and writing data** to Keboola Storage: Docker Runner ensures a custom component
cannot access arbitrary data in the project. It will only receive the input mapping defined by the end user;
and only those outputs defined in the output mapping by the end user will be written to the project.
- **Component isolation**: Each component is run in its own Docker container, which is isolated from other
containers; the component cannot be affected by other running components. It may also be limited
to have no network access.

## API
The Docker Runner API is described on [Apiary.io](https://kebooladocker.docs.apiary.io/#). Docker Runner
has API calls to

- run a [component](/extend/component/).
- [encrypt values](/overview/encryption/).
- [prepare the data folder](/extend/component/running/#preparing-the-data-folder).
- run [component actions](/extend/common-interface/actions/).
- run a [component](/extend/component/) with a [specified Docker image tag](https://kebooladocker.docs.apiary.io/#reference/run/create-a-job-with-image/run-job), usable for [testing images](/extend/component/deployment/#test-live-configurations).

## Configuration
Components executed by Docker Runner store their configurations in
[Storage API components configurations](https://keboola.docs.apiary.io/#reference/components-and-configurations).

When creating the configuration, use
[this JSON schema](https://github.com/keboola/docker-bundle/blob/master/Resources/schemas/configuration.json)
to validate the configuration before storing it. The configuration contains the following nodes,
all of them are optional:

- `parameters` --- an arbitrary object passed to the dockerized application itself
- `storage` --- configuration of [input and output mapping](/extend/common-interface/folders/); specific options correspond to the options of the
[unload data](https://keboola.docs.apiary.io/#reference/tables/unload-data-asynchronously) and
[load data](https://keboola.docs.apiary.io/#reference/tables/load-data-asynchronously) API calls.
- `runtime` --- configuration for modifying some image parameters at run time
- `processors` --- configuration of [Processors](/extend/component/processors/)
- `authorization` --- OAuth authorization [injected to the configuration](/extend/common-interface/oauth/); not stored in the component configuration
- `image_parameters` --- an arbitrary object passed from the [component](/extend/component/); not stored in the component configuration
- `action` --- an [action](/extend/common-interface/actions/) being executed; not stored in the component configuration


================================================
File: extend/generic-extractor/functions.md
================================================
---
title: Functions
permalink: /extend/generic-extractor/functions/
---

* TOC
{:toc}

Functions are simple pre-defined functions that

- allow you to add extra flexibility when needed.
- can be used in several places in the Generic Extractor configuration to introduce dynamically generated values instead of
those provided statically.
- allow referencing the existing values in the configuration instead of copying them.
- are advantageous and sometimes necessary when [publishing your configuration as a new component](/extend/generic-extractor/publish/).

## Configuration
A function is used instead of a simple value in specific parts of the Generic Extractor configuration (see [below](#function-contexts)).
A function configuration is an object with the properties `function` (one of the [available function names](#supported-functions) and `args`
(function arguments), for example:

{% highlight json %}
{
    "function": "concat",
    "args": [
        "John",
        "Doe"
    ]
}
{% endhighlight %}

The argument of a function can be any of the following:

- [Scalar](/extend/generic-extractor/tutorial/json/#data-values) (simple) value (as in the above example)
- Reference to a value from [function context (see below)](#function-contexts)
- Another function object

Additionally, the function may be replaced by a plain reference to the function context. This means you can write (where permitted)
a configuration value in three possible ways:

**A simple value:**

{% highlight json %}
{
    ...,
    "baseUrl": "http://example.com/
}
{% endhighlight %}

**A function call:**

{% highlight json %}
{
    ...,
    "baseUrl": {
        "function": "concat",
        "args": [
            "http://",
            "example.com"
        ]
    }
}
{% endhighlight %}

**A reference to a value from the function context:**
{% highlight json %}
{
    ...,
    "baseUrl": {
        "attr": "someUrl"
    }
}
{% endhighlight %}

These forms can be combined freely. They can be also nested in a virtually unlimited way. For instance:

{% highlight json %}
{
    ...,
    "baseUrl": {
        "function": "concat",
        "args": [
            "https://",
            {
                "attr": "domain"
            }
        ]
    }
}
{% endhighlight %}

### User Interface
You may create functions in the user interface's `User Parameters` or `User Data` sections. 
You can also create the functions directly from other configuration contexts, e.g., when defining the query parameters on the endpoint.

Aside from predefined functions, the UI also offers the most common templates that you can use.

{: .image-popup}
![img.png](/extend/generic-extractor/functions.png)

The UI also offers a convenient way to evaluate the function and see the results.

{: .image-popup}
![img.png](/extend/generic-extractor/function_eval.gif)


## Supported Functions

### md5
The [`md5` function](https://www.php.net/manual/en/function.md5.php) calculates the [MD5 hash](https://en.wikipedia.org/wiki/MD5) of a
string. The function takes one argument, which is the string to hash.

{% highlight json %}
{
    "function": "md5",
    "args": [
        "NotSoSecret"
    ]
}
{% endhighlight %}

The above will produce `1228d3ff5089f27721f1e0403ad86e73`.

See an [example](#job-parameters).

### sha1
The [`sha1` function](https://www.php.net/manual/en/function.sha1.php) calculates the [SHA-1 hash](https://en.wikipedia.org/wiki/SHA-1) of a
string. The function takes one argument which is the string to hash.

{% highlight json %}
{
    "function": "sha1",
    "args": [
        "NotSoSecret"
    ]
}
{% endhighlight %}

The above will produce `64d5d2977cc2573afbd187ff5e71d1529fd7f6d8`.

See an [example](#job-parameters).

### base64_encode
The [`base64_encode` function](https://www.php.net/manual/en/function.base64-encode.php) converts a
string to the [MIME Base64 encoding](https://en.wikipedia.org/wiki/Base64#MIME). The function
takes one argument which is the string to encode.

{% highlight json %}
{
    "function": "base64_encode",
    "args": [
        "TeaPot"
    ]
}
{% endhighlight %}

The above will produce `VGVhUG90`.

See an [example](#nested-functions).

### hash_hmac
The [`hash_hmac` function](https://www.php.net/manual/en/function.hash-hmac.php) creates
an [HMAC (Hash-based message authentication code)](https://en.wikipedia.org/wiki/Hash-based_message_authentication_code)
from a string. The function takes
three arguments:

1. Name of a hashing algorithm (see the
[list of supported algorithms](https://www.php.net/manual/en/function.hash-algos.php#refsect1-function.hash-algos-examples))
2. Value to hash
3. Secret key

{% highlight json %}
{
    "function": "hash_hmac",
    "args": [
        "sha256",
        "12345abcd5678efgh90ijk",
        "TeaPot"
    ]
}
{% endhighlight %}

The above will return `d868d581b2f2edd09e8e7ce12c00723b3fcffb6a5d74c40eae9d94181a0bf731`.

See an [example](#api-default-parameters).


### hash
This function works similarly to the `hash_hmac` function but requires only two arguments (no secret key required):

1. The name of a hashing algorithm (see the
   [list of supported algorithms](https://www.php.net/manual/en/function.hash-algos.php#refsect1-function.hash-algos-examples)).
2. The value to hash.

{% highlight json %}
{
    "function": "hash",
    "args": [
        "sha256",
        "12345abcd5678efgh90ijk"
    ]
}
{% endhighlight %}

### time
The [`time` function](https://www.php.net/manual/en/function.time.php) returns the current time as a
[Unix timestamp](https://en.wikipedia.org/wiki/Unix_time).
To obtain the current time in a more readable format, use the
the [`date` function](#date). It takes no arguments.

{% highlight json %}
{
    "function": "time"
}
{% endhighlight %}

The above will produce something like `1492674974`.

### date
The [`date` function](https://www.php.net/manual/en/function.date.php) formats the provided or the current
timestamp into a human readable format. The function takes either one or two arguments:

1. [Formatting string](https://www.php.net/manual/en/function.date.php#refsect1-function.date-parameters)
2. Optional [Unix timestamp](https://en.wikipedia.org/wiki/Unix_time); if not provided, the current time is used.

{% highlight json %}
{
    "function": "date",
    "args": [
        "Y-m-d"
    ]
}
{% endhighlight %}

The above will produce something like `2017-04-20`.

{% highlight json %}
{
    "function": "date",
    "args": [
        "Y-m-d H:i:s",
        1490000000
    ]
}
{% endhighlight %}

The above will produce `2017-03-20 8:53:20`.

See an [example](#user-data).

### strtotime
The [`strtotime` function](https://www.php.net/manual/en/function.strtotime.php) converts a string date into a [Unix timestamp](https://en.wikipedia.org/wiki/Unix_time). The function takes
one or two arguments:

1. String date
2. Base for relative dates (see below)

{% highlight json %}
{
    "function": "strtotime",
    "args": [
        "21 oct 2017 9:16pm"
    ]
}
{% endhighlight %}

The above will produce `1508620560`, which represents the date `2017-10-21 21:16:00`. However, the
[`strtotime` function](https://www.php.net/manual/en/function.strtotime.php) is most useful with relative dates which it also allows. For example, you can
write:

{% highlight json %}
{
    "function": "strtotime",
    "args": [
        "-7 days",
        1508620560
    ]
}
{% endhighlight %}

The above will give `1508015760`, which represents the date `2017-10-14 21:16:00`. The second argument
specifies the base date (as a Unix timestamp) from which the relative date is computed. This is particularly
useful for [incremental extraction](/extend/generic-extractor/incremental/). Also note that
it is common to combine the `strtotime` and `date` functions to convert between string and timestamp
representation of a date.

See an [example](#nested-strtotime).

### sprintf
The `sprintf` function formats values and inserts them into a string. The `sprintf` function maps directly to
the [original PHP function](https://www.php.net/manual/en/function.sprintf.php), which is very versatile and has many
uses. The function accepts two or more arguments:

1. String with [formatting directives](https://www.php.net/manual/en/function.sprintf.php) (marked with the percent character `%`)
2. Values inserted into the string:

{% highlight json %}
{
    "function": "sprintf",
    "args": [
        "Three %s are %.2f %s.",
        "apples",
        0.5,
        "plums"
    ]
}
{% endhighlight %}

The above will produce `Three apples are 0.50 plums.`

See a [simple insert example](#api-base-url) or a [formatting example](#job-placeholders).

### concat
The `concat` function concatenates an arbitrary number of strings into one. For example:

{% highlight json %}
{
    "function": "concat",
    "args": [
        "Hen",
        "Or",
        "Egg"
    ]
}
{% endhighlight %}

The above will produce `HenOrEgg` (see [example 1](#api-base-url), [example 2](#headers)). See also the
[`implode` function](#implode).

### implode
The [`implode` function](https://www.php.net/manual/en/function.implode.php) concatenates an arbitrary number
of strings into one using a delimiter. The function takes
two arguments:

1. Delimiter string which is used for the concatenation
2. Array of values to be concatenated

For example:

{% highlight json %}
{
    "function": "implode",
    "args": [
        ",",
        [
            "apples",
            "oranges",
            "plums"
        ]
    ]
}
{% endhighlight %}

The above will produce `apples,oranges,plums` (see an [example](#headers)).
The delimiter can be empty, in which case the `implode` function is equivalent to the [`concat` function](#concat):

{% highlight json %}
{
    "function": "implode",
    "args": [
        "",
        [
            "Hen",
            "Or",
            "Egg"
        ]
    ]
}
{% endhighlight %}

### ifempty
The `ifempty` function can be useful for handling optional values. The function takes two arguments and
returns the first one if it is not empty. If the first argument is empty, it returns the second argument.

{% highlight json %}
{
    "function": "ifempty",
    "args": [
        "",
        "Banzai"
    ]
}
{% endhighlight %}

The above will return `Banzai`. For the `ifempty` function, an empty string and the values `0` and `null` are
considered 'empty'.

See an [example](#optional-job-parameters).

## Function Contexts
Every place in the Generic Extractor configuration in which a function may be used may allow different arguments of the function.
This is referred to as a **function context**. Many contexts share access to **configuration attributes**.

### Configuration Attributes
The configuration attributes are accessible in specific function contexts and they represent the entire [`config`](/extend/generic-extractor/configuration/config/)
section of the Generic Extractor configuration. There is some processing involved:

- The [`jobs`](/extend/generic-extractor/configuration/config/jobs/) section is removed entirely.
- All other values are flattened (keys are concatenated using a dot `.`) into a one-level deep object.
- The result object is available in a property named `attr`.

For example, the following configuration:

{% highlight json %}
{
    "parameters": {
        "api": {
            "baseUrl": "http://example.com"
        },
        "config": {
            "debug": true,
            "outputBucket": "get-tutorial",
            "server": "localhost:8888",
            "incrementalOutput": false,
            "jobs": [
                {
                    "endpoint": "users",
                    "dataType": "users"
                }
            ],
            "http": {
                "headers": {
                    "X-AppKey": "ThisIsSecret",
                    "X-Auth": {
                        "function": "concat",
                        "args": [
                            "Tea",
                            "Pot"
                        ]
                    }
                }
            },
            "userData": {
                "tag": "fullExtract",
                "mode": "development"
            },
            "mappings": {
                "content": {
                    "whatever": "foobar"
                }
            }
        }
    }
}
{% endhighlight %}

will be converted to the following function context:

{% highlight json %}
{
	"attr": {
		"debug": true,
		"outputBucket": "mock-server",
		"server": "localhost:8888",
		"incrementalOutput": false,
		"http.headers.X-AppKey": "ThisIsSecret",
		"http.headers.X-Auth.function": "concat",
		"http.headers.X-Auth.args.0": "Tea",
		"http.headers.X-Auth.args.1": "Pot",
		"userData.tag": "fullExtract",
		"userData.mode": "development",
		"mappings.content.whatever": "foobar"
	}
}
{% endhighlight %}

See [example [EX119]](https://github.com/keboola/generic-extractor/tree/master/doc/examples/119-function-nested-config).

### Base URL Context
The Base URL function context is used when setting the [`baseURL` for API](/extend/generic-extractor/configuration/api/#base-url), and it
contains [configuration attributes](/#function-contexts).

See an [example](#api-base-url).

### Headers Context
The Headers function context is used when setting the [`http.headers` for API](/extend/generic-extractor/configuration/api/#headers)
or the [`http.headers` in config](/extend/generic-extractor/configuration/config/#http), and it contains
[configuration attributes](/#function-contexts).

See an [example](#headers).

### Parameters Context
The Parameters function context is used when setting job [request parameters --- `params`](/extend/generic-extractor/configuration/config/jobs/#request-parameters).
It contains [configuration attributes](/#function-contexts) plus the times of the current
(`currentStart`) and previous (`previousStart`) run of Generic Extractor.
The times are [Unix timestamps](https://en.wikipedia.org/wiki/Unix_time).
If the extraction is run for the first time, `previousStart` is 0.

With the following configuration:

{% highlight json %}
{
    "parameters": {
        "api": {
            "baseUrl": "http://example.com"
        },
        "config": {
            "debug": true,
            "outputBucket": "get-tutorial",
            "server": "localhost:8888",
            "jobs": [
                ...
            ]
        }
    }
}
{% endhighlight %}

the parameters function context will contain:

{% highlight json %}
{
    "attr": {
        "debug": true,
        "outputBucket": "mock-server",
        "server": "localhost:8888"
    },
    "time": {
        "previousStart": 0,
        "currentStart": 1492678268
    }
}
{% endhighlight %}

See an [example of using parameters context](#job-parameters).

The `time` values are used in [incremental processing](/extend/generic-extractor/incremental/).

### Placeholder Context
The Placeholder function context refers to configuration of [placeholders in child jobs](/extend/generic-extractor/configuration/config/jobs/children/#placeholders).
When using function to process a placeholder value, the placeholder must be specified as an object with the `path` property.
Therefore instead of writing:

{% highlight json %}
"placeholders": {
    "user-id": "userId"
}
{% endhighlight %}

write:

{% highlight json %}
"placeholders": {
    "user-id": {
        "path": "userId",
        "function": ...
    }
}
{% endhighlight %}

The placeholder function context contains the following structure:

{% highlight json %}
{
    "placeholder": {
        "value": "???"
    }
}
{% endhighlight %}

where `???` is the value obtained from the response JSON from the path provided in the `path` property
of the placeholder.

See an [example](#job-placeholders).

### User Data Context
The User Data function context is used when setting the [`userData`](/extend/generic-extractor/configuration/config/#user-data).
The parameters context contains [configuration attributes](/#function-contexts) plus the times of the current (`currentStart`) and
previous (`previousStart`) run of Generic Extractor. The User Data Context is therefore
same as the [Parameters Context](#parameters-context).

See an [example](#user-data).

### Login Authentication Context
The Login Authentication function context is used in the
[login authentication](/extend/generic-extractor/configuration/api/authentication/login/) method.
Functions are supported in both [`loginRequest`](/extend/generic-extractor/configuration/api/authentication/login/#configuration-parameters)
and [`apiRequest` ](/extend/generic-extractor/configuration/api/authentication/login/#configuration-parameters) configurations.
The `loginRequest` function context contains [configuration attributes](/#function-contexts).
In the `apiRequest` context, the flattened reponse of the login request is available additionally
to the [configuration attributes](/#function-contexts).
The login authentication context is the same for both `params` and `headers`
[login authentication configuration options](/extend/generic-extractor/configuration/api/authentication/login/#configuration-parameters). If the
login authentication request returns e.g.:

{% highlight json %}
{
    "user": "John Doe",
	"authorization": {
		"token": "quiteSecret",
		"validUntil": "2017-20-12 12:20:17"
	}
}
{% endhighlight %}

The following function context will be available in the API request headers and query:

{% highlight json %}
{
    "attr": {
		"outputBucket": "mock-server"
    },
    "response": {
        "user": "John Doe",
        "authorization.token": "quiteSecret",
        "authorization.validUntil": "2017-20-12 12:20:17"
    }
}
{% endhighlight %}

The login response is available in the `response` node. The `attr` node contains [configuration attributes](/extend/generic-extractor/functions/#configuration-attributes).
See an [example](/extend/generic-extractor/configuration/api/authentication/login/#login-authentication-with-functions) and a more
[complicated example](/extend/generic-extractor/configuration/api/authentication/login/#login-authentication-with-login-and-api-request) of using functions in
both login request and API request.

### Query Authentication Context
The Query Authentication function context is used in the
[query authentication](/extend/generic-extractor/configuration/api/authentication/query/) method.
The Query Authentication Context contains [configuration attributes](/#function-contexts) plus
a representation of the complete HTTP request to be sent (`request`) plus a key
value list of query parameters of the HTTP request (`query`).

The following configuration:

{% highlight json %}
{
    "parameters": {
        "api": {
            "baseUrl": "http://example.com/",
            "http": {
                "defaultOptions": {
                    "params": {
                        "account": "admin"
                    }
                }
            },
            "authentication": {
                "type": "query",
                "query": {
                    "signature": {
                        "function": "sha1",
                        "args": [
                            "time",
                            {
                                "attr": "#api-key"
                            }
                        ]
                    }
                }
            }
        },
        "config": {
            "#api-key": "12345abcd5678efgh90ijk",
            "outputBucket": "mock-server",
            "jobs": [
                {
                    "endpoint": "users",
                    "params": {
                        "showColumns": "all"
                    }
                }
            ]
        }
    }
}
{% endhighlight %}

leads to the following function context:

{% highlight json %}
{
	"query": {
		"account": "admin",
		"showColumns": "all"
	},
	"request": {
		"url": "http:\/\/example.com\/users?account=admin&showColumns=all",
		"path": "\/users",
		"queryString": "account=admin&showColumns=all",
		"method": "GET",
		"hostname": "example.com",
		"port": 80,
		"resource": "\/users?account=admin&showColumns=all"
	},
	"attr": {
		"#api-key": "12345abcd5678efgh90ijk",
		"outputBucket": "mock-server"
	}
}
{% endhighlight %}

See the [basic example](#api-default-parameter) and a [more complicated example](#api-query-authentication).

### OAuth 2.0 Authentication Context
The OAuth Authentication Context is used for the
[`oauth20`](/extend/generic-extractor/configuration/api/authentication/oauth20/) authentication method
(it is not applicable to `oauth10`) and contains the following:

- Representation of the complete HTTP request to be sent (`request`)
- A key value list of query parameters of the HTTP request (`query`)
- An `authorization` section containing the response from the OAuth service provider

This context is available for both the `headers` and `query` sections of the `oauth20` authentication methods.

The following configuration:

{% highlight json %}
{
    "parameters": {
        "api": {
            "baseUrl": "http://example.com/",
            "authentication": {
                "type": "oauth20",
                "format": "json",
                "headers": {
                    "Authorization": {
                        "function": "concat",
                        "args": [
                            "Bearer ",
                            {
                                "authorization": "#data.access_token"
                            }
                        ]
                    }
                }
            }
        },
        "config": {
            "outputBucket": "mock-server",
            "jobs": [
                {
                    "endpoint": "users",
                    "dataType": "users"
                }
            ]
        }
    },
    "authorization": {
        "oauth_api": {
            "credentials": {
                "#data": "{\"status\": \"ok\",\"access_token\": \"testToken\", \"foo\": {\"bar\": \"baz\"}}",
                "appKey": "clientId",
                "#appSecret": "clientSecret"
            }
        }
    }
}
{% endhighlight %}

leads to the following function context:

{% highlight json %}
{
	"query": {
		"showColumns": "all"
	},
	"request": {
		"url": "http:\/\/example.com\/users?showColumns=all",
		"path": "\/users",
		"queryString": "showColumns=all",
		"method": "GET",
		"hostname": "example.com",
		"port": 80,
		"resource": "\/users?showColumns=all"
	},
	"authorization": {
		"data.status": "ok",
		"data.access_token": "testToken",
		"data.foo.bar": "baz"
		"timestamp": 1492949837,
		"nonce": "99206d94a6846841",
		"clientId": "clientId",
	}
}
{% endhighlight %}

The `authorization` section of the configuration contains the
[OAuth2 response](/extend/generic-extractor/configuration/api/authentication/oauth20/). The function context contains
the parsed and flattened response fields under the key `data`, provided that the response was sent in JSON format
and that [`"format": "json"`](/extend/generic-extractor/configuration/api/authentication/oauth20/#configuration) was set.

In the response above, these are the keys `data.status`, `data.access_token`, `data.foo.bar`. This is defined
entirely by the behavior of the OAuth Service provider. If the response is a plaintext (usually directly a token),
then the entire response is available in the field `data`.

Apart from that, the fields `timestamp` (Unix timestamp of the request),
`nonce` (cryptographic [nonce](https://en.wikipedia.org/wiki/Cryptographic_nonce) for
signing the request) and `clientId` (the value of `authorization.oauth_api.credentials.appKey`, which is obtained when
the application is published) are added to the `authorization` section.

For usage, see [OAuth examples](/extend/generic-extractor/configuration/api/authentication/oauth20/).

### OAuth 2.0 Login Authentication Context
The OAuth Login Authentication Context is used for the
[`oauth20.login`](/extend/generic-extractor/configuration/api/authentication/oauth20-login/) authentication method
(it is not applicable to `oauth20`). The OAuth Login Authentication context contains
OAuth information split into the properties `consumer` (response obtained from the service provider) and
`user` (data obtained from the user). This context is available for
both the `headers` and `params` sections of the `oauth20` authentication methods.
For the context available in the `apiRequest` configuration, see the [login authentication](/extend/generic-extractor/functions/#login-authentication-context).

The following configuration:

{% highlight json %}
{
    "parameters": {
        "api": {
            "baseUrl": "http://example.com",
            "authentication": {
                "type": "oauth20.login",
                ...
            }
        },
        "config": {
            ...
        }
    },
    "authorization": {
        "oauth_api": {
            "credentials": {
                "#data": "{\"status\": \"ok\",\"access_token\": \"testToken\", \"mac_secret\": \"iAreSoSecret123\", \"foo\": {\"bar\": \"baz\"}}",
                "appKey": "clientId",
                "#appSecret": "clientSecret"
            }
        }
    }
}
{% endhighlight %}

leads to the following function context:

{% highlight json %}
{
    "consumer": {
        "client_id": "clientId",
        "client_secret": "clientSecret"
    },
    "user": {
        "status": "ok",
        "access_token": "testToken",
        "mac_secret": "iAreSoSecret123",
        "foo.bar": "baz"
    }
}
{% endhighlight %}

The `authorization` section of the configuration contains the
[OAuth2 response](/extend/generic-extractor/configuration/api/authentication/oauth20/). The function context
contains the parsed and flattened response fields in the `user` property. The content of the
`user` property is fully dependent on the response of the OAuth service provider. The
`consumer` property contains the `client_id` and `client_secret` which contain values of
`authorization.oauth_api.credetials.appKey` and
`authorization.oauth_api.credetials.appSecret` respectively.
(These are obtained by Keboola when the application is published).

For usage, see [OAuth Login examples](/extend/generic-extractor/configuration/api/authentication/oauth20-login/).

## Examples

### API Base URL
When [publishing your Generic Extractor configuration](/extend/generic-extractor/publish/), chances are
you want the end-user to provide a part of the API configuration. Due to the limitations of
[how templates work](/extend/generic-extractor/publish/#configuration-considerations), the parameter
obtained from the end-user configuration will be only available in the `config` section.

Let's say that the end-user enters `www.example.com` as the API server and that values become
available as the `server` property of the `config` section, for instance:

{% highlight json %}
"config": {
    "outputBucket": "ge-tutorial",
    "server": "www.example.com",
    "jobs": [
        {
            "endpoint": "users",
            "dataType": "users"
        }
    ]
}
{% endhighlight %}

This means that the [configuration attributes](#configuration-attributes) will be available as:

{% highlight json %}
{
    "attr": {
        "outputBucket": "ge-tutorial",
        "server": "www.example.com"
    }
}
{% endhighlight %}

Then use the [`concat` function](#concat) to access that value and merge it with other parts to create the
final API URL (`http://example.com/api/1.0/`):

{% highlight json %}
{
    "parameters": {
        "api": {
            "baseUrl": {
                "function": "concat",
                "args": [
                    "http://",
                    {
                        "attr": "server"
                    },
                    "/api/1.0/"
                ]
            }
        }
    }
}
{% endhighlight %}

See [example [EX087] with concat](https://github.com/keboola/generic-extractor/tree/master/doc/examples/087-function-baseurl)
or an alternative [example [EX088] with sprintf](https://github.com/keboola/generic-extractor/tree/master/doc/examples/088-function-baseurl-sprintf).

### API Default Parameters
Suppose you have an API which expects a `tokenHash` parameter to be sent with every request. The
token hash is supposed to be generated by the SHA-256 hashing algorithm from a token and secret
you obtain.

Because the [`api.http.defaultOptions.params`](/extend/generic-extractor/configuration/api/#headers) option does not
support functions, either supply the parameters in the [`jobs.params`](/extend/generic-extractor/configuration/config/jobs/#request-parameters)
configuration, or use [API Query Authentication](/extend/generic-extractor/configuration/api/authentication/query/).
Using (or abusing) the API Query Authentication is possible if the default parameters represent authentication, or
if the API does not use any authentication method (two authentication methods are not possible):

The below configuration reads the `#api-key` and `#secret-key` parameters from the `config` section,
computes SHA-256 hash and sends it as a `tokenHash` parameter with every request.

{% highlight json %}
{
    "parameters": {
        "api": {
            "baseUrl": "http://example.com/",
            "authentication": {
                "type": "query",
                "query": {
                    "tokenHash": {
                        "function": "hash_hmac",
                        "args": [
                            "sha256",
                            {
                                "attr": "#api-key"
                            },
                            {
                                "attr": "#secret-key"
                            }
                        ]
                    }
                }
            }
        },
        "config": {
            "#api-key": "12345abcd5678efgh90ijk",
            "#secret-key": "TeaPot",
            "debug": true,
            "outputBucket": "mock-server",
            "jobs": [
                {
                    "endpoint": "users",
                    "dataType": "users"
                }
            ]
        }
    }
}
{% endhighlight %}

See [example [EX099]](https://github.com/keboola/generic-extractor/tree/master/doc/examples/099-function-query-parameters).

The solution with using the `jobs.params` configuration can look like this:

{% highlight json %}
{
    "parameters": {
        "api": {
            "baseUrl": "http://example.com/"
        },
        "config": {
            "#api-key": "12345abcd5678efgh90ijk",
            "#secret-key": "TeaPot",
            "debug": true,
            "outputBucket": "mock-server",
            "jobs": [
                {
                    "endpoint": "users",
                    "dataType": "users",
                    "params": {
                        "tokenHash": {
                            "function": "hash_hmac",
                            "args": [
                                "sha256",
                                {
                                    "attr": "#api-key"
                                },
                                {
                                    "attr": "#secret-key"
                                }
                            ]
                        }
                    }
                }
            ]
        }
    }
}
{% endhighlight %}

The only practical difference is that the `tokenHash` parameter is going to be sent only with
the single `users` job.

See [example [EX098]](https://github.com/keboola/generic-extractor/tree/master/doc/examples/098-function-hmac).

### API Query Authentication
Suppose you have an API with only a single endpoint `/items` to which you have to
pass a `type` parameter to list resources of a given type. On top of that, the API requires
an `apiToken` parameter and a `signature` parameter (a hash of the token and type) to be sent with every request.
The following configuration handles the situation:

{% highlight json %}
{
    "parameters": {
        "api": {
            "baseUrl": "http://mock-server:80/101-function-query-auth/",
            "authentication": {
                "type": "query",
                "query": {
                    "apiToken": {
                        "attr": "#token"
                    },
                    "signature": {
                        "function": "sha1",
                        "args": [
                            {
                                "function": "concat",
                                "args": [
                                    {
                                        "attr": "#token"
                                    },
                                    {
                                        "query": "type"
                                    }
                                ]
                            }
                        ]
                    }
                },
                "apiRequest": {
                    "headers": {
                        "X-Api-Token": "token"
                    }
                }
            }
        },
        "config": {
            "#token": "1234abcd567efg890hij",
            "debug": true,
            "outputBucket": "mock-server",
            "jobs": [
                {
                    "endpoint": "items",
                    "dataType": "users",
                    "params": {
                        "type": "users"
                    }
                },
                {
                    "endpoint": "items",
                    "dataType": "orders",
                    "params": {
                        "type": "orders"
                    }
                }
            ]
        }
    }
}
{% endhighlight %}

There are two jobs, both to the same endpoint (`items`), but with a different `type` parameter and `dataType`.
The authentication method `query` adds two more parameters to each request: `apiToken` (contain the value
of `config.#token`) and `signature`. The `signature` parameter is created as an SHA-1 hash of the
token and resource type (`"query": "type"` is taken from the `jobs.params.type` value).

See [example [EX101]](https://github.com/keboola/generic-extractor/tree/master/doc/examples/101-function-query-auth).

### Job Placeholders
Let's say you have an API with an endpoint `/users`, returning a list of users, and an
endpoint `/user/{userId}`, returning details of a specific user with a given ID. The list response
looks like this:

{% highlight json %}
[
    {
        "id": 3,
        "name": "John Doe"
    },
    {
        "id": 234,
        "name": "Jane Doe"
    }
]
{% endhighlight %}

To obtain the details of the first user, the user-id has to be padded to five digits. The details API call for the
first user must be sent to `/user/00003`, and for the second user to `/user/00234`. To achieve this, use the
`sprintf` function, which allows [number padding](https://www.php.net/manual/en/function.sprintf.php#example-6129).

The following `placeholders` configuration in the child job calls the function with the first argument set to
`%'.05d` (which is a sprintf [format](https://www.php.net/manual/en/function.sprintf.php) to pad with zero to five digits)
and the second argument set to the value of the `id` property found in the parent response. The placeholder path must
be specified in the `path` property. That means that the configuration:

{% highlight json %}
"placeholders": {
    "user-id": "id"
}
{% endhighlight %}

has to be converted to:

{% highlight json %}
"placeholders": {
    "user-id": {
        "path": "id",
        "function": "sprintf",
        "args": [
            "%'.05d",
            {
                "placeholder": "value"
            }
        ]
    }
}
{% endhighlight %}

The following `user-detail` table will be extracted:

|id|name|address\_city|address\_country|address\_street|parent\_id|
|123|John Doe|London|UK|Whitehaven Mansions|00003|
|234|Jane Doe|St Mary Mead|UK|High Street|00234|

Notice that the `parent_id` column contains the processed value and not the original one.

See [example [EX085]](https://github.com/keboola/generic-extractor/tree/master/doc/examples/085-function-job-placeholders),
or a not-so-useful [example [EX086]](https://github.com/keboola/generic-extractor/tree/master/doc/examples/086-function-job-placeholders-reference)
(using reference).

### Job Parameters
Let's say you have an API which requires you to send a hash of a certain value with every request. Specifically,
each request must be done with the [HTTP POST method](/extend/generic-extractor/tutorial/rest/#method) with content:

{% highlight json %}
{
    "token": "someValue"
}
{% endhighlight %}

The following configuration does exactly that. The value of the token is taken from the configuration
root (using the `attr` reference). This is useful in case the configuration is used as part of a
[template](/extend/generic-extractor/publish/). The actual hash will be generated of the `NotSoSecret` value.


{% highlight json %}
{
    "parameters": {
        "api": {
            "baseUrl": "http://example.com/"
        },
        "config": {
            "debug": true,
            "outputBucket": "mock-server",
            "tokenValue": "NotSoSecret",
            "jobs": [
                {
                    "endpoint": "users",
                    "dataType": "users",
                    "method": "POST",
                    "params": {
                        "token": {
                            "function": "md5",
                            "args": [
                                {
                                    "attr": "tokenValue"
                                }
                            ]
                        }
                    }
                }
            ]
        }
    }
}
{% endhighlight %}

See [example [EX089]](https://github.com/keboola/generic-extractor/tree/master/doc/examples/089-function-job-parameters-md5)
or an alternative [example [EX090] with SHA1 hash](https://github.com/keboola/generic-extractor/tree/master/doc/examples/090-function-job-parameters-sha1).
or an alternative [example [EX136]](https://github.com/keboola/generic-extractor/tree/master/doc/examples/136-post-request-functions) with more deeply nested functions.

### Optional Job Parameters
Let's say you have an API which allows you to send the list of columns to be contained in the API response.
For example, to list users and include their `id`, `name` and `login` properties, call
`/users?showColumns=id,name,login`. Also, you want to enter these values as an array in the `config` section because
the config is generated by a [template](/extend/generic-extractor/publish/). If the end-user
does not wish to filter the columns, they can
list all the columns (which would be annoying) or leave the column filter empty. In that case, the API
call would be `/users?showColumns=all`.

The following configuration does exactly that:

{% highlight json %}
{
    "parameters": {
        "api": {
            "baseUrl": "http://example.com/"
        },
        "config": {
            "columns": "",
            "outputBucket": "mock-server",
            "jobs": [
                {
                    "endpoint": "users",
                    "dataType": "users",
                    "method": "GET",
                    "params": {
                        "showColumns": {
                            "function": "ifempty",
                            "args": [
                                {
                                    "attr": "columns"
                                },
                                "all"
                            ]
                        }
                    }
                }
            ]
        }
    }
}
{% endhighlight %}

See [example [EX097]](https://github.com/keboola/generic-extractor/tree/master/doc/examples/097-function-ifempty).

### User Data
Assume that you have an API returning a response that does not contain any time information. For example:

{% highlight json %}
[
    {
        "id": 3,
        "name": "John Doe"
    },
    {
        "id": 234,
        "name": "Jane Doe"
    }
]
{% endhighlight %}

Add the extraction time to each record so that you at least know when each record was obtained
(when the creation time is unknown). Add additional data to each record using
the [`userData` configuration](/extend/generic-extractor/configuration/config/#user-data):

{% highlight json %}
"userData": {
    "extractionDate": {
        "function": "date",
        "args": [
            "Y-m-d H:i:s",
            {
                "time": "currentStart"
            }
        ]
    }
}
{% endhighlight %}

The following table will be extracted:

|id|name|extractionDate|
|3|John Doe|2017-04-20 10:17:20|
|234|Jane Doe|2017-04-20 10:17:20|

Or, use an alternative configuration that also adds the current date:

{% highlight json %}
"userData": {
    "extractionDate": {
        "function": "date",
        "args": [
            "Y-m-d H:i:s"
        ]
    }
}
{% endhighlight %}

But whereas the first one puts a single same date to each record, the alternative configuration will return different times for different records
as they are extracted.

See [example [EX091]](https://github.com/keboola/generic-extractor/tree/master/doc/examples/091-function-user-data) or
an alternative [example [EX092] with a set date](https://github.com/keboola/generic-extractor/tree/master/doc/examples/092-function-user-date-set-date).

### Headers
Suppose you have an API which requires you to send a custom `X-Api-Auth` header with every request.
The header must contain a user name and password separated by a colon. For instance, `JohnDoe:TopSecret`.

This can be done using the following `api` configuration:

{% highlight json %}
"api": {
    "baseUrl": "http://example.com/",
    "http": {
        "headers": {
            "X-Api-Auth": {
                "function": "concat",
                "args": [
                    {
                        "attr": "credentials.#username"
                    },
                    ":",
                    {
                        "attr": "credentials.#password"
                    }
                ]
            }
        }
    }
}
{% endhighlight %}

Alternatively, achieve the same result using the `implode` function:

{% highlight json %}
"api": {
    "baseUrl": "http://mock-server:80/093-function-api-http-headers/",
    "http": {
        "headers": {
            "X-Api-Auth": {
                "function": "implode",
                "args": [
                    ":",
                    [
                        {
                            "attr": "credentials.#username"
                        },
                        {
                            "attr": "credentials.#password"
                        }
                    ]
                ]
            }
        }
    }
}
{% endhighlight %}

Both configurations rely on having the username and password parameters
in the [`config` section](/extend/generic-extractor/configuration/config/), in this case also nested in the `credentials` property:

{% highlight json %}
"config": {
    "credentials": {
        "#username": "JohnDoe",
        "#password": "TopSecret"
    },
    "jobs": ...
}
{% endhighlight %}

See [example [EX093]](https://github.com/keboola/generic-extractor/tree/master/doc/examples/093-function-api-http-headers) or an
[alternative example [EX094] setting headers in the `config` section](https://github.com/keboola/generic-extractor/tree/master/doc/examples/094-function-config-headers).

### Nested Functions
If the API in the [above example](#headers) tries to mimic the
[HTTP authentication](/extend/generic-extractor/configuration/api/authentication/basic/),
the header has to be sent as a [base64 encoded](https://en.wikipedia.org/wiki/Base64#MIME) value.
That is instead of sending a `JohnDoe:TopSecret`, you have to send `Sm9obkRvZTpUb3BTZWNyZXQ=`. To do this
you have to wrap the `concat` function which generates the header value in another function (`base64_encode`).

{% highlight json %}
"api": {
    "baseUrl": "http://example.com/",
    "http": {
        "headers": {
            "X-Api-Auth": {
                "function": "base64_encode",
                "args": [
                    {
                        "function": "concat",
                        "args": [
                            {
                                "attr": "#username"
                            },
                            ":",
                            {
                                "attr": "#password"
                            }
                        ]
                    }
                ]
            }
        }
    }
}
{% endhighlight %}

See [example [EX095]](https://github.com/keboola/generic-extractor/tree/master/doc/examples/095-function-nested).

### Nested StrToTime
Suppose you have an API which requires you to specify the `from` and `to` date parameters to obtain orders created
in that time interval. You want to specify only the `from` date and extract a week of data.
Enter (preferably in a [template](/extend/generic-extractor/publish/)) the
value `2017-10-04` and send an API request to
`/orders?from=2017-10-04&to=2017-10-11`. The following configuration can be used:

{% highlight json %}
{
    "parameters": {
        "api": {
            "baseUrl": "http://example.com/"
        },
        "config": {
            "startDate": "2017-10-04",
            "outputBucket": "mock-server",
            "jobs": [
                {
                    "endpoint": "users",
                    "dataType": "users",
                    "method": "GET",
                    "params": {
                        "from": {
                            "attr": "startDate"
                        },
                        "to": {
                            "function": "date",
                            "args": [
                                "Y-m-d",
                                {
                                    "function": "strtotime",
                                    "args": [
                                        "+7 days",
                                        {
                                            "function": "strtotime",
                                            "args": [
                                                {
                                                    "attr": "startDate"
                                                }
                                            ]
                                        }
                                    ]
                                }
                            ]
                        }
                    }
                }
            ]
        }
    }
}
{% endhighlight %}

The configuration probably seems rather complicated, so taken apart -- the most innermost part:

{% highlight json %}
{
    "function": "strtotime",
    "args": [
        {
            "attr": "startDate"
        }
    ]
}
{% endhighlight %}

takes the value from the `config` property `startDate` (which is `2017-10-04`) and converts it to
a timestamp value (`???` below).

Then there is an outer part:

{% highlight json %}
{
    "function": "strtotime",
    "args": [
        "+7 days",
        ???
    ]
}
{% endhighlight %}

that takes the timestamp representing `2017-10-04` and adds 7 days to it. This yields another
timestamp value (`???` below).

Then there is another outer part:

{% highlight json %}
{
    "function": "date",
    "args": [
        "Y-m-d",
        ???
    ]
}
{% endhighlight %}

converting the timestamp back to a string format (`Y-m-d` format) which yields `2017-10-11`.
This value is assigned to the `to` parameter of the API call.

See [example [EX096]](https://github.com/keboola/generic-extractor/tree/master/doc/examples/096-function-nested-from-to).


================================================
File: extend/generic-extractor/incremental.md
================================================
---
title: Incremental Loading
permalink: /extend/generic-extractor/incremental/
---

* TOC
{:toc}

Extracting data incrementally is universally beneficial --- it **speeds up the extraction** and **lowers the load** on both the API and
[Keboola Storage](https://help.keboola.com/storage/) (thus saving 
[credits](https://help.keboola.com/management/limits/#project-power)).

## Options
After you have incrementally extracted data from an API, the data must be 
[incrementally loaded](https://help.keboola.com/storage/tables/#incremental-loading)
into Storage. To do that, simply set `"incrementalOutput": true` in the `config` section. 

There are, however, a number of implications in the incremental loads. It essentially boils downs to the following use cases, 
depending on what kind of data you are importing (extracting from an API):

- The imported data contains only **added entries**. When `incrementalOutput` is turned on, the data will be 
simply appended to the target table in Storage. Turning `incrementalOutput` to false probably makes no sense 
because the table will contain only the new entries.
- The imported data contains **added and modified entries**. When `incrementalOutput` is turned on, set a primary key on the table so that new rows are added and existing [rows are updated](https://help.keboola.com/storage/tables/#primary-key-deduplication). 
If the primary key is not set, the modified entries will be duplicated in the target table. Turning 
`incrementalOutput` to false probably makes no sense because the table will contain only the new entries.
- The imported data contains **all rows**. In this case, set a primary key for the table or turn 
`incrementalOutput` to false. Turning `incrementalOutput` to true probably makes no sense because the table will 
contain duplicate entries. If you set the primary key, new rows will be added and modified rows will be updated. 
Note that in this case more [credits](https://help.keboola.com/management/limits/#project-power) are consumed.

In neither of these situations will the missing rows get deleted. If you want to do so, the only way is 
to turn `incrementalOutput` to false and do full loads. 

Using incremental loads obviously requires some support from the API. Generic Extractor supports incremental 
loads by using [`previousStart`](/extend/generic-extractor/functions/#parameters-context) and the
[`time` function](/extend/generic-extractor/functions/#time). Setting the primary key is done using
[mappings](/extend/generic-extractor/configuration/config/mappings/).

## Examples

### Previous Start Example
Assume you have an API supporting a parameter `modified_since` which expects a 
[Unix Timestamp](https://en.wikipedia.org/wiki/Unix_time). The response then contains only the 
records that were modified after the specified date. The following configuration can be used:

{% highlight json %}
{
    "config": {
        "incrementalOutput": true,
        "outputBucket": "mock-server",
        "jobs": [
            {
                "endpoint": "users",
                "dataType": "users",
                "params": {
                    "modified_since": {
                        "time": "previousStart"
                    }
                }
            }
        ]
    }
}
{% endhighlight %}

The configuration adds the `modified_since` parameter as a reference to the internal 
[`time.previousStart` value](/extend/generic-extractor/functions/#parameters-context), which contains the timestamp of the last 
**successful start** of the extraction of the particular configuration. The request generated by this configuration is something like:

    GET /users?modified_since=1492606006

where `1492606006` is the variable timestamp of the last successful start. This introduces state into the
Generic Extractor configuration as it now remembers when it last successfully ran. This means 
that if you run the above configuration every five minutes, it will extract the data modified within the last five minutes. 
If you run it every hour, it will extract the data modified within the last hour. 

Should one of the runs fail or be skipped for any reason, the extraction will pick up where it ended the last time it was successful. 
See [example [EX107]](https://github.com/keboola/generic-extractor/tree/master/doc/examples/107-incremental-load).

The last successful time is stored in the [configuration state](/extend/common-interface/config-file/#state-file).
If for some reason you need to reset it, 
[update the configuration via API](https://keboola.docs.apiary.io/#reference/components-and-configurations/manage-configurations/update-configuration).

### Previous Start Date
If an API similar to the one in the [above example](#previous-start-example) requires the date to be 
sent as a string, the following jobs configuration (which uses the [`date` function](/extend/generic-extractor/functions/#date))
can be used:

{% highlight json %}
{
    "jobs": [
        {
            "endpoint": "users",
            "dataType": "users",
            "params": {
                "modified_since": {
                    "function": "date",
                    "args": [
                        "Y-m-d H:i:s",
                        {
                            "time": "previousStart"
                        }
                    ]
                }
            }
        }
    ]
}
{% endhighlight %}

This sends a request like:

    GET /users?modified_since=2017-04-19%2012%3A46%3A46

in a more readable [url-decoded](https://meyerweb.com/eric/tools/dencoder/) form:

	GET /users?modified_since=2017-04-19 12:46:46

Otherwise the configuration behaves the same way as the [previous example](#previous-start-example).

See [example [EX108]](https://github.com/keboola/generic-extractor/tree/master/doc/examples/108-incremental-load-date).

### Incremental Load From To
Another option is an API which requires the `from` and `to` parameters. The following
configuration generates the `from` date as the date of the last extraction (using the [`time.previousStart` 
value](/extend/generic-extractor/functions/#parameters-context)). It also generates the `to` date as the date 
of the current extraction (using the [`time.currentStart` value](/extend/generic-extractor/functions/#parameters-context)):

{% highlight json %}
{
    "jobs": [
        {
            "endpoint": "users",
            "dataType": "users",
            "params": {
                "from": {
                    "function": "date",
                    "args": [
                        "Y-m-d",
                        {
                            "time": "previousStart"
                        }
                    ]
                },
                "to": {
                    "function": "date",
                    "args": [
                        "Y-m-d",
                        {
                            "time": "currentStart"
                        }
                    ]
                }
            }
        }
    ]
}
{% endhighlight %}

This configuration will send a request similar to this one:

    GET /109-incremental-load-from-to/users?from=2017-04-19&to=2017-04-24

See [example [EX109]](https://github.com/keboola/generic-extractor/tree/master/doc/examples/109-incremental-load-from-to).

### Incremental Relative Load
Suppose you have an API supporting the `from` and `to` parameters as in [the above example](#incremental-load-from-to) and 
want to extract the last day data. It can be done using the following configuration:

{% highlight json %}
{
    "jobs": [
        {
            "endpoint": "users",
            "dataType": "users",
            "params": {
                "from": {
                    "function": "date",
                    "args": [
                        "Y-m-d",
                        {
                            "function": "strtotime",
                            "args": [
                                "-1 day",
                                {
                                    "time": "currentStart"
                                }
                            ]
                        }
                    ]
                },
                "to": {
                    "function": "date",
                    "args": [
                        "Y-m-d",
                        {
                            "time": "currentStart"
                        }
                    ]
                }
            }
        }
    ]
}
{% endhighlight %}

This configuration leads to a request similar to this one:

    GET /110-incremental-relative/users?from=2017-04-23&to=2017-04-24

Remember, this is not a truly reliable incremental load. If you put such configuration 
into an orchestration, and the configuration does not run for some reason, you may miss some data. 
However, this may still be a useful approach for obtaining samples of data for POCs.

See [example [EX110]](https://github.com/keboola/generic-extractor/tree/master/doc/examples/110-incremental-relative).


================================================
File: extend/generic-extractor/index.md
================================================
---
title: Generic Extractor
permalink: /extend/generic-extractor/
---

* TOC
{:toc}

Generic Extractor is a [Keboola component](/overview/) that acts like a customizable
[HTTP REST](/extend/generic-extractor/tutorial/rest/) client. It can be configured to extract data
from virtually any sane web API.

Due to the versatility of different APIs running in the wild, Generic Extractor offers many [**configuration options**](/extend/generic-extractor/configuration/). 

You may opt to use the [**visual builder**](/extend/generic-extractor/configuration/#user-interface), which provides a very convenient way 
of configuring and testing the configuration. With it, you can build
an entirely new extractor for Keboola in **less than an hour**.

{: .image-popup}
![Generic Extractor - UI](/extend/generic-extractor/ui.png)

To get started quickly, follow our [Generic Extractor tutorial](/extend/generic-extractor/tutorial).

## Generic Extractor Requirements
Generic Extractor allows you to extract data from an API into Keboola only by configuring it.
No programming skills or additional tools are required. You just need to do two easy things before you start:

- Become familiar with [JSON format](/extend/generic-extractor/tutorial/json/).
- Have the documentation of your chosen API at hand. The API should be [RESTful](/extend/generic-extractor/tutorial/rest/)
and, more or less, follow the HTTP specification.

## Configuration & Development
Again, if you are new to Generic Extractor, we strongly suggest you go through the
[Generic Extractor tutorial](/extend/generic-extractor/tutorial/). It outlines the basic principles and the most important features.

With the new convenient user interface, you can set up and test the connection in a few clicks, 
just like you are used to in some other popular API development tools. 

Features such as cURL import, request tests, output mapping generator, or dynamic function templates and evaluation make the configuration process as easy as ever.

If you intend to develop a more complicated configuration, check out how to [run Generic Extractor locally](/extend/generic-extractor/running/).
The documentation includes [several examples](https://github.com/keboola/generic-extractor/tree/master/doc) that [can also be run locally](/extend/generic-extractor/running/#running-examples).

## Publishing Generic Extractor Configuration
Each Generic Extractor configuration can be [published](/extend/generic-extractor/publish/) as
a new standalone component. However, for registration, configurations must be
[converted to templates](/extend/generic-extractor/publish/#submission).

Publishing your Generic Extractor configuration is **not required**. However, when published,
it can be easily used in multiple projects. A great advantage of using templates is that they
do not limit the configuration. You can always switch to JSON
[free-form configuration](/extend/generic-extractor/publish/#submission) when necessary.

Also, templates can be used only with published components based on Generic Extractor configurations.

## Generic Extractor Source
As with other Keboola components, the Generic Extractor connector is available on
[GitHub](https://github.com/keboola/generic-extractor/). Apart from the
main repository, it uses some vital libraries (which partially define its capabilities):

- [Juicer](https://github.com/keboola/juicer) --- component responsible for processing HTTP JSON responses
- [CSV Map](https://github.com/keboola/php-csvmap) --- library that converts JSON data into CSV tables
- [Filter](https://github.com/keboola/php-filter) --- library that allows to match values together
- [JSON Parser](https://github.com/keboola/php-jsonparser) --- JSON parser which produces CSV tables while maintaining relations


================================================
File: extend/generic-extractor/map.md
================================================
---
title: Generic Extractor Parameter Map
permalink: /extend/generic-extractor/map/
---
*To configure your first Generic Extractor, follow our [tutorial](/extend/generic-extractor/tutorial/).*

Use the following sample configuration to navigate among various **configuration options**:

{% highlight json %}
{% include config-map.json %}
{% endhighlight %}

<script>
{% include config-events.js %}
</script>
<style>
pre a {
    border-bottom: 1px dashed navy;
}
</style>


================================================
File: extend/generic-extractor/publish.md
================================================
---
title: Publish Generic Extractor
permalink: /extend/generic-extractor/publish/
redirect_from:
    - /extend/generic-extractor/registration/
---

* TOC
{:toc}

It is possible to publish a Generic Extractor configuration as a completely separate component.
This enables sharing the API extractor between various projects and simplifies its further configuration.

## Configuration Considerations
Before converting your configuration to a universally available component, consider
what values in the configuration should be provided by the end-user (typically authentication values).
Then design a [configuration schema](/extend/component/ui-options/configuration-schema/) for setting
those values. You can [test the schema online](http://jeremydorn.com/json-editor/) ([alternative](https://mozilla-services.github.io/react-jsonschema-form/)).
The values obtained from the end user will be stored in the [`config` property](/extend/generic-extractor/configuration/config/).
Modify your configuration to read those values from there.

Do not forget that if you prefix a value with a hash `#`, it will be
[encrypted](/overview/encryption/) once the configuration is saved.
Also, try to make the extractor [work incrementally](/extend/generic-extractor/incremental/)
if possible.

## Publishing
To publish your Generic Extractor configuration, you need to [create a new component](/extend/component/tutorial/) in
the [Developer Portal](https://components.keboola.com/). Choose an appropriate name and the type `extractor`. Once you
have created the component, edit it, and fill in the following details:

- **Repository**
    - **Type** --- AWS ECR
    - **Image Name** -- `147946154733.dkr.ecr.us-east-1.amazonaws.com/developer-portal-v2/ex-generic-v2`
    - **Tag** -- see the [Generic Extractor GitHub repository](https://github.com/keboola/generic-extractor/releases)
    - **Region** -- leave empty
- **UI options** --- set to `genericTemplatesUI`

For a list of available tags, see the [Generic Extractor GitHub repository](https://github.com/keboola/generic-extractor/) or
[Generic Extractor Quay repository](https://quay.io/repository/keboola/generic-extractor/), both of which contain the same tags
as the above AWS ECR repository. It is also possible to use the `latest` tag, which points to the highest available tag. However,
we recommend that you configure your component with a specific tag and update it manually to avoid problems with breaking changes
in future Generic Extractor releases.

Because the UI is assumed to be `genericTemplatesUI`, provide a
[**configuration schema**](/extend/component/ui-options/configuration-schema/) and
a **template** to be used in conjunction with the schema. Optionally, the template UI may also contain an interface to
negotiate [OAuth authentication](/extend/generic-extractor/configuration/api/authentication/#oauth).
An example of the template UI is shown in the picture below.

{: .image-popup}
![Screenshot - Generic templates UI](/extend/generic-extractor/template-1.png)

The `Config` section of the templates UI is defined by the configuration schema you provide.
The `Template` section contains at least one template. A template is simply a configuration of
Generic Extractor.

For example, you might want to provide one configuration for incremental loading
and a different configuration for full loading. The template UI also has the option to
`Switch to JSON editor`, which displays the configuration JSON and allows the end user to modify it.
Notice that the JSON editor allows modification only to the [`config`](/extend/generic-extractor/configuration/config/)
section. Other sections, such as [`api`](/extend/generic-extractor/configuration/api/) or
[`authorization.oauth_api`](/extend/generic-extractor/configuration/api/authentication/#oauth), may not be modified by the end user.

You can review existing templates in their [GitHub repository](https://github.com/keboola/kbc-ui-templates/tree/master/resources).
If you feel confident, you can send a pull request with your templates, otherwise submit it when requesting the
[publication of your component](/extend/publish/).

## Example
Let's say you have the following working API configuration
(see [example [EX111]](https://github.com/keboola/generic-extractor/tree/master/doc/examples/111-templates-example)):

{% highlight json %}
{
    "parameters": {
        "api": {
            "baseUrl": "http://example.com/",
            "authentication": {
                "type": "login",
                "loginRequest": {
                    "endpoint": "token",
                    "headers": {
                        "Authorization": {
                            "function": "base64_encode",
                            "args": [
                                "JohnDoe:TopSecret"
                            ]
                        }
                    }
                },
                "apiRequest": {
                    "headers": {
                        "X-Api-Auth": "auth.token"
                    }
                }
            },
            "default": {
                "http": {
                    "params": {
                        "accountId": 123
                    }
                }
            }
        },
        "config": {
            "incrementalOutput": true,
            "jobs": [
                {
                    "endpoint": "users",
                    "dataType": "users",
                    "params": {
                        "type": "active"
                    }
                },
                {
                    "endpoint": "orders",
                    "dataType": "orders"
                }
            ]
        }
    }
}
{% endhighlight %}

and you identify that four values of that configuration need to be specified by the end user:
`JohnDoe`, `TopSecret`, `123`, and `active`.

For each of the values, create a parameter of the appropriate type:

- `JohnDoe` --- a string parameter `login`
- `TopSecret` --- a string parameter `#password` (it will be encrypted)
- `123` --- a numeric parameter `accountId`
- `active` --- an enumeration parameter `userType` with values `active`, `inactive`, `all`

The parameter names are completely arbitrary. However, they must not conflict with existing
configuration properties of [Generic Extractor](/extend/generic-extractor/configuration/config/) (e.g., `jobs`, `mappings`).
Now create a [configuration schema](/extend/component/ui-options/configuration-schema/) for the four parameters.

{% highlight json %}
{
  "title": "Person",
  "type": "object",
  "properties": {
    "login": {
      "type": "string",
      "title": "Login:",
      "description": "Your API user name",
      "minLength": 4
    },
    "#password": {
      "type": "string",
      "title": "Password:",
      "description": "Your API password",
      "minLength": 4
    },
    "accountId": {
      "type": "integer",
      "title": "Account ID",
      "description": "See in-app help for obtaining Account Id"
    },
    "userType": {
      "title": "User type:",
      "type": "string",
      "enum": [
        "active",
        "inactive",
        "all"
      ],
      "default": "active",
      "description": "Specify which users to obtain"
    }
  },
  "required": [
     "login", "#password", "accountId", "userType"
  ]
}
{% endhighlight %}

When you test the [schema online](http://jeremydorn.com/json-editor/) ([alternative](https://mozilla-services.github.io/react-jsonschema-form/)), it will produce a
configuration JSON:

{: .image-popup}
![Screenshot - Schema Test](/extend/generic-extractor/schema-test.png)

{% highlight json %}
{
  "login": "JohnDoe",
  "#password": "TopSecret",
  "accountId": 123,
  "userType": "inactive"
}
{% endhighlight %}

The above properties will be merged into the [`config` section](/extend/generic-extractor/configuration/config/). Now
modify the configuration so that it reads them from there using [functions and references](/extend/generic-extractor/functions/).

{% highlight json %}
{
    "parameters": {
        "api": {
            "baseUrl": "http://example.com/",
            "authentication": {
                "type": "login",
                "loginRequest": {
                    "endpoint": "token",
                    "headers": {
                        "Authorization": {
                            "function": "base64_encode",
                            "args": [
                                {
                                    "function": "concat",
                                    "args": [
                                        {
                                            "attr": "username"
                                        },
                                        ":",
                                        {
                                            "attr": "#password"
                                        }
                                    ]
                                }
                            ]
                        }
                    }
                },
                "apiRequest": {
                    "headers": {
                        "X-Api-Auth": "auth.token"
                    }
                }
            }
        },
        "config": {
            "incrementalOutput": true,
            "username": "JohnDoe",
            "#password": "TopSecret",
            "accountId": 123,
            "userType": "active",
            "jobs": [
                {
                    "endpoint": "users",
                    "dataType": "users",
                    "params": {
                        "accountId": {
                            "attr": "accountId"
                        },
                        "type": {
                            "attr": "userType"
                        }
                    }
                },
                {
                    "endpoint": "orders",
                    "dataType": "orders",
                    "params": {
                        "accountId": {
                            "attr": "accountId"
                        }
                    }
                }
            ]
        }
    }
}
{% endhighlight %}

The argument to the `base64_encode` function is now the
[`concat` function](/extend/generic-extractor/functions/#concat), which joins together the
values of the `username` and `#password` fields. The `accountId` parameter needs to be moved to the
`jobs` section because the `http.defaultOptions.params` section does not support function calls (yet!).
The `type` parameter was changed to a reference to the `userType` field
(see [example [EX111]](https://github.com/keboola/generic-extractor/tree/master/doc/examples/111-templates-example)).

When you handled the configuration parameters, turn the configuration into a template. Place
the `api` section to a separate, individual `api.json` file:

{% highlight json %}
{
    "baseUrl": "http://example.com/",
    "authentication": {
        "type": "login",
        "loginRequest": {
            "endpoint": "token",
            "headers": {
                "Authorization": {
                    "function": "base64_encode",
                    "args": [
                        {
                            "function": "concat",
                            "args": [
                                {
                                    "attr": "username"
                                },
                                ":",
                                {
                                    "attr": "#password"
                                }
                            ]
                        }
                    ]
                }
            }
        },
        "apiRequest": {
            "headers": {
                "X-Api-Auth": "auth.token"
            }
        }
    }
}
{% endhighlight %}

Once you make sure that the extractor works as it did before,
remove the user provided values (`username`, `#password`, `accountId`, `userType`) from
the `config` section, put it in a `data` section and add `name` and `description` to it.
Save the file into a separate `template.json` file. The template file therefore contains
`name`, `description` and `data` nodes.

{% highlight json %}
{
    "name": "Basic",
    "description": "Basic incremental template",
    "data": {
        "incrementalOutput": true,
        "jobs": [
            {
                "endpoint": "users",
                "dataType": "users",
                "params": {
                    "accountId": {
                        "attr": "accountId"
                    },
                    "type": {
                        "attr": "userType"
                    }
                }
            },
            {
                "endpoint": "orders",
                "dataType": "orders",
                "params": {
                    "accountId": {
                        "attr": "accountId"
                    }
                }
            }
        ]
    }
}
{% endhighlight %}

Create as many `template.json` files as you wish. However, all of them need to share the same `api.json`
configuration. When you want to publish your component, attach the `api.json` and all `template.json` files.


================================================
File: extend/generic-extractor/running.md
================================================
---
title: Running Generic Extractor
permalink: /extend/generic-extractor/running/
---

* TOC
{:toc}

Generic Extractor is normally run from within the Keboola user interface. It can be found in the **Extractors** section
and all you need to do is provide its configuration JSON. No other settings are necessary.

{: .image-popup}
![Screenshot - Generic Extractor Configuration](/extend/generic-extractor/configuration.png)

Because creating the configuration JSON can be a non-trivial task, there are some things which can help
you in developing the configuration.

## Debug Mode
Debug mode can be turned on by setting `"debug": true` in the `config` section of the configuration, e.g.:

{% highlight json %}
{
    "api": {
        ...
    },
    "config": {
        "debug": true,
        ...
    }
}
{% endhighlight %}

In debug mode, the extractor displays all API requests it sends, helping you understand what is really happening,
why something is skipped, etc.

{: .image-popup}
![Screenshot - Debug Logs](/extend/generic-extractor/events.png)

**Warning:** If the API sends sensitive data (e.g. authorization token) in the URL, these may become
visible in the events. Also, debug mode considerably slows the extraction. Therefore it should never
be turned on in production configurations.

## Running Locally
If you are working on a complicated configuration, or developing a new component based on
Generic Extractor, running every configuration from the Keboola UI may be slow and tedious.
You may run Generic Extractor locally, provided that you have access to [Docker](/extend/component/docker-tutorial/).
The following is **not necessary** to run or configure Generic Extractor in Keboola.

### Run Built Version
Create an empty directory somewhere and in it create a `config.json` file with a
configuration you want to execute. For example:

{% highlight json %}
{
  "parameters": {
    "api": {
      "baseUrl": "https://api.github.com",
      "http": {
        "Accept": "application/json",
        "Content-Type": "application/json;charset=UTF-8"
      }
    },
    "config": {
      "debug": true,
      "jobs": [
        {
          "endpoint": "/orgs/keboola/members",
          "dataType": "members"
        }
      ]
    }
  }
}
{% endhighlight %}

Then run Generic Extractor in the current directory by executing the following command on *nix systems:

    docker run -v ($pwd):/data quay.io/keboola/generic-extractor:latest

or on Windows:

    docker run -v %cd%:/data quay.io/keboola/generic-extractor:latest

You should see:

    DEBUG: Using NO Auth [] []
    DEBUG: Using automatic conversion of single values to arrays where required. [] []
    DEBUG: GET /orgs/keboola/members HTTP/1.1 Host: api.github.com User-Agent: Guzzle/5.3.1 curl/7.38.0 PHP/7.0.17   [] []
    DEBUG: Analyzing members {"rowsAnalyzed":[],"rowsToAnalyze":7} []
    DEBUG: Processing results for __kbc_default. [] []
    INFO: Extractor finished successfully. [] []

along with the output tables created in `/out/tables` sub-directory of the current directory.
It is recommended to remove the contents of the `out/tables` directory before running the extractor again.

**Important:** Generic Extractor itself is not able to decrypt encrypted values. That means that when you
supply the configuration directly in the `config.json` file, you must always provide decrypted values --- e.g.:

{% highlight json %}
{
    ...,
    "config": {
        "#username": "JohnDoe",
        "#password": "TopSecret",
        ...
    }
}
{% endhighlight %}

When you store such configuration in the Keboola UI, it will automatically be encrypted:

{% highlight json %}
{
    ...,
    "config": {
        "#username": "JohnDoe",
        "#password": "KBC::ComponentProjectEncrypted==r13Khq0lR4ycDNTujirz5/GMqNEVZ4tZ2OTmRcsNYqlP/a/STMelWtz9R8yEtr3ck6KiYA7XrL8pqIQv9S7Ro28KNZgmqtSNzKhFcEsItPnTDCQqvnU99q2a0ES+oN/v",
        ...
    }
}
{% endhighlight %}

The above configuration then **cannot** be run locally.
Read more about [encryption](/overview/encryption/).

### Building and Running the Image
To build the container from source:

- Clone this repository: `git clone https://github.com/keboola/generic-extractor.git`.
- Switch to the created directory: `cd generic-extractor`.
- Build the container: `docker compose build`.
- Install dependencies locally: `docker compose run --rm extractor composer install`.
- Create a **data folder** for configuration: `mkdir data`.

To run the built container:

- Create a configuration file `config.json` in the **data folder**.
- Run the extraction: `docker compose run --rm extractor`.
- You will find the extracted data in the `out/tables` sub-directory of the **data folder**.

Before running the extractor again, it is recommended to clear the `out` directory by
running `docker compose run --rm extractor rm -rf data/out`.

## Running Examples
[All examples](https://github.com/keboola/generic-extractor/tree/master/doc) referenced in this documentation are actually runnable against the proper API. Because
it is difficult to find the specific API for the case (and gain access to it), you can test
these configurations against a [mock server](https://github.com/keboola/ex-generic-mock-server).
Each example contains a set of requests (`*.request` file) and responses (`*.response`) and
optionally their headers (`*.requestHeaders` and `*.responseHeaders`).

To run the examples:

- Clone Generic Extractor repository: `git clone https://github.com/keboola/generic-extractor.git`.
- Navigate to the documentation directory: `cd generic-extractor/doc`.
- Run a single example of your choice, e.g.: `docker compose run -e "KBC_EXAMPLE_NAME=001-simple-job" extractor`.
- The output will be available in `examples/001-simple-job/out/tables`.
- Or run all examples by executing `./run-samples.sh`.

If you want to create your own example, follow the instructions in the [mock server repository](https://github.com/keboola/ex-generic-mock-server/blob/master/README.md#creating-examples).


================================================
File: extend/generic-extractor/configuration/configuration.md
================================================
---
title: Generic Extractor Configuration
permalink: /extend/generic-extractor/configuration/
---

* TOC
{:toc}

*To configure your first Generic Extractor, follow our [tutorial](/extend/generic-extractor/tutorial/).*

To get an overall idea of what to expect when configuring Generic Extractor, look at the following **overview** of various configuration sections.

Then review a [sample configuration](#configuration-map) featuring all configuration options and their
nesting. The **configuration map** is also available as a [separate article](/extend/generic-extractor/map/).


### User Interface

{% include branches-beta-warning.html %}

Recently, we created a convenient user interface that allows you to build a configuration for the Generic Extractor without writing JSON code. 
You can set up and test the connection in a few clicks, just like you are used to in some other popular API development tools. 

Features such as cURL import, request tests, output mapping generator, or dynamic function templates and evaluation make the configuration process as easy as ever.

You can switch between the JSON representation and the user interface in the upper right corner of the configuration editor.

{: .image-popup}
![UI Switch](/extend/generic-extractor/configuration/ui_switch.png)

#### Backward compatibility

The new user interface is mostly backward compatible with the old JSON configuration. However, some features are not yet supported in the new UI. 
In such cases, you will be notified in the UI what sections are not supported.

***NOTE:** The new UI does not affect the functionality of old configurations. All configurations will continue to work. 
However, in some cases, you might need to perform some manual adjustments in order to make the UI compatible.*


### JSON Configuration Sections
*Click on the section names if you want to learn more.*

- **parameters**
    - [**api**](/extend/generic-extractor/configuration/api/) --- sets the basic properties of the API.
        - [**baseUrl**](/extend/generic-extractor/configuration/api/#base-url) --- defines the URL to which the
        API requests should be sent.
        - [**caCertificate**](/extend/generic-extractor/configuration/api/#ca-certificate) --- defines custom certificate authority bundle in `crt`/`pem` format.
        - [**#clientCertificate**](/extend/generic-extractor/configuration/api/#client-certificate) --- defines client certificate and private key in `crt`/`pem` format.
        - [**pagination**](/extend/generic-extractor/configuration/api/pagination/) --- breaks a result with many items into separate pages.
        - [**authentication**](/extend/generic-extractor/configuration/api/authentication/) --- needs to be
        configured for any API which is not public.
        - [**retryConfig**](/extend/generic-extractor/configuration/api/#retry-configuration) --- automatically
        and repeatedly, retries failed HTTP requests.
        - [**http**](/extend/generic-extractor/configuration/api/#default-http-options) --- sets the timeouts, default
        headers, and parameters sent with each API call.
    - **aws**
      - [**signature**](/extend/generic-extractor/configuration/aws-signature) --- defines AWS credentials for signature request
    - [**config**](/extend/generic-extractor/configuration/config/) --- describes the actual extraction.
        - [**debug**](/extend/generic-extractor/running/#debug-mode) --- shows all HTTP requests sent by
        Generic Extractor.
        - [**outputBucket**](/extend/generic-extractor/configuration/config/#output-bucket) --- defines the name
        of a Storage Bucket in which the extracted tables will be stored.
        - [**http**](/extend/generic-extractor/configuration/config/#http) --- sets the HTTP headers sent with
        every request.
        - [**jobs**](/extend/generic-extractor/configuration/config/jobs/) --- describes the API endpoints
        (resources) to be extracted.
        - [**mappings**](/extend/generic-extractor/configuration/config/#mappings) --- describes how the JSON
        response is converted into CSV files that will be imported into Storage.
        - [**incrementalOutput**](/extend/generic-extractor/incremental/) ---  loads the extracted data into
        Storage incrementally.
        - [**userData**](/extend/generic-extractor/configuration/config/#user-data) --- adds arbitrary data to
        extracted records.
        - [**sshProxy**](/extend/generic-extractor/configuration/ssh-proxy/) --- securely access HTTP(s) endpoints inside your private Network.
        - [**iterations**](/extend/generic-extractor/configuration/iterations/) --- executes a configuration multiple times, each time
  with different values.
- [**authorization**](/extend/generic-extractor/configuration/api/authentication/#oauth) --- allows injecting OAuth authentication.

There are also simple pre-defined [**functions**](/extend/generic-extractor/functions/) available, adding extra
flexibility when needed.

Generic Extractor can be run from within the [**Keboola user interface**](/extend/generic-extractor/running/) (only
configuration [JSON](/extend/generic-extractor/tutorial/json/) is needed), or [**locally**](/extend/generic-extractor/running/#running-locally)
([Docker](/extend/component/docker-tutorial/) is needed).

### Configuration Map
The following sample configuration shows various configuration options and their nesting.
You can use the map to navigate between them. The parameter map is also available
[separately](/extend/generic-extractor/map/), and we recommend pinning it to your toolbar for quick reference.

{% highlight json %}
{% include config-map.json %}
{% endhighlight %}

<script>
{% include config-events.js %}
</script>
<style>
pre a {
    border-bottom: 1px dashed navy;
}
</style>


================================================
File: extend/generic-extractor/configuration/iterations.md
================================================
---
title: Iterations
permalink: /extend/generic-extractor/configuration/iterations/
redirect_from:
    - /extend/generic-extractor/iterations/
---

* TOC
{:toc}

The `iterations` section allows you to **execute a configuration multiple times, each time with different
values**. The most typical use for `iterations` is extraction of the same data from multiple accounts.
Iterations can always be replaced by creating multiple complete configurations of Generic Extractor.

Iterations are specified as an array of objects, where each object contains the same properties
as the [`config`](/extend/generic-extractor/configuration/config/) section. All properties of the object are optional.

Consider the following example of an `iterations` configuration defining that the entire Generic Configuration
will be executed twice: the first time with the username `JohnDoe`, and the second time with the username
`DoeJohn`.

{% highlight json %}
{
    "parameters": {
        "api": {
            "baseUrl": "http://example.com/",
            "authentication": {
                "type": "basic"
            }
        },
        "config": {
            "outputBucket": "ge-tutorial",
            "jobs": [
                {
                    "endpoint": "users"
                }
            ]
        },
        "iterations": [
            {
                "username": "JohnDoe",
                "#password": "TopSecret"
            },
            {
                "username": "DoeJohn",
                "#password": "EvenMoreSecret"
            }
        ]
    }
}
{% endhighlight %}

Since **all `iterations` properties override the `config` properties**, they are accessible
as [configuration attributes](/extend/generic-extractor/functions/#configuration-attributes)
via the `attr` property.

Keep in mind that `iterations` can refer directly only to the things specified in the `config` section.
For the `api` section, you must use [functions](/extend/generic-extractor/functions/).
Also, it is not possible to iterate over values returned in the response.
The number of iterations and their values must be defined in the configuration.

## Configuration
Because the values defined in `iterations` override those in the `config` section,
everything that can be in the `config` section is allowed as well
(including arbitrary user attributes used in [functions](/extend/generic-extractor/functions/)).
Using `jobs` and `mappings` in iterations does not make much sense though.

Also, if you use `userData` in iterations, they must result in the same columns; otherwise the resulting
table cannot be imported into Storage. If you use `incrementalOutput`, only the last value of `incrementalOutput`
is honoured.

## Examples

### Iterating Parameters
Suppose, you have an API which takes a URL parameter `account_id`, which restricts the returned data to a
certain account. The following configuration executes the entire configuration for two accounts --- `345` and `456`:

{% highlight json %}
{
    "parameters": {
        "api": {
            "baseUrl": "http://example.com/"
        },
        "config": {
            "outputBucket": "ge-tutorial",
            "userData": {
                "account": {
                    "attr": "accountId"
                }
            },
            "jobs": [
                {
                    "endpoint": "users",
                    "dataType": "users",
                    "params": {
                        "account_id": {
                            "attr": "accountId"
                        }
                    }
                }
            ]
        },
        "iterations": [
            {
                "accountId": 345
            },
            {
                "accountId": 456
            }
        ]
    }
}
{% endhighlight %}

Since the `iterations` section overrides the values in the `config` section, the below configuration
yields the exact same results as the configuration above:

{% highlight json %}
{
    "parameters": {
        "api": {
            "baseUrl": "http://example.com/"
        },
        "config": {
            "outputBucket": "ge-tutorial",
            "accountId": 123,
            "userData": {
                "account": {
                    "attr": "accountId"
                }
            },
            "jobs": [
                {
                    "endpoint": "users",
                    "dataType": "users",
                    "params": {
                        "account_id": {
                            "attr": "accountId"
                        }
                    }
                }
            ]
        },
        "iterations": [
            {
                "accountId": 345
            },
            {
                "accountId": 456
            }
        ]
    }
}
{% endhighlight %}

It looks as if the first execution is with `account_id=123`, but it is not the case. The configuration
will be executed only twice: the first time with `account_id=345` and the second time with `account_id=456`.
See [example [EX112]](https://github.com/keboola/generic-extractor/tree/master/doc/examples/112-iterations-params).

### Iterating Headers
Suppose you have an API from which you want to extract data from two accounts (`JohnDoe` and `DoeJohn`). The
API uses the [HTTP Basic Authentication](/extend/generic-extractor/configuration/api/authentication/basic/) method, and in addition,
each user has their own API token, which must be provided in the `X-Api-Token` header.

Even if the above parameters relate to the [`api` configuration](/extend/generic-extractor/configuration/api/), which cannot
be directly included in `iterations`, we can specify them as `http.headers` and therefore it is still possible to use them.

{% highlight json %}
{
    "parameters": {
        "api": {
            "baseUrl": "http://example.com/",
            "authentication": {
                "type": "basic"
            }
        },
        "config": {
            "outputBucket": "ge-tutorial",
            "jobs": [
                {
                    "endpoint": "users",
                    "dataType": "users"
                }
            ]
        },
        "iterations": [
            {
                "http": {
                    "headers": {
                        "X-Api-Token": "1234abcd"
                    }
                },
                "username": "JohnDoe",
                "#password": "TopSecret"
            },
            {
                "http": {
                    "headers": {
                        "X-Api-Token": "zyxv9876"
                    }
                },
                "username": "DoeJohn",
                "#password": "EvenMoreSecret"
            }
        ]
    }
}
{% endhighlight %}

Next to `username` and `#password` from the `config` section, the above configuration overrides also
the `http.headers.X-Api-Token` setting. The configuration can be simplified by using
[functions and references](/extend/generic-extractor/functions/):

{% highlight json %}
{
    "parameters": {
        "api": {
            "baseUrl": "http://example.com/",
            "authentication": {
                "type": "basic"
            }
        },
        "config": {
            "http": {
                "headers": {
                    "X-Api-Token": {
                        "attr": "apiToken"
                    }
                }
            },
            "outputBucket": "ge-tutorial",
            "jobs": [
                {
                    "endpoint": "users",
                    "dataType": "users"
                }
            ]
        },
        "iterations": [
            {
                "apiToken": "1234abcd",
                "username": "JohnDoe",
                "#password": "TopSecret"
            },
            {
                "apiToken": "zyxv9876",
                "username": "DoeJohn",
                "#password": "EvenMoreSecret"
            }
        ]
    }
}
{% endhighlight %}

Here, the `config` section specifies the part of the token authentication which is common to both iterations.
Each iteration then specifies only the token. By writing `"attr": "apiToken"` under `X-Api-Token` we say that
`X-Api-Token` will have the value of the `apiToken` property from the `config` section. That property is in
turn specified in the iteration objects.


See [example [EX113]](https://github.com/keboola/generic-extractor/tree/master/doc/examples/113-iterations-headers).


================================================
File: extend/generic-extractor/configuration/api/index.md
================================================
---
title: API Configuration
permalink: /extend/generic-extractor/configuration/api/
---

* TOC
{:toc}

*To configure your first Generic Extractor, follow our [tutorial](/extend/generic-extractor/tutorial/basic/).*
*Use [Parameter Map](/extend/generic-extractor/map/) to help you navigate among various
configuration options.*

The API section of Generic Extractor configuration **describes global characteristics of an API**. These include
[HTTP headers](/extend/generic-extractor/tutorial/rest/#headers), authentication and pagination methods.

A sample API configuration can look like this:

{% highlight json %}
{
    ...,
    "api": {
        "baseUrl": "https://example.com/v3.0/",
        "caCertificate": "-----BEGIN CERTIFICATE-----\nMIIFaz....",
        "pagination": {
            "method": "offset",
            "offsetParam": "offset",
            "limitParam": "count"
        },
        "authentication": {
            "type": "basic"
        },
        "retryConfig": {
            "account": 3
        },
        "http": {
            "headers": {
                "Accept": "application/json"
            },
            "defaultOptions": {
                "params": {
                    "company": 123
                }
            },
            "requiredHeaders": ["X-AppKey"],
            "ignoreErrors": [405],
            "connectTimeout": 30,
            "requestTimeout": 300
        }
    }
}
{% endhighlight %}

## Base URL
The `baseUrl` configuration **defines the URL to which the API requests should be sent**. We
recommend that the URL ends with a slash so that the `jobs.endpoint` can be set easily.
See the [`endpoint` configuration](/extend/generic-extractor/configuration/config/jobs/#endpoint) for a detailed description of
how `api.baseUrl` and `jobs.endpoint` work together.

## CA certificate
The `caCertificate` configuration **defines custom certificate authority bundle in 
[`crt`/`pem` format](https://serverfault.com/questions/9708/what-is-a-pem-file-and-how-does-it-differ-from-other-openssl-generated-key-file)**.
It allows connecting to a HTTPS server with a untrusted/self-signed certificate.
The value is not certificate of the server, but a certificate of the certificate authority used to generate the server certificate.
You can define a single root certificate, or a bundle of root and intermediate certificates
(see [EX141](https://github.com/keboola/generic-extractor/tree/master/doc/examples/141-https-self-signed)).

## Client certificate
The `#clientCertificate` configuration **defines the client certificate and private key**. This is required
if the server requires two-way SSL authentication, so in addition to the verification of the server,
the server also verifies the client (see [EX142](https://github.com/keboola/generic-extractor/tree/master/doc/examples/142-https-client-cert)).

**Value is the client certificate, followed by the private key. Both
in [`crt`/`pem` format](https://serverfault.com/questions/9708/what-is-a-pem-file-and-how-does-it-differ-from-other-openssl-generated-key-file)**.

Example:
```json
{
  "api": {
    "baseUrl": "https://my-server.com",
    "#clientCertificate": "-----BEGIN CERTIFICATE-----\n...\n----END CERTIFICATE-----\n-----BEGIN RSA PRIVATE KEY-----\n...\n-----END RSA PRIVATE KEY-----\n"
  }
}
```

## Pagination
Pagination (or scrolling) **describes how the API pages through a large set of results**. Because
there are many different pagination strategies, the configuration is described on a
[separate page](/extend/generic-extractor/configuration/api/pagination/).

## Authentication
Authentication (authorization) needs to be configured for any API which is not public.
Because there are many authorization methods used by different APIs, there are also many
[configuration options](/extend/generic-extractor/configuration/api/authentication/).

## Retry Configuration
By default, Generic Extractor **automatically retries failed HTTP requests** --- repeatedly, and on most errors.
This is one of the big advantages over writing your own extractor from scratch. Tweak the retry setting to optimize
the speed of an extraction or to avoid unwanted flooding of the API.

Every HTTP response contains a [Status code](/extend/generic-extractor/tutorial/rest/#http-status) and,
optionally, a Header describing the situation or further actions. Status codes 2xx (beginning with 2; e.g., 200
OK) represent success and no action is needed for them. Status codes 3xx (e.g., 301 Moved Permanently) represent
redirection and are automatically handled by Generic Extractor (the redirection is followed).

This leaves us with status codes 4xx (e.g., 404 Not Found) and 5xx (e.g., 500 Internal Server Error). The 4xx codes
represent the codes whose error is on the client side. 5xx represent errors on the server side. When
retrying, this distinction is really irrelevant because we need to use the codes that represent transient/temporary
errors. Unfortunately, there is no definitive official list of those. When it comes to communicating with
a real world API, the typical examples of transient errors are:

- Network outage/malfunction
- Target server maintenance/outage
- API throttling/rate limiting

The rate limiting behaviour is not universally agreed upon. A nice API should return a
`503 Service Unavailable` status together with a `Retry-After` HTTP header specifying number of
seconds to wait before the next request. This is, however, not supported by many APIs.
**Adjusting to the API rate limiting is the main reason for changing Retry Configuration**.

The next aspect to consider is "when to retry". Even if the error is transient, retrying
immediately (within few milliseconds) usually makes no sense because the error is probably still not gone.
There are two retry strategies:

- Either the API sends a `Retry-After` header (or its equivalent), or
- Generic Extractor uses an [exponential backoff algorithm](https://en.wikipedia.org/wiki/Exponential_backoff).

### API Retry Strategy
Per the HTTP specification, the API may send the [`Retry-After`](https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Retry-After)
header which should contain number of seconds to pause/sleep before the next request. Generic Extractor
supports some extensions to this. First, the *Retry Header* name may be customized. Second, the header
value may be as follows:

- Number of seconds before the next request
- [Unix timestamp](https://en.wikipedia.org/wiki/Unix_time) of the time of the next request
- String date in [RFC 1123 format](https://www.php.net/manual/en/class.datetime.php#datetime.constants.rfc1123) of the
time of the next request

The second and third options are often called **Rate Limit Reset** as they describe when the next successful request
can be made (i.e., the limit is reset).

### Backoff Strategy
The exponential backoff in Generic Extractor is defined as `truncate(2^(retry\_number - 1)) * 1000` seconds.
This means that the first retry (zero-based index) will be after 0 seconds (`(2^(0-1)) = 0.5`, truncated to 0).
The retry delays are the following:

|retry|1|2|3|4|5|6|7|8|9|10|11|12|
|---|---|---|---|---|---|---|---|---|---|---|---|---|
|delay|0s|1s|2s|4s|8s|16s|32s|64s|128s (~2min)|256s (~4min)|512s (~8.5min)|1024s (~17min)|

The default number of retries is **10** which means that the retries stop after
511 seconds (~8.5 minutes).

### Configuration
The default Retry configuration `retryConfig` is:

{% highlight json %}
{
    "http": {
        "retryHeader": "Retry-After",
        "codes": [500, 502, 503, 504, 408, 420, 429],
        "maxRetries": 10
    },
    "curl": {
        "codes": [28, 6, 7, 35, 52, 56]
    }
}
{% endhighlight %}

The above defined `curl.codes` cover the common network errors. You can find a full list of
supported codes in the [cURL documentation](https://curl.haxx.se/libcurl/c/libcurl-errors.html).
There is no way to set the actual backoff strategy as it is derived automatically from the
content of the HTTP header specified in `retryHeader`. Generic Extractor will fallback to the
exponential backoff strategy in case the header contents are invalid (that includes, e.g., a typo
in the header name). Make sure to check that the backoff is correct --- the times can be verified
in the [debug](/extend/generic-extractor/running/#debug-mode) messages:

    Http request failed, retrying in 1s

If the exponential backoff is used, you will see its sequence of times.
See an [example](/extend/generic-extractor/configuration/api/#retry-configuration).

## Default HTTP Options
The `http` configuration option allows you to set the timeouts, default headers and parameters sent with each API call
(defined later in the [`jobs` section](/extend/generic-extractor/configuration/config/jobs/#request-parameters)).

### Headers
The `http.headers` configuration allows you to **set the default headers sent with
each API call**. The configuration is an object where names are the names of
the headers and values are their values --- for instance:

{% highlight json %}
"http": {
    "headers": {
        "Accept": "application/json",
        "Accept-Encoding": "gzip"
    }
}
{% endhighlight %}

See the full [example](/extend/generic-extractor/configuration/api/#default-headers).

### Request Parameters
The `http.defaultOptions.params` configuration allows you to **set the
[request parameters](/extend/generic-extractor/tutorial/rest/#url) to be
sent with each API request**. The same rules apply as to the
[`jobs.params`](/extend/generic-extractor/configuration/config/jobs/#request-parameters).

See an [example](/extend/generic-extractor/configuration/api/#default-headers).

### Required Headers
Similar to the `http.headers` option, the `http.requiredHeaders` option allows you to **set the HTTP header
for every API request**. The difference is that the `requiredHeaders` configuration specifies **only the header names**.
The actual values must be provided in the [`config`](/extend/generic-extractor/configuration/config/)
configuration section. This is useful in case the header values change dynamically or they are provided as part
of [template configuration](/extend/generic-extractor/publish/).

If the `api` configuration section looks like this:

{% highlight json %}
"http": {
    "requiredHeaders": ["Accept", "Accept-Encoding"]
}
{% endhighlight %}

then the header values must be provided in the `config` configuration section:
{% highlight json %}
"http": {
    "headers": {
        "Accept": "application/json",
        "Accept-Encoding": "gzip"
    }
}
{% endhighlight %}

Failing to provide the header values in the `config` section will cause an error:

    Missing required header Accept in config.http.headers!

See the full [example](/extend/generic-extractor/configuration/api/#required-headers).

### Ignore Errors
The `ignoreErrors` option allows you to force Generic Extractor to ignore certain extraction errors.
The option lists HTTP codes for which any errors occurring during downloading
and JSON parsing the response will be ignored. The `ignoreErrors` option error is an array of HTTP
response status codes; the default value is an empty array.

If the `ignoreErrors` is set to a non-empty array -- for instance:

{% highlight json %}
"http": {
    "ignoreErrors": [404]
}
{% endhighlight %}

Then the following happens:

- A response with status 2XX is processed normally.
- A response with status 404 is processed as if it were a success response.
    - If parsing of the response body JSON succeeds, it is added as any other row.
    - If parsing of the response body JSON fails, it is added as a row with the `errorData` field.
- A response with status 4XX (other than 404) causes the extraction to fail.
- A response with status 5XX causes the request to be [retried](#retry-configuration). If that does
not help, it causes the extraction to fail.

If the `ignoreErrors` contains 5XX status codes, the [Retry rules](#retry-configuration) are still applied.
But regardless of the outcome of the retries, the response will be considered as success.

See [example [EX132]](https://github.com/keboola/generic-extractor/tree/master/doc/examples/132-ignore-errors).

**Important**: Use this feature with **caution**! It is designed to workaround weird or buggy REST
API implementations and should not be used blindly if other solutions may be applied (e.g.,
[`responseFilter`](/extend/generic-extractor/configuration/config/jobs/#response-filter). When ignoring errors,
**you might miss even those errors that require your attention.**

### Connect Timeout

The `connectTimeout` option is a float describing the number of seconds to wait while trying to connect to a server. 
Default value is `30` seconds. Use `0` to wait indefinitely, we do not recommend it.

{% highlight json %}
"http": {
    "connectTimeout": 30
}
{% endhighlight %}


### Request Timeout

The `requestTimeout` option is a float describing the total timeout of the request in seconds.
Default value is `300` seconds. Use `0` to wait indefinitely, we do not recommend it. 

{% highlight json %}
"http": {
    "requestTimeout": 300
}
{% endhighlight %}

## Examples

### Retry Configuration
Assume that you have an API which implements throttling in the following way: when
the number of requests is exceeded, it returns an empty response with the status code `202` and
a timestamp when a new requests can be made in the `X-RetryAfter` HTTP header.
Then create the following API configuration to make Generic Extractor handle the
situation:

{% highlight json %}
"api": {
    "baseUrl": "http://example.com/",
    "retryConfig": {
        "http": {
            "retryHeader": "X-RetryAfter",
            "codes": [500, 502, 503, 504, 408, 420, 429, 202]
        },
        "maxRetries": 3
    }
}
{% endhighlight %}

Notice that it is necessary to add the response code `202` to the existing default codes. I.e., setting
`"codes": [202]` is likely very wrong.

See [example [EX037]](https://github.com/keboola/generic-extractor/tree/master/doc/examples/037-retry-header).

### Default Headers
Assume that you have an API which returns a JSON response only if the client sends an
`Accept: application/json` header. Additionally, if the client sends an
`Accept-Encoding: gzip` header, the HTTP transmission will be compressed (and thus faster).
The following configuration sends both headers with every API request:

{% highlight json %}
"api": {
    "baseUrl": "http://example.com/",
    "http": {
        "headers": {
            "Accept": "application/json",
            "Accept-Encoding": "gzip"
        }
    }
}
{% endhighlight %}

See [example [EX038]](https://github.com/keboola/generic-extractor/tree/master/doc/examples/038-default-headers).

### Default Parameters
Assume that you have an API requiring all requests to contain a filter
for the account to which they belong. This is done by passing the `account=XXX` parameter.
The following configuration sends the parameter with every API request:

{% highlight json %}
"api": {
    "baseUrl": "http://example.com/",
    "http": {
        "defaultOptions": {
            "params": {
                "account": 123
            }
        }
    }
}
{% endhighlight %}

For this use case, the [query authentication](/extend/generic-extractor/configuration/api/authentication/query/)
may also be used.

See [example [EX039]](https://github.com/keboola/generic-extractor/tree/master/doc/examples/039-default-parameters).

### Required Headers
Assume that an API requires the header `X-AppKey` to be sent with each
API request. The following API configuration can be used:

{% highlight json %}
"api": {
    "baseUrl": "http://example.com",
    "http": {
        "requiredHeaders": ["X-AppKey"]
    }
},
{% endhighlight %}

Then the actual header value must be added to the `config` section.

{% highlight json %}
"http": {
    "headers": {
        "X-AppKey": "ThisIsSecret"
    }
}
{% endhighlight %}

For this use case, the [authentication](/extend/generic-extractor/configuration/api/authentication/) may also be used.
See [example [EX040]](https://github.com/keboola/generic-extractor/tree/master/doc/examples/040-required-headers).


================================================
File: extend/generic-extractor/configuration/api/authentication/api_key.md
================================================
---
title: API Key Authentication
permalink: /extend/generic-extractor/configuration/api/authentication/api_key/
---

API Key token authentication sends a token in either a header or query parameter of each API request.

E.g., Headers: `X-StorageApi-Token:your_token`

This method is available through UI. You can select the `Api Key Auth` method and fill in the token.

{: .image-popup}
![Api Key](/extend/generic-extractor/configuration/api/authentication/api_key.png)

### Configuration parameters

- `Key` - arbitrary name of the header or query parameter key, e.g., `X-StorageApi-Token`
- `Token` - the actual token value
- `Add to` - where to add the token, either to the headers or query parameters


### JSON

In the underlying JSON, the API Key is implemented as follows:

Place your token into the `config.#__AUTH_TOKEN` parameter. The `Authorization` header is then constructed using the `concat` function.

**Header section**

{% highlight json %}
{
    "api": {
        ...,
        "http": {
      "http": {
          "headers": {
            "X-StorageApi-Token": {
              "attr": "#__AUTH_TOKEN"
            }
          }
        }
      }
    },
    "config": {
       "#__AUTH_TOKEN": "secret",
       "jobs": [...]
    }
}
{% endhighlight %}


**Query section**

{% highlight json %}
{
    "api": {
        ...,
        "http": {
      "http": {
          "params": {
            "X-StorageApi-Token": {
              "attr": "#__AUTH_TOKEN"
            }
          }
        }
      }
    },
    "config": {
       "#__AUTH_TOKEN": "secret",
       "jobs": [...]
    }
}
{% endhighlight %}



================================================
File: extend/generic-extractor/configuration/api/authentication/basic.md
================================================
---
title: Basic Authentication
permalink: /extend/generic-extractor/configuration/api/authentication/basic/
---

Basic Authentication provides the [HTTP Basic Authentication](https://en.wikipedia.org/wiki/Basic_access_authentication)
method. It requires entering a username and password in the configuration and sends the encoded values in the 
`Authorization` header. 

### User Interface

In the user interface, you simply select the `Basic Authorization` method and enter the username and password.

### JSON 

A sample Basic authentication looks like this:

{: .image-popup}
![Basic](/extend/generic-extractor/configuration/api/authentication/basic.png)

{% highlight json %}
{
    "api": {
        ...,
        "authentication": {
            "type": "basic"
        }
    },
    "config": {
        "#username": "JohnDoe",
        "#password": "secret"
    }
}
{% endhighlight %}

The `username` and `password` fields are part of the [`config` section](/extend/generic-extractor/configuration/config/). 
They are also prefixed by the hash `#` character, which means they are stored [encrypted](/overview/encryption/). 
If the API expects something else than a username and password in the `Authorization` header, or if it requires 
a custom authorization header, use the [Default Headers option](/extend/generic-extractor/configuration/api/#headers).

## Configuration Parameters
This `basic` type of authentication has no configuration parameters. The login and password must be provided in the 
[`config` section](/extend/generic-extractor/configuration/config/) of the Generic Extractor configuration.



## Basic Configuration Example
Assume you have an API which requires you to use the HTTP Basic authentication to send the login and password in 
the `Authorization` header. Assume that your login is `JohnDo` and password is `secret`. The following 
configuration solves the situation:

{% highlight json %}
{
    "parameters": {
        "api": {
            "baseUrl": "http://example.com",
            "authentication": {
                "type": "basic"
            }
        },
        "config": {
            "debug": true,
            "#username": "JohnDoe",
            "#password": "secret",
            "outputBucket": "mock-server",
            "jobs": [
                {
                    "endpoint": "users"
                }
            ]
        }
    }
}
{% endhighlight %}

The following HTTP header will be sent:

    Authorization: Basic Sm9obkRvZTpzZWNyZXQ=

See [example [EX078]](https://github.com/keboola/generic-extractor/tree/master/doc/examples/078-basic-auth).


================================================
File: extend/generic-extractor/configuration/api/authentication/bearer_token.md
================================================
---
title: Bearer Token Authentication
permalink: /extend/generic-extractor/configuration/api/authentication/bearer_token/
---

Bearer token authentication sends a token in the `Authorization` header of each API request.

This method is available through UI. You can select the `Bearer Token` method and fill in the token.

{: .image-popup}
![img.png](/extend/generic-extractor/configuration/api/authentication/bearer.png)



### JSON

In the underlying JSON, the Bearer Token is implemented as follows:

Place your token into the `config.#__BEARER_TOKEN` parameter. The `Authorization` header is then constructed using the `concat` function.

{% highlight json %}
{
    "api": {
        ...,
        "http": {
      "headers": {
        "Authorization": {
          "function": "concat",
          "args": [
            "Bearer ",
            {
              "attr": "#__BEARER_TOKEN"
            }
          ]
        }
      }
    }
    },
    "config": {
       "#__BEARER_TOKEN": "secret",
       "jobs": [...]
    }
}
{% endhighlight %}



================================================
File: extend/generic-extractor/configuration/api/authentication/index.md
================================================
---
title: Authentication
permalink: /extend/generic-extractor/configuration/api/authentication/
---

*To configure your first Generic Extractor, follow our [tutorial](/extend/generic-extractor/tutorial/).*
*Use [Parameter Map](/extend/generic-extractor/map/) to help you navigate among various
configuration options.*

Unless the API you want to extract from is completely public, you need an authentication and possibly authorization method.
There are many authentication methods available. Generic Extractor supports the following ones:

- [URL Query](/extend/generic-extractor/configuration/api/authentication/query/) authentication --- sends credentials in the URL of each API request.
- [Basic HTTP](/extend/generic-extractor/configuration/api/authentication/basic/) authentication --- sends credentials in the `Authorization` header of each API request.
- [Login](/extend/generic-extractor/configuration/api/authentication/login/) authentication --- obtains temporary credentials (token) by logging in and then sends them in the URL or headers of each API request.
- [OAuth 1.0](/extend/generic-extractor/configuration/api/authentication/oauth10/) authentication --- authenticates with [OAuth 1.0 scheme](#oauth).
- [OAuth 2.0](/extend/generic-extractor/configuration/api/authentication/oauth20/) authentication --- authenticates with [OAuth 2.0 scheme](#oauth).
- [OAuth 2.0 Login](/extend/generic-extractor/configuration/api/authentication/oauth20-login/) authentication ---
crossover between the [OAuth 2.0](/extend/generic-extractor/configuration/api/authentication/oauth20/) and
[Login](/extend/generic-extractor/configuration/api/authentication/login/) authentication.

**NOTE:** The [UI](/extend/generic-extractor/configuration/#user-interface) also offers additional authentication methods that are implemented as a template:
- [Bearer Token](/extend/generic-extractor/configuration/api/authentication/bearer_token/)
- [API Key](/extend/generic-extractor/configuration/api/authentication/api_key/)
- [oAuth 2.0 Client Credentials](/extend/generic-extractor/configuration/api/authentication/oauth_cc/)

Use the authentication method supported by the target API. If the API supports multiple
authentication methods, the [URL Query](/extend/generic-extractor/configuration/api/authentication/query/) and
[Basic HTTP](/extend/generic-extractor/configuration/api/authentication/basic/) methods are the easiest to set up but also the least secure.

**User Interface**

Most of the authentication methods are available via the user interface:

{: .image-popup}
![Auth ui](/extend/generic-extractor/configuration/api/authentication/auth_ui.png)


An example authentication JSON configuration looks like this:

{% highlight json %}
{
    "api": {
        "authentication": {
            "type": "query",
            "query": {
                "apiKey": "2267709"
            }
        }
    },
    "config": {
        ...
    }
}
{% endhighlight %}

## OAuth
Generic Extractor also supports authentication using the [OAuth](https://en.wikipedia.org/wiki/OAuth) standard.
Due to the principles of OAuth, this authentication method is supported only for [published components](/extend/generic-extractor/publish/).
The OAuth protocol defines a scheme in which credentials are exchanged between the following:

- Consumer (Generic Extractor)
- Service provider (the API itself)
- End-user (the person authenticating against the API)

The OAuth specification defines what kind of information is exchanged in which steps. It is not a precise
specification and leaves quite some freedom for implementation. Also, there are two versions of
OAuth --- 1.0 and 2.0. They are completely incompatible (both the authentication steps and the exchanged fields differ).
Generic Extractor supports both [OAuth 1.0](/extend/generic-extractor/configuration/api/authentication/oauth10/)
and  [OAuth 2.0](/extend/generic-extractor/configuration/api/authentication/oauth20/). If you are developing a new component using Generic Extractor
[templates](/extend/generic-extractor/publish/#submission) and want to use and test OAuth authentication,
[inject the necessary credentials](/extend/common-interface/oauth/#credentials-injection) simply by passing them
in the configuration's `authorization` property.


================================================
File: extend/generic-extractor/configuration/api/authentication/login.md
================================================
---
title: Login
permalink: /extend/generic-extractor/configuration/api/authentication/login/
---

* TOC
{:toc}

Use the Login authentication to send a one-time **login request** to obtain temporary credentials
for authentication of all the other API requests.


## User Interface

Note that this configuration option is not yet covered. You can add the JSON configuration using the `Custom` auth method.

{: .image-popup}
![Login](/extend/generic-extractor/configuration/api/authentication/login.png)

However, this method is reused in the oAuth 2.0 Client Credentials authentication method available in the UI.

## JSON

A sample Login authentication looks like this:

{% highlight json %}
{
    "api": {
        ...,
        "authentication": {
            "type": "login",
            "loginRequest": {
                "endpoint": "login",
                "method": "GET",
                "headers": {
                    "X-Login": "JohnDoe",
                    "X-Password": "TopSecret"
                }
            },
            "format": "json",
            "apiRequest": {
                "headers": {
                    "X-ApiToken": {
                        "response": "authorization.token"
                    }
                }
            }
        }
    },
    "config": {
        ...
    }
}
{% endhighlight %}

## Configuration Parameters
The following configuration parameters are supported for the `login` type of authentication:

- `loginRequest` (required, object) --- a [job-like](/extend/generic-extractor/configuration/config/jobs/) object describing the login request; it has the following properties:
    - `endpoint` (required, string) --- an API endpoint for the login request; the same rules as for the [Job `endpoint`](/extend/generic-extractor/configuration/config/jobs/#specifying-endpoint) apply here.
    - `params` (optional, object) --- an object with key-value properties containing request parameters; object keys are parameters names; values are transformed the [same way as in jobs](/extend/generic-extractor/configuration/config/jobs/#request-parameters).
    - `method` (optional, string) --- an HTTP method to send the request; this defines how the [parameters are sent](/extend/generic-extractor/configuration/config/jobs/#request-parameters) to the API. The default value is `GET`.
    - `headers` (optional, object) --- an object with key-value properties containing HTTP headers. The names will be used as HTTP header names, and the values will be used as the value of the respective header.
- `format` (optional, string) --- defines the expected format of `loginRequest`; the allowed values are `json` (default) and `text`. If the format is text, then it is converted to a json with field `data` (see [example](#configuration-with-headers-and-text-response). This conversion will also be applied in case the response is a JSON [scalar](/extend/generic-extractor/tutorial/json/#data-values). But in that case, format `json` has to be used (see [example [EX129]](https://github.com/keboola/generic-extractor/tree/master/doc/examples/129-login-auth-scalar)).
- `apiRequest` (optional, object) --- an object which defines how the result of the **login request** will be used in the actual API request; it contains the following properties:
    - `headers` (optional, object) --- an object with key-value properties containing HTTP headers. The names are header names, the values are paths in the JSON response from which the actual values are extracted.
    - `query` (optional, object) --- an object with key-value properties containing URL query parameters. The names are parameter names, and the values are paths in the JSON response from which the actual values are extracted.
- `expires` (optional, mixed) --- either an integer value specifying a fixed number of seconds after which the **login request** will be sent again (see an [example](#expiration-basic)); or, an object with the following properties:
    - `response` (required, string) --- a path in the JSON response which contains the expiration time. It can be either:
        - a string which can be processed by the [`strtotime` function](https://www.php.net/manual/en/function.strtotime.php) (see an [example](#expiration-from-response)), or
        - a numeric [timestamp](https://en.wikipedia.org/wiki/Unix_time) (with `"relative": false`), or
        - a number of seconds for which the credentials are valid (with `"relative": true`).
    - `relative` (optional, boolean) --- When true, the expiration time is relative to the current time. The default value is `false`.

Note that the values in `apiRequest.headers` and `apiRequest.query` take precedence over the values specified in the
`api.http.defaultOptions.headers` (see an [example](#parameter-overriding)). If `expires` is not set, the login request
is called only once before all other requests. To call the login request before every request (e.g., to obtain access token from refresh token), set `"expires": 0`.



## Examples
Below are several examples showing you how to use various login authentication related features in Generic Extractor.

### Configuration with Headers
Let's say you have an API which requires every API call to be authorized with the `X-ApiToken` header. The value of that header (an API
token) is obtained by calling the `/login` endpoint with the headers `X-Login` and `X-Password`. The `/login` endpoint response looks
like this:

{% highlight json %}
{
    "authorization": {
        "token": "a1b2c3d435f6"
    }
}
{% endhighlight %}

The following API configuration deals with the authentication:

{% highlight json %}
"api": {
    "baseUrl": "http://example.com",
    "authentication": {
        "type": "login",
        "loginRequest": {
            "endpoint": "login",
            "method": "GET",
            "headers": {
                "X-Login": "JohnDoe",
                "X-Password": "TopSecret"
            }
        },
        "apiRequest": {
            "headers": {
                "X-ApiToken": {
                    "response": "authorization.token"
                }
            }
        }
    }
}
{% endhighlight %}

The first request will be sent to `/login` with the HTTP headers:

    X-Login: JohnDoe
    X-Password: TopSecret

All consecutive requests will be sent to the endpoints specified in the [`jobs`](/extend/generic-extractor/configuration/config/jobs/) section and
will contain the header:

    X-ApiToken: a1b2c3d435f6

See [example [EX079]](https://github.com/keboola/generic-extractor/tree/master/doc/examples/079-login-auth-headers).

### Configuration with Headers and Text Response
Let's say you have an API like the above, but it returns the login response as a plain text:

    a1b2c3d435f6

The following API configuration deals with the authentication:

{% highlight json %}
"api": {
    "baseUrl": "http://example.com",
    "authentication": {
        "type": "login",
        "loginRequest": {
            "endpoint": "login",
            "method": "GET",
            "headers": {
                "X-Login": "JohnDoe",
                "X-Password": "TopSecret"
            }
        },
        "format": "text",
        "apiRequest": {
            "headers": {
                "X-ApiToken": {
                    "response": "data"
                }
            }
        }
    }
}
{% endhighlight %}

The first request will be sent to `/login` with the HTTP headers:

    X-Login: JohnDoe
    X-Password: TopSecret

The plain text response `a1b2c3d435f6` is converted to the following JSON:

{% highlight json %}
{
    "data": "a1b2c3d435f6"
}
{% endhighlight %}

Therefore you can access it in the headers configuration using the `"response": "data"` reference.
All consecutive requests will be sent to the endpoints specified in the [`jobs`](/extend/generic-extractor/configuration/config/jobs/) section and
will contain the header:

    X-ApiToken: a1b2c3d435f6

See [example [EX128]](https://github.com/keboola/generic-extractor/tree/master/doc/examples/128-login-auth-text).

### Configuration with Query Parameters
Let's say you have an API which requires an [HTTP POST](https://en.wikipedia.org/wiki/POST_(HTTP)) request with `username` and
`password` to the endpoint `/login/form`.
On a successful login, it returns the following response:

{% highlight json %}
{
    "authentication": [
        {
            "secret": "a1b2c3d435f6"
        },
        {
            "token": {
                "id": 123
            }
        }
    ]
}
{% endhighlight %}

The actual API requests then must contain the `secretKey` and `tokenId` parameters in the URL.
The following `authentication` configuration takes care of the situation:

{% highlight json %}
"authentication": {
    "type": "login",
    "loginRequest": {
        "endpoint": "login/form",
        "method": "FORM",
        "params": {
            "username": "JohnDoe",
            "password": "TopSecret"
        }
    },
    "apiRequest": {
        "query": {
            "secretKey": {
                "response": "authentication.0.secret"
            },
            "tokenId": {
                "response": "authentication.1.token.id"
            }
        }
    }
}
{% endhighlight %}

The first API request will be sent as:

    POST /login/form

    username=JohnDoe&password=TopSecret

The [FORM method](/extend/generic-extractor/configuration/config/jobs/#form) sends the parameters
as [application/x-www-form-urlencoded](https://en.wikipedia.org/wiki/POST_(HTTP)#Use_for_submitting_web_forms).
The `apiRequest.query` settings then map the response values to the parameters of the other API calls,
so the second API call will be sent as:

    GET /users?secretKey=a1b2c3d435f6&tokenId=123

See [example [EX080]](https://github.com/keboola/generic-extractor/tree/master/doc/examples/080-login-auth-query).
Notice that the example uses completely different URL for the login request.

### Parameter Overriding
The above examples show how to use query parameters and headers separately. However, they can be mixed freely; they can also be
mixed with parameters and headers entered elsewhere in the configuration. The following example shows how parameters from
different places are merged together:

<details>
  <summary>Click to expand the example.</summary>

{% highlight json %}
{
    "parameters": {
        "api": {
            "baseUrl": "http://example.com/",
            "http": {
                "defaultOptions": {
                    "headers": {
                        "X-Mode": "development",
                        "X-Account-Id": 123
                    },
                    "params": {
                        "debug": "1",
                        "orderBy": "default",
                        "secretKey": "123"
                    }
                }
            },
            "authentication": {
                "type": "login",
                "loginRequest": {
                    "endpoint": "login",
                    "method": "POST",
                    "params": {
                        "username": "JohnDoe",
                        "password": "TopSecret"
                    }
                },
                "apiRequest": {
                    "query": {
                        "apiToken": {
                            "response": "authorization.token"
                        },
                        "secretKey": {
                            "response": "authorization.secretKey"
                        },
                        "customerId": {
                            "response": "authorization.accountId"
                        }
                    },
                    "headers": {
                        "X-SecretKey": {
                            "response": "authorization.secretKey"
                        },
                        "X-Account-Id": {
                            "response": "authorization.accountId"
                        }
                    }
                }
            }
        },
        "config": {
            "debug": true,
            "outputBucket": "ge-tutorial",
            "jobs": [
                {
                    "endpoint": "users",
                    "params": {
                        "orderBy": "userName",
                        "secretKey": "none",
                        "customerId": "234"
                    }
                }
            ]
        }
    }
}
{% endhighlight %}

</details>
<br>
The example configuration sends its first request as:

    POST /login

    {"username":"JohnDoe","password":"TopSecret"}

with this header:

    Content-Type: application/json

Notice that in the case of the **login request** both `headers` and `params` from `api.defaultOptions` are ignored. Only the
`headers` and `params` from `api.authentication.loginRequest` are used (and encoded as JSON because of `"method": "POST"`).

The second API call is sent as:

    GET /users?debug=1&orderBy=userName&secretKey[0]=none&secretKey[1]=a1b2c3d435f6&customerId[0]=234&customerId[1]=abc&apiToken=987654

with this header:

    X-Mode: development
    X-Account-Id: abc
    X-SecretKey: a1b2c3d435f6

The request URL contains the following query parameters:

- `debug=1` --- coming from the `api.http.defaultOptions.params` option
- `orderBy=userName` --- coming from the `config.jobs.params` option, which overrides the value specified in `api.http.defaultOptions.params`
- `secretKey[0]=none` --- coming from the `config.jobs.params` option, which overrides the value specified in `api.http.defaultOptions.params`
- `secretKey[1]=a1b2c3d435f6` --- coming from the `api.authentication.apiRequest.query` option
- `customerId[0]=234` --- coming from the `config.jobs.params` option
- `customerId[1]=abc` --- coming from the `api.authentication.apiRequest.query` option
- `apiToken=987654` --- coming from the `api.authentication.apiRequest.query` option

The request headers contain:

- `X-Mode` --- coming from the `api.http.defaultOptions.headers` option
- `X-Account-Id` --- coming from the `api.authentication.apiRequest.headers` option, which overrides the values specified in `api.http.defaultOptions.headers`
- `X-SecretKey` --- coming from the `api.authentication.apiRequest.headers` option

As you can see, the headers specified elsewhere are **overwritten** by the `api.authentication.apiRequest` while the parameters
specified elsewhere are **merged** with the `api.authentication.apiRequest`.

See [example [EX081]](https://github.com/keboola/generic-extractor/tree/master/doc/examples/081-login-auth-headers-query-override).

### Expiration Basic
It is possible that the credentials provided by the **login request** have a time-limited validity. This is handled by the `expires`
option. If the obtained credentials are always valid for a certain period of time, for example for 1 hour, modify the [first
example](#configuration-with-headers) to this:

{% highlight json %}
{
    "parameters": {
        "api": {
            "baseUrl": "http://example.com/",
            "authentication": {
                "type": "login",
                "loginRequest": {
                    "endpoint": "login",
                    "method": "GET",
                    "headers": {
                        "X-Login": "JohnDoe",
                        "X-Password": "TopSecret"
                    }
                },
                "apiRequest": {
                    "headers": {
                        "X-ApiToken": {
                            "response": "authorization.token"
                        }
                    }
                },
                "expires": "3600"
            }
        }
    }
}
{% endhighlight %}

This causes Generic Extractor to call the **login request** every hour.

See [example [EX082]](https://github.com/keboola/generic-extractor/tree/master/doc/examples/082-login-auth-expires).

### Expiration from Response
In case the credentials provided by the **login request** have a time-limited validity, use the `expires` option.
If the validity of the credentials is returned in the response, modify the [first example](#configuration-with-headers) to this:

{% highlight json %}
{
    "parameters": {
        "api": {
            "baseUrl": "http://example.com/",
            "authentication": {
                "type": "login",
                "loginRequest": {
                    "endpoint": "login",
                    "method": "GET",
                    "headers": {
                        "X-Login": "JohnDoe",
                        "X-Password": "TopSecret"
                    }
                },
                "apiRequest": {
                    "headers": {
                        "X-ApiToken": {
                            "response": "authorization.token"
                        }
                    }
                },
                "expires": {
                    "response": "authorization.expires"
                }
            }
        }
    }
}
{% endhighlight %}

This assumes that the response of the **login request** looks like this:

{% highlight json %}
{
    "authorization": {
        "token": "a1b2c3d435f6",
        "expires": "2017-02-20 12:34:45"
    }
}
{% endhighlight %}

See [example [EX083]](https://github.com/keboola/generic-extractor/tree/master/doc/examples/083-login-auth-expires-date).

### Relative Expiration from Response
In case the API returns credentials validity in the **login request** and that validity is expressed in seconds,
use the `expires` option together with setting `relative` to `true`.
The result is the behavior of the [first example](#expiration-basic) but the value is taken
from the response as in the [second example](#expiration-from-response).

{% highlight json %}
{
    "parameters": {
        "api": {
            "baseUrl": "http://example.com/",
            "authentication": {
                "type": "login",
                "loginRequest": {
                    "endpoint": "login",
                    "method": "GET",
                    "headers": {
                        "X-Login": "JohnDoe",
                        "X-Password": "TopSecret"
                    }
                },
                "apiRequest": {
                    "headers": {
                        "X-ApiToken": {
                            "response": "authorization.token"
                        }
                    }
                },
                "expires": {
                    "response": "authorization.expires",
                    "relative": true
                }
            }
        }
    }
}
{% endhighlight %}

This assumes that the response of the **login request** looks like this:

{% highlight json %}
{
    "authorization": {
        "token": "a1b2c3d435f6",/
        "expires": 3600
    }
}
{% endhighlight %}

See [example [EX084]](https://github.com/keboola/generic-extractor/tree/master/doc/examples/084-login-auth-expires-seconds).

### Login Authentication with Functions
Suppose you have an API which requires you to send a username and password separated by a colon and
base64 encoded --- for example, `JohnDoe:TopSecret` (base64 encoded to `Sm9obkRvZTpUb3BTZWNyZXQ=`) in the
`X-Authorization` header to an `/auth` endpoint. The login endpoint then returns a token
which can be used with other API calls.

The following configuration reads both the login and password parameters from the
[`config` section](/extend/generic-extractor/functions/#configuration-attributes) and
uses the `login` authorization method to send them to the special `/auth` endpoint.

{% highlight json %}
{
    "parameters": {
        "api": {
            "baseUrl": "http://example.com/",
            "authentication": {
                "type": "login",
                "loginRequest": {
                    "endpoint": "auth",
                    "headers": {
                        "X-Authorization": {
                            "function": "base64_encode",
                            "args": [
                                {
                                    "function": "concat",
                                    "args": [
                                        {
                                            "attr": "#login"
                                        },
                                        ":",
                                        {
                                            "attr": "#password"
                                        }
                                    ]
                                }
                            ]
                        }
                    }
                },
                "apiRequest": {
                    "headers": {
                        "X-Api-Token": "token"
                    }
                }
            }
        },
        "config": {
            "#login": "JohnDoe",
            "#password": "TopSecret",
            "debug": true,
            "outputBucket": "mock-server",
            "jobs": [
                {
                    "endpoint": "users",
                    "dataType": "users"
                }
            ]
        }
    }
}
{% endhighlight %}

See [example [EX100]](https://github.com/keboola/generic-extractor/tree/master/doc/examples/100-function-login-headers).

### Login Authentication with Login and API Request
Suppose you have an API similar to the one in the [previous example](#login-authentication-with-functions).
It requires you to send a username and password separated by a colon and
base64 encoded --- for example, `JohnDoe:TopSecret` (base64 encoded to `Sm9obkRvZTpUb3BTZWNyZXQ=`) in the
`X-Authorization` header to an `/auth` endpoint. The difference is that the login endpoint returns a token
which must be further processed. The other API requests expects that the received token is concatenated again
with the user name --- for example, `JohnDoe:d868d581b2f` and an SHA1 hash is generated (e.g.
`09e4e6977b72ecc9fa2120f49a4a74f5c268d277`). This value must be sent as an `auth` query parameter.

The `loginRequest` part of the following configuration is the same as in the
[previous example](#login-authentication-with-functions) --- it reads both the login and password parameters
from the `config` section and uses the `login` authorization method to send them to the special `/auth` endpoint.
The `apiRequest` part of the configuration uses the [`sha1`](/extend/generic-extractor/functions/#sha1) function on
the result of the [`concat`](/extend/generic-extractor/functions/#concat) function. The `concat` function takes
the login parameter from the [`config` section](/extend/generic-extractor/functions/#configuration-attributes)
(via `"attr": "#login"` reference) and the token parameter from the
[response of the login request](/extend/generic-extractor/functions/#login-authentication-context)
(via `"response": "authorization.token"` reference).

{% highlight json %}
{
    "parameters": {
        "api": {
            "baseUrl": "http://example.com/",
            "authentication": {
                "type": "login",
                "loginRequest": {
                    "endpoint": "auth",
                    "headers": {
                        "X-Authorization": {
                            "function": "base64_encode",
                            "args": [
                                {
                                    "function": "concat",
                                    "args": [
                                        {
                                            "attr": "#login"
                                        },
                                        ":",
                                        {
                                            "attr": "#password"
                                        }
                                    ]
                                }
                            ]
                        }
                    }
                },
                "apiRequest": {
                    "query": {
                        "auth": {
                            "function": "sha1",
                            "args": [
                                {
                                    "function": "concat",
                                    "args": [
                                        {
                                            "attr": "#login"
                                        },
                                        ":",
                                        {
                                            "response": "authorization.token"
                                        }
                                    ]
                                }
                            ]
                        }
                    }
                }
            }
        },
        "config": {
            "#login": "JohnDoe",
            "#password": "TopSecret",
            "debug": true,
            "outputBucket": "mock-server",
            "jobs": [
                {
                    "endpoint": "users",
                    "dataType": "users"
                }
            ]
        }
    }
}
{% endhighlight %}

See [example [EX117]](https://github.com/keboola/generic-extractor/tree/master/doc/examples/117-function-login-params-response)
or [example [EX118]](https://github.com/keboola/generic-extractor/tree/master/doc/examples/118-function-login-headers-response), which uses headers.


================================================
File: extend/generic-extractor/configuration/api/authentication/oauth10.md
================================================
---
title: OAuth 1.0 Authentication
permalink: /extend/generic-extractor/configuration/api/authentication/oauth10/
---



**Note** that this configuration option is not yet supported and the test endpoint button will not work.

OAuth 1.0 authentication is one of the [two OAuth methods](/extend/generic-extractor/configuration/api/authentication/#oauth) and
is supported only for [published components](/extend/generic-extractor/publish/).
It is configured by setting the `type` key to `oauth10`:

{% highlight json %}
{
    "api": {
        ...,
        "authentication": {
            "type": "oauth10"
        }
    },
    "config": {
        ...
    }
}
{% endhighlight %}

No other configuration parameters are necessary (nor available). The OAuth authentication process is
described by the [following diagram](https://oauth.net/core/1.0/#anchor9):

![OAuth 1.0 Diagram](/extend/generic-extractor/configuration/api/authentication/oauth10-diagram.png)

In the diagram, only the step `G` represents the actual communication with the API (extraction of data).
The final authorization section of the Generic Extractor configuration is generated between
steps `F` and `G`. When a component is published, the steps `A` - `F` of the process are handled by
Keboola (and the end-user).

To **develop and test** a new component with the OAuth authorization, go through
the steps `A` - `F` manually. At the last step, you obtain a response containing the fields
`oauth_token` and `oauth_token_secret`, e.g.:

{% highlight json %}
{
    "oauth\_token": "JohnDoe1234",
    "oauth\_token\_secret": "TopSecret5678"
}
{% endhighlight %}

Then, inject the OAuth credentials into the configuration root:

{% highlight json %}
{
    "parameters": {
        "api": {
            ...
        },
        "config": {
            ...
        }
    },
    "authorization": {
        "oauth_api": {
            "credentials": {
                "#data": "{\"oauth\_token\":\"JohnDoe1234\",\"oauth\_token\_secret\":\"TopSecret5678\"}",
                "appKey": 1234,
                "#appSecret": "TopSecret"
            }
        }
    }
}
{% endhighlight %}

The `authorization` field has a single property `oauth_api`, which has a single property `credentials` with three child properties:

- `#data` --- contains the response from the service provider, the response is a JSON string (not an object!).
- `appKey` --- contains the [Consumer Key](https://oauth.net/core/1.0/#anchor3).
- `#appSecret` --- contains the [Consumer Secret](https://oauth.net/core/1.0/#anchor3) (use an empty string if
not used by the service provider).

With the above configuration, Generic Extractor generates the `Authorization` header; the signature
method used is [HMAC-SHA1](https://oauth.net/core/1.0/#anchor16). For example:

    Authorization: OAuth oauth_consumer_key="1234", oauth_nonce="72469d96572dabb4d0ea02b057ea4f246d722b72", oauth_signature="zl0y5CyySCPj8IqODV3Egjqgg6Q%3D", oauth_signature_method="HMAC-SHA1", oauth_timestamp="1492904452", oauth_token="JohnDoe1234", oauth_version="1.0"

The full configuration is, e.g.:

{% highlight json %}
{
    "parameters": {
        "api": {
            "baseUrl": "http://example.com/",
            "authentication": {
                "type": "oauth10"
            }
        },
        "config": {
            "debug": true,
            "outputBucket": "mock-server",
            "jobs": [
                {
                    "endpoint": "users",
                    "dataType": "users"
                }
            ]
        }
    },
    "authorization": {
        "oauth_api": {
            "credentials": {
                "#data": "{\"oauth_token\":\"userToken\",\"oauth_token_secret\":\"tokenSecret\"}",
                "appKey": 1234,
                "#appSecret": "TopSecret"
            }
        }
    }
}
{% endhighlight %}

See [example [EX102]](https://github.com/keboola/generic-extractor/tree/master/doc/examples/102-oauth1) or
learn [more about Keboola-OAuth integration](/extend/common-interface/oauth).


================================================
File: extend/generic-extractor/configuration/api/authentication/oauth20-login.md
================================================
---
title: Login Using OAuth 2.0 Authentication
permalink: /extend/generic-extractor/configuration/api/authentication/oauth20-login/
---

* TOC
{:toc}

**Note** that this configuration option is not yet supported and the test endpoint button will not work.

The OAuth Login method is useful when you need to send a one-time **login request** to obtain temporary credentials
for authentication of all the other API requests. A sample OAuth Login authentication looks like this:

{% highlight json %}
{
    "api": {
        ...,
        "authentication": {
            "type": "oauth20.login",
            "loginRequest": {
                "endpoint": "login",
                "method": "GET",
                "headers": {
                    "X-Login": "JohnDoe",
                    "X-Password": "TopSecret"
                }
            },
            "apiRequest": {
                "headers": {
                    "X-ApiToken": {
                        "response": "authorization.token"
                    }
                }
            }
        }
    },
    "config": {
        ...
    }
}
{% endhighlight %}

## Configuration Parameters
The configuration parameters are identical to the [Login](/extend/generic-extractor/configuration/api/authentication/login/) method.
The difference, however, is in the [function context](/extend/generic-extractor/functions/#oauth-20-login-authentication-context).
The **login request** is assumed to require the OAuth2 authorization and its response must be in JSON format (plaintext is not supported).

## Examples
The following examples demonstrate how to use OAuth with a basic login request and Google API in Generic Extractor.

### Basic Configuration
The following configuration shows how to set up an OAuth **login request**:

{% highlight json %}
{
    "parameters": {
        "api": {
            "baseUrl": "http://mock-server:80/105-oauth2-login/",
            "authentication": {
                "type": "oauth20.login",
                "loginRequest": {
                    "endpoint": "token",
                    "headers": {
                        "X-Refresh-Token": {
                            "user": "refresh_token"
                        },
                        "X-App-Key": {
                            "consumer": "client_id"
                        }
                    }
                },
                "apiRequest": {
                    "headers": {
                        "X-Access-Token": {
                            "response": "credentials.access_token"
                        }
                    }
                }
            }
        },
        "config": {
            "outputBucket": "mock-server",
            "jobs": [
                {
                    "endpoint": "users",
                    "dataType": "users"
                }
            ]
        }
    },
    "authorization": {
        "oauth_api": {
            "credentials": {
                "#data": "{\"status\": \"ok\",\"refresh_token\": \"1234abcd5678efgh\"}",
                "appKey": "someId",
                "#appSecret": "clientSecret"
            }
        }
    }
}
{% endhighlight %}

First, an OAuth login is negotiated. The result of this authentication is a response from the API (inserted into
the `authorization.oauth_api.credentials.#data` property):

{% highlight json %}
{
    "status": "ok",
    "refresh_token": "1234abcd5678efgh"
}
{% endhighlight %}

This is sent to the `/token` endpoint with the following headers:

    X-Refresh-Token: 1234abcd5678efgh
    X-App-Key: someId

This API call then returns the following response:

{% highlight json %}
{
	"credentials": {
		"validUntil": "2017-10-04 12:45:09",
		"access_token": "mkoijn098uhbygv"
	}
}
{% endhighlight %}

From that, the value of the `credentials.access_token` property is taken, inserted into the `X-Access-Token` header
and sent to other API requests (`/users`).

See [example [EX105]](https://github.com/keboola/generic-extractor/tree/master/doc/examples/105-oauth2-login).


### Google API Configuration
The following example shows how to set up the OAuth authentication for Google APIs. The access token is refreshed with each API call.

#### Generate access tokens
First, visit [Google API Console](https://console.developers.google.com/apis/credentials) to obtain OAuth 2.0 credentials, such as a
**Client ID** and **Client secret**.

Add `https://developers.google.com/oauthplayground` to Authorized redirect URIs:

{: .image-popup}
![Google API Console](/extend/generic-extractor/configuration/api/authentication/oauth20-login-console.png)

Then, generate **access** and **refresh** tokens using [Google OAuth 2.0 Playground](https://developers.google.com/oauthplayground/).

Provide your Client ID and Client secret in the settings of OAuth 2.0 Playground:

{: .image-popup}
![Google OAuth 2.0 Playground 1](/extend/generic-extractor/configuration/api/authentication/oauth20-login-playground-1.png)

Make sure the Offline Access option is checked and close the settings dialog.

On the left side, choose which scopes you would like to authorize and click on **Authorize APIs**.

{: .image-popup}
![Google OAuth 2.0 Playground 1](/extend/generic-extractor/configuration/api/authentication/oauth20-login-playground-2.png)

Then exchange the authorization code for tokens:

{: .image-popup}
![Google OAuth 2.0 Playground 1](/extend/generic-extractor/configuration/api/authentication/oauth20-login-playground-3.png)

Use the generated tokens in the Generic Extractor configuration.

#### Configuration
Paste the JSON response with the generated access and refresh tokens as a string under the `#data` key in
`authorization.oauth_api.credentials`.
Escape double quotes `"` in the JSON response and preferably remove newlines too, so it looks like this:

`{\"access_token\": \"MY_ACCESS_TOKEN\",\"refresh_token\": \"MY_REFRESH_TOKEN\"}`

Here is a complete configuration example for AdSense:

{% highlight json %}
{
  "parameters": {
    "api": {
      "baseUrl": "https://www.googleapis.com",
      "authentication": {
        "type": "oauth20.login",
        "loginRequest": {
          "endpoint": "/oauth2/v4/token",
          "method": "FORM",
          "headers": {
            "Content-Type": "application/x-www-form-urlencoded"
          },
          "params": {
            "client_id": {
              "consumer": "client_id"
            },
            "client_secret": {
              "consumer": "client_secret"
            },
            "refresh_token": {
              "user": "refresh_token"
            },
            "grant_type": "refresh_token"
          }
        },
        "apiRequest": {
          "query": {
            "access_token": {
                "response": "access_token"
            }
          }
        }
      }
    },
    "config": {
      "debug": true,
      "outputBucket": "adsense",
      "jobs": [
        {
          "endpoint": "/adsense/v1.4/reports/",
          "dataField": "rows",
          "dataType": "rows"
        }
      ]
    }
  },
  "authorization": {
    "oauth_api": {
      "credentials": {
        "#data": "{\"access_token\": \"MY_ACCESS_TOKEN\",\"refresh_token\": \"MY_REFRESH_TOKEN\"}",
        "appKey": "MY_CLIENT_ID",
        "#appSecret": "MY_CLIENT_SECRET"
      }
    }
  }
}
{% endhighlight %}

See [example [EX114]](https://github.com/keboola/generic-extractor/tree/master/doc/examples/114-oauth2-google).


================================================
File: extend/generic-extractor/configuration/api/authentication/oauth20.md
================================================
---
title: OAuth 2.0 Authentication
permalink: /extend/generic-extractor/configuration/api/authentication/oauth20/
---

* TOC
{:toc}

OAuth 2.0 Authentication is one of [two OAuth methods](/extend/generic-extractor/configuration/api/authentication/#oauth) and
is supported only for [components registered in the developer portal](/extend/generic-extractor/publish/).
It is configured by setting the `type` key to `oauth20`:

{% highlight json %}
{
    "api": {
        ...,
        "authentication": {
            "type": "oauth20"
        }
    },
    "config": {
        ...
    }
}
{% endhighlight %}

The OAuth 2.0 authentication process is described by the [following diagram](https://docs.spring.io/spring-social/docs/1.0.0.M3/reference/html/serviceprovider.html):

![Diagram - OAuth 2.0 authentication](/extend/generic-extractor/configuration/api/authentication/oauth20-diagram.png)

In the diagram, step `6` represents the end of authentication and the actual communication with
the API (extraction of data) may begin.
The final authorization section of the Generic Extractor configuration is generated between
steps `5` and `6`. When a component is published, steps `1` --- `6` of the process are handled by
Keboola (and the end-user).

To **develop and test** a new component with the OAuth authorization, go through
steps `1` --- `6` manually. At step `5`, you will obtain a response which needs to be put
in the `authorization.oauth_api.credentials.data` section of the configuration. The response can be
either plaintext or a JSON. Let's say you obtain a simple plaintext string:

    SomeToken1234abcd567ef

The following configuration needs to be supplied to Generic Extractor:

{% highlight json %}
{
    "parameters": {
        "api": {
            ...
        },
        "config": {
            ...
        }
    },
    "authorization": {
        "oauth_api": {
            "credentials": {
                "#data": "SomeToken1234abcd567ef",
                "appKey": "clientId",
                "#appSecret": "clientSecret"
            }
        }
    }
}
{% endhighlight %}

The `authorization` field has a single property `oauth_api` with a single property `credentials`. This
has three child properties:

- `#data` --- contains the response from the service provider; the response is a plaintext string or a JSON string (not an object!).
- `appKey` --- contains the Client ID (use an empty string if not used by the service provider).
- `#appSecret` --- contains the Client Secret (use an empty string if not used by the service provider).

Note that the properties `appKey` and `#appSecret` must exist even if not used by the API; set them
to empty strings. For more information about OAuth 2, see the [official documentation](https://oauth.net/2/)
or learn [more about Keboola-OAuth integration](/extend/common-interface/oauth).

## Configuration Parameters
The following configuration parameters are supported for the `oauth20` authentication type:

- `format` (optional, string) --- If the OAuth service provider response is JSON, use the only possible
value -- `json`. Otherwise do not specify format at all (plaintext is assumed).
- `headers` (optional, object) --- Object whose properties represent the key-value pairs sent as HTTP headers.
- `query` (optional, object) --- Object whose properties represent the key-value pairs of the URL query.

At least one of the `headers` or `query` options should always be specified; otherwise no authentication
will be sent with the API requests. Both fields also allow and practically require using
[functions](/extend/generic-extractor/functions/) to generate an OAuth signature. Specific authentication values
are available in the [OAuth function context](/extend/generic-extractor/functions/#oauth-20-authentication-context).

## Examples
The following two examples demonstrate the support for OAuth 2 in Generic Extractor.

### Bearer Authentication
The most basic OAuth authentication method is with "Bearer Token". If you have an API which supports
this authentication method, the following configuration can be used:

{% highlight json %}
{
    "parameters": {
        "api": {
            "baseUrl": "https://example.com/",
            "authentication": {
                "type": "oauth20",
                "headers": {
                    "Authorization": {
                        "function": "concat",
                        "args": [
                            "Bearer ",
                            {
                                "authorization": "data"
                            }
                        ]
                    }
                }
            }
        },
        "config": {
            "jobs": [
                {
                    "endpoint": "users",
                    "dataType": "users"
                }
            ]
        }
    },
    "authorization": {
        "oauth_api": {
            "credentials": {
                "#data": "SomeToken1234abcd567ef",
                "appKey": "clientId",
                "#appSecret": "clientSecret"
            }
        }
    }
}
{% endhighlight %}

The response obtained from the service provider (the API) is a plaintext string `SomeToken1234abcd567ef`, which
is simply a token to be used to access other API calls. The `api.authentication.headers` section creates
the header `Authorization: Bearer SomeToken1234abcd567ef` using the
[`concat` function](/extend/generic-extractor/functions/#concat).

See [example [EX103]](https://github.com/keboola/generic-extractor/tree/master/doc/examples/103-oauth2-bearer).

### HMAC Authentication
If you have an API which requires an [HMAC](https://en.wikipedia.org/wiki/Hash-based_message_authentication_code)
signed token, generate the correct signature using [functions](/extend/generic-extractor/functions).
The following example assumes you obtain the following response from the API upon authentication:

{% highlight json %}
{
    "status": "ok",
    "access_token": "testToken",
    "mac_secret": "iAreSoSecret123"
}
{% endhighlight %}

The user token is represented by the `access_token` and the token secret (MAC secret) is contained in the
`mac_secret` property. The following configuration generates the MAC signed `Authorization` header:

{% highlight json %}
{
    "parameters": {
        "api": {
            "baseUrl": "https://example.com/",
            "authentication": {
                "type": "oauth20",
                "format": "json",
                "headers": {
                    "Authorization": {
                        "function": "concat",
                        "args": [
                            "MAC id=\"",
                            {
                                "authorization": "data.access_token"
                            },
                            "\", ts=\"",
                            {
                                "authorization": "timestamp"
                            },
                            "\", nonce=\"",
                            {
                                "authorization": "nonce"
                            },
                            "\", mac=\"",
                            {
                                "function": "md5",
                                "args": [
                                    {
                                        "function": "hash_hmac",
                                        "args": [
                                            "sha256",
                                            {
                                                "function": "implode",
                                                "args": [
                                                    "\n",
                                                    [
                                                        {
                                                            "authorization": "timestamp"
                                                        },
                                                        {
                                                            "authorization": "nonce"
                                                        },
                                                        {
                                                            "request": "method"
                                                        },
                                                        {
                                                            "request": "resource"
                                                        },
                                                        {
                                                            "request": "hostname"
                                                        },
                                                        {
                                                            "request": "port"
                                                        },
                                                        "\n"
                                                    ]
                                                ]
                                            },
                                            {
                                                "authorization": "data.mac_secret"
                                            }
                                        ]
                                    }
                                ]
                            }
                        ]
                    }
                }
            }
        },
        "config": {
            "debug": true,
            "outputBucket": "mock-server",
            "jobs": [
                {
                    "endpoint": "users",
                    "dataType": "users"
                }
            ]
        }
    },
    "authorization": {
        "oauth_api": {
            "credentials": {
                "#data": "{\"status\": \"ok\",\"access_token\": \"testToken\", \"mac_secret\": \"iAreSoSecret123\"}",
                "appKey": "clientId",
                "#appSecret": "clientSecret"
            }
        }
    }
}
{% endhighlight %}

The above configuration generates the following header:

    Authorization: MAC id="testToken", ts="1492958193", nonce="605cce2a2f687253", mac="ae96f93def8f02770f30e858e074b2a7

The configuration probably looks rather complicated. Most of it is to generate the `mac` value in the above header.
The first step is the [`implode` function](/extend/generic-extractor/functions/#implode) generating a
[Normalized request string](https://tools.ietf.org/html/draft-ietf-oauth-v2-http-mac-01#section-3.2.1). This is then
passed to the [`hash_hmac` function](/extend/generic-extractor/functions/#hash_hmac) along with the
parameters `sha256` (specifying the hashing algorithm) and the hashing key taken from the `authorization` property
`data.mac_secret`. The last (topmost) step is the [`concat` function](/extend/generic-extractor/functions/#concat); it
concatenates all parts of the `Authorization` header.

See [example [EX104]](https://github.com/keboola/generic-extractor/tree/master/doc/examples/104-oauth2-hmac).


================================================
File: extend/generic-extractor/configuration/api/authentication/oauth_cc.md
================================================
---
title: oAuth 2.0 Client Credentials Authentication
permalink: /extend/generic-extractor/configuration/api/authentication/oauth_cc/
---

oAuth 2.0 Client Credentials authentication performs the [oAuth 2.0 client_credentials flow](https://auth0.com/docs/get-started/authentication-and-authorization-flow/client-credentials-flow).

This method is available through the UI and is implemented via the [Login](/extend/generic-extractor/configuration/api/authentication/login/) method.

{: .image-popup}
![img.png](/extend/generic-extractor/configuration/api/authentication/oauth_cc.png)

### Configuration Parameters

- `Login Request type`
  - `Basic Auth`: The client_id and client_secret are sent in the Authorization header as a Basic authorization, e.g. `Authorization: Basic base64(client_id:client_secret)`.
  - `Post Form`: The client_id and client_secret are sent as form data in the POST request body, e.g., `{login_url}?client_id=client_id&client_secret=client_secret`.
- `Client ID`: The client_id value
- `Client Secret`: The client_secret value
- `Access Token URL`: The URL where the access token is requested, e.g., `https://login-demo.io/oauth/v2/oauth-token`
- `Scope`: The scope of the access token. It is specific per API and can be left empty.

### JSON

In the underlying JSON, the method is implemented as follows:

Place your secret into the `config.#__CLIENT_SECRET` and ID into the `config.#__CLIENT_ID` parameter. The `Authorization` header is then constructed using the `concat` function.

**Basic Auth**

{% highlight json %}
{
    "api": {
      ...,
      "authentication": {
        "type": "login",
        "format": "json",
        "loginRequest": {
          "endpoint": "https://login-demo.io/oauth/v2/oauth-token",
          "method": "FORM",
          "headers": {
            "Accept": "application/json",
            "Authorization": {
              "function": "concat",
              "args": [
                "Basic ",
                {
                  "function": "base64_encode",
                  "args": [
                    {
                      "function": "concat",
                      "args": [
                        {
                          "attr": "__CLIENT_ID"
                        },
                        ":",
                        {
                          "attr": "#__CLIENT_SECRET"
                        }
                      ]
                    }
                  ]
                }
              ]
            }
          },
          "params": {
            "grant_type": "client_credentials",
            "scope": "read"
          }
        },
        "apiRequest": {
          "headers": {
            "Authorization": {
              "function": "concat",
              "args": [
                "Bearer ",
                {
                  "response": "access_token"
                }
              ]
            }
          }
        }
      }
  },
    "config": {
       "__CLIENT_ID": "CLIENT ID"
       "#__CLIENT_SECRET": "secret",
       "jobs": [...]
    }
}
{% endhighlight %}



**Post Form**

{% highlight json %}
{
    "api": {
    ...,
    "authentication": {
      "type": "login",
      "format": "json",
      "loginRequest": {
        "endpoint": "https://login-demo.io/oauth/v2/oauth-token",
        "method": "FORM",
        "headers": {
          "Accept": "application/json"
        },
        "params": {
          "grant_type": "client_credentials",
          "scope": "read",
          "client_id": {
            "attr": "__CLIENT_ID"
          },
          "client_secret": {
            "attr": "#__CLIENT_SECRET"
          }
        }
      },
      "apiRequest": {
        "headers": {
          "Authorization": {
            "function": "concat",
            "args": [
              "Bearer ",
              {
                "response": "access_token"
              }
            ]
          }
        }
      }
    }
  },
    "config": {
       "__CLIENT_ID": "CLIENT ID"
       "#__CLIENT_SECRET": "secret",
       "jobs": [...]
    }
}
{% endhighlight %}



================================================
File: extend/generic-extractor/configuration/api/authentication/query.md
================================================
---
title: Query Authentication
permalink: /extend/generic-extractor/configuration/api/authentication/query/
---

Query Authentication provides the simplest authentication method, in which
the credentials are sent in the [request URL](/extend/generic-extractor/tutorial/rest#url).
This method is most often used with APIs that authenticate using API tokens and
signatures. Dynamic values of query parameters can be generated using 
[user functions](/extend/generic-extractor/functions/). 


## User Interface
In the user interface, you simply select the `Query` method and enter the key-value pairs of the query parameters.

{: .image-popup}
![img.png](/extend/generic-extractor/configuration/api/authentication/query.png)

***Note:** Unless you need multiple parameters, the [API Key authentication method](/extend/generic-extractor/configuration/api/authentication/api_key) may be more suitable.*


## JSON

A sample Query authentication configuration looks like this:

{% highlight json %}
{
    "api": {
        ...,
        "authentication": {
            "type": "query",
            "query": {
                "apikey": "2267709"
            }
        }
    }
}
{% endhighlight %}

## Configuration Parameters
The following configuration parameters are supported for the `query` type of authentication:

- `query` (required, object): An object whose properties represent key-value pairs of the URL query.

## Basic Configuration Example
Let's say you have an API that requires an `api-token` parameter (with value 2267709) to be sent with
each request. The following authentication configuration does exactly that:

{% highlight json %}
"authentication": {
    "type": "query",
    "query": {
        "api-token": "2267709"
    }
}
{% endhighlight %}

For this use case, it is also possible to use the [`defaultOptions` setting](/extend/generic-extractor/configuration/api/#default-parameters).
However, we recommend using the `authentication` setting for credentials so that the Generic Extractor
configuration remains organized.

See [example [EX077]](https://github.com/keboola/generic-extractor/tree/master/doc/examples/077-query-auth).

## Configuration With Encrypted Token Example
Usually, you want the value used for authentication to be encrypted (the `api-token` parameter with the value 2267709 in our example), so you do not expose it to other users or store it in the configuration 
versions history. The following authentication configuration, combined with the parameter defined in the [`config`](https://developers.keboola.com/extend/generic-extractor/configuration/config/) section, does 
that (the value with the prefix `#` is encrypted upon saving the configuration):

{% highlight json %}
{
    "api": {
        ...,
        "authentication": {
            "type": "query",
            "query": {
                "api-token": {
                    "attr": "#token"
                }
            }
        }
    },
    "config": {
        ...,
        "#token": "2267709" 
        }
    }
}
{% endhighlight %}


See [example [EX094]](https://github.com/keboola/generic-extractor/tree/master/doc/examples/094-function-config-headers).


================================================
File: extend/generic-extractor/configuration/api/pagination/cursor.md
================================================
---
title: Cursor Scroller
permalink: /extend/generic-extractor/configuration/api/pagination/cursor/
---

* TOC
{:toc}

The Cursor Scroller can be used with an API which expects the client to maintain a cursor (pointer)
to the last obtained item. For example, on the first request, it returns items with ID 1-100; for the second
request, you must tell the API to start with ID 101. 

{% highlight json %}
{
    "api": {
        "pagination": {
            "method": "cursor",
            "idKey": "id",
            "param": "startWith",
            "increment": 1
        },
        ...
    }
}
{% endhighlight %}

## Configuration Parameters
The following configuration parameters are supported for the `cursor` method of pagination:

- `idKey` (required, string) --- path to the key which contains the value of the cursor; the path is entered relative to the exported items.
- `param` (required, string) --- name of the [query string](/extend/generic-extractor/tutorial/rest/#url) parameter in which the above **cursor value** should be sent to the API.
- `increment` (optional, integer) --- value by which the cursor value will be incremented/decremented; the default value is `0`.
- `reverse` (optional, boolean) --- when `true`, the cursor is reversed; the default value is `false`.

In default mode, Generic Extractor examines the response and finds the **maximum** value in the
property specified in the `idKey`. Then it adds `increment` to the value and sends it to the 
API in a parameter whose name is in the `param` value. If the cursor is set to reverse, 
the **minimum** value of the `idKey` is taken. The `increment` is added to that value, so it should be probably
set to negative when using `reverse=true`.
The request parameter specified in the `param` configuration overwrites the parameter of the same name defined in the
[job parameters](/extend/generic-extractor/configuration/config/jobs/#request-parameters). Other job parameters are carried over without modification 
(see an [example](#reverse-configuration)).

### Stopping Condition
The pagination ends **when the `dataField` of the response contains no items**. Because of this, each 
run with the `cursor` scroller produces a similar warning:
    
    Warning: datafield 'items' contains no data!

This is expected behavior. [Common stopping conditions](/extend/generic-extractor/configuration/api/pagination/#stopping-strategy) also apply.

## Examples
This section contains two API pagination examples where the Cursor Scroller is used.

### Basic Configuration
Let's say you have an API which has an endpoint `/users` returning the following response:

{% highlight json %}
{
    "items": [
        {
            "name": "Jimmy Doe",
            "fields": {
                "id": 345
            }
        },
        {
            "name": "Jenny Doe",
            "fields": {
                "id": 456            
            }
        }
    ]
}
{% endhighlight %}

For the next page of results, the API requires you to send a request to `/users?continueAfter=456`. The following 
configuration handles the case:

{% highlight json %}
"pagination": {
    "method": "cursor",
    "idKey": "fields.id",
    "param": "continueAfter"
}
{% endhighlight %}

Notice that the `idKey` parameter is relative to the extracted array of items (`fields.id` and not `items[].fields.id`).

See [example [EX060]](https://github.com/keboola/generic-extractor/tree/master/doc/examples/060-pagination-cursor-basic).

### Reverse Configuration
Some APIs return items starting with the newest item and therefore need to be queried for offset in 
reverse order. Let's say a request to `/users?startWith=last` will produce:

{% highlight json %}
{
    "items": [
        {
            "id": 345,
            "name": "Jimmy Doe"
        },
        {
            "id": 456,
            "name": "Jenny Doe"
        }
    ]
}
{% endhighlight %}

To retrieve the next set of results, send a request to `GET /users?startWith=344` --- i.e. with the
ID lower than the lowest one already retrieved. The following configuration does exactly that:

{% highlight json %}
{
    "parameters": {
        "api": {
            "baseUrl": "http://example.com/",
            "pagination": {
                "method": "cursor",
                "idKey": "id",
                "param": "startWith",
                "increment": -1,
                "reverse": true
            }
        },
        "config": {
            "debug": true,
            "outputBucket": "mock-server",
            "jobs": [
                {
                    "endpoint": "users",
                    "dataField": "items",
                    "params": {
                        "startWith": "last"
                    }
                }
            ]
        }
    }
}
{% endhighlight %}

The important part is `"reverse": true` which causes Generic Extractor to look for the lowest value of the
property specified in `idKey` (user id). Another important part --- `"increment": -1` causes ID to be lowered 
by 1 between the requests. Also notice that the initial value of the API parameter `startWith` is specified 
in the `jobs.params` configuration and it is overridden by the scroller in the subsequent requests.

See [example [EX061]](https://github.com/keboola/generic-extractor/tree/master/doc/examples/061-pagination-cursor-reverse).


================================================
File: extend/generic-extractor/configuration/api/pagination/index.md
================================================
---
title: Pagination
permalink: /extend/generic-extractor/configuration/api/pagination/
---

* TOC
{:toc}

*If new to Generic Extractor, learn about [pagination in our tutorial](/extend/generic-extractor/tutorial/pagination/) first.*
*Use [Parameter Map](/extend/generic-extractor/map/) to help you navigate among various configuration options.*

[Pagination](https://en.wikipedia.org/wiki/Pagination), or paging, describes **how an API splits a large list of items into
separate pages**. Pagination may also be called scrolling or traversing (scrolling through a large result set). Sometimes
it is also referred to as setting a [cursor](https://en.wikipedia.org/wiki/Cursor_(databases)) (pointing to a current
result).

Almost every API has some form of pagination because returning extensive lists of large results is impractical for many
reasons, such as memory overflow issues and long transfer and processing times. So, unless you only want to do an ad-hoc query to
extract thousands of items at most, setting pagination is important.

When configuring Generic Extractor, there is a slight distinction between pagination and scrolling:

- **Pagination** describes paging of the entire API.
- **Scrolling** (scroller) describes paging of a single resource.

As long as the API uses the same pagination method for all resources, there is no need to distinguish between the
two. Setting up pagination for Generic Extractor boils down to two crucial questions:

- **How to obtain the next set of items?** (paging strategy)
- **How to determine that all items were obtained and scrolling can stop?** (stopping strategy)

An example pagination configuration looks like this:

{% highlight json %}
{
    ...,
    "pagination": {
        "method": "offset",
        "limit": "2"
    }
}
{% endhighlight %}

## Paging Strategy
Generic Extractor supports the following paging strategies (scrollers); they are configured
using the `method` option:

- [`response.url`](/extend/generic-extractor/configuration/api/pagination/response-url/) --- uses a URL provided in the response.
- [`offset`](/extend/generic-extractor/configuration/api/pagination/offset/) --- uses the page size (limit) and **item offset** (like in SQL).
- [`pagenum`](/extend/generic-extractor/configuration/api/pagination/pagenum/) --- uses the page size (limit) and **page number**.
- [`response.param`](/extend/generic-extractor/configuration/api/pagination/response-param/) --- uses a specific value (token) provided in the response.
- [`cursor`](/extend/generic-extractor/configuration/api/pagination/cursor/) --- uses the identifier of the item in response to maintain a scrolling cursor.
- [`multiple`](/extend/generic-extractor/configuration/api/pagination/multiple/) --- allows to set different scrollers for different API endpoints.

### Choosing Paging Strategy
If the API responses contain direct links to the next set of results, use the
[`response.url` method](/extend/generic-extractor/configuration/api/pagination/response-url/).
This applies to the APIs following the [JSON API specification](https://jsonapi.org/). The response usually
contains a `links` section:

{% highlight json %}
{
    "results": [
        ...
    ],
    "links": {
        "next": "http://example.com/posts?page=2"
    }
}
{% endhighlight %}

If the API response contains a parameter used to obtain the next page, use the
[`response.param` method](/extend/generic-extractor/configuration/api/pagination/response-param/).
It is preferred to use an
authoritative value provided by the API than any of the following methods.
This can be some kind of scrolling token or even a page number of the next page, for example:

{% highlight json %}
{
    "results": [
        ...
    ],
    "scrolling": {
        "next_page": 2
    }
}
{% endhighlight %}

If the API does not provide a scrolling hint within the response, use one of the
`offset`, `pagenum` or `cursor` methods:

- Use the [`pagenum` method](/extend/generic-extractor/configuration/api/pagination/pagenum/) if the API expects the **page**
number/index. For example, `/users?page=2` retrieves the 2nd page regardless of how many items the page contains.
- Use the [`offset` method](/extend/generic-extractor/configuration/api/pagination/offset/) if the API expects the **item**
number/index. For example, `/users?startWith=20` retrieves the 20th and following items.
- Use the [`cursor` method](/extend/generic-extractor/configuration/api/pagination/cursor/) if the API expects an item **identifier**.
For example, `/users?startWith=20` retrieves an item with ID 20 and the following items.

If the API uses different paging methods for different endpoints, use the
[`multiple` method](/extend/generic-extractor/configuration/api/pagination/multiple/) together with
any of the above methods.

## Stopping Strategy
Generic Extractor stops scrolling

- based on the `nextPageFlag` condition configuration.
- based on the `forceStop` condition configuration.
- based on the `limitStop` condition configuration.
- when the **same result** is obtained twice.

Apart from those, each pagination method may have its own
[stopping strategy](#combining-multiple-stopping-strategies).

The **same result** condition deals with the situation when there is no clear limit to
stop the scrolling. Generic Extractor keeps requesting higher and higher pages from the API.
Let's say that there are 150 pages of results in total. When Generic Extractor asks for page 151, various
situations can arise:

- Most common --- API returns an **empty page**; scrolling with
[`pagenum`](/extend/generic-extractor/configuration/api/pagination/pagenum/) and
[`offset` methods](/extend/generic-extractor/configuration/api/pagination/pagenum/) will stop, and other methods will probably stop
too (depends on how empty the response is).
- Less common --- API returns an **error** --- in this case a different stopping condition such as [`nextFlag`](#next-page-flag) or
[`forceStop`](#force-stop) has to be used.
- Less common --- API keeps returning the **last page**, the extraction is stopped when a page is obtained twice (see
[example [041]](https://github.com/keboola/generic-extractor/tree/master/doc/examples/041-paging-stop-same)). If the API returns
the last page and it is the same as the previous page, the extraction is stopped. You will see this in the Generic Extractor logs as
the following message:

		Job '1234567890' finished when last response matched the previous!

- Even less common --- API keeps returning the **first page**, the extraction is stopped when a page is obtained twice (see
[example [EX042]](https://github.com/keboola/generic-extractor/tree/master/doc/examples/042-paging-stop-same-2)). If the API returns
the first page, it is not same as the previous page and therefore another request is sent to `users?offset=6&limit=2`. Then the result
is the same as the previous page, the same check kicks in and the extraction is stopped too. However, the results from the first
page will be duplicated.

### Next Page Flag
The above describes automatic behavior of Generic Extractor regarding scrolling stopping.
Using **Next Page Flag** allows you to do a **manual setup of the stopping strategy**: Generic Extractor analyzes the response,
looks for a particular field (the flag) and decides whether to continue scrolling based on the value or presence of that flag.

Next Page Flag is configured using three options:

- **`field`** (required) --- name of a field containing any value. The field must be in the root of the response.
    It will be converted to [boolean](/extend/generic-extractor/tutorial/json/#data-values).
- **`stopOn`** (required) --- value to which the field will be compared to. When the values are equal, the scrolling stops.
- **`ifNotSet`** --- assumed value of the `field` in case it is not present in the response. It defaults to the `stopOn` value.

The boolean conversion has the following rules:

- `false`, `0`, `null`, string `"0"`, empty array `[]` is **`false`**.
- Everything else is **`true`**.

Example `nextPageFlag` setting:

{% highlight json %}
"pagination": {
    "nextPageFlag": {
        "field": "moreItems",
        "stopOn": false,
        "ifNotSet": true
    },
    ...
}
{% endhighlight %}

See our [Next Page Flag Examples](#next-page-flag-examples).

### Force Stop
Force stop configuration allows you to stop scrolling when some extraction limits are hit.
The supported options are:

- `pages` --- maximum number of pages to extract
- `time` --- maximum number of seconds the extraction should run
- `volume` --- maximum number of bytes which can be extracted

This is an example or the `forceStop` setting:

{% highlight json %}
"pagination": {
    "forceStop": {
        "pages": 20,
        "time": 3600
    },
    ...
}
{% endhighlight %}

The volume of the response is measured as number of bytes in compressed JSON. Therefore the response

{% highlight json %}
{
    "items": [
        {
            "id": 123,
            "name": "John Doe"
        },
        {
            "id": 234,
            "name": "Jane Doe"
        }
    ]
}
{% endhighlight %}

is compressed (minified) to:

{% highlight json %}
    {"items":[{"id":123,"name":"John Doe"},{"id":234,"name":"Jane Doe"}]}
{% endhighlight %}

which makes it 69 bytes long.


The following is a **force stop example** configuration that will stop scrolling after extracting two pages of results, or
after extracting 69 bytes of minified JSON data (whichever comes first).

{% highlight json %}
"pagination": {
    "forceStop": {
        "pages": 2,
        "volume": 69
    },
    "method": "offset",
    "limit": "2"
}
{% endhighlight %}

See [example [EX048]](https://github.com/keboola/generic-extractor/tree/master/doc/examples/048-force-stop)
and [example [EX116]](https://github.com/keboola/generic-extractor/tree/master/doc/examples/116-multiple-conditions-multiple-jobs)
(combining multiple conditions)
and [example [EX140]](https://github.com/keboola/generic-extractor/tree/master/doc/examples/140-pagination-forcestop-child-filter)
(combining with child jobs).

### Limit Stop
Limit stop configuration allows you to stop scrolling when a specified number of items is extracted.
The supported options are:

- `count` (required, integer) --- total number of items to extract
- `field` (required, string) --- path to the key which contains the value with total number of items

The two options are **mutually exclusive**, but one of them is required. In both cases, the total number of items may not be
honored exactly. If the total amount is not divisible by the page size, then the leftover from the last page (if any)
is extracted too (see example [EX127](https://github.com/keboola/generic-extractor/tree/master/doc/examples/127-pagination-stop-field) and [EX138](https://github.com/keboola/generic-extractor/tree/master/doc/examples/138-pagination-stop-field-child-filter) (combining with child jobs)).
This is an example or the `limitStop` setting:

{% highlight json %}
"pagination": {
    "limitStop": {
        "field": "items.count"
    },
    ...
}
{% endhighlight %}

The above configuration will search the response for the key `count` inside the key `items`. The obtained value is
expected to be the total number of items to extract. In the sample response below, it will be `4`:

{% highlight json %}
{
    "items": [
        {
            "id": 123,
            "name": "John Doe"
        },
        {
            "id": 234,
            "name": "Jane Doe"
        }
    ],
    "scroller": {
        "count": 4,
        "offset": 0
    }
}
{% endhighlight %}

Note that if the field does not exist in the response (e.g., you misspell it in the configuration), paging stops after the first page.
See [example [EX126]](https://github.com/keboola/generic-extractor/tree/master/doc/examples/126-pagination-stop-limit)
(a modified version of [EX049](https://github.com/keboola/generic-extractor/tree/master/doc/examples/049-pagination-offset-rename).
For `count` configuration, see [example [EX127]](https://github.com/keboola/generic-extractor/tree/master/doc/examples/127-pagination-stop-field)
(a modified version of [EX051](https://github.com/keboola/generic-extractor/tree/master/doc/examples/051-pagination-pagenum-basic).

### Combining Multiple Stopping Strategies
All stopping strategies are evaluated simultaneously and for the scrolling to continue, none of
the stopping conditions must be met. In other words, the scrolling continues until any of the
stopping conditions is true. To this you need to account specific stopping strategies for
each scroller. For example, the scrolling of this configuration:

{% highlight json %}
"pagination": {
    "nextPageFlag": {
        "field": "isLast",
        "stopOn": true
    },
    "forceStop": {
        "pages": 20
    },
    "method": "offset",
    "limit": "10"
}
{% endhighlight %}

will stop if **any** of the following is true:

- An empty page is encountered (`offset` scroller specific).
- A page contains less then 10 items (`offset` scroller specific).
- A page contains the same items as the previous page.
- 20 pages were extracted (`forceStop`).
- The `isLast` field is present in the response and is true (`nextPageFlag`).
- The `isLast` field is not present in the response.

## Next Page Flag Examples
In this section, we want to show you the following examples of the Next Page Flag stopping strategy:

- Has-More Scrolling
- Non-Boolean Has-More Scrolling
- Is-Last Scrolling

### Has-More Scrolling
Assume that the API returns a response which contains a `hasMore` field. The field is present in
every response and has always the value `true` except for the last response where it is `false`.
The following pagination configuration can be used to configure the stopping strategy:

{% highlight json %}
"pagination": {
    "nextPageFlag": {
        "field": "hasMore",
        "stopOn": false,
        "ifNotSet": false
    },
    ...
}
{% endhighlight %}

It means that the scrolling will **continue** till the field `hasMore` is present in the response and true.
In this case, setting `ifNotSet` is not necessary.

See [example [EX045]](https://github.com/keboola/generic-extractor/tree/master/doc/examples/045-next-page-flag-has-more)
and [example [EX139]](https://github.com/keboola/generic-extractor/tree/master/doc/examples/139-pagination-hasmore-child-filter)] (combining with child jobs).

### Non-Boolean Has-More Scrolling
Assume that the API returns a response which contains a `hasMore` field. The field is present only in the
last response and has the value `"no"` there.
The following pagination configuration can be used to configure the stopping strategy:

The configuration:

{% highlight json %}
"pagination": {
    "nextPageFlag": {
        "field": "hasMore",
        "stopOn": true,
        "ifNotSet": false
    },
    ...
}
{% endhighlight %}

means that the scrolling will **continue** until the field `hasMore` is present. This takes advantage of the
boolean conversion which converts the value `"no"` to true. If the field `hasMore` is not present, it defaults
to false. In this case setting `ifNotSet` is mandatory.

See [example [EX046]](https://github.com/keboola/generic-extractor/tree/master/doc/examples/046-next-page-flag-has-more-2).

### Is-Last Scrolling
Assume that the API returns a response which contains an `isLast` field. The field is present only in the
last response and has the value `true` there.
The following pagination configuration can be used to configure the stopping strategy:

{% highlight json %}
"pagination": {
    "nextPageFlag": {
        "field": "isLast",
        "stopOn": true,
        "ifNotSet": false
    },
    ...
}
{% endhighlight %}

The scrolling will **stop** when the field `isLast` is present in the response and true.
Because the field `isLast` is not present at all times, the `ifNotSet` configuration is required.

See [example [EX047]](https://github.com/keboola/generic-extractor/tree/master/doc/examples/047-next-page-flag-is-last).



================================================
File: extend/generic-extractor/configuration/api/pagination/multiple.md
================================================
---
title: Multiple Scrollers
permalink: /extend/generic-extractor/configuration/api/pagination/multiple/
---

* TOC
{:toc}

Setting the pagination method to `multiple` allows you to use **multiple scrollers on a single API**.
This type of pagination contains the definition of all scrollers used in the entire configuration.
Each [job](/extend/generic-extractor/configuration/config/jobs/) is then assigned a 
[`scroller`](/extend/generic-extractor/configuration/config/jobs/#scroller) in its configuration.

This is useful mainly if the API has inconsistent pagination methods among various API calls. 
It may be also useful in case you need to vary parameters --- for instance, set different page sizes for
different endpoints.

{% highlight json %}
{
    "api": {
        "pagination": {
            "method": "multiple",
            "scrollers": {
                "resource_scroller": {
                    "method": "offset",
                    "limit": 100
                },
                "search_scroller": {
                    "method": "pagenum"
                }
            }
        },
        ...
    },
    ...
}
{% endhighlight %}

## Configuration
The following configuration parameters are supported for the `multiple` method of pagination:

- `scrollers` (required, object) --- object with configuration of the scrollers (see below)
- `default` (optional, string) --- name of a scroller used for all jobs without a specified scroller; if not 
specified, then the jobs with no assigned scroller will not use any type of pagination.

The `scrollers` configuration is an object whose keys are arbitrary scroller names. The values of the 
keys are standard scroller configurations. Any of the supported 
[paging strategies](/extend/generic-extractor/configuration/api/pagination/#paging-strategy) can be used, and 
multiple paging strategies can be mixed. The configurations are the same as if there was a single scroller.
The name of the scroller must be used in a specific [job `scroller` parameter](/extend/generic-extractor/configuration/config/jobs/#scroller).

A `default` scroller can be set (must be one of the names defined in `scrollers`). In that case, all jobs
without an assigned scroller will use the default one.

### Stopping Condition
There are no specific stopping conditions for the `multiple` pagination. Each scroller acts upon its 
normal stopping conditions.

## Examples
Assume you have an API with several endpoints (`/users`, `/orders`, `/search`, etc.). Most endpoints
use the offset pagination strategy (meaning that the results are split into pages of the same size, and 
the next page is obtained by setting offset to a multiple of the page size). The `/search` endpoint uses the 
page number pagination strategy because the retrieved pages are not of equal size. The following 
configuration extracts from two endpoints with different paging strategies.

{% highlight json %}
{
    "parameters": {
        "api": {
            "baseUrl": "http://example.com/",
            "pagination": {
                "method": "multiple",
                "scrollers": {
                    "list_scroller": {
                        "method": "offset",
                        "limit": "2"
                    },
                    "search_scroller": {
                        "method": "pagenum"
                    }
                },
                "default": "list_scroller"
            }
        },
        "config": {
            "debug": true,
            "outputBucket": "mock-server",
            "jobs": [
                {
                    "endpoint": "users"
                },
                {
                    "endpoint": "search",
                    "scroller": "search_scroller"
                }
            ]
        }
    }
}
{% endhighlight %}

The `api.pagination.scrollers` defines both pagination methods: 

{% highlight json %}
"scrollers": {
    "list_scroller": {
        "method": "offset",
        "limit": "2"
    },
    "search_scroller": {
        "method": "pagenum"
    }
}
{% endhighlight %}

It is then important to actually use the scroller in the `job.scroller` configuration for the endpoint `/search`. 
The endpoint `/users` has no assigned scroller, therefore it uses the default one, which is `list_scroller`.

See [example [EX062]](https://github.com/keboola/generic-extractor/tree/master/doc/examples/062-pagination-multiple-scrollers).

================================================
File: extend/generic-extractor/configuration/api/pagination/offset.md
================================================
---
title: Offset Scroller
permalink: /extend/generic-extractor/configuration/api/pagination/offset/
---

* TOC
{:toc}

The Offset scroller handles a pagination strategy in which the API splits the results into pages
of the same size (limit parameter) and navigates through them using the **item offset** parameter. This 
is similar to paging in SQL language. If you need to use the page offset, use the 
[Page Number Scroller](/extend/generic-extractor/configuration/api/pagination/pagenum/).

An example configuration:

{% highlight json %}
{
    "api": {
        "pagination": {
            "method": "offset",
            "limit": 100,
            "limitParam": "count",
            ...
        },
        ...
    }
}
{% endhighlight %}

## Configuration Parameters
The following configuration parameters are supported for the `offset` method of pagination:

- `limit` (required, integer) --- page size
- `limitParam` (optional, string) --- name of the parameter in which the API expects the page size; the default value is `limit`.
- `offsetParam` (optional, string) --- name of the parameter in which the API expects the item offset; the default value is `offset`.
- `firstPageParams` (optional, boolean) --- when false, the first page is retrieved without the page parameters; the default value is `true`.
- `offsetFromJob` (optional, boolean) --- when true, the offset parameter value is taken from the job parameters; the default value is `false`.

The limit value is configured by the `limit` parameter, but it may be overridden in 
the [job parameters](/extend/generic-extractor/configuration/config/jobs/#request-parameters). The offset value is computed automatically starting from 0, but it may be overridden in the job parameters if `offsetFromJob` is set to `true`.

**Important:** Do not set the limit parameter above the limit supported by the API. To give an example, if the API returned 
100 items at most and you set the limit 1000, it would cause the extraction to stop after the first page. This is because the 
[underflow condition](/extend/generic-extractor/configuration/api/pagination/#stopping-strategy) would be triggered.

### Stopping Condition
Scrolling is stopped **when the result contains less items than requested**	 --- specified in the
`limit` configuration (underflow). This also includes an instance when no items are returned, or the 
response is empty.

Let's say that you have an API endpoint `users` which takes the parameters `limit` and `offset`. 
There are four users in total. The response looks as follows:

{% highlight json %}
[
    {
        "id": 345,
        "name": "Jimmy Doe"
    },
    {
        "id": 456,
        "name": "Jenny Doe"
    }
]
{% endhighlight %}

Querying `users?offset=0&limit=2` returns the first two users. Querying `users?offset=2limit` returns
the second two users. Generic Extractor will then query `users?offset=4&limit=2`. 

If the response is empty (the API returns an empty page, `[])`, the **underflow** check kicks in 
and the extraction is stopped. See [example [043]](https://github.com/keboola/generic-extractor/tree/master/doc/examples/043-paging-stop-underflow).

Note that the **emptiness** is evaluated on the extracted array as [auto-detected](/extend/generic-extractor/configuration/config/jobs/#data-field) or 
specified by the [`dataField`](/extend/generic-extractor/configuration/config/jobs/#data-field) configuration. 
That means that the entire response
may be non-empty. See [example [044]](https://github.com/keboola/generic-extractor/tree/master/doc/examples/044-paging-stop-underflow-struct).

You will also see the following warning in the logs:

    WARNING: dataField `results.users.items` contains no data!

which is expected.

All [common stopping conditions](/extend/generic-extractor/configuration/api/pagination/#stopping-strategy) apply as well.

## Examples
This section contains three examples of API pagination using the Offset Scroller.

### Basic Scrolling
This is the simplest scrolling setup:

{% highlight json %}
"pagination": {
    "method": "offset",
    "limit": "20"
}
{% endhighlight %}

The first request is sent with the parameters `limit=20` and `offset=0`, for example, `/users?limit=20&offset=0`.
The next request has `limit=20` and `offset=20`, for example, `/users?limit=20&offset=20`.
See [example [EX043]](https://github.com/keboola/generic-extractor/tree/master/doc/examples/043-paging-stop-underflow) and
[example [EX044] with a more structured response](https://github.com/keboola/generic-extractor/tree/master/doc/examples/044-paging-stop-underflow-struct).

### Renaming Parameters
The `limitParam` and `offsetParam` configuration options allow you to rename the limit and 
offset for the needs of a specific API:

{% highlight json %}
"pagination": {
    "method": "offset",
    "limitParam": "count",
    "offsetParam": "skip",
    "limit": "100"
}
{% endhighlight %}

Here the API expects the parameters `count` and `skip`. The first request will be sent with the parameters `count=100` 
and `skip=0`, for example, `/users?count=2&skip=0`. 

See [example [EX049]](https://github.com/keboola/generic-extractor/tree/master/doc/examples/049-pagination-offset-rename).

### Overriding Limit and Offset
It is possible to override both the limit and offset parameters of a specific API job. 
This is useful in case you want to use different limits for different API endpoints.

In the configuration below, the first API request to the `users` endpoint will be
`GET /users?count=2&skip=2`. This is because the values `count=2` and `skip=2` are taken from the 
job `params`. 

Notice that the job `params` names must correspond to the names of the offset and limit parameters 
(`skip` and `count` in this case). The limit parameter is always overridden to 5, no setting is necessary. 
The offset parameter is overridden to 2; this requires setting `offsetFromJob`. 
Without it being set, the `jobs.params.skip` value would be ignored. 

{% highlight json %}
{
    "parameters": {
        "api": {
            "baseUrl": "http://example.com/",
            "pagination": {
                "method": "offset",
                "limitParam": "count",
                "offsetParam": "skip",
                "offsetFromJob": true,
                "limit": "20"
            }
        },
        "config": {
            "jobs": [
                {
                    "endpoint": "users",
                    "dataField": "items",
                    "params": {
                        "count": 2,
                        "skip": 2
                    }
                },
                {
                    "endpoint": "orders",
                    "dataField": "items",
                    "params": {
                        "count": 10
                    }
                }
            ]            
        }
    }
}
{% endhighlight %}

The entire endpoint configuration means that the first two items of the `users` endpoint will be skipped.
For the `orders` endpoint, the `skip` (offset) parameter is not overridden, and therefore it starts at zero.
The `count` (limit) parameter is set to 10. Therefore the first request to that endpoint will be
`GET /orders?count=10&skip=0`. 

See [example [EX050]](https://github.com/keboola/generic-extractor/tree/master/doc/examples/050-pagination-offset-override).


================================================
File: extend/generic-extractor/configuration/api/pagination/pagenum.md
================================================
---
title: Page Number Scroller
permalink: /extend/generic-extractor/configuration/api/pagination/pagenum/
---

* TOC
{:toc}

The Page Number Scroller handles a pagination strategy in which the API splits the results into pages
of the same size (limit parameter) and navigates through them using the **page offset** parameter. 
If you need to use the item offset, use the [Offset Scroller](/extend/generic-extractor/configuration/api/pagination/offset/).

{% highlight json %}
{
    "api": {
        "pagination": {
            "method": "pagenum",
            "limit": 100,
            "limitParam": "count",
            ...
        },
        ...
    }
}
{% endhighlight %}

## Configuration Parameters
The following configuration parameters are supported for the `pagenum` method of pagination:

- `limit` (optional, integer) --- page size
- `limitParam`(optional, string) --- name of the parameter in which the API expects the page size; the default value is `limit`.
- `pageParam` (optional, string) --- name of the parameter in which the API expects the page number; the default value is `page`.
- `firstPageParams` (optional, boolean) --- when `false`, the first page will be retrieved without the page parameters; the default 
value is `true`.
- `firstPage` (optional, integer) --- index of the first page; the default value is `1`.

### Stopping Condition
The `pagenum` scroller uses similar stopping condition as the [`offset` scroller](/extend/generic-extractor/configuration/api/pagination/offset/#stopping-condition). 
Scrolling is stopped in case of an underflow --- when the result contains **less items than requested** (including zero). However, 
in the `pagenum` scroller, the **`limit` parameter is not required** and has **no default value**. This means that if you omit it, 
the scrolling will stop only if an empty page is encountered.

## Examples
This section contains three API pagination examples where the Page Number Scroller is used.

### Basic Scrolling
The most simple scrolling setup is the following:

{% highlight json %}
"pagination": {
    "method": "pagenum"
}
{% endhighlight %}

The first request is sent with the parameter `page=1`, for example `/users?page=1`.
The next request will have `page=2`, for example `/users?page=2`.

See [example [EX051]](https://github.com/keboola/generic-extractor/tree/master/doc/examples/051-pagination-pagenum-basic).

### Renaming Parameters
The `limitParam` and `pageParam` configuration options allow you to rename the limit and 
offset for the needs of a specific API:

{% highlight json %}
"pagination": {
    "method": "pagenum",
    "limit": 20,
    "limitParam": "count",
    "pageParam": "set"
}
{% endhighlight %}

Here the API expects the parameters `count` and `set`. The first request will be sent with the parameters `count=20` 
and `set=1`; for example, `/users?set=1&count=20`. 

**Important:** Without setting a value for the `limit` option, the `limitParam` will not be sent at all 
(no matter how you name it).

See [example [EX052]](https://github.com/keboola/generic-extractor/tree/master/doc/examples/052-pagination-pagenum-rename).

### Overriding Parameters
It is possible to override the limit parameter of a specific API job. 
This is useful when you want to use different limits for different API endpoints.

In the following configuration, the first request is sent to `/users?count=2` because the 
`limit` parameter was renamed to `count`. Then the default value of `count` was overridden for the 
`users` API endpoint in `jobs.params.count`. 

The `firstPageParams` is set to false, which means that
the page parameter (named `count`) is **not** sent in the first request. The second API 
request is sent to `/users?count=2&set=1`. Because the `firstPage` option is set to `0`, the 
second page index is `1`.

{% highlight json %}
{
    "parameters": {
        "api": {
            "baseUrl": "http://example.com/",
            "pagination": {
                "method": "pagenum",
                "limit": 200,
                "limitParam": "count",
                "pageParam": "set",
                "firstPage": 0,
                "firstPageParams": false
            }
        },
        "config": {
            "jobs": [
                {
                    "endpoint": "users",
                    "dataField": "items",
                    "params": {
                        "count": 2
                    }
                }
            ]
        }
    }
}
{% endhighlight %}

See [example [EX053]](https://github.com/keboola/generic-extractor/tree/master/doc/examples/053-pagination-pagenum-override).


================================================
File: extend/generic-extractor/configuration/api/pagination/response-param.md
================================================
---
title: Response Parameter Scroller
permalink: /extend/generic-extractor/configuration/api/pagination/response-param/
---

* TOC
{:toc}

The Response Parameter Scroller can be used with APIs that provide a certain kind
of value in the response which must be used in the next request.

{% highlight json %}
{
    "api": {
        "pagination": {
            "method": "response.param",
            "responseParam": "links.next",
            "queryParam": "page"
        },
        ...
    },
    ...
}
{% endhighlight %}

## Configuration Parameters
The following configuration parameters are supported for the `response.param` method of pagination:

- `responseParam` (required, string) --- path to the key which contains the value used for scrolling
- `queryParam` (required, string) --- name of the [query string](/extend/generic-extractor/tutorial/rest/#url) parameter in which
the above value should be sent to the API; the `queryParam` **overrides** the values from the [job
parameters](/extend/generic-extractor/configuration/config/jobs/#request-parameters)
(see an [example](#overriding-parameters)).
- `includeParams` (optional, boolean) --- when `true`, the job parameters
**are added** to the provided URL. The default value is `false`.
- `scrollRequest` (optional, object) --- [job-like](/extend/generic-extractor/configuration/config/jobs/) object (supported fields are
`endpoint`, `method` and `params`) which allows to sent an initial scrolling request (see an [example](#using-scroll-request)).

### Stopping Condition
The pagination ends **when the value of `responseParam` parameters is empty** --- the key is not present at all, is null, is
an empty string, or is `false`. Take care when configuring the `responseParam` parameter. If you, for example, misspell the name of
the key, the extraction will not go beyond the first page.
[Common stopping conditions](/extend/generic-extractor/configuration/api/pagination/#stopping-strategy) also apply.

## Examples
The following API pagination examples demonstrate the use of the Response Parameter Scroller.

### Basic Configuration
Assume you have an API which returns, for instance, the next page number inside the response:

{% highlight json %}
{
    "items": [
        {
            "id": 123,
            "name": "John Doe"
        },
        {
            "id": 234,
            "name": "Jane Doe"
        }
    ],
    "scrolling": {
        "next_page": 2
    }
}
{% endhighlight %}

The following configuration can handle such situation:

{% highlight json %}
{
    "parameters": {
        "api": {
            "baseUrl": "http://example.com/",
            "pagination": {
                "method": "response.param",
                "responseParam": "scrolling.next_page",
                "queryParam": "page"
            }
        },
        "config": {
            "outputBucket": "mock-server",
            "jobs": [
                {
                    "endpoint": "users",
                    "dataField": "items"
                }
            ]
        }
    }
}
{% endhighlight %}

The first request is sent to `/users`. For the second request, the value found in the response
in the property `scrolling.next_page` is sent as the `page` parameter. Therefore the request
is sent to `/users?page=2`.

See [example [EX057]](https://github.com/keboola/generic-extractor/tree/master/doc/examples/057-pagination-response-param-basic).

### Overriding Parameters
The following configuration passes the parameter `orderBy` to every request:

{% highlight json %}
{
    "parameters": {
        "api": {
            "baseUrl": "http://example.com/",
            "pagination": {
                "method": "response.param",
                "responseParam": "scrolling.next_page",
                "includeParams": true,
                "queryParam": "page"
            }
        },
        "config": {
            "debug": true,
            "outputBucket": "mock-server",
            "jobs": [
                {
                    "endpoint": "users",
                    "dataField": "items",
                    "params": {
                        "page": "start",
                        "orderBy": "id"
                    }
                }
            ]
        }
    }
}
{% endhighlight %}

The `includeParams` configuration set to `true` causes the parameters from the `job.params` settings to
be sent with every request. If you set `includeParams` to false, they will be sent only with
the first request.

Also notice that the `page` parameter from `job.params` is overridden by the `page` parameter specified
in the `pagination.queryParam`. Therefore the first request is sent to `/users?page=start&orderBy=id`
and the second request to `/users?page=2&orderBy=id`.

See [example [EX058]](https://github.com/keboola/generic-extractor/tree/master/doc/examples/058-pagination-response-param-override).

### Using Scroll Request
The response param scroller supports sending of an initial scrolling request. This can be used
in situations where the API requires special initialization of a scrolling endpoint;
for instance, the [Elastic](https://www.elastic.co/guide/en/elasticsearch/reference/5.2/search-request-scroll.html).
Another example is an API which has something like a search endpoint which needs an initial request and
then allows you to scroll through the results (this is not exactly [RESTful](/extend/generic-extractor/tutorial/rest/) though).

Let's consider an API which --- to list users --- requires that you send a POST request to the
`/search` endpoint with the configuration:

{% highlight json %}
{
    "object": "users",
    "orderBy": "id"
}
{% endhighlight %}

It will then respond with a **search token** representing an internal cursor:

{% highlight json %}
{
    "scroll": {
        "token": "b97d814f1a715d939f3f96bc574445de",
        "totalCount": 4
    }
}
{% endhighlight %}

To obtain the actual result, send a request to the `/results` endpoint with the parameter
`scrollToken=b97d814f1a715d939f3f96bc574445de`. The response looks like this:

{% highlight json %}
{
    "items": [
        {
            "id": 123,
            "name": "John Doe"
        },
        {
            "id": 234,
            "name": "Jane Doe"
        }
    ],
    "scroll": {
        "token": "4015e9ce43edfb0668ddaa973ebc7e87"
    }
}
{% endhighlight %}

The following configuration is able to handle the situation:

{% highlight json %}
{
    "parameters": {
        "api": {
            "baseUrl": "http://example.com/",
            "pagination": {
                "method": "response.param",
                "responseParam": "scroll.token",
                "queryParam": "scrollToken",
                "scrollRequest": {
                    "endpoint": "results",
                    "method": "GET"
                }
            }
        },
        "config": {
            "debug": true,
            "outputBucket": "mock-server",
            "jobs": [
                {
                    "endpoint": "search",
                    "method": "POST",
                    "dataField": "items",
                    "dataType": "users",
                    "params": {
                        "object": "users",
                        "orderBy": "id"
                    }
                }
            ]
        }
    }
}
{% endhighlight %}

The configuration is actually turned upside-down. The `jobs` section defines the initial search request
(`POST` to `/search` with the required parameters `object` and `orderBy`). The first request sent to the API
is therefore:

    POST /search

    {"object":"users","orderBy":"id"}

When the response contains a `scroll.token` field, the scroller starts to act and overrides the above
configuration with the one provided in the `scrollRequest` configuration. The next request is therefore
a `GET` to `/results?scrollToken=b97d814f1a715d939f3f96bc574445de`. The `queryParam` configuration
causes the `scrollToken` request parameter to be added. This will repeat until the `scroll.token` field in
the response is empty.

See [example [EX059]](https://github.com/keboola/generic-extractor/tree/master/doc/examples/059-pagination-response-param-scroll-request).


================================================
File: extend/generic-extractor/configuration/api/pagination/response-url.md
================================================
---
title: Response URL Scroller
permalink: /extend/generic-extractor/configuration/api/pagination/response-url/
---

* TOC
{:toc}

The Response URL Scroller can be used with APIs that provide the URL of the 
next page in the response. This scroller is suitable for APIs supporting the 
[JSON API specification](https://jsonapi.org/format/#fetching-pagination).

{% highlight json %}
{
    "api": {
        "pagination": {
            "method": "response.url",
            "urlKey": "links.next"
        },
        ...
    }
}
{% endhighlight %}

## Configuration Parameters
The following configuration parameters are supported for the `response.url` pagination method:

- `urlKey` (optional, string) --- path in the response to the field which contains the URL of the next request; 
the default value is `next_page`.
- `delimiter` (optional, string) --- char used as the delimiter of the nested keys in the `urlKey`; 
the default value is `.`.
- `paramIsQuery` (optional, boolean) 
	- if `true` --- URL is assumed to be only [query string](/extend/generic-extractor/tutorial/rest/#url) parameters; 
	the parameters in the response **override** the [parameters in the job](/extend/generic-extractor/configuration/config/jobs/#request-parameters). 
	- if `false` --- URL with a path is assumed. `false` is the default value; the parameters in the response 
	**are overridden** by the parameters in the job. 
- `includeParams` (optional, boolean) 
	- if `true` --- job parameters **are added** to the parameters of the URL provided in the response; the default value is `false`. 

See the [examples below](#examples).

### Stopping Condition
The pagination ends **when the value of the `urlKey` parameter is empty** --- the key is not present at all, is null,
is an empty string or is `false`. Be careful when configuring the `urlKey` parameter. If you, for example, misspell the
key name, the extraction will not go beyond the first page. 
[Common stopping conditions](/extend/generic-extractor/configuration/api/pagination/#stopping-strategy) also apply.

## Examples
This section provides three API pagination examples where the Response URL Scroller is used.

### Basic Configuration
To configure pagination for an API that supports the [JSON API specification](https://jsonapi.org/format/#fetching-pagination),
use the configuration below:

{% highlight json %}
"pagination": {
    "method": "response.url",
    "urlKey": "links.next"
}
{% endhighlight %}

The configuration expects a response to contain a `links.next` field with the URL of the next page, e.g.:

{% highlight json %}
{
    "items": [
        {
            "id": 123,
            "name": "John Doe"
        },
        {
            "id": 234,
            "name": "Jane Doe"
        }
    ],
    "links": {
        "next": "/users?page=2"
    }
}
{% endhighlight %}

The URL may be either an *absolute link* (`http://example.com/users?page=2`) or an *absolute path* (`/users?page=2`). 
If the URL is *relative* (`users?page=2`), it is appended to the endpoint URL.

See [example [EX054]](https://github.com/keboola/generic-extractor/tree/master/doc/examples/054-pagination-response-url-basic).

### Merging Parameters
To pass additional parameters to each of the page URLs, use the `includeParams` parameter:

{% highlight json %}
{
    "parameters": {
        "api": {
            "baseUrl": "http://example.com/",
            "pagination": {
                "method": "response.url",
                "urlKey": "links.next",
                "includeParams": true
            }
        },
        "config": {
            "debug": true,
            "outputBucket": "mock-server",
            "jobs": [
                {
                    "endpoint": "users",
                    "dataField": "items",
                    "params": {
                        "account": 123
                    }
                }
            ]
        }
    }
}
{% endhighlight %}

A sample response:

{% highlight json %}
{
    "items": [
        {
            "id": 123,
            "name": "John Doe"
        },
        {
            "id": 234,
            "name": "Jane Doe"
        }
    ],
    "links": {
        "next": "/users?page=2"
    }
}
{% endhighlight %}

In the above configuration, the `account` parameter is sent with every API request. If it were not for the
`includeParams` option, it would be sent **only with the first request**. Note that adding 
a `jobs.params.page` parameter would overwrite the `page` parameter in the response URL and thus 
would probably break the paging.

See [example [EX055]](https://github.com/keboola/generic-extractor/tree/master/doc/examples/055-pagination-response-url-params).

### Overriding Parameters
Sometimes the API does not pass the entire URL, but only the [query string](/extend/generic-extractor/tutorial/rest/#url)
parameters which should be used for querying the next page.

{% highlight json %}
{
    "items": [
        {
            "id": 123,
            "name": "John Doe"
        },
        {
            "id": 234,
            "name": "Jane Doe"
        }
    ],
    "links": {
        "next": "?page=2"
    }
 }
{% endhighlight %}

Then use the `paramsIsQuery` configuration so that your Generic Extractor can produce a 
valid URL:

{% highlight json %}
{
    "parameters": {
        "api": {
            "baseUrl": "http://mock-server:80/056-pagination-response-url-params-override/",
            "pagination": {
                "method": "response.url",
                "urlKey": "links.next",
                "paramIsQuery": true,
                "includeParams": true
            }
        },
        "config": {
            "debug": true,
            "outputBucket": "mock-server",
            "jobs": [
                {
                    "endpoint": "users",
                    "dataField": "items",
                    "params": {
                        "account": 123,
                        "page": "start"
                    }
                }
            ]
        }
    }
}
{% endhighlight %}

Also notice that with the above 
configuration the `page` parameter specified in the job is used only for the first page because it 
is overridden by the `page` parameter given in the response. That is to say that the first request is sent to
`/users?account=123&page=start` and the second request is sent to `/users?account=123&page=2`.

See [example [EX056]](https://github.com/keboola/generic-extractor/tree/master/doc/examples/056-pagination-response-url-params-override).


================================================
File: extend/generic-extractor/configuration/aws-signature/index.md
================================================
---
title: AWS Signature
permalink: /extend/generic-extractor/configuration/aws-signature/
---

* TOC
{:toc}

Generic extractor allows signaturing requests by [**AWS**](https://docs.aws.amazon.com/general/latest/gr/signature-version-4.html).
Signature is the process to add authentication information to your requests. When you use AWS tools, extractor sign your API request.

A sample AWS signature configuration looks like this:

{% highlight json %}
{
  ...,
  "aws": {
    "signature": {
      "credentials": {
        "accessKeyId": "testAccessKey",
        "#secretKey": "testSecretKey",
        "serviceName": "testService",
        "regionName": "testRegion"
      }
    }
  }
}
{% endhighlight %}

See [example [EX143]](https://github.com/keboola/generic-extractor/tree/master/doc/examples/143-aws-signature-request).

## AWS Signature Credentials
- **accessKeyId** --- AWS access key ID
- **#secretKey** --- AWS secret access key
- **serviceName** --- Signing to a particular service name
- **regionName** --- Signing to a particular region name


================================================
File: extend/generic-extractor/configuration/config/index.md
================================================
---
title: Extraction Configuration
permalink: /extend/generic-extractor/configuration/config/
---

* TOC
{:toc}

*To configure your first Generic Extractor, follow our [tutorial](/extend/generic-extractor/tutorial/).*
*Use [Parameter Map](/extend/generic-extractor/map/) to help you navigate among various
configuration options.*

The `config` section of Generic Extractor configuration **describes the actual extraction**, including properties of HTTP requests,
and mapping between source JSON and target CSV.

A sample `config` configuration can look like this:

{% highlight json %}
{
    ...,
    "config": {
        "debug": false,
        "outputBucket": "ge-tutorial",
        "incrementalOutput": false,
        "compatLevel": 2,
        "jobs": [
            ...
        ],
        "mappings": {
            ...
        },
        "http": {
            ...
        },
        "userData": {
            ...
        }
    }
}
{% endhighlight %}

Apart from the properties listed below, the `config` section can contain any number of
other properties which are not used by Generic Extractor itself, but may be referenced
from within [functions](/extend/generic-extractor/functions/).

The keys prefixed by the hash character `#` are [automatically encrypted](/overview/encryption/) when the
configuration is saved. It is advisable to store sensitive information in such fields. Note, however, they
are not automatic aliases to un-encrypted fields. That means that when using a `#password` field, you
must always refer to it as `#password` (for instance, in [functions](/extend/generic-extractor/functions)).
Also, you cannot encrypt any Generic Extractor configuration fields (such as `jobs`, `mappings`, ...).

## Jobs
The Jobs configuration describes the API endpoints (resources) which will be extracted. This
includes configuring the HTTP method and parameters. The `jobs` configuration is
**required** and is described in a [separate article](/extend/generic-extractor/configuration/config/jobs/).

## Output Bucket
The `outputBucket` option defines the name of the [Storage Bucket](https://help.keboola.com/storage/buckets/)
in which the extracted tables will be stored. The configuration is **required** unless
the extractor is [published](/extend/generic-extractor/publish/) as a standalone component with the
[Default Bucket](/extend/common-interface/folders/#default-bucket) option.

The following configuration will make Generic Extractor put all extracted tables in the `ge-tutorial` bucket
(the names of the tables are defined by the [`dataType`](/extend/generic-extractor/configuration/config/jobs/#dataType) setting):

{% highlight json %}
{
    ...,
    "config": {
        "outputBucket": "ge-tutorial",
        ...
    }
}
{% endhighlight %}

If you omit the `outputBucket` configuration, you will receive an error similar to this:

    CSV file 'campaigns' file name is not a valid table identifier, either set output mapping for 'campaigns' or make sure that the file name is a valid Storage table identifier.

## Mappings
The Mappings configuration describes how the JSON response is converted into
CSV files that will be imported into Storage. The `mappings` configuration is **optional** and
is described in a [separate article](/extend/generic-extractor/configuration/config/mappings/).

## Debug
The `debug` boolean option allows you to turn on more verbose logging which shows
all HTTP requests sent by Generic Extractor. The default value is `false`.
Read more about running Generic Extractor in a [separate article](/extend/generic-extractor/running/).

## HTTP
The `http` option allows you to set the HTTP headers sent with every request. This primarily serves the purpose of providing values for [`api.http.requiredHeaders` option](/extend/generic-extractor/configuration/api/#required-headers).
It is also possible to use the `http` option without `api.http.requiredHeaders` in
which case it is essentially equal to [`api.http.headers`](/extend/generic-extractor/configuration/api/#default-headers).

{% highlight json %}
{
    ...,
    "config": {
        "http": {
            "headers": {
                "X-AppKey": "ThisIsSecret"
            }
        },
        ...
    }
}
{% endhighlight %}

See [example [EX074]](https://github.com/keboola/generic-extractor/tree/master/doc/examples/074-http-headers).

## Incremental Output
The `incrementalOutput` boolean option allows you to load the extracted data into
[Storage](http://help.keboola.com/storage/) incrementally. This flag in no way affects the data extraction.
When `incrementalOutput` is set to `true`, the contents of the target table in Storage will not be cleared.
The default value is `false`.

How to configure Generic Extractor to extract data in increments from an API
is described in a [dedicated article](/extend/generic-extractor/incremental/).

See [example [EX075]](https://github.com/keboola/generic-extractor/tree/master/doc/examples/075-incremental-output).

## User Data
The `userData` option allows you to add arbitrary data to extracted records.
It is an object with arbitrary property names which are added as columns to all records extracted
from parent jobs. The property values are the columns values. It is also possible to use
[functions](/extend/generic-extractor/functions/) as `userData` property values.

The following configuration:

{% highlight json %}
{
    "config": {
        "userData": {
            "tag": "fullExtract",
            "mode": "development"
        }
    }
}
{% endhighlight %}

and the following response:

{% highlight json %}
[
    {
        "id": 123,
        "name": "John Doe"
    },
    {
        "id": 234,
        "name": "Jane Doe"
    }
]
{% endhighlight %}

will produce the following `users` table:

|id|name|tag|mode|
|123|John Doe|fullExtract|development|
|234|Jane Doe|fullExtract|development|

The `userData` values are added to the parent jobs only. They will not affect the
[child jobs](/extend/generic-extractor/configuration/config/jobs/children). If the result table contains
columns with the same names as the `userData` properties. If there is already a column with the same name,
the `userData` column will be renamed.

See [example [EX076]](https://github.com/keboola/generic-extractor/tree/master/doc/examples/076-user-data).

## Compatibility Level
As we develop the Generic Extractor, some of the new features might lead to minor differences in extraction results.
When such a situation arises, a new *compatibility level* is introduced. The `compatLevel` setting allows
you to force the old compatibility level and **temporarily** maintain the old behavior. The current
compatibility level is **3**. The `compatLevel` setting is intended only to ease updates and migrations,
never use it in new configurations (any version of old behavior is considered unsupported).

When a new Level is introduced, the following will happen:

- Configurations that explicitly specify `compatLevel` will stay unchanged.
- All other configurations will automatically use the latest level.

Note that there is an exception: all configurations running before Level 3 was introduced will use compatibility
Level 1. This means that they use the legacy (Level 1) JSON parser, and you will see the following warning in
events: `Using legacy JSON parser, because it is in configuration state.`

### Level 2
Level 2 has different behavior in [`responseFilter`](/extend/generic-extractor/configuration/config/jobs/#response-filter) handling.
In current behavior (level 3 and above), a filtered JSON property consistently produces a valid JSON.
Previously (level 2 and below), a scalar value was not filtered. Given the data:

{% highlight json %}
[
    {
        "id": 1,
        "data": {
            "a": "b"
        }
    },
    {
        "id": 2,
        "data": "c"
    }
]
{% endhighlight %}

With `responseFilter` set to `data`, the level 2 version produces the following table:

|id|data|
|---|---|
|1|{"a":"b"}|
|2|c|

Level 3 and above produces:

|id|data|
|---|---|
|1|{"a":"b"}|
|2|"c"|

That means that the `data` column is always a valid JSON string.
Compare the results of examples
[EX121](https://github.com/keboola/generic-extractor/tree/master/doc/examples/121-inconsistent-object-legacy)
and
[EX122](https://github.com/keboola/generic-extractor/tree/master/doc/examples/122-multiple-filters-legacy).
using compatibility level 2 with the result produced by examples
[EX016](https://github.com/keboola/generic-extractor/tree/master/doc/examples/016-inconsistent-object)
and
[EX018](https://github.com/keboola/generic-extractor/tree/master/doc/examples/018-multiple-filters)
which use the current JSON parser.


### Level 1
Level 1 uses a JSON parser which cannot handle duplicate columns properly. This applies to a number of situations:

- The response contains properties which are evaluated to the same name, e.g.:
{% highlight json %}
{
    "some.property": "first",
    "some_property": "second"
}
{% endhighlight %}
- The response contains nested properties which are evaluated to the same name, e.g.:
{% highlight json %}
{
    "some_property": "first",
    "some": {
        "property": "second"
    }
}
{% endhighlight %}
- The response contains names which are generated internally by Generic Extractor (`parent_id`, `JSON_parentId`), e.g. -- in a child job:
{% highlight json %}
{
    "parent_id": 1,
    "name": "someName"
}
{% endhighlight %}
- The user data contains a column which is present in the response.

In either of these situations, the Level 1 extractor generates an empty column with hash, and
the original (or first encountered) column values are overwritten. In the current version
(Level 2 and above), both columns are retained. The second encountered column has a
numbered suffix. If you are upgrading from a Level 1 extractor, delete the column
with hash from the target Storage table, otherwise you'll get an error (`Some columns are missing in
the csv files`).

There are also some differences in the naming of very long columns. For example, a property
`data.modules.#DistributionGroups.outputs.groupCharacteristics.persistent` is shortened to
`d__m__DistributionGroups_outputs_groupCharacteristics_persistent` in a Level 1 extractor, and
to `DistributionGroups_outputs_groupCharacteristics_persistent` in Level 2 and above.

Compare the results of examples
[EX124](https://github.com/keboola/generic-extractor/tree/master/doc/examples/124-naming-conflict-legacy)
and
[EX125](https://github.com/keboola/generic-extractor/tree/master/doc/examples/125-user-data-legacy),
using compatibility level 1 with the result produced by examples
[EX025](https://github.com/keboola/generic-extractor/tree/master/doc/examples/025-naming-conflict)
and
[EX076](https://github.com/keboola/generic-extractor/tree/master/doc/examples/076-user-data)
which use the current JSON parser.

================================================
File: extend/generic-extractor/configuration/config/mappings.md
================================================
---
title: Mapping
permalink: /extend/generic-extractor/configuration/config/mappings/
---

*If you are new to Generic Extractor, learn about [mapping in our tutorial](/extend/generic-extractor/tutorial/mapping/) first.*
*Use the [Parameter Map](/extend/generic-extractor/map/) to help you navigate among various configuration options.*


* TOC
{:toc}

Mapping allows you to **modify a response conversion process** in which Generic Extractor receives JSON responses,
[merges them](/extend/generic-extractor/configuration/config/jobs/#merging-responses), and
converts them to CSV files, which are then imported to Keboola.

Manually define mapping if you wish to do the following:

- Set up a primary key to simplify relations between result tables and speed up the extraction,
- Avoid extraction of unnecessary properties which make result tables cluttered,
- Split a single response into multiple result tables,
- Override the automatic conversion for any other reason.

The automatic conversion between JSON and CSV (Storage Tables) is defined by the following rules (see an
[example](#automatic-mapping)):

- If the value of a JSON field is a [scalar](/extend/generic-extractor/tutorial/json/#data-values), it is saved as \
the value of the column with the name of the field.
- If the value of a JSON field is an [object](/extend/generic-extractor/tutorial/json/#data-values), each of the
object property values will be added as a value of a column with an auto-generated name.
- If the value of a JSON field is an [array](/extend/generic-extractor/tutorial/json/#data-values), a new table
will be created and linked by the `JSON_parentId` column.

Mapping configuration allows you to manually modify or override this behavior for a
[`dataType`](/extend/generic-extractor/configuration/config/jobs/#data-type)
defined in a job. The following is a mapping configuration example:

{% highlight json %}
"mappings": {
    "users": {
        "address.country": {
            "type": "column",
            "mapping": {
                "destination": "country"
            }
        }
    }
}
{% endhighlight %}

## Configuration
The `mappings` configuration is a deeply nested object. The first level of keys are `dataType`
values used in the [job configurations](/extend/generic-extractor/configuration/config/jobs/#data-type). The
second level of keys are the names of the properties found (or expected) in the response.
Then, the value is an object with the following properties:

- `type` (optional, string) --- Mapping type, either `column`, `table` or `user`. The default value is `column`.
- `mapping` (required, object) --- Mapping configuration; depends on the mapping type.

The following configuration shows a sample mapping configuration for dataType `users` and column `id`:

{% highlight json %}
"mappings": {
    "users": {
        "id": {
            "type": "column",
            "mapping": {
                "destination": "user_id"
            }
        }
    }
}
{% endhighlight %}

### User Interface
In the UI, the mapping can be created for each endpoint in the `Endpoints`.`Mapping section` by clicking `Create Mapping` toggle.

{: .image-popup}
![Create mapping](/extend/generic-extractor/tutorial/create_mapping_toggle.png)

#### Mapping Detection

You may opt to generate the mapping automatically by clicking the `Infer Mapping` button in the top right corner. 

This operation will generate a mapping based on the enpoint's sample response, which may help as a starting point for further manual adjustments. 

In most cases, this method is sufficient and doesn't require any additional edits.

{: .image-popup}
![Create mapping](/extend/generic-extractor/tutorial/create_mapping.png)


##### Primary key
You can specify a `.` separated path of the elements in the response to create a primary key. **NOTE** that if you are mapping child jobs, 
the parent keys will automatically be included.

##### Nesting level
Currently, the automatic detection outputs only single table mapping. You can control the nesting level by specifying 
the `Nesting Level` property. For example, a depth of 1 transforms `{"address": {"street": "Main", "details": {"postcode": "170 00"}}}` into two columns: `address_street` and `address_details`. 
All elements that have ambiguous types or are beyond the specified depth are stored in a single column as JSON, e.g., with the [`force_type`](https://developers.keboola.com/extend/generic-extractor/configuration/config/mappings/#mapping-without-processing) option.

### Column Mapping
Column mapping represents a basic mapping type that allows you to select extracted
columns, rename them, and optionally set a primary key on them. The mapping
configuration requires:

- `type` (optional, string) --- Can be omitted or must be `column`.
- `mapping` (required, object) --- Object with two properties:
  - `destination` (required, string) --- Name of the column in the output table
  - `primaryKey` (optional, boolean) --- If `true`, then a primary key will be set on the column. The default value is `false`.
- `forceType` (optional, boolean) --- If set to `true`, the property will not be processed and will be stored as an encoded
JSON (see an [example](#mapping-without-processing)).

### User Mapping
User mapping has the same configuration as the [column mapping](#column-mapping). The only difference is
that it applies to *virtual properties*. This is useful mainly for working with auto-generated properties/columns
in child jobs (see an [example](#mapping-child-jobs)).

### Table Mapping
Table mapping allows you to create a new table from a particular property of the response object. Table
mapping is, by default, used for arrays. The mapping configuration requires:

- `type` (required, string) --- Must be set to `table`.
- `destination` (required, string) --- Name of the output table.
- `tableMapping` (required, object) --- Object with another mapping configuration (required unless `parentKey.disable` is
set to `true` --- see below).
- `parentKey` (optional, object) --- Configuration of the parent-child relationship between tables:
    - `destination` (optional, string) --- Name of the column which links to the parent table. The default value is the name
	of the parent table with the suffix `_pkey`. See an [example](#using-primary-keys).
    - `primaryKey` (optional, boolean) --- Set to `true` to mark the link column as a primary key for the child table too.
	The default value is `false`. See an [example](#using-primary-keys).
    - `disable` (optional, boolean) --- Completely disables the parent-child relationship, disables configured
	`tableMapping`. See an [example](#disabled-parent-key).

The following configuration takes the `contacts` property from the response and makes a new table
(`user-contact`) from it; the `contacts.email` is mapped to the `email` column and the property
`contacts.phone` is mapped to the column `tel`. See more in the [examples](#table-mapping-examples).

{% highlight json %}
"contacts": {
    "type": "table",
    "destination": "user-contact",
    "tableMapping": {
        "email": {
            "type": "column",
            "mapping": {
                "destination": "email"
            }
        },
        "phone": {
            "type": "column",
            "mapping": {
                "destination": "tel"
            }
        }
    }
}
{% endhighlight %}

## Examples
The following examples demonstrate how to map JSON responses to CSV files.

### Automatic Mapping
Without any configuration, the following JSON response:

{% highlight json %}
[
    {
        "id": 123,
        "name": "John Doe",
        "address": {
            "street": "Blossom Avenue",
            "country": "United Kingdom"
        },
        "interests": [
            "girls", "cars", "flowers"
        ]
    },
    {
        "id": 234,
        "name": "Jane Doe",
        "address": {
            "street": "Whiteheaven Mansions",
            "city": "London",
            "country": "United Kingdom"
        },
        "interests": [
            "boys", "cars", "flowers"
        ]
    }
]
{% endhighlight %}

is converted to the following CSV files (and subsequently Storage tables):

users:

|id|name|address\_street|address\_country|address\_city|interests|
|---|---|---|---|---|---|
|123|John Doe|Blossom Avenue|United Kingdom||users_dab021748b7f93c10476ebe151de4459|
|234|Jane Doe|Whiteheaven Mansions|United Kingdom|London|users_aeb1d126471eef24c0769437f4e7adaa|

users_interests:

|data|JSON_parentId|
|---|---|
|girls|users_dab021748b7f93c10476ebe151de4459|
|cars|users_dab021748b7f93c10476ebe151de4459|
|flowers|users_dab021748b7f93c10476ebe151de4459|
|boys|users_aeb1d126471eef24c0769437f4e7adaa|
|cars|users_aeb1d126471eef24c0769437f4e7adaa|
|flowers|users_aeb1d126471eef24c0769437f4e7adaa|

The nested properties `address.street`, `address.county` and `address_city` were automatically
flattened into columns named as a concatenation of the parent and child property names. The
array property `interests` was turned into a separate table and linked using
`JSON_parentId` column and auto-generated keys.

See [example [EX063]](https://github.com/keboola/generic-extractor/tree/master/doc/examples/063-mapping-automatic).

**Note:** When using automatic mapping, you may get result tables with **changing structure**. A typical example is 
when the API returns a completely empty response in which case no tables are created for the job.
When Manual mapping is used, the generated table structure always honors the mapping setting.
See [example [EX137]](https://github.com/keboola/generic-extractor/tree/master/doc/examples/137-mapping-tables-nested-empty).

### Basic Manual Mapping
Maybe you are not interested in the user `interests` and want to simplify the user table
to three columns: `country`, `name` and `id`. The following mapping configuration does the trick:

{% highlight json %}
{
    "parameters": {
        "api": {
            "baseUrl": "http://example.com/"
        },
        "config": {
            "debug": true,
            "outputBucket": "mock-server",
            "jobs": [
                {
                    "endpoint": "users",
                    "dataType": "users"
                }
            ],
            "mappings": {
                "users": {
                    "address.country": {
                        "type": "column",
                        "mapping": {
                            "destination": "country"
                        }
                    },
                    "name": {
                        "type": "column",
                        "mapping": {
                            "destination": "name"
                        }
                    },
                    "id": {
                        "mapping": {
                            "destination": "id",
                            "primaryKey": true
                        }
                    }
                }
            }
        }
    }
}
{% endhighlight %}

The `mappings` settings has the key `users` which is the value of the `job.dataType` property. The keys in
the `users` objects are the names of the properties in the JSON response. The values are the mapping configurations for
each property. The mapping is always exhaustive; only the mentioned properties get processed, while the others are
completely ignored. The above configuration also sets the primary key on the `id` column.

All three mapped properties are mapped to columns (the `id` property relies on the default value for `type`).
Notice that in the nested properties, you need to enter the name/path in the JSON response (`address.country`).
You cannot use the auto-generated name produced without any mapping (`address_country`), because the automatic
processing is turned off by the mapping.

Take great care to **use the correct keys** in the mapping! If you misspell the first-level key, the entire configuration
will be ignored (it will refer to a non-existent data type). If you misspell the second-level key, you will get
an empty column in the result (referring to a non-existent property of the response). With the
correct settings, the following table will be produced:

|country|name|id|
|---|---|---|
|United Kingdom|John Doe|123|
|United Kingdom|Jane Doe|234|

See [example [EX064]](https://github.com/keboola/generic-extractor/tree/master/doc/examples/064-mapping-basic).

### Mapping Child Jobs
Let's say that you have an API endpoint `/users` which returns a response similar to:

{% highlight json %}
[
    {
        "id": 123,
        "name": "John Doe"
    },
    {
        "id": 234,
        "name": "Jane Doe"
    }
]
{% endhighlight %}

More details about the user can be retrieved through another endpoint --- `/user/{id}`, where `{id}` is
the user ID:

{% highlight json %}
{
    "id": 123,
    "name": "John Doe",
    "address": {
        "city": "London",
        "country": "UK",
        "street": "Whitehaven Mansions"
    },
    "interests": [
        "girls", "cars", "flowers"
    ]
}
{% endhighlight %}

To handle this situation in Generic Extractor, use a [child job](/extend/generic-extractor/configuration/config/jobs/#children):

{% highlight json %}
"jobs": [
    {
        "endpoint": "users",
        "dataType": "users",
        "children": [
            {
                "endpoint": "user/{user-id}",
                "dataType": "user-detail",
                "dataField": ".",
                "placeholders": {
                    "user-id": "id"
                }
            }
        ]
    }
]
{% endhighlight %}

The produced user-detail table will look like this:

|id|name|address\_city|address\_country|address\_street|interests|parent_id|
|---|---|---|---|---|---|---|
|123|John Doe|London|UK|Whitehaven Mansions|user-detail_3484bd6e10690a3a2e77079f69ceaa42|123|
|234|Jane Doe|St Mary Mead|UK|High Street|user-detail_a7655e39a0399dc842b44365778cd295|234|

Note that the name of the column `parent_id` depends on the [placeholder configuration](/extend/generic-extractor/configuration/config/jobs/children/#basic-example)
and is not always `parent_id` (see [example](/extend/generic-extractor/configuration/config/jobs/children/#basic-job-with-array-values)).

Now you can use the following mapping to shape the table:

{% highlight json %}
"mapping": {
    "user-detail": {
        "address.country": {
            "type": "column",
            "mapping": {
                "destination": "country"
            }
        },
        "parent_id": {
            "type": "user",
            "mapping": {
                "destination": "user_id"
            }
        }
    }
}
{% endhighlight %}

and get the following user-detail table:

|country|user_id|
|---|---|
|UK|123|
|UK|234|

The important part of the mapping configuration is that you **must** use `"type": "user"`
for the mapping type of the `parent_id` (`user_id`) column. This is because the
column `parent_id` does not really exist in the response as it is generated dynamically for the child job.

See [example [EX065]](https://github.com/keboola/generic-extractor/tree/master/doc/examples/065-mapping-child-jobs).

### Mapping without Processing
The `forceType` configuration property allows you to skip a part of the API response from processing.
With the following API response:

{% highlight json %}
[
    {
        "id": 123,
        "name": "John Doe",
        "address": {
            "street": "Blossom Avenue",
            "country": "United Kingdom"
        },
        "interests": [
            "girls", "cars", "flowers"
        ]
    },
    {
        "id": 234,
        "name": "Jane Doe",
        "address": {
            "street": "Whiteheaven Mansions",
            "city": "London",
            "country": "United Kingdom"
        },
        "interests": [
            "boys", "cars", "flowers"
        ]
    }
]
{% endhighlight %}

and the following mapping configuration:

{% highlight json %}
"mappings": {
    "users": {
        "name": {
            "mapping": {
                "destination": "name"
            }
        },
        "id": {
            "type": "column",
            "mapping": {
                "destination": "id",
                "primaryKey": true
            }
        },
        "interests": {
            "type": "column",
            "mapping": {
                "destination": "interests"
            },
            "forceType": true
        }
    }
}
{% endhighlight %}

the result table `users` contains the `interests` field unprocessed and left as JSON fragments:

|name|id|interests|
|---|---|---|
|John Doe|123|["girls","cars","flowers"]|
|Jane Doe|234|["boys","cars","flowers"]|

The same result can be achieved by using the [`responseFilter` job property](/extend/generic-extractor/configuration/config/jobs/#response-filter):

{% highlight json %}
{
    "parameters": {
        "api": {
            "baseUrl": "http://example.com/"
        },
        "config": {
            "jobs": [
                {
                    "endpoint": "users",
                    "dataType": "users",
                    "responseFilter": "interests"
                }
            ]
        }
    }
}
{% endhighlight %}

See [example [EX073]](https://github.com/keboola/generic-extractor/tree/master/doc/examples/073-mapping-forceType).

### Table Mapping Examples

#### Basic table mapping
Because all output columns must be listed in a mapping, using only column mapping settings skips
the `interests` property of the response:

{% highlight json %}
[
    {
        "id": 123,
        "name": "John Doe",
        "address": {
            "street": "Blossom Avenue",
            "country": "United Kingdom"
        },
        "interests": [
            "girls", "cars", "flowers"
        ]
    },
    {
        "id": 234,
        "name": "Jane Doe",
        "address": {
            "street": "Whiteheaven Mansions",
            "city": "London",
            "country": "United Kingdom"
        },
        "interests": [
            "boys", "cars", "flowers"
        ]
    }
]
{% endhighlight %}

The `interests` property cannot be saved as a column therefore, a mapping of the `table` type must be used:

{% highlight json %}
"mappings": {
    "users": {
        "name": {
            "type": "column",
            "mapping": {
                "destination": "name"
            }
        },
        "id": {
            "type": "column",
            "mapping": {
                "destination": "id"
            }
        },
        "interests": {
            "type": "table",
            "destination": "user-interests",
            "tableMapping": {
                ".": {
                    "type": "column",
                    "mapping": {
                        "destination": "interest"
                    }
                }
            }
        }
    }
}
{% endhighlight %}

The table mapping follows the same structure as normal mapping. Each item is another mapping
definition identified by the property name in the JSON file. Because the `interests` property
itself is an array, its value has no name, and therefore, the key is only a dot `"."`. The mapping
value is a standard [column mapping](/extend/generic-extractor/configuration/config/mappings/#column-mapping).
The above configuration produces the same result as automatic column mapping.

See [example [EX066]](https://github.com/keboola/generic-extractor/tree/master/doc/examples/066-mapping-tables-basic).

#### Nested properties
Let's say that you have an API that returns a response like this (it will be used in the following two examples as well):

{% highlight json %}
[
    {
        "id": 123,
        "name": "John Doe",
        "contacts": {
            "email": "john.doe@example.com",
            "phone": "987345765",
            "addresses": [
                {
                    "street": "Blossom Avenue",
                    "country": "United Kingdom"
                },
                {
                    "street": "Whiteheaven Mansions",
                    "city": "London",
                    "country": "United Kingdom"
                }
            ]
        }
    },
    {
        "id": 234,
        "name": "Jane Doe",
        "contacts": {
            "email": "jane.doe@example.com",
            "skype": "jane.doe",
            "addresses": [
                {
                    "street": "Whiteheaven Mansions",
                    "city": "London",
                    "country": "United Kingdom"
                }
            ]
        }
    }
]
{% endhighlight %}

With the automatic mapping (without any `mappings` configuration), the following tables will be extracted:

users:

|id|name|contacts\_email|contacts\_phone|contacts\_addresses|contacts\_skype|
|---|---|---|---|---|---|---|
|123|John Doe|john.doe@example.com|987345765|users.contacts_912c86dec7acdb9d8a17c97eb464aec6||
|234|Jane Doe|jane.doe@example.com||users.contacts_4cf9e859113127acb138872cc630e75f|jane.doe|

users.contacts:

|street|country|city|JSON_parentId|
|---|---|---|---|
|Blossom Avenue|United Kingdom||users.contacts_912c86dec7acdb9d8a17c97eb464aec6|
|Whiteheaven Mansions|United Kingdom|London|users.contacts_912c86dec7acdb9d8a17c97eb464aec6|
|Whiteheaven Mansions|United Kingdom|London|users.contacts_4cf9e859113127acb138872cc630e75f|

This might not be exactly what you want. Perhaps you would like the contacts to be separate from the users and
addresses. This can be done using the following mapping configuration:

{% highlight json %}
"mappings": {
    "users": {
        "id": {
            "type": "column",
            "mapping": {
                "destination": "id"
            }
        },
        "name": {
            "type": "column",
            "mapping": {
                "destination": "name"
            }
        },
        "contacts": {
            "type": "table",
            "destination": "user-contact",
            "tableMapping": {
                "email": {
                    "type": "column",
                    "mapping": {
                        "destination": "email"
                    }
                },
                "phone": {
                    "type": "column",
                    "mapping": {
                        "destination": "tel"
                    }
                },
                "addresses": {
                    "type": "table",
                    "destination": "user-address",
                    "tableMapping": {
                        "street": {
                            "type": "column",
                            "mapping": {
                                "destination": "street"
                            }
                        },
                        "country": {
                            "type": "column",
                            "mapping": {
                                "destination": "country"
                            }
                        }
                    }
                }
            }
        }
    }
}
{% endhighlight %}

The above configuration defines that the `contacts` field will be mapped into a separate table
with the columns `email` and `tel` (value of `mapping.destination`). The `address` field will be
mapped into yet another separate table with the columns `street` and `country`.

With the above configuration, the following tables will be created:

users:

|id|name|user-contact|
|---|---|---|
|123|John Doe|b5d72095c441b3a3d6f23ad8142c3f8b|
|234|Jane Doe|5f7f2ab65a680f1a9387a8fafe6b9050|

user-contact:

|email|tel|user-address|users_pk|
|---|---|---|---|
|john.doe@example.com|987345765|1c439a9a39548290f7b7a4513a9224e7|b5d72095c441b3a3d6f23ad8142c3f8b|
|jane.doe@example.com||605e865710f95dba665f6d0e8bc19f1a|5f7f2ab65a680f1a9387a8fafe6b9050|

user-address:

|street|country|user-contact_pk|
|---|---|---|
|Blossom Avenue|United Kingdom|1c439a9a39548290f7b7a4513a9224e7|
|Whiteheaven Mansions|United Kingdom|1c439a9a39548290f7b7a4513a9224e7|
|Whiteheaven Mansions|United Kingdom|605e865710f95dba665f6d0e8bc19f1a|

See [example [EX067]](https://github.com/keboola/generic-extractor/tree/master/doc/examples/067-mapping-tables-nested).

#### Array items
The following examples deal with *arrays of objects*. If you need to deal with *array of scalar* values, see
the [corresponding example](#multiple-primary-key-columns).

Consider the same API response as above:
<details>
  <summary>Click to expand the response.</summary>

{% highlight json %}
[
    {
        "id": 123,
        "name": "John Doe",
        "contacts": {
            "email": "john.doe@example.com",
            "phone": "987345765",
            "addresses": [
                {
                    "street": "Blossom Avenue",
                    "country": "United Kingdom"
                },
                {
                    "street": "Whiteheaven Mansions",
                    "city": "London",
                    "country": "United Kingdom"
                }
            ]
        }
    },
    {
        "id": 234,
        "name": "Jane Doe",
        "contacts": {
            "email": "jane.doe@example.com",
            "skype": "jane.doe",
            "addresses": [
                {
                    "street": "Whiteheaven Mansions",
                    "city": "London",
                    "country": "United Kingdom"
                }
            ]
        }
    }
]
{% endhighlight %}
</details>
<br>
Let's say that you know that the `addresses` array contains only two items at most, and therefore,
you want to mark them as the primary and secondary addresses:

{% highlight json %}
"mappings": {
    "users": {
        "id": {
            "type": "column",
            "mapping": {
                "destination": "id"
            }
        },
        "name": {
            "type": "column",
            "mapping": {
                "destination": "name"
            }
        },
        "contacts": {
            "type": "table",
            "destination": "user-contact",
            "tableMapping": {
                "email": {
                    "type": "column",
                    "mapping": {
                        "destination": "email"
                    }
                },
                "phone": {
                    "type": "column",
                    "mapping": {
                        "destination": "tel"
                    }
                },
                "addresses.0": {
                    "type": "table",
                    "destination": "primary-address",
                    "tableMapping": {
                        "street": {
                            "type": "column",
                            "mapping": {
                                "destination": "street"
                            }
                        },
                        "country": {
                            "type": "column",
                            "mapping": {
                                "destination": "country"
                            }
                        }
                    }
                },
                "addresses.1": {
                    "type": "table",
                    "destination": "secondary-address",
                    "tableMapping": {
                        "street": {
                            "type": "column",
                            "mapping": {
                                "destination": "street"
                            }
                        },
                        "country": {
                            "type": "column",
                            "mapping": {
                                "destination": "country"
                            }
                        }
                    }
                }
            }
        }
    }
}
{% endhighlight %}


The important part of the pretty long configuration is:

{% highlight json %}
"addresses.0": {
    "type": "table",
    "destination": "primary-address",
    "tableMapping": {
        "street": {
            "type": "column",
            "mapping": {
                "destination": "street"
            }
        },
        "country": {
            "type": "column",
            "mapping": {
                "destination": "country"
            }
        }
    }
}
{% endhighlight %}

This picks the first item (remember that array indexes are
[zero-based](/extend/generic-extractor/tutorial/json/#references)) and places it in the
`primary-address` table. Analogously, the `addresses.1` mapping picks the second item from the `addresses`
array and stores it in the `secondary-address` table.

See [example [EX068]](https://github.com/keboola/generic-extractor/tree/master/doc/examples/068-mapping-tables-nested-array).

#### Directly mapping array
The following examples deal with *arrays of objects*; if you need to deal with *array of scalar* values, see
the [corresponding example](#multiple-primary-key-columns).

Consider the same API response as above:
<details>
 <summary>Click to expand the response.</summary>

{% highlight json %}
[
    {
        "id": 123,
        "name": "John Doe",
        "contacts": {
            "email": "john.doe@example.com",
            "phone": "987345765",
            "addresses": [
                {
                    "street": "Blossom Avenue",
                    "country": "United Kingdom"
                },
                {
                    "street": "Whiteheaven Mansions",
                    "city": "London",
                    "country": "United Kingdom"
                }
            ]
        }
    },
    {
        "id": 234,
        "name": "Jane Doe",
        "contacts": {
            "email": "jane.doe@example.com",
            "skype": "jane.doe",
            "addresses": [
                {
                    "street": "Whiteheaven Mansions",
                    "city": "London",
                    "country": "United Kingdom"
                }
            ]
        }
    }
]
{% endhighlight %}
</details>
<br>

If you map the table as in the [previous example](#array-items), you will receive a `primary-address` table:

|street|country|user-contact_pk|
|---|---|---|
|Blossom Avenue|United Kingdom|1c439a9a39548290f7b7a4513a9224e7|
|Whiteheaven Mansions|United Kingdom|605e865710f95dba665f6d0e8bc19f1a|

Notice that the records link to the `user-contact` table. This may produce unnecessarily complicated
links between the tables because, from the response, it is obvious that each address is assigned to
a specific user. To avoid this, you can directly map a nested property:

{% highlight json %}
"mappings": {
    "users": {
        "id": {
            "type": "column",
            "mapping": {
                "destination": "id"
            }
        },
        "name": {
            "type": "column",
            "mapping": {
                "destination": "name"
            }
        },
        "contacts": {
            "type": "table",
            "destination": "user-contact",
            "tableMapping": {
                "email": {
                    "type": "column",
                    "mapping": {
                        "destination": "email"
                    }
                },
                "phone": {
                    "type": "column",
                    "mapping": {
                        "destination": "tel"
                    }
                }
            }
        },
        "contacts.addresses.0": {
            "type": "table",
            "destination": "primary-address",
            "tableMapping": {
                "street": {
                    "type": "column",
                    "mapping": {
                        "destination": "street"
                    }
                },
                "country": {
                    "type": "column",
                    "mapping": {
                        "destination": "country"
                    }
                }
            }
        }
    }
}
{% endhighlight %}

The mapping for the `primary-address` table is now **not nested** inside the mapping for the
`contacts` table. Therefore, it links directly to the `users` table. The content is the same because
the mapping still refers to the same property --- the first item of the `addresses` property of `contacts`
(`contacts.addresses.0`). The following table is produced:

|street|country|users_pk|
|---|---|---|
|Blossom Avenue|United Kingdom|b5d72095c441b3a3d6f23ad8142c3f8b|
|Whiteheaven Mansions|United Kingdom|5f7f2ab65a680f1a9387a8fafe6b9050|

The user table now contains an additional column --- `primary-address`:

|id|name|user-contact|primary-address|
|---|---|---|---|
|123|John Doe|b5d72095c441b3a3d6f23ad8142c3f8b|b5d72095c441b3a3d6f23ad8142c3f8b|
|234|Jane Doe|5f7f2ab65a680f1a9387a8fafe6b9050|5f7f2ab65a680f1a9387a8fafe6b9050|

See [example [EX069]](https://github.com/keboola/generic-extractor/tree/master/doc/examples/069-mapping-tables-nested-direct).

#### Using primary keys
In the above example, you can see that the `primary-address` table contains
an auto-generated key to link back to users. This is unnecessary because you can safely link to
the user ID. To do this, you only need to specify the primary key for the table:

{% highlight json %}
"mappings": {
    "users": {
        "id": {
            "type": "column",
            "mapping": {
                "destination": "id",
                "primaryKey": true
            }
        },
        "name": {
            "type": "column",
            "mapping": {
                "destination": "name"
            }
        },
        "contacts": {
            "type": "table",
            "destination": "user-contact",
            "parentKey": {
                "primaryKey": true,
                "destination": "userId"
            },
            "tableMapping": {
                "email": {
                    "type": "column",
                    "mapping": {
                        "destination": "email"
                    }
                },
                "phone": {
                    "type": "column",
                    "mapping": {
                        "destination": "phone"
                    }
                }
            }
        },
        "contacts.addresses.0": {
            "type": "table",
            "destination": "primary-address",
            "tableMapping": {
                "street": {
                    "type": "column",
                    "mapping": {
                        "destination": "street"
                    }
                },
                "country": {
                    "type": "column",
                    "mapping": {
                        "destination": "country"
                    }
                }
            }
        }
    }
}
{% endhighlight %}

The most important part in the above configuration is the `"primaryKey": true` setting for
the `id` column in the `users` table. Thanks to this, Generic Extractor is able to automatically link
all related records to this ID. In the `user-contact` and `primary-address` tables, the column
`users_pk` will be created, which will contain the user ID. The name is auto-generated as the
name of the parent table with the suffix `_pk`.

To override this auto-generated name, the following configuration is used in the `user-contact`
table, renaming the `users_pk` column to `userId`.

{% highlight json %}
"parentKey": {
    "primaryKey": true,
    "destination": "userId"
},
{% endhighlight %}

It also marks the `userId` column in the `user-contact` table as the primary key. The following tables
are produced by the above mapping configuration:

users:

|id|name|
|---|---|
|123|John Doe|
|234|Jane Doe|

user-contact:

|email|phone|userId|
|---|---|---|
|john.doe@example.com|987345765|123|
|jane.doe@example.com||234|

primary-address:

|street|country|users_pk|
|---|---|---|
|Blossom Avenue|United Kingdom|123|
|Whiteheaven Mansions|United Kingdom|234|

See [example [EX070]](https://github.com/keboola/generic-extractor/tree/master/doc/examples/070-mapping-tables-nested-direct-pk).

#### Multiple primary key columns
Generic Extractor allows you to set only a single (primary) key for a table. This means that
if you set `primaryKey` on multiple columns, you will create a compound primary key. Let's say
that you have an API with the following response:

{% highlight json %}
[
    {
        "firstName": "John",
        "lastName": "Doe",
        "interests": [
            "girls", "cars", "flowers"
        ]
    },
    {
        "firstName": "John",
        "lastName": "Doe",
        "interests": [
            "boys", "cars", "flowers"
        ]
    }
]
{% endhighlight %}

Notice that the response does not contain a single unique property (id). You can create the
following configuration:

{% highlight json %}
"mappings": {
    "users": {
        "firstName": {
            "mapping": {
                "destination": "first_name",
                "primaryKey": true
            }
        },
        "lastName": {
            "mapping": {
                "destination": "last_name",
                "primaryKey": true
            }
        },
        "interests": {
            "type": "table",
            "destination": "interests",
            "tableMapping": {
                ".": {
                    "type": "column",
                    "mapping": {
                        "destination": "interest"
                    }
                }
            }
        }
    }
}
{% endhighlight %}

to extract the following tables:

users:

|first\_name|last\_name|
|---|---|
|John|Doe|
|Jane|Doe|

interests:

|interest|users\_pk|
|---|---|
|girls|John,Doe|
|cars|John,Doe|
|flowers|John,Doe|
|boys|Jane,Doe|
|cars|Jane,Doe|
|flowers|Jane,Doe|

**Important:** If you set a column (or combination of columns) as a primary key that has duplicate
values, the rows will not be imported!

See [example [EX071]](https://github.com/keboola/generic-extractor/tree/master/doc/examples/071-mapping-multiple-pk).

#### Multiple primary keys from nested columns
The [above example](#multiple-primary-key-columns) shows how to set a compound primary key.
It is also possible to create a compound key using a [parent column](#using-primary-keys).
Let's say that you have an API with the following response:

{% highlight json %}
[
    {
        "id": 123,
        "name": "John Doe",
        "addresses": [
            {
                "index": 1,
                "street": "Blossom Avenue",
                "country": "United Kingdom"
            },
            {
                "index": 2,
                "street": "Whiteheaven Mansions",
                "city": "London",
                "country": "United Kingdom"
            }
        ]
    },
    {
        "id": 234,
        "name": "Jane Doe",
        "addresses": [
            {
                "index": 1,
                "street": "Whiteheaven Mansions",
                "city": "London",
                "country": "United Kingdom"
            }
        ]
    }
]
{% endhighlight %}

Notice that the `addresses` response does not contain a single unique property, but there is an `index`
property which is unique within a specific user. The primary key for an address would, therefore, be the
combination of `id` and `index`.

Create the following configuration:

{% highlight json %}
"mappings": {
    "users": {
        "id": {
            "mapping": {
                "destination": "id",
                "primaryKey": true
            }
        },
        "name": {
            "mapping": {
                "destination": "name"
            }
        },
        "addresses": {
            "type": "table",
            "parentKey": {
                "destination": "userId",
                "primaryKey": true
            },
            "destination": "user-address",
            "tableMapping": {
                "index": {
                    "type": "column",
                    "mapping": {
                        "destination": "index",
                        "primaryKey": true
                    }
                },
                "street": {
                    "type": "column",
                    "mapping": {
                        "destination": "street"
                    }
                },
                "country": {
                    "type": "column",
                    "mapping": {
                        "destination": "country"
                    }
                }
            }
        }
    }
}
{% endhighlight %}

to extract the following tables:

users:

|id|name|
|---|---|
|123|John Doe|
|234|Jane Doe|

user-address:

|index|street|country|userId|
|1|Blossom Avenue|United Kingdom|123|
|2|Whiteheaven Mansions|United Kingdom|123|
|1|Whiteheaven Mansions|United Kingdom|234|

When imported to Storage, the primary key for the `user-address` table will be set to
the combination of `index` and `userId`. The configuration has three important parts.

The first part:

{% highlight json %}
"id": {
    "mapping": {
        "destination": "id",
        "primaryKey": true
    }
}
{% endhighlight %}

sets the `id` property from a user as the primary key for the resulting table.

The second part:

{% highlight json %}
"parentKey": {
    "destination": "userId",
    "primaryKey": true
}
{% endhighlight %}

adds the primary key from users (i.e., the `id` property) to the child table `user-address` as a `userId` column.
It also sets it as the primary key for the `user-address` table.

The third part:

{% highlight json %}
"index": {
    "type": "column",
    "mapping": {
        "destination": "index",
        "primaryKey": true
    }
}
{% endhighlight %}

adds the `index` column from the `user-address` table to the list of the primary key columns in that table.

**Important:** If you set a column (or a combination of columns) as a primary key that has duplicate
values, the rows will not be imported!

See [example [EX115]](https://github.com/keboola/generic-extractor/tree/master/doc/examples/115-multiple-pk-parent).

#### Disabled parent key
It is also possible to entirely disable the relationships between parts of the response objects.
Consider, for example, this API response:

{% highlight json %}
[
    {
        "id": 123,
        "name": "John Doe",
        "children": [
            {
                "id": 1234,
                "name": "Jenny Doe",
                "favoriteColors": "blue,pink"
            },
            {
                "id": 1235,
                "name": "Jimmy Doe",
                "favoriteColors": "red,green,blue"
            }
        ]
    },
    {
        "id": 234,
        "name": "Jane Doe",
        "children": [
            {
                "id": 2345,
                "name": "Janet Doe",
                "favoriteColors": "black"
            }
        ]
    }
]
{% endhighlight %}

You may extract (by default) the `children` as a separate entity related to their parents. Another
option is to extract the `children` as an entity equal to their parents. This can be done by
disabling the relationship:

{% highlight json %}
"mappings": {
    "users": {
        "id": {
            "type": "column",
            "mapping": {
                "destination": "id"
            }
        },
        "name": {
            "type": "column",
            "mapping": {
                "destination": "name"
            }
        },
        "favoriteColors": {
            "type": "column",
            "mapping": {
                "destination": "colors"
            }
        },
        "children": {
            "type": "table",
            "destination": "users",
            "parentKey": {
                "disable": true
            }
        }
    }
}
{% endhighlight %}

The important part is `parentKey.disable` set to `true` in the `children` mapping. Then, an already
existing mapping can be referenced --- `"destination": "users"` defines that the children are to be mapped using
the same configuration as their parents.

Notice that the `children` mapping contains no `tableMapping` configuration. This is because the mapping of
the `users` data type is used both for users and their children. Setting `tableMapping` for `children` would have
no effect. This also means that the `favoriteColors` column configuration **must be** defined in the `users`
mapping (even though it is not used by the users in the API response).

See [example [EX072]](https://github.com/keboola/generic-extractor/tree/master/doc/examples/072-mapping-pk-disable).

#### User data in mapping

There are situations when you need to add custom columns to the output data. For this purpose, the
[`userData` functionality](/extend/generic-extractor/configuration/config/#user-data) can be used.

Consider this API response:

{% highlight json %}
[
    {
        "id": 123,
        "name": "John Doe"
    },
    {
        "id": 234,
        "name": "Jane Doe"
    }
]
{% endhighlight %}

Let's say you want to add a `country` column to output data, but you want to use custom mapping. To
handle this situation, you have to define mapping also for the `userData`.

{% highlight json %}
"userData": {
    "country": "UK"
},
"mappings": {
    "users": {
        "id": {
            "type": "column",
            "mapping": {
                "destination": "id"
            }
        },
        "name": {
            "type": "column",
            "mapping": {
                "destination": "name"
            }
        },
        "country": {
            "type": "user",
            "mapping": {
                "destination": "country"
            }
        }
    }
}
{% endhighlight %}

The produced user table will look like this:

|id|name|country|
|---|---|---|
|123|John Doe|UK|
|234|Jane Doe|UK|

See [example [EX134]](https://github.com/keboola/generic-extractor/tree/master/doc/examples/134-user-data-in-mapping).


================================================
File: extend/generic-extractor/configuration/config/jobs/children.md
================================================
---
title: Child Jobs
permalink: /extend/generic-extractor/configuration/config/jobs/children/
---

* TOC
{:toc}

*If new to Generic Extractor, learn about [jobs in our tutorial](/extend/generic-extractor/tutorial/jobs/) first.*
*Use [Parameter Map](/extend/generic-extractor/map/) to help you navigate among various 
configuration options.*

Child jobs allow you to **iterate/traverse over sub-resources of an API resource**. Because child jobs may contain
other child jobs, you may query for sub-sub-resources in a virtually unlimited depth.

For instance, when downloading a list of users, you can download details of each user or a list of orders for each
user. See the Generic Extractor tutorial for a basic [example of using child
jobs](/extend/generic-extractor/tutorial/jobs/#child-jobs).

Apart from two additional fields, `placeholders` and `recursionFilter`, configuring a child job is no different than
configuring [any other job](/extend/generic-extractor/configuration/config/jobs).

<details>
  <summary>Click to see a sample job configuration.</summary>

{% highlight json %}
{
    ...,
    "config": {
        "jobs": [
            {
                "endpoint": "users",
                "method": "get",
                "dataField": "items",
                "dataType": "users",
                "params": {
                    "type": "active"
                },
                "responseFilter": "additional.address/details",
                "responseFilterDelimiter": "/",
                "children": [
                    {
                        "endpoint": "users/{user_id}/orders",
                        "dataField": "items",
                        "recursionFilter": "id>20",
                        "placeholders": {
                            "user_id": "id"
                        }
                    }
                ]
            }
        ]
    }
}
{% endhighlight %}
</details>
<br>

## Placeholders
In a child job, the `endpoint` configuration must contain a **placeholder** enclosed in curly braces `{}`.
For example, the following endpoint defines the placeholder **user-id**:

{% highlight json %}
{
    ...,
    "endpoint": "user/{user-id}"
}
{% endhighlight %}

The **placeholder name** is rather arbitrary (it should not contain any special characters though). To assign it
a value, use the `placeholders` configuration. It is an object whose properties are placeholder names. The value
of each `placeholders` object property is a **property path** in the parent job response.
The placeholder in the child `endpoint` will be replaced by the **value** of that parent property. The property
path is configured relative to the extracted object ([see an example](#accessing-deeply-nested-id)). The child
`endpoint` is configured relative to the [`api.baseUrl` configuration](/extend/generic-extractor/configuration/api/#base-url), 
not relative to the parent endpoint.

The following configuration:

{% highlight json %}
{
    ...,
    "endpoint": "user/{user-id}",
    "placeholders": {
        "user-id": "userId"
    }
}
{% endhighlight %}

means that Generic Extractor sends as many requests to the `/user/XXX` endpoint as there
are result objects in the parent API response. The `XXX` will be replaced by the `userId` value
of each individual response. Placeholders must be used in child jobs so that each child job sends a different API request.

{% comment %}
TODO: Un-comment this when this https://github.com/keboola/generic-extractor/issues/49 is fixed.

The `placeholders` object can be specified as an object whose values are strings with the paths. It is
also possible to use a more complicated structure where the value is another object with `path` property.
The following configuration is equivalent to the above one:

{% highlight json %}
{
    ...,
    "endpoint": "user/{user-id}",
    "placeholders": {
        "user-id": {
            "path": "userId"
        }
    }
}
{% endhighlight %}

This is useful when using [User Defined functions](/extend/generic-extractor/user-functions/)
{% endcomment %}

**Note:** It is technically possible to define a child job without using `placeholders` configuration
or without having a placeholder in the `endpoint`. But then all the child requests would be the same and
that is usually not what you intend to do.

### Placeholder Level
Optionally, the placeholder name may be prefixed by a nesting **level**. Nesting allows you to
refer to properties in other objects than the direct parent. The level is written as the
placeholder name prefix, delimited by a colon `:`. For example, `2:user-id`.

The default level is 1, meaning that the placeholder `user-id` is equivalent to `1:user-id` and
that the property path will be searched in the direct parent of the child job. The level
is counted from the child 'upwards'. Therefore a placeholder `2:user-id` means that
the property path will be searched in the parent of the child parent (two levels up).
See the [corresponding examples](#nesting-level).

## Filter
The configuration option `recursionFilter` allows you to skip some child jobs. This can be
useful in these cases:

- Some resources are not accessible to you and querying them would cause an error in the extraction.
- Some resources return inconsistent or incomplete responses.
- You are not interested in some of the resources and want to speed up the extraction.

The `responseFilter` configuration contains a string expression with a filter condition composed of the following:

- Name of a property from the parent response
- Comparison operator: `<`, `>`, `<=`, `>=`, `==` (equal), `!=` (not equal), `~~` (like), `!~` (unlike)
- Value to compare
- Logical operators: `|` (or), `&` (and); optionally, they may be used to join multiple conditions.

An example response filter may be `type!=employee` or `product.value>150`. To test for an empty value (`null`, `false`, `""`, `0`) do not use any value -- e.g. `type!=` filter matches an empty value.

**Important:** The expression is whitespace sensitive. Therefore `type != employee` filters the `"type "` property
to not contain the value `" employee"` (which is probably not what you intended to do). String comparisons are always
**case sensitive**.

## Examples
This section contains a number of examples using child jobs.

### Basic Example
Let's say that you have an API with two endpoints:

- `/users/` --- Returns a list of users.
- `/user/?` --- Returns user details with a given user ID.

The `users` endpoint returns a response like this:

{% highlight json %}
[
    {
        "id": 123,
        "name": "John Doe"
    },
    {
        "id": 234,
        "name": "Jane Doe"
    }
]
{% endhighlight %}

The `user/123` endpoint returns a response like this:

{% highlight json %}
{
    "id": 123,
    "name": "John Doe",
    "address": {
        "city": "London",
        "country": "UK",
        "street": "Whitehaven Mansions"
    }
}
{% endhighlight %}

Now use the following configuration, retrieving the user list and user
details for each user:

{% highlight json %}
{
    "parameters": {
        "api": {
            "baseUrl": "http://example.com/"
        },
        "config": {
            "outputBucket": "mock-server",
            "jobs": [
                {
                    "endpoint": "users",
                    "children": [
                        {
                            "endpoint": "user/{user-id}",
                            "dataField": ".",
                            "placeholders": {
                                "user-id": "id"
                            }
                        }
                    ]
                }
            ]
        }
    }
}
{% endhighlight %}

The `jobs` section defines a single job for the `users` resource. This job has child jobs for
the `users/{user-id}` resource. The `user-id` placeholder in the endpoint URL is
replaced by the value of the `id` property of each user in the parent job response. This means that
Generic Extractor makes three API calls:

- `users`
- `users/123`
- `users/234`

The [`dataField`](/extend/generic-extractor/configuration/config/jobs/#data-field) is set to a dot to retrieve the 
entire response as a single object. Running Generic Extractor produces the following tables:

users:

|id|name|
|---|---|
|123|John Doe|
|234|Jane Doe|

user__user-id:

|id|name|address\_city|address\_country|address\_street|parent\_id|
|---|---|---|---|---|---|
|123|John Doe|London|UK|Whitehaven Mansions|123|
|234|Jane Doe|St Mary Mead|UK|High Street|234|

Notice that the table representing child resources contains all the responses
merged into a single table; the [usual merging rules](/extend/generic-extractor/configuration/config/jobs/#merging-response) apply.

Also notice that a new column --- `parent_id` was added, containing the **placeholder value** used
to retrieve the resource. The `parent_id` column is not always named `parent_id`.
Its name is created by joining the `parent_` prefix to the **placeholder path**.

To create a friendly name for the table, it is good to use the [dataType](/extend/generic-extractor/configuration/config/jobs/#data-type) 
property (see the next example). The auto-generated name is rather ugly.

See [example [EX021]](https://github.com/keboola/generic-extractor/tree/master/doc/examples/021-basic-child-job).

### Basic Job With Data Type
To avoid automatic table names, it is advisable to always use the `dataType` property for
child jobs:

{% highlight json %}
"jobs": [
    {
        "endpoint": "users",
        "children": [
            {
                "endpoint": "user/{user-id}",
                "dataField": ".",
                "dataType": "user-detail",
                "placeholders": {
                    "user-id": "id"
                }
            }
        ]
    }
]
{% endhighlight %}
In the above configuration, `dataType` is set to `user-detail`, hence you will obtain the
following tables:

users:

|id|name|
|---|---|
|123|John Doe|
|234|Jane Doe|

user-detail:

|id|name|address\_city|address\_country|address\_street|parent\_id|
|---|---|---|---|---|---|
|123|John Doe|London|UK|Whitehaven Mansions|123|
|234|Jane Doe|St Mary Mead|UK|High Street|234|

See [example [EX022]](https://github.com/keboola/generic-extractor/tree/master/doc/examples/022-basic-child-job-datatype).

### Basic Job With Array Values
It is also possible that the main job returns objects which contain direct references 
to the children:

{% highlight json %}
[
    {
        "id": 123,
        "name": "John Doe",
        "children": ["a1", "a2"]
    },
    {
        "id": 234,
        "name": "Jane Doe",
        "children": ["a3"]
    }
]
{% endhighlight %}

The following configuration is the same as in the 
[previous example](/extend/generic-extractor/configuration/config/jobs/children/#basic-example):

{% highlight json %}
"jobs": [
    {
        "endpoint": "users",
        "children": [
            {
                "endpoint": "user/{child-id}",
                "dataField": ".",
                "placeholders": {
                    "child-id": "children"
                }
            }
        ]
    }
]
{% endhighlight %}

The child jobs will iterate both over the returned array of objects and
the array of each `children`. Therefore the following tables will be extracted:

users:

|id|name|
|---|---|
|123|John Doe|
|234|Jane Doe|

user-child:

|id|name|address_city|address_country|address_street|parent_children|
|---|---|---|---|---|---|
|a1|John Doe|London|UK|Whitehaven Mansions|a1|
|a2|Jane Doe|St Mary Mead|UK|High Street|a2|
|a3|Jimmy Doe|Scaryville|Nowhere|Cemetery Lane|a3|

See [example [EX135]](https://github.com/keboola/generic-extractor/tree/master/doc/examples/135-basic-child-job-array).

### Accessing Nested ID
If the placeholder value is nested within the response object, you can use
dot notation to access child properties of the response object. For instance, if the
parent response with a list of users returns a response similar to this:

{% highlight json %}
[
    {
        "name": "John Doe",
        "user-info": {
            "id": 123,
            "active": true
        }
    },
    {
        "name": "Jane Doe",
        "user-info": {
            "id": 234,
            "active": false
        }
    }
]
{% endhighlight %}

you have to modify the `placeholders` definition:

{% highlight json %}
"jobs": [
    {
        "endpoint": "users",
        "children": [
            {
                "endpoint": "user/{user-id}",
                "dataField": ".",
                "dataType": "user-detail",
                "placeholders": {
                    "user-id": "user-info.id"
                }
            }
        ]
    }
]
{% endhighlight %}

Setting the placeholder to `"user-id": "user-info.id"` means that the `user-id` placeholder
will be replaced by the value of the `id` property inside the `user-info` object in the parent response.
If you fail to set a correct path for the placeholder, you will receive an error:

    `No value found for user-id in the parent result. (level: 1)`

When you set the correct path, you will get the following tables:

users:

|name|user-info\_id|user-info\_active|
|---|---|---|
|John Doe|123|1|
|Jane Doe|234||

user detail:

|id|name|address\_city|address\_country|address\_street|parent\_user-info\_id|
|---|---|---|---|---|---|
|123|John Doe|London|UK|Whitehaven Mansions|123|
|234|Jane Doe|St Mary Mead|UK|High Street|234|

Notice that the parent reference column name is the concatenation of the `parent` prefix and
`user-info_id` placeholder path (with special characters replaced by the underscore `_`).

See [example [EX023]](https://github.com/keboola/generic-extractor/tree/master/doc/examples/023-child-job-nested-id).

### Accessing Deeply Nested Id
The placeholder path is configured **relative to** the extracted object. Assume that the
parent endpoint returns a complicated response like this:

{% highlight json %}
{
    "active-users": {
        "items": [
            {
                "name": "John Doe",
                "user-info": {
                    "id": 123,
                    "active": true
                }
            },
            {
                "name": "Jane Doe",
                "user-info": {
                    "id": 234,
                    "active": true
                }
            }
        ],
        "description": "Active Users"
    },
    "inactive-users": {
        "items": [
            {
                "name": "Jimmy Doe",
                "user-info": {
                    "id": 345,
                    "active": false
                }
            }
        ],
        "description": "Inactive Users"
    }
}
{% endhighlight %}

The following job definition extracts the `active-users` array together with the details for each user:

{% highlight json %}
"jobs": [
    {
        "endpoint": "users",
        "dataField": "active-users.items",
        "children": [
            {
                "endpoint": "user/{user-id}",
                "dataField": ".",
                "dataType": "user-detail",
                "placeholders": {
                    "user-id": "user-info.id"
                }
            }
        ]
    }
]
{% endhighlight %}

Notice that the placeholder path remains set to `user-info.id` because it is relative to
the parent object, which itself is located at the path `active-users.items`. This
may be confusing because the endpoint property in that child job is set relative to the
`api.baseUrl` and not to the parent URL.

See [example [EX024]](https://github.com/keboola/generic-extractor/tree/master/doc/examples/024-child-job-deeply-nested-id).

### Naming Conflict
Because a new column is added to the table representing child properties, it is possible that you
run into a naming conflict. That is, if the child response with user details looks like this:

{% highlight json %}
{
    "id": 123,
    "name": "John Doe",
    "parent_id": "admins",
    "address": {
        "city": "London",
        "country": "UK",
        "street": "Whitehaven Mansions"
    }
}
{% endhighlight %}

and you use the following job configuration:

{% highlight json %}
"jobs": [
    {
        "endpoint": "users",
        "children": [
            {
                "endpoint": "user/{user-id}",
                "dataField": ".",
                "placeholders": {
                    "user-id": "id"
                }
            }
        ]
    }
]
{% endhighlight %}

the output for the child job will contain the column `parent_id`. At the same time, Generic Extractor will attempt
to create the column `parent_id` with the placeholder value, overwriting the original column. That column will be lost.

See [example [EX025]](https://github.com/keboola/generic-extractor/tree/master/doc/examples/025-naming-conflict).

### Nesting Level
By default, the placeholder value is taken from the object retrieved in the parent job. As long as the child
jobs are nested only one level deep, there is no other option anyway. Let's see what happens with a deeper nesting.

Assume that you have an API with the following endpoints:

- `/users/` --- Returns a list of users.
- `/user/?` --- Returns user details with given user ID.
- `/user/?/orders` --- Returns a list of user orders.
- `/user/?/orders/?` --- Returns order detail with given user and order ID.

The `users` endpoint returns a response like this:

{% highlight json %}
[
    {
        "userId": 123,
        "name": "John Doe"
    },
    {
        "userId": 234,
        "name": "Jane Doe"
    }
]
{% endhighlight %}

The `user/123` endpoint returns a response like this:

{% highlight json %}
{
    "userId": 123,
    "name": "John Doe",
    "description": "Good ol' father John"
}
{% endhighlight %}

The `user/123/orders` endpoint returns a response like this:

{% highlight json %}
[
    {
        "orderId": "1234",
        "price": "$12"
    },
    {
        "orderId": "1345",
        "price": "$1212"
    }
]
{% endhighlight %}

The `user/123/order/1234` endpoint returns a response like this:

{% highlight json %}
{
    "orderId": 1234,
    "price": "$12",
    "timestamp": "2017-05-06 8:21:45",
    "state": "cancelled"
}
{% endhighlight %}

Then you can create a job configuration with three nested children to retrieve all the API resources:

{% highlight json %}
"jobs": [
    {
        "endpoint": "users",
        "children": [
            {
                "endpoint": "user/{1:user-id}",
                "dataField": ".",
                "dataType": "user-detail",
                "placeholders": {
                    "1:user-id": "userId"
                },
                "children": [
                    {
                        "endpoint": "user/{2:user-id}/orders",
                        "dataType": "orders",
                        "placeholders": {
                            "2:user-id": "userId"
                        },
                        "children": [
                            {
                                "endpoint": "user/{3:user-id}/order/{1:order-id}",
                                "dataType": "order-detail",
                                "dataField": ".",
                                "placeholders": {
                                    "3:user-id": "userId",
                                    "1:order-id": "orderId"
                                }
                            }
                        ]
                    }
                ]
            }
        ]
    }
]
{% endhighlight %}

The `jobs` configuration retrieves all users from the `users` API endpoint. The first child retrieves
details for each user (from `user/?` endpoint) and stores them in the `user-detail` table. The second
child retrieves each user orders (from `user/?/orders` endpoint) and stores them in the `orders` table.
Finally, the deepest nested child returns details of each order (for each user) from the
`user/?/order/?` endpoint and stores them in the `order-detail` table. Therefore the following four tables
will be produced:

users:

|userId|name|
|---|---|
|123|John Doe|
|234|Jane Doe|

user-detail:

|userId|name|description|parent\_userId|
|---|---|---|---|
|123|John Doe|Good ol' father John|123|
|234|Jane Doe|Good young mommy Jenny|234|

orders:

|orderId|price|parent\_userId|
|---|---|---|
|1234|$12|123|
|1345|$1212|123|
|2345|$42|234|

order-detail:

|orderId|price|timestamp|state|parent\_userId|parent\_orderId|
|---|---|---|---|---|---|
|1234|$12|2017-05-06 8:21:45|cancelled|123|1234|
|1345|$1212|2017-12-24 12:30:53|delivered|123|1345|
|2345|$42|2017-01-12 2:12:43|cancelled|234|2345|

Notice that each table contains additional columns with the placeholder property path prefixed with `parent_`.

See [example [EX026]](https://github.com/keboola/generic-extractor/tree/master/doc/examples/026-basic-deeper-nesting).

### Nesting Level Alternative
Because the required user and order IDs are present in multiple requests (in the list and in the detail), there
are multiple ways how the jobs may be configured. For example, the following configuration produces the
exact same result as the above configuration:

{% highlight json %}
"jobs": [
    {
        "endpoint": "users",
        "children": [
            {
                "endpoint": "user/{user-id}",
                "dataField": ".",
                "dataType": "user-detail",
                "placeholders": {
                    "user-id": "userId"
                },
                "children": [
                    {
                        "endpoint": "user/{user-id}/orders",
                        "dataType": "orders",
                        "children": [
                            {
                                "endpoint": "user/{user-id}/order/{order-id}",
                                "dataType": "order-detail",
                                "dataField": ".",
                                "placeholders": {
                                    "order-id": "orderId"
                                }
                            }
                        ]
                    }
                ]
            }
        ]
    }
]
{% endhighlight %}

Even though the above configuration is less explicit and not really recommended, it is still acceptable.
Placeholders are defined globally, which means that the second nested child job to `user/{user-id}/orders` does
not define any because it relies on those defined by its parent job (which happen to be correct). Also the
deepest child defines only the `order-id` placeholder because, again, the `user-id` placeholder was defined in
some of its parents. 

Although the placeholders are defined globally, the ones defined in child jobs override the ones in the parent
jobs. For example, in the following (probably **very incorrect**) configuration, the `1:user-id` placeholder in 
the deepest child will really contain the `orderId` value.

{% highlight json %}
"jobs": [
    {
        "endpoint": "users",
        "children": [
            {
                "endpoint": "user/{1:user-id}",
                "dataField": ".",
                "dataType": "user-detail",
                "placeholders": {
                    "1:user-id": "userId"
                },
                "children": [
                    {
                        "endpoint": "user/{2:user-id}/orders",
                        "dataType": "orders",
                        "placeholders": {
                            "2:user-id": "userId"
                        },
                        "children": [
                            {
                                "endpoint": "user/{1:user-id}/order/{2:order-id}",
                                "dataType": "order-detail",
                                "dataField": ".",
                                "placeholders": {
                                    "1:user-id": "orderId",
                                    "2:order-id": "userId"
                                }
                            }
                        ]
                    }
                ]
            }
        ]
    }
]
{% endhighlight %}

See [example [EX027]](https://github.com/keboola/generic-extractor/tree/master/doc/examples/027-basic-deeper-nesting-alternative).

### Deep Job Nesting
Let's look at how to retrieve more nested API resources:

{% highlight json %}
"jobs": [
    {
        "endpoint": "users",
        "children": [
            {
                "endpoint": "user/{1:user-id}",
                "dataField": ".",
                "dataType": "user-detail",
                "placeholders": {
                    "1:user-id": "id"
                },
                "children": [
                    {
                        "endpoint": "user/{2:user-id}/orders",
                        "dataType": "orders",
                        "placeholders": {
                            "2-user-id": "id"
                        },
                        "children": [
                            {
                                "endpoint": "user/{3:user-id}/order/{1:order-id}",
                                "dataType": "order-detail",
                                "dataField": ".",
                                "placeholders": {
                                    "3:user-id": "id",
                                    "1:order-id": "id"
                                },
                                "children": [
                                    {
                                        "endpoint": "user/{4:user-id}/order/{2:order-id}/items",
                                        "dataType": "order-items",
                                        "placeholders": {
                                            "4:user-id": "id",
                                            "2:order-id": "id"
                                        },
                                        "children": [
                                            {
                                                "endpoint": "user/{5:user-id}/order/{3:order-id}/item/{1:item-id}",
                                                "dataType": "item-detail",
                                                "dataField": ".",
                                                "placeholders": {
                                                    "5:user-id": "id",
                                                    "3:order-id": "id",
                                                    "1:item-id": "id"
                                                }
                                            }
                                        ]
                                    }
                                ]
                            }
                        ]
                    }
                ]
            }
        ]
    }
]
{% endhighlight %}

The above configuration assumes that all API resources simply have an `id` property (unlike in the
previous example, where the users had `userId` and the orders had `orderId`). This makes the configuration look
rather cryptic. Read the deepest child placeholder configuration

    "5:user-id": "id",
    "3:order-id": "id",
    "1:item-id": "id"

as:

- Go five levels up, pick the `id` property from the response and put it in place of the `user-id` in the endpoint URL.
- Go three levels up, pick the `id` property from the response and put it in place of the `order-id` in the endpoint URL.
- Go one level up, pick the `id` property from the response and put it in place of the `item-id` in the endpoint URL.

**Important:** Once you run into using placeholders with the same property path, their order becomes important.
This is because the property path is used as the name of an additional column in the extracted table. Because
the property path is `id` in all cases, it will lead to the column `parent_id` in all cases, and therefore it
will get overwritten. With the above configuration, the following `item-detail` table will be produced:

|id|code|name|parent_id|
|---|---|---|---|
|345|PA10|Pick Axe|345|
|456|TB20|Tooth Brush|456|

where the `parent_id` column refers to the `1:item-id` placeholder. If you used this placeholder configuration:

{% highlight json %}
"placeholders": {
    "1:item-id": "id",
    "3:order-id": "id",
    "5:user-id": "id"
}
{% endhighlight %}

you would obtain the following `item-detail` table:

|id|code|name|parent_id|
|---|---|---|---|
|345|PA10|Pick Axe|123|
|456|TB20|Tooth Brush|123|

where the `parent_id` column refers the `5:user-id` placeholder.

See [example [EX028]](https://github.com/keboola/generic-extractor/tree/master/doc/examples/028-advanced-deep-nesting).

### Nested Array

Suppose now that the endpoint `/users` returns a more complicated response:

{% highlight json %}
{
    "members": {
        "description": "Active System Members",
        "tags": [
            "active",
            "crm"
        ],
        "count": "2",
        "items": [
            {
                "name": "John Doe",
                "user-info": {
                    "id": 123,
                    "active": true
                }
            },
            {
                "name": "Jane Doe",
                "user-info": {
                    "id": 234,
                    "active": false
                }
            }
        ]
    }
}
{% endhighlight %}

The API also has an endpoint `/user/{userId}` which returns details about a specific user. If 
you want to obtain all the fields from the above response and also the details about each user, 
you have to create a rather tricky configuration. Even though you may be tempted to start with 
the following job configuration:

{% highlight json %}
{
    "endpoint": "users",
    "dataField": "."
}
{% endhighlight %}

this is not possible because the root of the response in the `members` field is not 
an array and therefore it cannot create child jobs. For that reason the job configuration must start with:

{% highlight json %}
{
    "endpoint": "users",
    "dataField": "members.items",
}
{% endhighlight %}

The `members.items` is an array which now can be used as a source for child jobs:

{% highlight json %}
{
    "endpoint": "users",
    "dataField": "members.items",
    "dataType": "users",
    "children": [
        {
            "endpoint": "user/{user-id}",
            "dataField": ".",
            "dataType": "user-detail",
            "placeholders": {
                "user-id": "user-info.id"
            }
        }
    ]
}
{% endhighlight %}

Notice that the placeholder path (`user-info.id`) is entered relative to the `dataField` setting
(`members.items`). Now, to extract the other fields from the `/users` response (other than `member.items`), 
create another job:

{% highlight json %}
{
    "endpoint": "users",
    "dataField": ".",
    "dataType": "users-2"
}
{% endhighlight %}

Note that the `dataType` must be different than in the first job because the structure of the response is different.
You will receive a number of tables:

users (first job):

|name|user-info\_id|user-info\_active|
|---|---|---|
|John Doe|123|1|
|Jane Doe|234||

user-detail (first job children):

|id|name|address\_city|address\_country|address\_street|parent\_user-info\_id|
|---|---|---|---|---|---|
|123|John Doe|London|UK|Whitehaven Mansions|123|
|234|Jane Doe|St Mary Mead|UK|High Street|234|

users-2 (second job):

|members\_description|members\_tags|members\_count|members\_items|
|---|---|---|---|
|Active System Members|users-2.members\_c6eb0647a7f2fb2cbe02ba62d56e3312|2|users-2.members\_c6eb0647a7f2fb2cbe02ba62d56e3312|

users-2\_members\_items (second job, generated from array node `items`):

|name|user-info\_id|user-info\_active|JSON\_parentId|
|---|---|---|---|
|John Doe|123|1|users-2.members_c6eb0647a7f2fb2cbe02ba62d56e3312|
|Jane Doe|234||users-2.members_c6eb0647a7f2fb2cbe02ba62d56e3312|

The `users-2\_members\_items` contains the same results as the `users` table, but it also contains the 
`JSON\_parentId` column which allows you to link the user list to the list description in the `users-2` table.
This makes the response in the `users` table quite useless, but the job is still required to generate
the child jobs to obtain the `user-detail` table. See [example [EX106]](https://github.com/keboola/generic-extractor/tree/master/doc/examples/106-child-jobs-array).

### Simple Filter
Let's assume that you have an API which has two endpoints:

- `users` --- Returns a list of users.
- `users/?` --- Returns a user detail.

The `users` endpoint returns a response like this:

{% highlight json %}
[
    {
        "id": 123,
        "name": "John Doe",
        "role": "parent",
        "type": "admin"
    },
    {
        "id": 234,
        "name": "Jane Doe",
        "role": "parent",
        "type": "administrator"
    },
    {
    	"id": 345,
    	"name": "Jimmy Doe",
    	"role": "child",
    	"type": "user"
    },
    {
    	"id": 456,
    	"name": "Janet Doe",
    	"role": "child",
    	"type": "user"
    }
]
{% endhighlight %}

The `user/123` endpoint returns a response like this:

{% highlight json %}
{
    "id": 123,
    "name": "John Doe",
    "userRole": "parent",
    "userType": "admin",
    "description": "Father John"
}
{% endhighlight %}

A simple child filter can be then set up using the following `jobs` configuration:

{% highlight json %}
"jobs": [
    {
        "endpoint": "users",
        "children": [
            {
                "endpoint": "user/{user-id}",
                "dataField": ".",
                "dataType": "user-detail",
                "placeholders": {
                    "user-id": "id"
                },
                "recursionFilter": "role==parent"
            }
        ]
    }
]
{% endhighlight %}

The `recursionFilter` setting will cause Generic Extractor to query only the sub-resources for which the
filter evaluates to true. The filter property name `type` refers to the parent response, but it
filters only the children. So, the following tables will be returned:

users:

|id|name|role|type|
|---|---|---|---|
|123|John Doe|parent|admin|
|234|Jane Doe|parent|administrator|
|345|Jimmy Doe|child|user|
|456|Janet Doe|child|user|

user-detail:

|id|name|userRole|userType|description|parent\_id|
|---|---|---|---|---|---|
|123|John Doe|parent|admin|Father John|123|
|234|Jane Doe|parent|administrator|Mother Jane|234|

You can see from the above tables that the filter is applied to the child results only so that
the details are retrieved only for the desired users.

See [example [EX029]](https://github.com/keboola/generic-extractor/tree/master/doc/examples/029-simple-filter).

### Not Like Filter
Apart from the standard comparison operators, the recursive filter allows to use
a **like** comparison operator `~`. It expects that the value contains a placeholder `%`,
which matches any number of characters. The following configuration:

{% highlight json %}
"jobs": [
    {
        "endpoint": "users",
        "children": [
            {
                "endpoint": "user/{user-id}",
                "dataField": ".",
                "recursionFilter": "type!~%min%",
                "dataType": "user-detail",
                "placeholders": {
                    "user-id": "id"
                }
            }
        ]
    }
]
{% endhighlight %}

filters out all child resources not containing the string `min` in their parent type property.
The expression `%min%` matches any string which contains any number of characters (including none)
before and after the string `min`. The operator `!~` is negative like, therefore the
following `user-detail` table will be extracted:

|id|name|userRole|userType|description|parent\_id|
|---|---|---|---|---|---|
|345|Jimmy Doe|child|user|Sonny Jimmy|345|
|456|Janet Doe|child|user|Missy Jennie|456|

See [example [EX030]](https://github.com/keboola/generic-extractor/tree/master/doc/examples/030-not-like-filter).

### Combining Filters
Multiple filters can be combined using the
[logical](https://en.wikipedia.org/wiki/Boolean_algebra#Basic_operations) `&` (and) and `|` (or) operators.
For example, the following configuration retrieves details for users who have
both `id < 400` and `role = child`:

{% highlight json %}
"jobs": [
    {
        "endpoint": "users",
        "children": [
            {
                "endpoint": "user/{user-id}",
                "dataField": ".",
                "dataType": "user-detail",
                "recursionFilter": "id<400&role==child",
                "placeholders": {
                    "user-id": "id"
                }
            }
        ]
    }
]
{% endhighlight %}

The following `user-detail` will be produced:

|id|name|userRole|userType|description|parent\_id|
|---|---|---|---|---|---|
|345|Jimmy Doe|child|user|Sonny Jimmy|345|

See [example [EX031]](https://github.com/keboola/generic-extractor/tree/master/doc/examples/031-combined-filter).

### Multiple Filter Combinations
Although you can join a multiple filter expression with logical operators as in the
above example, there is no support for parentheses. The following configuration
combines multiple filters:

{% highlight json %}
"jobs": [
    {
        "endpoint": "users",
        "recursionFilter": "role=parent|id>300&id<400",
        "children": [
            {
                "endpoint": "user/{user-id}",
                "dataField": ".",
                "placeholders": {
                    "user-id": "id"
                }
            }
        ]
    }
]
{% endhighlight %}

The precedence of logical operators is defined so that the first operator occurring in the
expression takes precedence over the second. That is to say that the condition `role=parent|id>300&id<400`
is interpreted as `role=parent|(id>300&id<400)` because the operator `|` takes precedence
over the `&` operator. The condition `id>300&id<400|role==parent` is interpreted as
`id>300&(id<400|role==parent)` because the `&` operator takes precedence over the `|` operator.

With the above configuration, the following `user-detail` table will be produced:

|id|name|userRole|userType|description|parent\_id|
|---|---|---|---|---|---|
|123|John Doe|parent|admin|Father John|123|
|234|Jane Doe|parent|administrator|Mother Jane|234|
|345|Jimmy Doe|child|user|Sonny Jimmy|345|

Because the described system of operator precedence may lead to rather unusual behaviour,
we recommend that you keep the recursive filter simple.

See [example [EX032]](https://github.com/keboola/generic-extractor/tree/master/doc/examples/032-multiple-combined-filter).


================================================
File: extend/generic-extractor/configuration/config/jobs/index.md
================================================
---
title: Jobs
permalink: /extend/generic-extractor/configuration/config/jobs/
---

* TOC
{:toc}

*If new to Generic Extractor, learn about [jobs in our tutorial](/extend/generic-extractor/tutorial/jobs/) first.*
*Use [Parameter Map](/extend/generic-extractor/map/) to help you navigate among various
configuration options.*

The jobs section of the extraction configuration contains **descriptions of the API resources to be
extracted**. The `jobs` configuration property is an array of processed API endpoints. A
**single job represents a single [API resource](/extend/generic-extractor/tutorial/rest)**.

<details>
  <summary>Click to see a sample job configuration.</summary>

{% highlight json %}
{
    ...,
    "config": {
    "jobs": [
        {
                "endpoint": "users",
                "method": "get",
                "dataField": "items",
                "dataType": "users",
                "params": {
                    "type": "active"
                },
                "responseFilter": "additional.address/details",
                "responseFilterDelimiter": "/",
                "children": [
                    {
                        "endpoint": "users/{user_id}/orders",
                        "dataField": "items",
                        "recursionFilter": "id>20",
                        "placeholders": {
                            "user_id": "id"
                        }
                    }
                ]
            }
        ]
    }
}
{% endhighlight %}
</details>
<br>
Generic Extractor reads and processes the responses from the API endpoints in a pretty complex
way. Each response is processed in the following steps:

1. Receive the response JSON.
2. Find the relevant object in the response as specified by the [`dataField` property](#data-field) or default rules.
3. Flatten the object structure into one or more tables.
4. Create the required tables in Storage and load data into them.

## Merging Responses
The first two steps are the responsibility of [Jobs](/extend/generic-extractor/configuration/config/jobs/)
resulting in an array of objects. Generic Extractor then tries to find a common super-set of
properties of all objects, for example, with the following response:

{% highlight json %}
[
    {
        "id": 123,
        "name": "foo",
        "color": "green"
    },
    {
        "id": 321,
        "name": "bar",
        "size": "large"
    }
]
{% endhighlight %}

The super-set of object properties consists of `id`, `name`, `color` and `size`. In the Generic Extractor
configuration, this is [referred to as **`dataType`**](#data-type). If the `dataType` configuration is not set, a
name is automatically generated. Merging the object structure requires that the objects are compatible.

The responses are merged into type-less tables. This means that values `42` and `apples` are perfectly compatible
because they get converted to a string. Also, the scalar and array values are compatible because the
scalar is [upgraded to an array](#upgrading-to-array). The following are incompatible combinations:

- Scalar (simple) and object values
- Object and array values

For example, this would not be allowed:

{% highlight json %}
[
    {
        "id": 123,
        "name": "foo",
        "color": "green"
    },
    {
        "id": 321,
        "name": "bar",
        "color": {
            "items": ["red", "blue"]
        }
    }
]
{% endhighlight %}

If you want to process the above response, use the
[`responseFilter` setting](/extend/generic-extractor/configuration/config/jobs/#response-filter).

## Endpoint
The endpoint property is **required** and represents the URL of the resource. It can be either of the following:

- URL fragment relative to the [`baseURL` property](/extend/generic-extractor/configuration/api/#baseurl) of the API definition
- Absolute URL from the domain specified in the [`baseURL` property](/extend/generic-extractor/configuration/api/#baseurl) of the API definition
- Full absolute URL

Assume the following [API definition](/extend/generic-extractor/configuration/api/):

{% highlight json %}
"api": {
    "baseURL": "https://example.com/3.0/"
}
{% endhighlight %}

### Relative URL Fragment
The relative endpoint **must not start** with a slash; so, with
`endpoint` set to  `campaign`, the final resource URL would be
`https://example.com/3.0/campaign`.

### Absolute Domain URL
The absolute endpoint **must start** with a slash. So, with `/endpoint`
set to `campaign`, the final resource URL would be `https://example.com/campaign`.
This means that the path part specified in the `baseURL` is ignored and fully
replaced by the value specified in `endpoint`.

### Absolute Full URL
The full absolute URL must start with a protocol. So, with the endpoint set to
`https://eu.example.com/campaign`, this would be the final resource URL
and the path specified in the `baseURL` is completely ignored.

### Specifying Endpoint
The following table summarizes possible outcomes:

|`baseURL`|`endpoint`|actual URL|
|---------|----------|----------|
|`https://example.com/3.0/`|`campaign`|`https://example.com/3.0/campaign`|
|`https://example.com/3.0/`|`campaign/`|`https://example.com/3.0/campaign/`|
|`https://example.com/3.0/`|`/1.0/campaign`|`https://example.com/1.0/campaign`|
|`https://example.com/3.0/`|`https://eu.example.com/3.0/`|`https://eu.example.com/3.0/campaign`|
|`https://example.com/`|`campaign`|`https://example.com/campaign`|
|`https://example.com`|`campaign`|`https://example.comcampaign`|
|`https://example.com/`|`https://elpmaxe.com/endpoint`|`https://elpmaxe.com/endpoint`|

It is highly recommended to use the relative URL fragments. This means that the
`baseURL` property of the `api` section **must end** with a slash.

Use the other two options for handling exceptions in the API extraction (for instance, falling back
to an older API version). Note that using a different domain (or even a base path) may
interfere with the authentication --- depending on the specification of the target API.

Also, closely follow the target API specification regarding trailing slashes. For some APIs,
both `https://example.com/3.0/campaign` and `https://example.com/3.0/campaign/` URLs may
be accepted and valid. For other APIs, however, only one version may be supported.

## Request Parameters
The `params` section defines [request parameters](/extend/generic-extractor/tutorial/rest). They
may be optional or required, depending on the target API specification. The `params` section is
an object with arbitrary properties (or, more precisely, parameters understood by the target
API). It is also allowed to use [function calls](/extend/generic-extractor/functions/).

Assume that `api.baseUrl` is set to `https://example.com/3.0/`, `jobs[].endpoint`
is set to `mock-api` and that the `param` parameters are set as follows:

{% highlight json %}
    "params": {
        "startDate": "2016-01-20",
        "types": ["new", "active", "finished"],
        "filter": {
            "query": "q=user:johnDoe",
            "tags": {
                "first": true,
                "second": false
            }
        }
    }
{% endhighlight %}

See our [examples](/extend/generic-extractor/configuration/config/jobs/#examples-with-http-methods-and-parameters).

## Method
The `method` parameter defines the [HTTP request method](/extend/generic-extractor/tutorial/rest/).
The following are the allowed values:

- `GET` (default)
- `POST`
- `FORM`

### GET
The HTTP method encodes the parameters in the URL. Therefore the above `params` definition gets transformed
in the following URL:

    https://example.com/3.0/mock-api?startDate=2016-01-20&types%5B0%5D=new&types%5B1%5D=active&types%5B2%5D=finished&filter%5Bquery%5D=q%3Duser%3AjohnDoe&filter%5Btags%5D%5Bfirst%5D=1&filter%5Btags%5D%5Bsecond%5D=0

or, in a more readable [URLDecoded](https://urldecode.org/) form:

    https://example.com/3.0/mock-api?/mock-server/web/users/12/orders/2/tickets/000/comments?startDate=2016-01-20&types[0]=new&types[1]=active&types[2]=finished&filter[query]=q=user:johnDoe&filter[tags][first]=1&filter[tags][second]=0

### POST
The HTTP POST method sends the parameters in the request body. They are sent as a JSON object in the same form
as entered in the configuration. For the above defined `params` property, the request body would be:

{% highlight json %}
{
    "startDate": "2016-01-20",
    "types": ["new", "active", "finished"],
    "filter": {
        "query": "q=user:johnDoe",
        "tags": {
            "first": true,
            "second": false
        }
    }
}
{% endhighlight %}

Also, the `Content-Type: application/json` HTTP header is added to the request.
See our [examples](/extend/generic-extractor/configuration/config/jobs/#examples-with-http-methods-and-parameters).

### FORM
The `FORM` method type sends the request the same way the HTTP POST method does. However,
the parameters from the `param` object are encoded as form data, mimicking the request being sent by
a web form. This method **does not support nested objects** in the `param` object.
For example, the following `params` field:

{% highlight json %}
    "params": {
        "startDate": "2016-01-20",
        "types": ["new", "active", "finished"]
    }
{% endhighlight %}

will be sent as the following POST request body:

    startDate=2016-01-20&types%5B0%5D=new&types%5B1%5D=active&types%5B2%5D=finished

or, in a more readable [URLDecoded](https://urldecode.org/) form:

   startDate=2016-01-20&types[0]=new&types[1]=active&types[2]=finished

Also, the `Content-Type: application/x-www-form-urlencoded` HTTP header will be added to the request.

## Data Type
The `dataType` parameter assigns a name to the object(s) obtained from the endpoint.
Setting it is optional. If not set, a name will be generated automatically from the `endpoint`
value and parent jobs.

Data types are used in [mappings](/extend/generic-extractor/configuration/config/mappings/) and for naming output
tables within their [output buckets](/extend/generic-extractor/configuration/config/#output-bucket).

Note that you can use the same `dataType` for multiple resources, provided that the result objects may
be [merged into a single one](/extend/generic-extractor/configuration/config/mappings/). This can be used,
for example, in a situation where two API endpoints return the same resource:

{% highlight json %}
    "jobs": [
        {
            "endpoint": "solved-tickets/",
            "dataType": "tickets"
        },
        {
            "endpoint": "unsolved-tickets/",
            "dataType": "tickets"
        }
    ]
{% endhighlight %}

In the above case, only a single `tickets` table will be produced in the output bucket. It
will contain records from both API endpoints.

## Data Field
The `dataField` parameter is used to determine what part of the API **response** will be
extracted. The following rules apply by default:

- If the response is a single *array*, use the whole response.
- If the response is an [object](/extend/generic-extractor/tutorial/json/) and there is a single *array* property,
use that property.
- If the response is an object with none or multiple array properties, require that `dataField` is configured.

Apart from cases where required, the `dataField` configuration may also be set to override the
above default behaviour. The `dataField` parameter contains a
[dot separated path](/extend/generic-extractor/tutorial/json/) to the response property you want to
extract. The `dataField` parameter may be written in two ways --- either as a simple string or
as an object with the `path` property. For instance, these two configurations are equivalent:

{% highlight json %}
    "jobs": [
        {
            "endpoint": "solved-tickets/",
            "dataField": "tickets"
        }
    ]
{% endhighlight %}

{% highlight json %}
    "jobs": [
        {
            "endpoint": "solved-tickets/",
            "dataField": {
                "path": "tickets"
            }
        }
    ]
{% endhighlight %}

### Data Field Delimiter
The path to the response property is by default expected to be dot separated. That is --- a path
`members.active` refers to the property `active` nested inside the property `members`. If you need to refer to a
property containing a dot, you have to change the data field path delimiter to some other character. This can be
done using the `delimiter` property:

{% highlight json %}
    "jobs": [
        {
            "endpoint": "solved-tickets/",
            "dataField": {
                "path": "members.active",
                "delimiter": "|"
            }
        }
    ]
{% endhighlight %}

The above configuration refers to the property named `members.active`. To refer to the property `items` nested
inside the property `members.active` you have to use:

{% highlight json %}
    "jobs": [
        {
            "endpoint": "solved-tickets/",
            "dataField": {
                "path": "members.active|items",
                "delimiter": "|"
            }
        }
    ]
{% endhighlight %}

The `delimiter` character is completely arbitrary but must be something that is not used in the property names in the response.
See [example [EX120]](https://github.com/keboola/generic-extractor/tree/master/doc/examples/120-datafield-separator).

## Response Filter
The `responseFilter` option allows you to skip parts of the API response from processing. This can
be useful in these cases:

- You do not want to flatten the JSON structure using the default
[JSON Parser](/extend/generic-extractor/configuration/config/jobs/#merging-responses) (as in the above examples).
- The API response is inconsistent and the objects cannot be flattened.

The value of the `responseFilter` property is either a path to a property in the response, or
an array of such paths. The path is dot-separated unless set otherwise in the `responseFilterDelimiter` configuration.
If you want to refer to the items of an array, use `[]` --- see an [example below](#skip-flattening-in-nested-objects).
The same result can be achieved using `forceType` parameter in
[column mapping](/extend/generic-extractor/configuration/config/mappings/#column-mapping).

## Children
The `children` configuration allows you to retrieve sub-resources of the processes API resource.
These **child jobs** (**nested jobs**) are executed for each object retrieved from the
parent response. The definition of child jobs is the same as the definition of parent jobs,
except for **placeholders**. The children configuration is described in a
[separate article](/extend/generic-extractor/configuration/config/jobs/children/).

## Scroller

The `scroller` parameter assigns a predefined scroller when
[`multiple` pagination](/extend/generic-extractor/configuration/api/pagination/multiple/) is used,
and is pointless when the `multiple` pagination method is not used.

If `scroller` is not set, the pagination method specified in the [`api` configuration](/extend/generic-extractor/configuration/api/pagination/)
is used. If there is no pagination method specified, the job has no pagination.

## Examples
The following examples show how simple objects are extracted from different objects.

### Simple array
To extract data from the following API response:

{% highlight json %}
[
    {
        "id": 123,
        "name": "John Doe",
        "married": true
    },
    {
        "id": 234,
        "name": "Jane Doe",
        "married": false
    }
]
{% endhighlight %}

do not set the `dataField` parameter at all, or set it to an empty string (`"dataField": ""`).
The following table will be extracted:

|id|name|married|
|--|---|---|
|123|John Doe|1|
|234|Jane Doe||

Notice that the [boolean value](/extend/generic-extractor/tutorial/json/#data-values) `married` is converted
to `1` when true and left empty otherwise (`false` and `null`).

See [example [EX001]](https://github.com/keboola/generic-extractor/tree/master/doc/examples/001-simple-job).

### Array within an object
To extract data from the following API response:

{% highlight json %}
{
    "users": [
        {
            "id": 123,
            "name": "John Doe"
        },
        {
            "id": 234,
            "name": "Jane Doe"
        }
    ]
}
{% endhighlight %}

do not set the `dataField` parameter at all, or set it to an empty string or to the value `users`
(`"dataField": ""` or `"dataField": "users"`).
The following table will be extracted:

|id|name|
|--|----|
|123|John Doe|
|234|Jane Doe|

See [example [EX002]](https://github.com/keboola/generic-extractor/tree/master/doc/examples/002-array-in-object).

### Multiple arrays within an object
To extract data from the following API response:

{% highlight json %}
{
    "users": [
        {
            "id": 123,
            "name": "John Doe"
        },
        {
            "id": 234,
            "name": "Jane Doe"
        }
    ],
    "userTypes": [
        "member",
        "guest"
    ]
}
{% endhighlight %}

set the `dataField` parameter to the value `users` (`"dataField": "users"`). Not setting the
`dataField` parameter would result in an error
(`More than one array found in the response! Use the 'dataField' parameter to specify a key to the data array.`).
The following table will be extracted:

|id|name|
|--|----|
|123|John Doe|
|234|Jane Doe|

See [example [EX003]](https://github.com/keboola/generic-extractor/tree/master/doc/examples/003-multiple-arrays-in-object).

### Array within a nested object
To extract data from the following API response:

{% highlight json %}
{
    "members": {
        "active": [
            {
                "id": 123,
                "name": "John Doe"
            },
            {
                "id": 234,
                "name": "Jane Doe"
            }
        ],
        "inactive": [
            {
                "id": 345,
                "name": "Jimmy Doe"
            }
        ]
    }
}
{% endhighlight %}

set the `dataField` parameter to the value `members.active` (`"dataField": "members.active"`). Not setting the
`dataField` parameter would result in a warning (`No data array found in the response!`).
The following table will be extracted:

|id|name|
|--|----|
|123|John Doe|
|234|Jane Doe|

See [example [EX004]](https://github.com/keboola/generic-extractor/tree/master/doc/examples/004-array-in-nested-object).

### Two arrays within a nested object
To extract both `active` and `inactive` arrays from the above API response, use two jobs:

{% highlight json %}
{
    "members": {
        "active": [
            {
                "id": 123,
                "name": "John Doe"
            },
            {
                "id": 234,
                "name": "Jane Doe"
            }
        ],
        "inactive": [
            {
                "id": 345,
                "name": "Jimmy Doe"
            }
        ]
    }
}
{% endhighlight %}

In the first job, set the `dataField` parameter to the value `members.active`. In the second job, set
the `dataField` parameter to the value `members.inactive`. The entire `jobs` section will look like this:

{% highlight json %}
    "jobs": [
        {
            "endpoint": "users-5",
            "dataField": "members.active"
        },
        {
            "endpoint": "users-5",
            "dataField": "members.inactive"
        }
    ]
{% endhighlight %}


The following table will be extracted:

|id|name|
|--|----|
|123|John Doe|
|234|Jane Doe|
|345|Jimmy Doe|

See [example [EX005]](https://github.com/keboola/generic-extractor/tree/master/doc/examples/005-two-arrays-in-nested-object).

### Simple object
You may encounter an API response like this:

{% highlight json %}
{
    "id": 123,
    "name": "John Doe"
}
{% endhighlight %}

You have to set the `dataField` parameter to the value `.` (`"dataField": "."`). Not setting the
`dataField` parameter would result in a warning (`No data array found in the response!`) and no data extracted.
The following table will be extracted:

|id|name|
|--|----|
|123|John Doe|

See [example [EX006]](https://github.com/keboola/generic-extractor/tree/master/doc/examples/006-simple-object).

### Nested object
You may encounter an API response like this:

{% highlight json %}
{
    "user": {
        "id": 123,
        "name": "John Doe"
    }
}
{% endhighlight %}

Set the `dataField` parameter to the value `user` (`"dataField": "user"`). Not setting the
`dataField` parameter would result in a warning (`No data array found in the response!`) and no data extracted.
The following table will be extracted:

|id|name|
|--|----|
|123|John Doe|

See [example [EX007]](https://github.com/keboola/generic-extractor/tree/master/doc/examples/007-nested-object).

### Single object in an array
You may encounter an API response like this:

{% highlight json %}
{
    "member": {
        "history": [
            {
                "id": 123,
                "name": "John Doe",
                "version": 2
            },
            {
                "id": 123,
                "name": "Jonh Doe",
                "version": 1
            }
        ]
    }
}
{% endhighlight %}

To extract the first item from the `history` array, set the `dataField` parameter to the value `member.history.0`.
The following table will be extracted:

|id|name|version|
|--|----|-------|
|123|John Doe|2 |

See [example [EX008]](https://github.com/keboola/generic-extractor/tree/master/doc/examples/008-single-object-in-array).

### Nested array
You may encounter an API response like this:

{% highlight json %}
{
    "members": [
        {
            "type": "active",
            "items": [
                {
                    "id": 123,
                    "name": "John Doe"
                },
                {
                    "id": 234,
                    "name": "Jane Doe"
                }
            ]
        },
        {
            "type": "inactive",
            "items": [
                {
                    "id": 345,
                    "name": "Jimmy Doe"
                }
            ]
        }
    ]
}
{% endhighlight %}

To extract the `items` from the `members` array, set the `dataField` parameter to the value `members.0.items`.
The following table will be extracted:

|id|name|
|--|----|
|123|John Doe|
|234|Jane Doe|

See [example [EX009]](https://github.com/keboola/generic-extractor/tree/master/doc/examples/009-nested-array).

## Examples with Complicated Objects
The above examples show how simple objects are extracted from different objects. Generic
Extractor can also extract objects with non-scalar properties. The default
[JSON to CSV mapping](/extend/generic-extractor/configuration/config/mappings/) flattens nested objects and produces secondary tables from nested arrays.

### Object with nested array
You may encounter an API response like this:

{% highlight json %}
{
    "members": [
        {
            "id": 123,
            "name": "John Doe",
            "tags": ["active", "admin"]
        },
        {
            "id": 234,
            "name": "Jane Doe",
            "tags": ["active"]
        }
    ]
}
{% endhighlight %}

To extract the `members` array, set the `dataField` parameter to the value `members` or to an empty value.
The following tables will be extracted:

Users:

|id|name|tags|
|---|---|----|
|123|John Doe|users-10_3ca896f39b257a4f2d2f4784e7680c87|
|234|Jane Doe|users-10_a15f4be71e739e1b2ea32bd4209d756e|

Tags:

|data|JSON_parentId|
|----|-------------|
|active|users-10_3ca896f39b257a4f2d2f4784e7680c87|
|admin|users-10_3ca896f39b257a4f2d2f4784e7680c87|
|active|users-10_a15f4be71e739e1b2ea32bd4209d756e|

Each member contains a nested array of `tags` that cannot be serialized into a single
database (CSV) column. Therefore the [JSON-CSV mapper] creates another table for the
`tags` with tag values. It also generates a unique member identifier, puts it
in the `tags` column and uses it in a new `JSON_parentId` column. This
way, the 1:N relationship between Members and Tags is represented.

See [example [EX010]](https://github.com/keboola/generic-extractor/tree/master/doc/examples/010-object-with-nested-array).

If the response contains an array nested in an array, Generic extractor is not able to process it.
In such case the, contents of the array are extracted as a JSON encoded string. See [example [EX130]](https://github.com/keboola/generic-extractor/tree/master/doc/examples/130-unsupported-nested-array).
You will also see a warning in the extraction events, e.g.:

    Converting nested array 'rows.[]' to JSON string.


### Upgrading to array
You may encounter the following API response:

{% highlight json %}
{
    "members": [
        {
            "id": 123,
            "name": "John Doe",
            "tags": "active"
        },
        {
            "id": 234,
            "name": "Jane Doe",
            "tags": ["active", "admin"]
        }
    ]
}
{% endhighlight %}

When you extract the `members` array (set the `dataField` parameter to the value `members` or to an empty value),
the following tables will be extracted:

Users:

|id|name|tags|
|---|---|----|
|123|John Doe|users-17_c6f3e32262682b6efd6c85ad97d2d503|
|234|Jane Doe|users-17_92df9d5b9af8821316172285b196318e|

Tags:

|data|JSON_parentId|
|----|-------------|
|active|users-17_c6f3e32262682b6efd6c85ad97d2d503|
|active|users-17_92df9d5b9af8821316172285b196318e|
|admin|users-17_92df9d5b9af8821316172285b196318e|

As you can see, the scalar value `tags` in the first member object was automatically upgraded to
a single-element array because the `tags` property is an array elsewhere (second member) in the response.

See [example [EX017]](https://github.com/keboola/generic-extractor/tree/master/doc/examples/017-upgrading-array).

### Object with nested object
You may encounter an API response like this:

{% highlight json %}
{
    "members": [
        {
            "id": 123,
            "name": "John Doe",
            "address": {
                "street": "Elm Street",
                "city": "New York"
            }
        },
        {
            "id": 234,
            "name": "Jane Doe",
            "address": {
                "street": "Bates Street",
                "city": "Chicago",
                "state": "USA"
            }
        }
    ]
}
{% endhighlight %}

To extract the `members` array, set the `dataField` parameter to the value `members` or to an empty value.
The following table will be extracted:

|id|name|address\_street|address\_city|address_state|
|---|---|---|---|---|
|123|John Doe|Elm Street|New York||
|234|Jane Doe|Bates Street|Chicago|USA|

The properties of nested `address` objects are automatically flattened into the parent object. Therefore
the `address.city` property is flattened into the `address_city` column.

See [example [EX011]](https://github.com/keboola/generic-extractor/tree/master/doc/examples/011-object-with-nested-object).

### Object with a deeply nested object
The above two examples show the basic principles of the JSON-CSV mapping used by Generic Extractor.
They are applied to all child properties. So, when you encounter an API response like this:

{% highlight json %}
{
    "members": [
        {
            "id": 123,
            "name": "John Doe",
            "contacts": [
                {
                    "type": "address",
                    "properties": {
                        "street": "Elm Street",
                        "city": "New York"
                    }
                },
                {
                    "type": "email",
                    "primary": true,
                    "properties": {
                        "address": "john.doe@example.com"
                    }
                }
            ]
        },
        {
            "id": 234,
            "name": "Jane Doe",
            "contacts": [
                {
                    "type": "address",
                    "primary": false,
                    "properties": {
                        "street": "Bates Street",
                        "city": "Chicago",
                        "state": "USA"
                    }
                },
                {
                    "type": "phone",
                    "primary": true,
                    "properties": {
                        "number": "123 456 789"
                    }
                }
            ]
        }
    ]
}
{% endhighlight %}

the following two tables will be extracted:

Users:

|id|name|contacts|
|---|---|---|
|123|John Doe|users-12_8505d6585e28c00d461ba64f085d1055|
|234|Jane Doe|users-12_ec8c48efecb10334072f03a860113ea2|

Contacts:

|type|properties\_street|properties\_city|properties\_address|properties\_state|properties\_number|primary|JSON_parentId|
|---|---|---|---|---|---|---|---|
|address|Elm Street|New York|||||users-12_8505d6585e28c00d461ba64f085d1055|
|email|||john.doe@example.com|||1|users-12_8505d6585e28c00d461ba64f085d1055|
|address|Bates Street|Chicago||USA|||users-12_ec8c48efecb10334072f03a860113ea2|
|phone|||||123 456 789|1|users-12_ec8c48efecb10334072f03a860113ea2|

The obtained table is rather sparse because the properties of the nested `contacts`
objects do not match exactly. For example, the `properties_number` column was created
as a result of flattening the `properties.number` object that is contained in the response
only once. Therefore the column has a single value.

The rows in the *Contacts* table are again linked through an
auto-generated key to the parent *Users* table. Also notice that the
[Boolean value](/extend/generic-extractor/tutorial/json/#data-values)
`primary` is converted to `1` when true and left empty otherwise.

See [example [EX012]](https://github.com/keboola/generic-extractor/tree/master/doc/examples/012-deeply-nested-object).

## Response Filter Examples

### Skip flattening
If you have an API response like this:

{% highlight json %}
{
    "members": [
        {
            "id": 123,
            "name": "John Doe",
            "tags": ["active", "admin"]
        },
        {
            "id": 234,
            "name": "Jane Doe",
            "tags": ["active"]
        }
    ]
}
{% endhighlight %}

and extract the `members` array with the
[default settings](/extend/generic-extractor/configuration/config/jobs/#an-object-with-nested-object), two tables will be
produced. If you set the response filter to `"responseFilter": "tags"`, then the `tags` property of the `members`
items will not be processed and will be stored as a [serialized](https://en.wikipedia.org/wiki/Serialization)
JSON string. The following table will be extracted:

|id|name|tags|
|---|---|---|
|123|John Doe|["active","admin"]|
|234|Jane Doe|["active"]|

The `tags` column contains serialized JSON fragments which can be processed by
the JSON capable database (e.g., [Snowflake](https://docs.snowflake.net/manuals/sql-reference/functions-semistructured.html)).

See [example [EX013]](https://github.com/keboola/generic-extractor/tree/master/doc/examples/013-skip-flatten).

### Skip flattening in nested objects
If you have the following API response:

{% highlight json %}
{
    "members": [
        {
            "id": 123,
            "name": "John Doe",
            "contacts": [
                {
                    "type": "address",
                    "properties": {
                        "street": "Elm Street",
                        "city": "New York"
                    }
                },
                {
                    "type": "email",
                    "primary": true,
                    "properties": {
                        "address": "john.doe@example.com"
                    }
                }
            ]
        },
        {
            "id": 234,
            "name": "Jane Doe",
            "contacts": [
                {
                    "type": "address",
                    "primary": false,
                    "properties": {
                        "street": "Bates Street",
                        "city": "Chicago",
                        "state": "USA"
                    }
                },
                {
                    "type": "phone",
                    "primary": true,
                    "properties": {
                        "number": "123 456 789"
                    }
                }
            ]
        }
    ]
}
{% endhighlight %}

and extract the `members` array with the
[default settings](/extend/generic-extractor/configuration/config/jobs/#an-object-with-a-deeply-nested-object),
two tables will be produced and the `properties` object will be flattened into a sparse table.
To avoid that, set the response filter to `"responseFilter": "contacts[].properties"`. This will
leave the `properties` child of the `contacts` array of the `members` array unprocessed.
The following two tables will be produced:

Users:

|id|name|contacts|
|---|---|---|
|123|John Doe|users-12_0b9650e0f68b0c6738843d5b4ff0a961|
|234|Jane Doe|users-12_cf76fb6794380244946d2bc4fa3aa04a|

Contacts:

|type|properties|primary|JSON_parentId|
|---|---|---|---|
|address|{"street":"Elm Street","city":"New York"}||users-12_0b9650e0f68b0c6738843d5b4ff0a961|
|email|{"address":"john.doe@example.com"}|1|users-12_0b9650e0f68b0c6738843d5b4ff0a961|
|address|{"street":"Bates Street","city":"Chicago","state":"USA"}||users-12_cf76fb6794380244946d2bc4fa3aa04a|
|phone|{"number":"123 456 789"}|1|users-12_cf76fb6794380244946d2bc4fa3aa04a|

The `properties` column contains JSON serialized objects. When setting the `responseFilter` parameter,
remember to use the correct path to the properties you wish to skip from processing. That is to say that
setting `responseFilter` to

- `contacts` skips the entire `contacts` property and does not create the *Contacts:* table at all.
- `properties` does nothing because there is no `properties` property under the `members` array items.
- `contacts.properties` does nothing because there is no `properties` property under the `contacts` array.

The last two options might seem inconsistent. This is because the `responseFilter` path is set **relative to**
the objects of the processed array (not to the array itself, not to the JSON root). Thus the only correct
setting in this case is `contacts[].properties`.

See [example [EX014]](https://github.com/keboola/generic-extractor/tree/master/doc/examples/014-skip-flatten-nested).

{% comment %}
TODO: Un-comment this when this is fixed: https://github.com/keboola/generic-extractor/issues/59

### Skip Boolean conversion
If you have an API response like this:

{% highlight json %}
[
    {
        "id": 123,
        "name": "John Doe",
        "married": true
    },
    {
        "id": 234,
        "name": "Jane Doe",
        "married": false
    }
]
{% endhighlight %}

and want to avoid the [default Boolean conversion](#simple-array), add the `married` property to
the response filter. Setting `"responseFilter": "married"` will cause Generic Extractor to
return the following table:

|id|name|married|
|---|---|---|
|123|John Doe|true|
|234|Jane Doe|false|

See [example [EX015]](https://github.com/keboola/generic-extractor/tree/master/doc/examples/015-skip-boolean).

{% endcomment %}

### Inconsistent object
If you have an API response like this:

{% highlight json %}
[
    {
        "id": 123,
        "name": "foo",
        "color": "green"
    },
    {
        "id": 321,
        "name": "bar",
        "color": {
            "items": ["red", "blue"]
        }
    }
]
{% endhighlight %}

you will receive an error similar to `Error parsing response JSON: Unhandled type change from "scalar" to "object" in 'users-16.color'`. This means that the objects returned in the response are incompatible and cannot
be [merged into a table](#merging-responses) by Generic Extractor.

To avoid the error and still retrieve the data,
use the `responseFilter` to skip the `color` property. When you set `"responseFilter": "color"`, you
will obtain the following table:

|id|name|color|
|---|---|---|
|123|foo|"green"|
|321|bar|{"items":["red","blue"]}|

See [example [EX016]](https://github.com/keboola/generic-extractor/tree/master/doc/examples/016-inconsistent-object).

### Multiple filters
You might have a complex API response like this:

{% highlight json %}
{
    "members": [
        {
            "id": 123,
            "name": "John Doe",
            "tags": {
                "items": ["active", "admin"]
            },
            "contacts": [
                {
                    "type": "address",
                    "properties": {
                        "street": "Elm Street",
                        "city": "New York"
                    }
                },
                {
                    "type": "email",
                    "primary": true,
                    "properties": "john.doe@example.com"
                }
            ]
        },
        {
            "id": 234,
            "name": "Jane Doe",
            "tags": "none",
            "contacts": [
                {
                    "type": "address",
                    "primary": false,
                    "properties": {
                        "street": "Bates Street",
                        "city": "Chicago",
                        "state": "USA"
                    }
                },
                {
                    "type": "phone",
                    "primary": true,
                    "properties": "123 456 789"
                }
            ]
        }
    ]
}
{% endhighlight %}

Because both `tags` and `contacts.properties` properties are inconsistent (sometimes using an object,
sometimes using a scalar value), you have to define multiple response filters. This can be done by using
an array of paths:

{% highlight json %}
"responseFilter": [
    "contacts[].properties",
    "tags"
]
{% endhighlight %}

Then you will obtain the following tables:

Users:

|id|name|tags|contacts|
|---|---|---|---|
|123|John Doe|{"items":["active","admin"]}|users-18_19318ac6aa76a92c8d90e603f69e02f6|
|234|Jane Doe|"none"|users-18_3fdf6b12b11f85cb4eb9c34ce0322ecd|

Contacts:

|type|properties|primary|JSON_parentId|
|---|---|---|---|
|address|{"street":"Elm Street","city":"New York"}||users-18_19318ac6aa76a92c8d90e603f69e02f6|
|email|"john.doe@example.com"|1|users-18_19318ac6aa76a92c8d90e603f69e02f6|
|address|{"street":"Bates Street","city":"Chicago","state":"USA"}||users-18_3fdf6b12b11f85cb4eb9c34ce0322ecd|
|phone|"123 456 789"|1|users-18_3fdf6b12b11f85cb4eb9c34ce0322ecd|

See [example [EX018]](https://github.com/keboola/generic-extractor/tree/master/doc/examples/018-multiple-filters).

### Setting delimiter
The default delimiter used for referencing nested properties is a dot `.`. If the names of
properties in the API response contain dots, it might be necessary to change the default delimiter.
The API response might look like this:

{% highlight json %}
{
    "members": [
        {
            "id": 123,
            "name": "John Doe",
            "primary.address": {
                "street": "Elm Street",
                "city": "New York"
            },
            "secondary.address": {
                "street": "Cemetery Ridge",
                "city": "New York"
            }
        },
        {
            "id": 234,
            "name": "Jane Doe",
            "primary.address": {
                "street": " Blossom Avenue",
                "state": "U.K."
            },
            "secondary.address": {
                "street": "1313 Webfoot Walk",
                "city": "Duckburg",
                "state": "Calisota"
            }
        }
    ]
}
{% endhighlight %}

If you want to filter the `secondary.address` field, you cannot set the `responseFilter` setting to
`secondary.address` because it would be interpreted as an `address` property of the `secondary` property.
If you set `"responseFilter": "secondary.address`, the extraction will work as if you did not set the
filter at all; it will be filtering the non-existent `address` property.

For the filter to work correctly, set the `responseFilterDelimiter` to an arbitrary character not
used in the response property names. The following would be a valid configuration:

{% highlight json %}
{
    ...
    "responseFilter": "secondary.address",
    "responseFilterDelimiter": "#"
}
{% endhighlight %}

It might by tempting to change the response filter to `secondary#address`. However, this would be
incorrect as it would again mean that we are referring to an `address` property nested in the `secondary`
object. With the above settings you will obtain a table like this:

|id|name|primary\_address\_street|primary\_address\_city|primary\_address\_state|secondary\_address|
|---|---|---|---|---|---|
|123|John Doe|Elm Street|New York||{"street":"Cemetery Ridge","city":"New York"}|
|234|Jane Doe|Blossom Avenue||U.K.|{"street":"1313 Webfoot Walk","city":"Duckburg","state":"Calisota"}|

See [example [EX019]](https://github.com/keboola/generic-extractor/tree/master/doc/examples/019-different-delimiter).

### Setting delimiter --- more complex
For the custom set delimiter in the response filter, you need to have a complex API response. For example:

{% highlight json %}
{
    "members": [
        {
            "id": 123,
            "name": "John Doe",
            "primary.address": {
                "street": "Elm Street",
                "city": "New York",
                "tags": []
            },
            "secondary.address": {
                "street": "Cemetery Ridge",
                "city": "New York",
                "tags": ["work", "usaddress"]
            }
        },
        {
            "id": 234,
            "name": "Jane Doe",
            "primary.address": {
                "street": " Blossom Avenue",
                "state": "U.K.",
                "tags": ["home"]
            },
            "secondary.address": {
                "street": "1313 Webfoot Walk",
                "city": "Duckburg",
                "state": "Calisota"
            }
        }
    ]
}
{% endhighlight %}

To filter out all the `tags` properties, you need to set the following:

{% highlight json %}
{
    "responseFilter": [
        "secondary.address#tags",
        "primary.address#tags"
    ],
    "responseFilterDelimiter": "#"
}
{% endhighlight %}

You will obtain a table similar to the one below:

|id|name|primary\_address\_street|primary\_address\_city|primary\_address\_tags|primary\_address\_state|secondary\_address\_street|secondary\_address\_city|secondary\_address\_tags|secondary\_address\_state|
|123|John Doe|Elm Street|New York|||Cemetery Ridge|New York|["work","usaddress"]||
|234|Jane Doe|Blossom Avenue||["home"]|U.K.|1313 Webfoot Walk|Duckburg||Calisota|

See [example [EX020]](https://github.com/keboola/generic-extractor/tree/master/doc/examples/020-setting-delimiter-complex).

## Examples with HTTP Methods and Parameters

### Request parameters
Assume that you have an API with the endpoint `users` which requires the
[GET parameter](/extend/generic-extractor/tutorial/rest/#url) `type` to specify which
users are to be retrieved. For example, a request to `/users?type=active` returns a response
with active users:

{% highlight json %}
[
    {
        "id": 123,
        "name": "John Doe",
        "married": true
    },
    {
        "id": 234,
        "name": "Jane Doe",
        "married": false
    }
]
{% endhighlight %}

To retrieve inactive users, send a request to `/users?type=inactive`. This
can be solved using the following jobs configuration:

{% highlight json %}
"jobs": [
    {
        "endpoint": "users",
        "params": {
            "type": "active"
        }
    },
    {
        "endpoint": "users",
        "params": {
            "type": "inactive"
        }
    }
]
{% endhighlight %}

The [`params` configuration](/extend/generic-extractor/configuration/config/jobs/#request-parameters) option specifies the
parameters to be sent to the API. Therefore the `type` property is the name defined by the API itself.
The above configuration produces the following table:

|id|name|married|
|---|---|---|
|123|John Doe|1|
|234|Jane Doe||
|345|Jimmy Doe||

See [example [EX033]](https://github.com/keboola/generic-extractor/tree/master/doc/examples/033-job-parameters)
or [example [EX136]](https://github.com/keboola/generic-extractor/tree/master/doc/examples/136-post-request-functions) which is also using
[functions](/extend/generic-extractor/functions/).

### POST request
You may encounter an API which is not exactly [RESTful](/extend/generic-extractor/tutorial/rest/)
and has to be queried using the [HTTP POST method](/extend/generic-extractor/tutorial/rest/#method).
Assume that you have an API with the endpoint `getUsers` that expects an empty HTTP POST request. The endpoint
then returns the following response:

{% highlight json %}
[
    {
        "id": 123,
        "name": "John Doe",
        "married": true
    },
    {
        "id": 234,
        "name": "Jane Doe",
        "married": false
    }
]
{% endhighlight %}

Generic Extractor can handle this too, using the [`method` configuration](/extend/generic-extractor/configuration/config/jobs/#method):

{% highlight json %}
"jobs": [
    {
        "endpoint": "getUsers",
        "method": "POST"
    }
]
{% endhighlight %}

The above configuration produces the following table:

|id|name|married|
|---|---|---|
|123|John Doe|1|
|234|Jane Doe||

See [example [EX034]](https://github.com/keboola/generic-extractor/tree/master/doc/examples/034-post-request).

### Complex POST request
A not-exactly-[RESTful](/extend/generic-extractor/tutorial/rest/) API (see above) may require some JSON
parameters in the request. Let's say you have the `getUsers` endpoint which requires an HTTP POST request with
the following body:

{% highlight json %}
{
    "filter": {
        "type": "active"
    },
    "return": {
        "fields": ["id", "name"]
    }
}
{% endhighlight %}

The request returns the following JSON:

{% highlight json %}
[
    {
        "id": 123,
        "name": "John Doe"
    },
    {
        "id": 234,
        "name": "Jane Doe"
    }
]
{% endhighlight %}

The above situation can be handled by passing the entire request JSON to the
[`params` configuration](/extend/generic-extractor/configuration/config/jobs/#request-parameters).

{% highlight json %}
"jobs": [
    {
        "endpoint": "getUsers",
        "method": "POST",
        "params": {
            "filter": {
                "type": "active"
            },
            "return": {
                "fields": ["id", "name"]
            }
        }
    }
]
{% endhighlight %}

The above configuration produces the following table:

|id|name|
|---|---|
|123|John Doe|
|234|Jane Doe|

See [example [EX035]](https://github.com/keboola/generic-extractor/tree/master/doc/examples/035-complex-post).

### Complex GET request
Sometimes even the HTTP GET requests require complex parameters. Suppose the API
endpoint `/users` requires the `filter` and `return` definitions. The API may describe
the configuration in many different ways, for instance:

|filter|name|example value|
|---|---|---|
|Name of property for filtering|field|type|
|Filtering operator|operator|equal|
|Value to use in filter|value|active|

|return|name|example value|
|---|---|---|
|Names of properties to return in response|fields|id,name|

In the HTTP protocol, this would be encoded in the following [query string](/extend/generic-extractor/tutorial/rest/#url):

    filter[field]=type&filter[operator]=equal&filter[value]=active&return[fields][0]=id&return[fields][1]=name

or, in the [URL Encoded](https://www.w3schools.com/tags/ref_urlencode.asp) form:

    filter%5Bfield%5D%3Dtype%26filter%5Boperator%5D%3Dequal%26filter%5Bvalue%5D%3Dactive%26return%5Bfields%5D%5B0%5D%3Did%26return%5Bfields%5D%5B1%5D%3Dname

The following JSON is returned:

{% highlight json %}
[
    {
        "id": 123,
        "name": "John Doe"
    },
    {
        "id": 234,
        "name": "Jane Doe"
    }
]
{% endhighlight %}

The above situation can be handled by encoding the parameters in a JSON into the
[`params` configuration](/extend/generic-extractor/configuration/config/jobs/#request-parameters).

{% highlight json %}
"jobs": [
    {
        "endpoint": "getUsers",
        "method": "POST",
        "params": {
            "filter": {
                "field": "type",
                "operator": "equal",
                "value": "active"
            },
            "return": {
                "fields": ["id", "name"]
            }
        }
    }
]
{% endhighlight %}

The above configuration produces the following table:

|id|name|
|---|---|
|123|John Doe|
|234|Jane Doe|

See [example [EX036]](https://github.com/keboola/generic-extractor/tree/master/doc/examples/036-complex-get).


================================================
File: extend/generic-extractor/configuration/ssh-proxy/index.md
================================================
---
title: SSH Proxy Configuration
permalink: /extend/generic-extractor/configuration/ssh-proxy/
---

* TOC
{:toc}

*To configure your first Generic Extractor, follow our [tutorial](/extend/generic-extractor/tutorial/).*
*Use [Parameter Map](/extend/generic-extractor/map/) to help you navigate among various
configuration options.*

An SSH proxy for Generic Extractor allows you tu securely access HTTP(s) endpoints inside your private network.
It creates an SSH tunnel, and all traffic from Generic Extractor is forwarded through the tunnel to the destination server.

A sample `config` configuration can look like this:

{% highlight json %}
{
    ...,
    "sshProxy": {
        "host": "proxy.example.com",
        "user": "proxy",
        "port": 22,
        "#privateKey": "-----BEGIN RSA PRIVATE KEY-----\n...\n-----END RSA PRIVATE KEY-----"
    }
}
{% endhighlight %}


## Usage
Before using an SSH proxy, set up an **SSH proxy server**
to act as a gateway to your private network where your destination server resides.

Complete the following steps to set up an SSH proxy for Generic Extractor:

### 1. Set Up SSH Proxy Server
Here is a very basic [Dockerfile](https://docs.docker.com/engine/reference/builder/) example.
All it does is run an sshd daemon and expose port 22. You can, of course, set this up in your system in
a similar way without using Docker.

{% highlight dockerfile %}
FROM ubuntu:14.04

RUN apt-get update

RUN apt-get install -y openssh-server
RUN mkdir /var/run/sshd

RUN echo 'root:root' |chpasswd

RUN sed -ri 's/^PermitRootLogin\s+.*/PermitRootLogin yes/' /etc/ssh/sshd_config
RUN sed -ri 's/UsePAM yes/#UsePAM yes/g' /etc/ssh/sshd_config

EXPOSE 22

CMD    ["/usr/sbin/sshd", "-D"]
{% endhighlight %}

This server should be in the same private network where your destination server resides. It should be accessible publicly from the internet via SSH.
The default port for SSH is 22, but you can choose a different port.

We highly recommend to allow access only from the [Keboola IP address ranges](https://help.keboola.com/extractors/ip-addresses/).

See the following pages for more information about setting up SSH on your server:

- [OpenSSH configuration](https://help.ubuntu.com/community/SSH/OpenSSH/Configuring)
- [Dockerized SSH service](https://docs.docker.com/engine/examples/running_ssh_service/)


### 2. Generate SSH Key Pair
Generate an SSH key pair and copy the public key to your **SSH proxy server**.
Paste it to the **public.key** file, and then append it to the authorized_keys file.

{% highlight bash %}
mkdir ~/.ssh
cat public.key >> ~/.ssh/authorized_keys
{% endhighlight %}

### 3. Configure Generic Extractor SSH Proxy

{% highlight json %}
{
    ...,
    "sshProxy": {
        "host": "your-ssh-proxy-host",
        "user": "ssh-proxy-user",
        "port": 22,
        "#privateKey": "your-generated-private-key"
    }
}
{% endhighlight %}

See [example [EX131]](https://github.com/keboola/generic-extractor/tree/master/doc/examples/131-ssh-tunnel).
and [example [EX133]](https://github.com/keboola/generic-extractor/tree/master/doc/examples/133-ssh-tunnel-iterations-params).


================================================
File: extend/generic-extractor/tutorial/basic.md
================================================
---
title: Basic Configuration
permalink: /extend/generic-extractor/tutorial/basic/
---

* TOC
{:toc}

Before configuring Generic Extractor, you should have a basic understanding
of [REST API](/extend/generic-extractor/tutorial/rest/) and
[JSON format](/extend/generic-extractor/tutorial/json/). This tutorial uses the
[MailChimp API](https://mailchimp.com/developer/reference/), so
have its documentation at hand. You also need the
[MailChimp API key](/extend/generic-extractor/tutorial/#prepare).

## Configuration
Generic Extractor configuration is written in [JSON format](/extend/generic-extractor/tutorial/json/)
and comprises [several sections](/extend/generic-extractor/configuration/#configuration-sections) (a
[configuration map](/extend/generic-extractor/map/) for navigation is available). 

A [user interface](/extend/generic-extractor/configuration/#user-interface) is available that can help you with the configuration
 and generate the JSON configuration for you.

### Base Configuration
The first configuration part is a `Base Configuration` section where you can set the Base URL and Authentication method of the 
API you connect to.

In our case, we will use the MailChimp API, so the `Base URL` will be `https://us13.api.mailchimp.com/3.0/`, and the `Authentication` method will be `Basic Authentication`.

**Important:** Make sure that the `baseUrl` URL ends with a slash!

In the `Destination` section, you can set:
- The `Output Bucket` where the data will be stored. It will be set to the ID of the [Storage Bucket](https://help.keboola.com/storage/buckets/)
- `Incremental Output` option, which defines whether you want the result to overwrite the existing data or append to it. [See more](/extend/generic-extractor/incremental/)
  - Note that when using Incremental Output, you should set up the mapping.

{: .image-popup}
![Base Configuration](/extend/generic-extractor/tutorial/base_configuration.png)

#### JSON
If you switch to the `JSON` mode, the created configuration will translate to the `api` section where you set the **basic properties** of the API.
In the most simple case, this is the `baseUrl` property and `authentication`, as shown in this JSON snippet:

{% highlight json %}
{
    "api": {
        "baseUrl": "https://us13.api.mailchimp.com/3.0/",
        "authentication": {
            "type": "basic"
        }
    }
}
{% endhighlight %}

**Important:** Make sure that the `baseUrl` URL ends with a slash!

The `config` section describes the **actual extraction**. Its most important parts are the `outputBucket` and
`jobs` properties. `outputBucket` must be set to the ID of the [Storage Bucket](https://help.keboola.com/storage/buckets/)
where the data will be stored. If no bucket exists, it will be created.

It also contains the authentication parameters, such as `username` and `password`. Start with this
configuration section:

{% highlight json %}
"config": {
    "username": "dummy",
    "#password": "c40xxxxxxxxxxxxxxxxxxxxxxxxxxxxx-us13",
    "outputBucket": "ge-tutorial",
    "incrementalOutput": false
}
{% endhighlight %}

The `password` property is prefixed with the hash mark `#`, meaning the value will be [encrypted](/overview/encryption/) once
you save the configuration.

### Endpoint Section
Once you set up the Base Configuration, you can set up the actual endpoint to be queried. 

Start by clicking the **+ New Endpoint** button:

{: .image-popup}
![New Endpoint](/extend/generic-extractor/tutorial/new_endpoint.png)

You will be asked to provide the relative endpoint URL path. In our case, we will use the `campaigns` endpoint.

{: .image-popup}
![New Endpoint modal](/extend/generic-extractor/tutorial/new_endpoint_modal.png)

- In the URL section, you will see the resulting endpoint URL combined with the `Base URL` you set up in the `Base Configuration` section.
  - **Important:** Do not start the URL with a slash. If you do so, the URL
will be absolute from the domain `https://us13.api.mailchimp.com/campaigns`, which is invalid
(it is missing the `3.0` part). An alternative would be to put `/3.0/campaigns` in the `endpoint` property.
- Alternatively, you may opt to create the endpoint using the **cURL command**, which is usually available in the API documentation. 

Now you are getting close to a runnable configuration, and you may proceed with testing the configuration by clicking the `TEST ENDPOINT` button:

{: .image-popup}
![Test endpoint](/extend/generic-extractor/tutorial/test_endpoint.png)

In the test endpoint popup, you will see the following sections:
- `Records`: The actual data that will be used for parsing.
- `Response`: The response from the API. It includes headers, status code, and response body in the `data` property.
- `Request`: The request that has been sent to the API.
- `Debug log`: A log outputted by the component for debugging purposes.

In the `Records` section, you will now see the following:
```
[
  "The root element of the response is not a list; please change your Data Selector path to list"
]
```

Also, if you try to run this configuration, you will get an error similar to this:

    The response contains more than one array! Use the 'dataField' parameter to specify a key to the data array.
    (endpoint: campaigns, arrays in the response root: campaigns, _links)

That means that the extractor got the response but cannot automatically process it. The `Data Selector` path doesn't point to an array.

Examine the `data` attribute of the response, and you will see the following objects: `campaigns`, `total_items`, and `_links`:

{% highlight json %}
{
  "campaigns": [
    {
      "id": "42694e9e57",
      "type": "regular",
      ...
    },
    {
      "id": "f6276207cc",
      "type": "regular",
      ...
    }
  ],
  "total_items": 2,
  "_links": [
    {
      "rel": "parent",
      "href": "https://usX.api.mailchimp.com/3.0/",
      "method": "GET",
      "targetSchema": "https://api.mailchimp.com/schema/3.0/Root.json"
    },
    {
      "rel": "self",
      "href": "https://usX.api.mailchimp.com/3.0/campaigns",
      "method": "GET",
      "targetSchema": "https://api.mailchimp.com/schema/3.0/Campaigns/Collection.json",
      "schema": "https://api.mailchimp.com/schema/3.0/CollectionLinks/Campaigns.json"
    }
  ]
}
{% endhighlight %}

Generic Extractor expects the response to be an array of items. If it receives an object, it
searches its properties to find an array. Finding multiple arrays will be confusing because it is unclear which array you want. 
To fix this, change the `Data Selector` parameter  (aka `dataField`) to value `campaigns` to point to the array of items you want to extract.

{: .image-popup}
![Selector](/extend/generic-extractor/tutorial/data_selector.png)

Now, run the configuration by clicking the **Run** button and go to the job details to see what happened:

{: .image-popup}
![Screenshot - Generic Extractor job](/extend/generic-extractor/tutorial/job-1.png)

The extraction produced two tables. The `in.c-ge-tutorial.campaigns` table contains all the
fields of a campaign and as many rows as you have campaigns.

{: .image-popup}
![Screenshot - Campaigns Table](/extend/generic-extractor/tutorial/table-campaigns-sample.png)

The table `in.c-ge-tutorial.campaigns__links` contains the contents of the `_links` property.
Because the `_links` property is a nested array within a single campaign object, it cannot be easily
represented in a single column of the `campaigns` table. Generic Extractor, therefore, replaces the column
value with a generated key, for example, `campaigns_75d5b14d79d034cd07a9d95d5f0ca5bd`, and automatically
creates a new table that has the column `JSON_parentId` with that value so that you can join the tables together.

### Final JSON Configuration
The main parts of the configuration and their nesting are shown in the following schema:

{: .image-popup}
![Schema - Generic Extractor configuration](/extend/generic-extractor/generic-intro.png)

The resulting JSON configuration will look like this:

{% highlight json %}
{
    "parameters": {
        "api": {
            "baseUrl": "https://us13.api.mailchimp.com/3.0/",
            "authentication": {
                "type": "basic"
            }
        }
        "config": {
            "username": "dummy",
            "#password": "c40xxxxxxxxxxxxxxxxxxxxxxxxxxxxx-us13",
            "outputBucket": "ge-tutorial",
            "jobs": [
                {
                    "endpoint": "campaigns",
                    "dataField": {
                      "path": "campaigns",
                      "delimiter": "."
                    }
                }
            ]
        }
    }
}
{% endhighlight %}

**Important:** It may seem confusing that the `endpoint` and `dataField` properties are set to `campaigns`.
This is just a coincidence; the `endpoint` property refers to the `campaigns` in the resource URL, and
the `dataField` refers to the `campaigns` property in the JSON retrieved as the API response.

## Summary
The above tutorial demonstrates a very basic configuration of Generic Extractor. The extractor is capable
of doing much more; see other parts of this tutorial for an explanation of pagination, jobs and mapping:

- [Pagination](/extend/generic-extractor/tutorial/pagination/) --- breaks a result with many items into separate pages.
- [Jobs](/extend/generic-extractor/tutorial/jobs/) --- describe the API endpoints
		(resources) to be extracted.
- [Mapping](/extend/generic-extractor/tutorial/mapping/) --- describes how the JSON
		response is converted into CSV files that will be imported into Storage.


================================================
File: extend/generic-extractor/tutorial/index.md
================================================
---
title: Generic Extractor Tutorial
permalink: /extend/generic-extractor/tutorial/
---

* TOC
{:toc}

In this tutorial, we will guide you through configuring Generic Extractor for a new API.
In our case, MailChimp --- an email marketing service.

Even though there already is a MailChimp extractor available in Keboola as a
[component](/extend/generic-extractor/publish/) based on Generic Extractor,
the [MailChimp](https://mailchimp.com/) API is ideal for this tutorial because it is fairly
easy to understand and has excellent documentation.

## Prepare
There are a few things you need to do before you start:

1. Read our [quick introduction to REST](/extend/generic-extractor/tutorial/rest/) for a basic understanding of
**HTTP requests** and **REST API**.
2. Read our [quick introduction to JSON](/extend/generic-extractor/tutorial/json/) to learn how to write **JSON
configurations**.
3. [Create your MailChimp account](https://login.mailchimp.com/signup/), free of charge, if you do not have one
already.
4. Follow the MailChimp wizard or [help](https://us13.admin.mailchimp.com/campaigns/) and **fill the account with
data**:
	- Create a new Campaign (choose the *regular type*).
	- Create a new List and add some addresses to it (preferably yours).
	- Go back to Campaigns, select your campaign and hit "Next" in the bottom right corner.
	- Design a test email and send it.
	- Check that you have received the email and read it.
5. To gain access to the MailChimp API, go to your Account detail and under Extras find the option to
[generate your API Key](https://mailchimp.com/help/about-api-keys/#Find-or-Generate-Your-API-Key).
It will look like this: `c40xxxxxxxxxxxxxxxxxxxxxxxxxxxxx-us13`.

## Get Started
Let's take a closer look at the [MailChimp API](https://mailchimp.com/developer/) now.
There are plenty of documentation guides available. To explore the API and review what information is in
each resource, use, for example, the [Playground](https://us1.api.mailchimp.com/playground/).

The basic properties of the API are outlined in the
[Getting Started Guide](https://mailchimp.com/developer/guides/get-started-with-mailchimp-api-3/#resources).
The following are the crucial parts for our use-case:

- The root API URL is `https://<dc>.api.mailchimp.com/3.0`, where `<dc>` refers to a data center for your
account. The data center is the last part of the API key; if the API key is
`c40xxxxxxxxxxxxxxxxxxxxxxxxxxxxx-us13`, the root URL is `https://us13.api.mailchimp.com/3.0`.
- API Authentication can be done using **HTTP Basic Authentication** where you use **any string** (text) for
username and the API key for password.

Now, go straight to the documentation of the
[**Campaign** resource](https://mailchimp.com/developer/reference/campaigns/).
Because you intend to extract data from MailChimp, the only part you are interested in is the **Read Method**.

{: .image-popup}
![Screenshot - Read Campaign Documentation](/extend/generic-extractor/tutorial/mailchimp-api-docs-1.png)

The documentation lists the URL (`/campaigns`) of the **Campaign Resource**, and the query string
parameters (these go into the URL), such as `fields`, `count`, etc. It also lists example
requests and responses. The response body is in [JSON](/extend/generic-extractor/tutorial/json) format and starts like this:

{% highlight json %}
{
  "campaigns": [
    {
      "id": "42694e9e57",
      "type": "regular",
      "create_time": "2015-09-15T14:40:36+00:00",
      ...
{% endhighlight %}

## Next Steps
Now you have everything you need to actually start extracting the data. Continue with your Generic Extractor
configuration here:

- [Basic configuration](/extend/generic-extractor/tutorial/basic/) --- sets the basic properties of the API and describes the actual extraction.
- [Pagination](/extend/generic-extractor/tutorial/pagination/) --- breaks a result with a
		large number of items into separate pages.
- [Jobs](/extend/generic-extractor/tutorial/jobs/) --- describes the API endpoints
		(resources) to be extracted.
- [Mapping](/extend/generic-extractor/tutorial/mapping/) --- describes how the JSON
		response is converted into CSV files that will be imported into Storage.

================================================
File: extend/generic-extractor/tutorial/jobs.md
================================================
---
title: Jobs Tutorial
permalink: /extend/generic-extractor/tutorial/jobs/
---

* TOC
{:toc}

On your way through the Generic Extractor tutorial, you have learned about

- [Basic configuration](/extend/generic-extractor/tutorial/basic/) and 
- [Configuration of pagination](/extend/generic-extractor/tutorial/pagination/).

Now, we will show you how to use Generic Extractor's **sub-jobs**.

Let's start this section with a closer examination of the `campaigns` resource of the MailChimp API. 
Besides retrieving multiple campaigns using the `/campaigns` endpoint, it can also retrieve detailed 
information about a single campaign using `/campaigns/{campaign_id}`. 

{: .image-popup}
![Screenshot - Mailchimp documentation](/extend/generic-extractor/tutorial/mailchimp-api-docs-1.png)

Moreover, each campaign has three **sub-resources**: 
`/campaigns/{campaign_id}/content`, `/campaigns/{campaign_id}/feedback` 
and `/campaigns/{campaign_id}/send-checklist`. The `{campaign_id}` expression represents a placeholder 
that a specific campaign ID should replace. To retrieve the sub-resource, use child jobs. 

## Child Jobs

In the 
[previous part](/extend/generic-extractor/tutorial/pagination/#running) of the tutorial, you created this job 
property in the Generic Extractor configuration:

{% highlight json %}
"jobs": [
    {
        "endpoint": "campaigns",
        "dataField": "campaigns"
    }
]
{% endhighlight %}

All sub-resources are retrieved by configuring the `children` property in JSON; its structure is the same as the 
structure of the `jobs` property, but it must additionally define `placeholders`.

In the UI, you just create a new endpoint and mark it as a `Child Job` of the parent job of your choice. Any placeholders, 
e.g., variables that will be set from the parent object, should be enclosed in curly braces, e.g., `{campaign_id}`. 

{: .image-popup}
![Create endpoint](/extend/generic-extractor/tutorial/create_endpoint_child.png)

Once the endpoint is created, the `Placeholders section` will be prefilled for you. We will set the `Response Path` value to `id`,
since we want to use the `id` property from the parent response to replace the `{campaign_id}` placeholder in the child endpoint.

{: .image-popup}
![Child endpoint](/extend/generic-extractor/tutorial/child_endpoint.png)


Now, you can test the endpoint as in previous examples. 
The  `Mapping.Data Selector` (aka `dataField`) property must refer to an array, i.e., `items` or `_links` in our case 
(see the [documentation](https://mailchimp.com/developer/reference/campaigns/campaign-checklist/)).

When you look at the debug log, you will also see that the connector is making all the parent requests:

{: .image-popup}
![child_debug](child_debug.png)

**The resulting underlying JSON will look like this:**

{% highlight json %}
"jobs": [
    {
        "endpoint": "campaigns",
        "dataField": "campaigns",
        "children": [
            {
                "endpoint": "campaigns/{campaign_id}/send-checklist",
                "dataField": "items",
                "placeholders": {
                    "campaign_id": "id"
                }
            }
        ]
    }
]
{% endhighlight %}


The `children` are executed for each element retrieved from the parent endpoint, i.e., for each campaign.
The `placeholders` setting connects the placeholders used in the `endpoint` property with 
the data in the actual parent response. 
That means that the `campaign_id` placeholder in the `campaigns/{campaign_id}/send-checklist` endpoint 
will be replaced by the `id` property of the JSON [response](https://mailchimp.com/developer/reference/campaigns/): 

{: .image-popup}
![Screenshot - Mailchimp docs](/extend/generic-extractor/tutorial/mailchimp-api-docs-2.png)

Also, note that the placeholder name is completely arbitrary (i.e., it is just a coincidence that
it is also named `campaign_id` in the Mailchimp documentation). Therefore, the following configuration is 
also valid:

{% highlight json %}
{
    "parameters": {
        "api": {
            "baseUrl": "https://us13.api.mailchimp.com/3.0/",
            "authentication": {
                "type": "basic"
            },
            "pagination": {
                "method": "offset",
                "offsetParam": "offset",
                "limitParam": "count",
                "limit": 1
            }            
        },
        "config": {
            "debug": true,
            "username": "dummy",
            "#password": "c40xxxxxxxxxxxxxxxxxxxxxxxxxxxxx-us13",
            "outputBucket": "ge-tutorial",
            "jobs": [
                {
                    "endpoint": "campaigns",
                    "dataField": "campaigns",
                    "children": [
                        {
                            "endpoint": "campaigns/{cid}/send-checklist",
                            "dataField": "items",
                            "placeholders": {
                                "cid": "id"
                            }
                        }
                    ]
                }
            ]
        }
    }
}
{% endhighlight %}

Running the above configuration gives you a new table named, for example, 
`in.c-ge-tutorial.campaigns__campaign_id__send-checklist`. The table
contains messages from campaign checking. You will see something like this:

{: .image-popup}
![Screenshot - Job Table](/extend/generic-extractor/tutorial/job-table-1.png)

Note that apart from the API response properties `type`, `heading`, and `details`, an additional field, 
`parent_id`, was added. It contains the value of the placeholder (`campaign_id`) for the particular 
request. So, to join the two tables together in SQL, you would use the join condition: 

    campaigns.id=campaigns__campaign_id__send-checklist.parent_id

However, you have to remember what table the `parent_id` column refers to.

## Multiple Jobs
You have probably noticed that the `jobs` and `children` properties are arrays. It means that you can retrieve multiple 
endpoints in a single configuration. Let's pick the campaign `content` sub-resource too:

{: .image-popup}
![second child](/extend/generic-extractor/tutorial/2_child.png)


The placeholder configuration is the same, however,
the question is what to put in the `Data Selector` (`dataField`). If you examine the sample [response](https://mailchimp.com/developer/reference/campaigns/campaign-content/)
after running the test endpoint, it looks like this:

{% highlight json %}

{
  "plain_text": "** Designing...*|END:IF|*",
  "html": "<!DOCTYPE html...</html>",
  "_links": [
    {
      "rel": "parent",
      "href": "https://usX.api.mailchimp.com/3.0/campaigns/42694e9e57",
      "method": "GET",
      "targetSchema": "https://api.mailchimp.com/schema/3.0/Campaigns/Instance.json"
    },
    ...
  ]
}

{% endhighlight %}

If you use JSON configuration with no `dataField` like in the above configuration and run it, you will obtain a table like this:

{: .image-popup}
![Screenshot - Job Table](/extend/generic-extractor/tutorial/job-table-2.png)

This is not what you expected. Instead of obtaining the campaign content, you 
got the `_links` property from the response because Generic Extractor automatically 
picks an array in the response. To get the entire response as a **single table record**, set `dataField` 
to the [path](/extend/generic-extractor/tutorial/json/#references) in the object. Because you want to use the 
**entire response**, set `dataField` to `.` to start in the root. 

***Note:** If you use the UI editor, the `Data Selector` (`dataField`) is automatically set to `.` by default.*

**The resulting JSON:**

{% highlight json %}
"jobs": [
    {
        "endpoint": "campaigns",
        "dataField": "campaigns",
        "children": [
            {
                "endpoint": "campaigns/{campaign_id}/send-checklist",
                "dataField": {
                      "path": "items",
                      "delimiter": "."
                    },
                "placeholders": {
                    "campaign_id": "id"
                }
            },
            {
                "endpoint": "campaigns/{campaign_id}/content",
                "dataField": {
                      "path": ".",
                      "delimiter": "."
                    },
                "placeholders": {
                    "campaign_id": "id"
                }
            }
        ]
    }
]
{% endhighlight %}

Running the above configuration will get you the table `in.c-ge-tutorial.campaigns__campaign_id__content`
with columns like `plain_text`, `html`, and others. 

You will also get the table `in.c-ge-tutorial.campaigns__campaign_id__content__links`. It 
represents the `links` property of the `content` resource. The links table contains the 
`JSON_parentId` column, which includes a generated hash, such as 
`campaigns/{campaign_id}/content_1c3b951ece2a05c1239b06e99cf804c2`, whose value is inserted into
the `links` column of the campaign content table. This is done automatically because once
you say that the entire response is supposed to be a single table row, the array `_links` 
property will not fit into a single value of a table.

## Summary
Now that you know how to extract sub-resources using child jobs, as well as resources composed directly of 
properties (without an array of items), you probably think that the `_links` property, found all over the 
MailChimp API and giving us a lot of trouble, is best to be ignored. The answer to this is 
**mapping**, described in the tutorial's [next part](/extend/generic-extractor/tutorial/mapping/). 

You might also have noticed some duplicate records in the table `in.c-ge-tutorial.campaigns__campaign_id__content` 
along the way. You'll look into this as well.


================================================
File: extend/generic-extractor/tutorial/json.md
================================================
---
title: JSON Introduction
permalink: /extend/generic-extractor/tutorial/json/
---

* TOC
{:toc}

[JSON (JavaScript Object Notation)](http://www.json.org/) is an easy-to-work-with format for describing structured 
data. Before you start working with JSON, familiarize yourself with basic programming jargon. It is also recommended 
to have a text editor with JSON support (you can also use an [online editor](http://www.jsoneditoronline.org/)).

## Object Representation
To describe structured data, JSON uses **objects** and **arrays**. 

### Objects
Objects consist of **properties** and their **values**. Because the values in an object are identified by names 
(property names), they are not kept in a particular order. 

The following object describes *John Doe* using two properties : `firstName` and `lastName`.

{% highlight json %}
{
    "firstName": "John",
    "lastName": "Doe"
}
{% endhighlight %}

*Notice that the object is enclosed in `{}`. The properties and values are both in double quotes and are separated 
by a colon. The individual properties are separated from each other using commas.*

### Arrays
As objects collect named values, **arrays** are ordered lists of values that do not have a property 
name but are identified by their numeric position.   

Let's go on to describing John Doe's family using an **array** (marked by `[]`) of three **objects**:

{% highlight json %}
[
    {
        "firstName": "John",
        "lastName": "Doe",
        "role": "father"
    },
    {
        "firstName": "Jenny",
        "lastName": "Doe",
        "role": "mother"
    },
    {
        "firstName": "Jimmy",
        "lastName": "Doe",
        "role": "son"
    }    
]
{% endhighlight %}

*Objects are also separated from each other by commas. Notice that the last item (property or object) is not 
followed by a comma.*

### Terminology
The terminology varies a lot and other expressions are also commonly used: 

- Object --- also a record / structure / dictionary / hash table / keyed list / key value / associative array
- Property --- also a field / key / index
- Array --- also a collection / list / vector / ordinal array / sequence

## Data Values
Each property value always has one of the following data types:

- String --- text
- Number --- number
- Integer --- whole number (without decimal part)
- Boolean --- value which is either `true` or `false`
- Array --- ordered list of values
- Object --- collection of named values

The types `string`, `number`, `integer` and `boolean` represent **scalar values** (simple). The types `array` and 
`object` represent **structured values** (they are composed of other values). For example:

{% highlight json %}
{
    "stringProperty": "someText",
    "numberProperty": 12.45,
    "integerProperty": 42,
    "booleanProperty": false,
    "arrayProperty": ["first", "second"],
    "objectProperty": {
        "name": "John",
        "surname": "Doe"
    }
}
{% endhighlight %}

*Notice that only strings and property names are enclosed in double quotes. The boolean value  is `false` without 
double quotes because `false`, `true` and `null` (no or an unknown value) are **keywords**, not strings.*

## References
There are multiple ways to refer to particular properties in a JSON document (for instance, [JSONPath](http://jsonpath.com/). 
For the purpose of this documentation, we will use simple *dot notation*. Let's consider this JSON describing the
Doe's family:

{% highlight json %}
{
    "address": {
        "city": "Fresno",
        "street": "Main Street"        
    },
    "members": [
        {
            "firstName": "John",
            "age": 42,
            "shoeSize": 42.5,
            "lastName": "Doe",
            "interests": ["cars", "girls", "lego"],
            "adult": true
        },
        {
            "firstName": "Jenny",
            "adult": true,
            "shoeSize": 24.5,
            "lastName": "Doe",
            "age": 42,
            "interests": ["cars", "boys", "painting"]
        },
        {
            "adult": false,
            "firstName": "Jimmy",
            "lastName": "Doe",
            "shoeSize": null,
            "age": 1,
            "interests": ["cars", "lego", "painting"]
        }
    ]
}
{% endhighlight %}

To refer to John's city, we would write `address.city`. To refer to little Jimmy's shoe size, we
would write `members[2].shoeSize`. Array items indexes are *zero-based*, so the third item has 
index `2`. 

The order of items in an object is not important. It is also worth noting that `[]` represents an empty array and 
`{}` represents an empty object.

## Summary
This page contains a little introduction to JSON documents. We intentionally avoided many details, 
but you should now understand what JSON is, and how to write some stuff in it.


================================================
File: extend/generic-extractor/tutorial/mapping.md
================================================
---
title: Mapping Tutorial
permalink: /extend/generic-extractor/tutorial/mapping/
---

* TOC
{:toc}

In the previous part of the tutorial, you [extracted the content of a MailChimp campaign](/extend/generic-extractor/tutorial/jobs/). 
Now, it's time to clean up the response.

This is the initial configuration:

{: .image-popup}
![Whole cfg](/extend/generic-extractor/tutorial/mapping_all.png)

**In JSON:**

{% highlight json %}
{
    "parameters": {
        "api": {
            "baseUrl": "https://us13.api.mailchimp.com/3.0/",
            "authentication": {
                "type": "basic"
            },
            "pagination": {
                "method": "offset",
                "offsetParam": "offset",
                "limitParam": "count",
                "limit": 1
            }
        },
        "config": {
            "debug": true,
            "username": "dummy",
            "#password": "c40xxxxxxxxxxxxxxxxxxxxxxxxxxxxx-us13",
            "outputBucket": "ge-tutorial",
            "jobs": [
                {
                    "endpoint": "campaigns",
                    "dataField": "campaigns",
                    "children": [
                        {
                            "endpoint": "campaigns/{campaign_id}/send-checklist",
                            "dataField": {
                                  "path": "items",
                                  "delimiter": "."
                                },
                            "placeholders": {
                                "campaign_id": "id"
                            }
                        },
                        {
                            "endpoint": "campaigns/{campaign_id}/content",
                            "dataField": {
                                  "path": ".",
                                  "delimiter": "."
                                },
                            "placeholders": {
                                "campaign_id": "id"
                            }
                        }
                    ]
                }
            ]
        }
    }
}
{% endhighlight %}

It extracts MailChimp campaigns with the `send-checklist` items and campaign `content`. 
However, you are probably not interested in some parts of the content resource. Also, the table contains duplicates.

***Technical note on duplicates:** If you examine the job events, you will see 
the request `GET /3.0/campaigns/f7ed43aaea/content?count=1&offset=0` sent. That is, 
pagination applies to **all API requests**. Generic Extractor tries to page the 
unpaged `/content` resource. This may ultimately lead to duplicates because the extraction of that
resource is only terminated after the resource returns the same response twice.*

## Mapping

A mapping defines the shape of Generic Extractor outputs. It is stored
in the `config.mappings` property and is identified by the resource data type. 
When a resource is assigned an internal  `Result Name` (`dataType`), a mapping can be created 
for it. To use a mapping, first define a `Result Name` (`dataType`) in the job property. 

### UI 

The mapping can be created in the `Mapping section` in the UI by clicking the `Create Mapping` toggle.

{: .image-popup}
![Create mapping](/extend/generic-extractor/tutorial/create_mapping_toggle.png)

You may generate the mapping automatically by clicking the**Infer Mapping** button in the top right corner. 

This operation will generate a mapping based on the sample response of the endpoint. 

{: .image-popup}
![Create mapping](/extend/generic-extractor/tutorial/create_mapping.png)


#### Primary key
To create a primary key, you can specify a `.` separated path of the elements in the response. ***Note:** If you are mapping child jobs, 
the parent keys will automatically be included.*

#### Nesting level
Currently, the automatic detection outputs only single table mapping. You can control the nesting level by specifying 
the `Nesting Level` property. For example, a depth of 1 transforms `{"address": {"street": "Main", "details": {"postcode": "170 00"}}}` into two columns: 
`address_street` and `address_details`. 
All elements that have ambiguous types or are beyond the specified depth are stored in a single column as JSON, e.g., with the [`force_type`](https://developers.keboola.com/extend/generic-extractor/configuration/config/mappings/#mapping-without-processing) option.

For example, if you click to generate mapping on the `Campaigns` endpoint with level 2 and primary key `id`, you will get this result
(note the link between the `Result Name` (`dataType`) and mappings key):

```
"mappings": {"campaigns": {
  "id": {
    "mapping": {
      "destination": "id",
      "primaryKey": true
    }
  },
  "web_id": "web_id",
  "type": "type",
  "create_time": "create_time",
  "archive_url": "archive_url",
  "long_archive_url": "long_archive_url",
  "status": "status",
  "emails_sent": "emails_sent",
  "send_time": "send_time",
  "content_type": "content_type",
  "needs_block_refresh": "needs_block_refresh",
  "resendable": "resendable",
  "recipients.list_id": "recipients_list_id",
  "recipients.list_is_active": "recipients_list_is_active",
  "recipients.list_name": "recipients_list_name",
  "recipients.segment_text": "recipients_segment_text",
  "recipients.recipient_count": "recipients_recipient_count",
  "settings.subject_line": "settings_subject_line",
  "settings.title": "settings_title",
  "settings.from_name": "settings_from_name",
  "settings.reply_to": "settings_reply_to",
  "settings.use_conversation": "settings_use_conversation",
  "settings.to_name": "settings_to_name",
  "settings.folder_id": "settings_folder_id",
  "settings.authenticate": "settings_authenticate",
  "settings.auto_footer": "settings_auto_footer",
  "settings.inline_css": "settings_inline_css",
  "settings.auto_tweet": "settings_auto_tweet",
  "settings.fb_comments": "settings_fb_comments",
  "settings.timewarp": "settings_timewarp",
  "settings.template_id": "settings_template_id",
  "settings.drag_and_drop": "settings_drag_and_drop",
  "tracking.opens": "tracking_opens",
  "tracking.html_clicks": "tracking_html_clicks",
  "tracking.text_clicks": "tracking_text_clicks",
  "tracking.goal_tracking": "tracking_goal_tracking",
  "tracking.ecomm360": "tracking_ecomm360",
  "tracking.google_analytics": "tracking_google_analytics",
  "tracking.clicktale": "tracking_clicktale",
  "delivery_status.enabled": "delivery_status_enabled",
  "_links": {
    "type": "column",
    "mapping": {
      "destination": "links"
    },
    "forceType": true
  }

}}
```

### JSON

The value of the `Result Name` (`dataType`) property is an arbitrary name. Apart from identifying
the resource type, it is also used as the **output table name**. If you run
the job, the content will be stored in `in.c-ge-tutorial.content`.

Each mapping item is identified by the property name of the resource and must contain 
`mapping.destination` with the target column name in the output table. For example:

{% highlight json %}
"mappings": {
    "content": {
        "plain_text": {
            "mapping": {
                "destination": "text"
            }
        }
{% endhighlight %}

The above mapping setting defines that the 
resource property `plain_text` will be stored in the table column `text` for the `content` data type. No other
properties of the content resource will be imported. In other words, the mapping defines
all columns of the output table.

To give an example, if you are interested in having the `plain_text` and `html` versions of the 
campaign content, use a mapping like this:

{% highlight json %}
"mappings": {
    "content": {
        "plain_text": {
            "mapping": {
                "destination": "text"
            }
        },
        "html": {
            "mapping": {
                "destination": "html"
            }
        }
    }
}
{% endhighlight %}

Note that the `destination` value is arbitrary but must be a valid column name.
The data type name (`content`) must match the value of the `dataType` property 
as defined in some jobs.

## Parent Reference
The above mapping works, but it is missing the campaign ID, and you cannot
match the content to some campaign records. Therefore, you must extract the campaign ID 
from the context (i.e., the job parameter). This can be done using a special `user` mapping.

When the mapping `type` is set to `user`, use the special prefix `parent_` to refer to
a `placeholder` defined in the job. You can create the following mapping:

{% highlight json %}
"mappings": {
    "content": {
        "parent_id": {
            "type": "user",
            "mapping": {
                "destination": "campaign_id"
            }
        }
    }
}
{% endhighlight %}

The above configuration defines a mapping for the `content` data type.
In the result table named `content`, the column `campaign_id` will be created.
Its content will be the value of the `id` placeholder 
(`parent_id` minus the `parent_` prefix) in the respective job.

Apart from specifying what columns should be in the output table, the 
mapping allows you to set a column as part of a primary key. The entire configuration would 
then look like this:

{% highlight json %}
{
    "parameters": {
        "api": {
            "baseUrl": "https://us13.api.mailchimp.com/3.0/",
            "authentication": {
                "type": "basic"
            },
            "pagination": {
                "method": "offset",
                "offsetParam": "offset",
                "limitParam": "count",
                "limit": 10
            }
        },
        "config": {
            "debug": true,
            "username": "dummy",
            "#password": "c40xxxxxxxxxxxxxxxxxxxxxxxxxxxxx-us13",
            "outputBucket": "ge-tutorial",
            "jobs": [
                {
                    "endpoint": "campaigns",
                    "dataField": "campaigns",
                    "children": [
                        {
                            "endpoint": "campaigns/{campaign_id}/send-checklist",
                            "dataField": "items",
                            "placeholders": {
                                "campaign_id": "id"
                            }
                        },
                        {
                            "endpoint": "campaigns/{campaign_id}/content",
                            "dataField": ".",
                            "dataType": "content",
                            "placeholders": {
                                "campaign_id": "id"
                            }
                        }
                    ]
                }
            ],
            "mappings": {
                "content": {
                    "parent_id": {
                        "type": "user",
                        "mapping": {
                            "destination": "campaign_id",
                            "primaryKey": true
                        }
                    },
                    "plain_text": {
                        "mapping": {
                            "destination": "text"
                        }
                    },
                    "html": {
                        "mapping": {
                            "destination": "html"
                        }
                    }
                }
            }
        }
    }
}
{% endhighlight %}

## Review
Now, let's review what parts are connected and how. Note that the values in blue 
have been chosen arbitrarily when the configuration was created:

{: .image-popup}
![Configuration Schema](/extend/generic-extractor/tutorial/configuration-schema.svg)

## Summary
Mapping lets you precisely define what the extraction output will look like; it also 
defines primary keys. 

If you do a one-time ad-hoc extraction, you may skip setting up the mapping and clean 
the extracted data later in [Transformations](https://help.keboola.com/manipulation/transformations/). 
However, if you intend to use your configuration regularly or want to make it into a component, 
setting up a mapping is recommended.

## Tips and Tricks

### Key Containing a Dot Character

The key of the mapping supports dot notation to traverse into children. So, if the key contains a dot, you need to change the delimiter. See the following example: 

{% highlight json %}
"mappings": {
    "content": {
        "created.date": {
            "delimiter": "/",
            "type": "column",
            "mapping": {
                "destination": "createdDate"
            }
        }
    }
}
{% endhighlight %}

As you changed the delimiter from the default `.` to `/`, it's no longer parsed as two separate keys `created` and `date`, but rather just a single key `created.date`.


================================================
File: extend/generic-extractor/tutorial/pagination.md
================================================
---
title: Pagination Tutorial
permalink: /extend/generic-extractor/tutorial/pagination/
---

* TOC
{:toc}

Pagination breaks a result with a large number of items into separate pages and is used very commonly in 
many API calls. 

In the previous part of the tutorial, you [fetched campaigns from 
the MailChimp API](/extend/generic-extractor/tutorial/). If you created a new account, chances are that you probably have 
only one campaign. You should now create some more campaigns (you do not have to configure them anyhow).

If the API has consistent pagination for all resources (which the
[MailChimp API has](https://mailchimp.com/developer/guides/get-started-with-mailchimp-api-3/#Parameters)),
then the pagination is defined in the `Pagination` section of the endpoint configuration (or in the `api` section in the underlying JSON).

## Preparation
The MailChimp API uses the [`offset` pagination method](https://mailchimp.com/developer/guides/get-started-with-mailchimp-api-3/#Parameters),
which means that each page has a fixed `limit` (by default 10 items), and you need to use the offset to move 
that fixed-size page over the next set of results. For the first page, the `offset` is 0, for the second 
page, the `offset` is 10. This is the same kind of pagination as in SQL.

The offset pagination method is configured with the following basic properties:

- `method` --- for MailChimp, set this property to `offset`.
- `offsetParam` --- name of the API parameter which defines the [page offset](https://mailchimp.com/developer/guides/get-started-with-mailchimp-api-3/#Parameters)
- `limitParam` -- name of the API parameters which define the [page size (limit)](https://mailchimp.com/developer/guides/get-started-with-mailchimp-api-3/#Parameters)

So, for MailChimp, configure the pagination this way:

- Click `Create New Pagination` in the Endpoint's Pagination section:

{: .image-popup}
![Create pagination.png](/extend/generic-extractor/tutorial/img.png)

- Name your pagination and select the Offset method:

![Pagination](/extend/generic-extractor/tutorial/pagination.png)

### JSON

The resulting JSON configuration will look like this:

{% highlight json %}
"api": {
    "baseUrl": "https://us13.api.mailchimp.com/3.0/",
    "authentication": {
      "type": "basic"
    },
    "pagination": {
      "method": "multiple",
      "scrollers": {
        "default": {
          "method": "offset",
          "limit": 100,
          "limitParam": "count",
          "offsetParam": "offset",
          "firstPageParams": true,
          "offsetFromJob": false
        }
      }
    }
}

{% endhighlight %}

Alternatively, you can use a single pagination method instead of a scroller when configuring manually:

{% highlight json %}
"api": {
    "baseUrl": "https://us13.api.mailchimp.com/3.0/",
    "authentication": {
        "type": "basic"
    },
    "pagination": {
        "method": "offset",
        "offsetParam": "offset",
        "limitParam": "count"
    }
},
{% endhighlight %}

The entire Generic Extractor configuration will look like this:

{% highlight json %}
{
  "api": {
    "baseUrl": "https://us13.api.mailchimp.com/3.0/",
    "authentication": {
      "type": "basic"
    },
    "pagination": {
      "method": "multiple",
      "scrollers": {
        "default": {
          "method": "offset",
          "limit": 100,
          "limitParam": "count",
          "offsetParam": "offset",
          "firstPageParams": true,
          "offsetFromJob": false
        }
      }
    }
  },
  "config": {
    "outputBucket": "ge-tutorial",
    "incrementalOutput": false,
    "jobs": [
      {
        "__NAME": "campaigns",
        "endpoint": "campaigns",
        "method": "GET",
        "dataType": "campaigns",
        "dataField": {
          "path": ".",
          "delimiter": "."
        }
      }
    ],
    "__AUTH_METHOD": "basic",
    "username": "dummy",
    "#password": "c40xxxxxxxxxxxxxxxxxxxxxxxxxxxxx-us13"
  }
}
{% endhighlight %}

***Note:** The `__` prefixed parameters are for internal use by the UI and should not be modified. 
Also, they have no effect on component functionality.*

## Running

Now, make sure that you have more than one campaign in your account. 

## Testing
Because you probably have fewer than ten (the default page size) campaigns in your MailChimp account, 
there is no way to tell whether the pagination works. Let's make sure by setting the `limit` 
to 1 and turning the `debug` mode on so that you can see all the requests sent by Generic Extractor.

Run the configuration and review the events produced by the job. You should see something like this:

{: .image-popup}
![Screenshot - Debug Events](/extend/generic-extractor/tutorial/job-2.png)

The oldest events are at the bottom, so you can see that the extractor started by sending an HTTP request:

    GET /3.0/campaigns/?count=1&offset=0

Then, it continued with 

    GET /3.0/campaigns/?count=1&offset=1
    GET /3.0/campaigns/?count=1&offset=2

and so on. You should also see a warning that the `dataField 'campaigns' contains no data`. 
This is expected because Generic Extractor tries bigger offsets until the number of returned items is 
less than the page size. With the page size set to 1, this means that the last page will contain no data.

## Summary
In this part of the tutorial, you learned how to set up simple pagination. This is very important
because most APIs use some sort of pagination and without proper setting you would be 
getting incomplete data. The next two parts of our tutorial deal with setting up jobs and mapping:

- [Jobs](/extend/generic-extractor/tutorial/jobs/) --- describe the API endpoints 
		(resources) to be extracted.
- [Mapping](/extend/generic-extractor/tutorial/mapping/) --- describes how the JSON 
		response is converted into CSV files that will be imported into Storage.


================================================
File: extend/generic-extractor/tutorial/rest.md
================================================
---
title: REST HTTP API Introduction
permalink: /extend/generic-extractor/tutorial/rest/
---

* TOC
{:toc}

An [API (Application Programming Interface)](https://en.wikipedia.org/wiki/Application_programming_interface) is 
an [interface](https://en.wikipedia.org/wiki/Interface_(computing)) to an application, or a **service**
designed for machine access. It can be seen as the UI (User Interface) of an application designed
for machines (other applications). 

So that another application can be programmed to consume the API, it has to have some sort of specification.
A common specification for communicating on the web is the [HTTP protocol](https://en.wikipedia.org/wiki/Hypertext_Transfer_Protocol). 
Used by web browsers and other API clients, it defines how two parties (client and server) ought to communicate:

- Client creates an HTTP **request** and sends it to the server over the network.
- Server processes the request, creates a **response**, and sends it to the client over the network.

## HTTP Request
An HTTP request is composed of:

- URL
- HTTP Method
- HTTP Headers
- Optional Body

### URL
A [URL (Uniform Resource Locator)](https://en.wikipedia.org/wiki/URL) is the address you see in your web browser 
address bar. It allows you to **locate a resource**. Each URL has several parts, and it is important to know them.
For example, the address

    https://www.example.com:8080/customers/acme/order/?show=deleted&fields=all

is composed of:

- `https` --- **Protocol** (HTTP or HTTPS),
- `www.example.com` --- **Host** --- network address of the HTTP server,
- `8080` --- **port** --- Optional network identifier within the target server; its default value is `80`.
- `/customers/acme/order/` --- Optional **path** to a **resource** we wish to obtain; its default value is `\`.
- `show=deleted&fields=all` --- Optional **request parameters** (also called **query string** or **query
string parameters**), separated by the character `&` (ampersand); the actual parameters are:
    - `show` with the value `deleted`, and
    - `fields` with the value `all`.

Because the URL contains a number of special characters (`?`, `&`, `/` and many others), when these parameters
need to be part of the URL, they must be encoded (URL encoded, urlencoded, escaped). Therefore a URL:

    http://example.com/this address & special

will be actually sent to the server as:

    http%3A%2F%2Fexample.com%2Fthis+address+%26+special

The web browser (and Generic Extractor too) will normally do this conversion for you. However, you might run into
the encoded format in Generic Extractor events. There are plenty of [online tools to decode](https://urldecode.org/) 
this encoded format.

Sometimes, you may also encounter the term [URI (Uniform Resource Identifier)](https://en.wikipedia.org/wiki/Uniform_Resource_Identifier). 
It is used when a single **Resource** may be accessed through multiple URLs. For example, the web page 
`http://example.com` may display the same content as `http://example.com/home`. In such case one of the URLs 
(probably the second one) is chosen as an identifier, and becomes URI. For our use, there is no important 
difference between URI and URL.

An API **end-point** is identified by its URL, or URI, and should represent a distinct **resource** (users, 
invoices etc.). ***Important:** The terms end-point, resource, URL and URI are used interchangeably throughout the 
tutorial because they ultimately refer to the same thing.*

### Method
An HTTP **Method** describes a type of the request to make. It also called an **HTTP Verb** because it 
describes what to do with the **resource**. Common HTTP verbs are:

- `GET` --- Obtain a resource.
- `POST` and `PATCH` --- Update a resource.
- `PUT` --- Create a resource.
- `DELETE` --- Delete a resource.

Since Generic Extractor only reads data from another API, you will mostly use the `GET` method (and sometimes the 
`POST` method). The other HTTP methods are not important for us. 

### Headers
An HTTP request can contain [**headers**](https://en.wikipedia.org/wiki/List_of_HTTP_header_fields#Request_Headers), 
which include additional information about the request and response. A typical example of a header is 
`Content-type`. For instance, for a web page, `Content-Type: text/html` would be used because an 
[HTML page](https://en.wikipedia.org/wiki/HTML) is being transferred. For an API request, it is commonly set 
to `Content-type: application/json` because we are transferring [JSON data](http://www.json.org/). 

Apart from standard headers, there are also non-standard headers; these are marked with the prefix `X-`. An 
example is the `X-StorageAPIToken` header used with Keboola [Storage API](/integrate/storage/api/).

### Body
The `POST`, `PUT` and `PATCH` requests can send parameters the same way as the `GET` requests in the URL. 
But they can also send them in the request **body**. These are sometimes called **POST data/postdata**.

## HTTP Response
An HTTP response is composed of:

- Response Headers --- same as the request headers (only sent by the server)
- Response Body --- actual content of the resource
- Status Code --- status of the request

#### HTTP Status
The HTTP Status and [status code](https://en.wikipedia.org/wiki/List_of_HTTP_status_codes) represent 
a standardized way of describing the response state. For example, the status `200 OK` (200 is the status code) 
is associated with a successful response. There are many HTTP Statuses, but the following rules apply:

- Status codes `2xx` (e.g., 200) represent success.
- Status codes `3xx` represent [redirection](https://en.wikipedia.org/wiki/URL_redirection).
- Status codes `4xx` represent a client error (the request is wrong).
- Status codes `5xx` represent a server error (the server failed to create the response).

## REST API
[REST (Representational state transfer)](https://www.restapitutorial.com/lessons/whatisrest.html) (or RESTful) 
is an API which follows a set of [loosely defined](http://restcookbook.com/Miscellaneous/rest-and-http/) principles:

- The API URLs (or URIs) represent individual **resources**. Each API endpoint should represent a resource of 
a *single type*. For example, it represents a list of users, and not a list of users and their invoices.
- Each resource is **represented** in a structured format ([JSON](http://www.json.org/) or 
[XML](https://en.wikipedia.org/wiki/XML)). The data is not transferred, for instance, as ordinary text or a web 
page.
- **Messages** (request and response) are transferred using various HTTP methods (`GET`, `POST`, etc.). 
For example, for obtaining data, the `GET` method should be used. Also the `GET` method
should not cause any modifications of data.
- The entire communication is **stateless**. This means that multiple requests can be called in an
arbitrary order and must yield the same results. It is not correct for an API to have endpoints such as 
`setFilter` and`getFilteredResult` because they imply that any state (a filter) is retained between those API 
endpoints.

## Summary
The above describes the basic concepts of an API, HTTP protocol and HTTP REST API. When you 
understand these concepts (and the associated jargon), you can use Generic Extractor 
to get responses from virtually any HTTP REST API. Since the REST rules are not rigidly specified, it 
is not possible to ensure that Generic Extractor will be capable of reading 100% of APIs, 
even when declared as RESTful by someone.



================================================
File: extend/generic-writer/index.md
================================================
---
title: Generic Writer
permalink: /extend/generic-writer/
---

* TOC
{:toc}

Generic Writer is a [Keboola component](/overview/) that allows you to send any type of HTTP requests with or without data to arbitrary HTTP endpoints. 

It is a counterpart to the [Generic Extractor](/extend/generic-extractor) that allows you to extract data from virtually any API.

The core concepts and configuration of the writer are also quite similar to the Generic Extractor, so it should be easy to 
configure for anyone familiar with the extractor.

## Generic Writer Requirements
The requirements are the same as for the [Generic Extractor](/extend/generic-extractor/#generic-extractor-requirements).
No programming skills or additional tools are required. You just need to do two easy things before you start:

- Learn how to [write JSON](/extend/generic-extractor/tutorial/json/).
- Have the documentation of your chosen API at hand.

## Functionality Notes

The writer writes data to a specified endpoint in a specified format. It supports a single table and a single endpoint per configuration.

The content can be sent in two ways:

1. Send all content at once – either BINARY or JSON in chunks
2. Iterate through each row – where the data is sent in iterations specified in the input data. By default 1 row = 1 iteration. 
This allows to change the endpoint dynamically based on the input using placeholders: `www.example.com/api/user/{{id}}`.
Or sending data with different user parameters that are present in the input table.

## Use Cases

There are variety of use-cases for the generic writer. You may create, update or even delete objects via RESTful API or just trigger 
simple webhooks by sending GET requests to specified endpoints or send notifications to slack. The setup is quite straightforward and it 
allows you to leverage secure [encripted parameters](overview/encryption/) and dynamic functions. 

**The typical use cases are:**

- Webhook triggers
- Notifications, e.g., Slack
- Writing JSON data (UPDATES, etc.)
- Sending CSV files as binary data (may be gzipped)
- Calling arbitrary endpoints with parameters defined on the input
    - E.g., `DELETE api.com/[[user_id]]` where `user_id` is a column in the input table

For real configuration examples, see the [configuration examples section](/extend/generic-writer/configuration-examples)
 or the collection of [functional examples](https://bitbucket.org/kds_consulting_team/kds-team.wr-generic/src/master/docs/examples/).


================================================
File: extend/generic-writer/configuration/configuration-examples.md
================================================
---
title: Generic Writer Configuration Examples
permalink: /extend/generic-writer/configuration-examples/
---

* TOC
{:toc}


### Configuration Example – Iterations

This configuration sends the POST request to `https://example.com/test/[[id]]` where `[[id]]` is a column expected in the input table. 
It will send as many requests as there are rows in the input table. Each request object is wrapped in `{"data":{}}` object.

```json
{
 "api": {
  "base_url": "https://example.com"
 },
 "user_parameters": {
  "date": {
   "function": "concat",
   "args": [
    {
     "function": "string_to_date",
     "args": [
      "yesterday",
      "%Y-%m-%d"
     ]
    },
    "T"
   ]
  }
 },
 "request_parameters": {
  "method": "POST",
  "endpoint_path": "/test/[[id]]?",
  "headers": {
   "Authorization": {
    "attr": "token_encoded"
   },
   "Content-Type": "application/json"
  },
  "query_parameters": {
   "date": {
    "attr": "date"
   }
  }
 },
 "request_content": {
  "content_type": "JSON",
  "json_mapping": {
   "nesting_delimiter": "_",
   "chunk_size": 1,
   "column_data_types": {
    "autodetect": true
   },
   "request_data_wrapper": "{ \"data\": [[data]]}",
   "column_names_override": {}
  },
  "iterate_by_columns": [
   "id"
  ]
 }
}
```

### Exponea Batch Events Writer

Write customer [events](https://docs.exponea.com/reference#add-event) into the [Exponea API](https://docs.exponea.com)
in [batches](https://docs.exponea.com/reference#batch-commands) of `3` requests.


**Writer config:**

```json
{
 "debug": false,
 "api": {
  "base_url": "https://api-demoapp.exponea.com"
 },
 "user_parameters": {
  "#token": "12345",
  "token_encoded": {
   "function": "concat",
   "args": [
    "Basic ",
    {
     "function": "base64_encode",
     "args": [
      {
       "attr": "#token"
      }
     ]
    }
   ]
  }
 },
 "request_parameters": {
  "method": "POST",
  "endpoint_path": "/track/v2/projects/1234566/batch?",
  "headers": {
   "Authorization": {
    "attr": "token_encoded"
   },
   "Content-type": "application/csv"
  }
 },
 "request_content": {
  "content_type": "JSON",
  "json_mapping": {
   "nesting_delimiter": "__",
   "chunk_size": 3,
   "column_data_types": {
    "autodetect": true
   },
   "request_data_wrapper": "{\"commands\":{{data}}}"
  }
 }
}
```

**Input table:**

| name             | data__customer_ids__registered | data__properties__price | data__timestamp | data__event_type | data__properties__test |
|------------------|--------------------------------|-------------------------|-----------------|------------------|------------------------|
| customers/events | milan@test.com              | 150                     | 123456.78       | testing_event    | a                      |
| customers/events | petr@test.com               | 150                     | 123456.78       | testing_event    | a                      |
| customers/events | masha@test.com    | 150                     | 123456.78       | testing_event    | a                      |


**Result request:**

```json
{
    "commands": [{
            "name": "customers/events",
            "data": {
                "customer_ids": {
                    "registered": "milan@keboola.com"
                },
                "properties": {
                    "price": 150,
                    "test": "a"
                },
                "timestamp": 123456.78,
                "event_type": "testing_event"
            }
        }, {
            "name": "customers/events",
            "data": {
                "customer_ids": {
                    "registered": "petr@keboola.com"
                },
                "properties": {
                    "price": 150,
                    "test": "a"
                },
                "timestamp": 123456.78,
                "event_type": "testing_event"
            }
        }, {
            "name": "customers/events",
            "data": {
                "customer_ids": {
                    "registered": "masha.reutovski@keboola.com"
                },
                "properties": {
                    "price": 150,
                    "test": "a"
                },
                "timestamp": 123456.78,
                "event_type": "testing_event"
            }
        }
    ]
}

```

### Customer.io User Event

Update user events via the [Customer.io API](https://customer.io/docs/api/#apitrackeventsevent_add) based on the user_id column.

The API uses Basic http authentication.

**Writer config:**

```json
{
 "api": {
  "base_url": "https://track.customer.io",
  "authentication": {
        "type": "BasicHttp",
        "parameters": {
          "username": "test_user",
          "#password": "pass"
        }
      }
 },
 "request_parameters": {
  "method": "POST",
  "endpoint_path": "/api/v1/customers/{{user_id}}/events?",
  "headers": {
   "Authorization": {
    "attr": "token_encoded"
   },
   "Content-type": "application/csv"
  }
 },
 "request_content": {
  "content_type": "JSON",
  "json_mapping": {
   "nesting_delimiter": "_",
   "chunk_size": 1,
   "column_data_types": {
    "autodetect": true
   },
   "request_data_wrapper": "",
   "column_names_override": {}
  },
  "iterate_by_columns": [
   "user_id"
  ]
 }
}
```


**Input Table:**

| user_id        | data_price | data_date | name          |
|----------------|------------|-----------|---------------|
| a@test.com     | 150        | 1.1.20    | testing_event |
| petr@test.com  | 150        | 1.1.20    | testing_event |
| masha@test.com | 150        | 1.1.20    | testing_event |

**Json request:**

For each row in the input one request:

POST `https://track.customer.io/api/v1/customers/a@test.com/events`

```json
{"data": {"price": 150, "date": "1.1.20"}, "name": "testing_event"}
```


### Slack Notification

Send notifications to Slack channels via an API. Note that you need to create an app with appropriate permissions at https://api.slack.com/apps
 and retrieve the API token.



**Input Table:**

| channel        | text       |
|----------------|------------|
| AC098098   | Hello        |
| AC092131   | World        |


**Configuration:**

```json
{
 "debug": true,
 "api": {
  "base_url": "https://slack.com"
 },
 "user_parameters": {
  "#token": "",
  "token_encoded": {
   "function": "concat",
   "args": [
    "Bearer ",
    {
     "attr": "#token"
    }
   ]
  }
 },
 "request_parameters": {
  "method": "POST",
  "endpoint_path": "/api/chat.postMessage?",
  "headers": {
   "Authorization": {
    "attr": "token_encoded"
   },
   "Content-type": "application/json"
  }
 },
 "request_content": {
  "content_type": "JSON",
  "json_mapping": {
   "nesting_delimiter": "_",
   "chunk_size": 1,
   "column_data_types": {
    "autodetect": true
   },
   "request_data_wrapper": ""
  }
 }
}

```


================================================
File: extend/generic-writer/configuration/configuration.md
================================================
---
title: Generic Writer Configuration 
permalink: /extend/generic-writer/configuration/
---

* TOC 
{:toc}

This component allows you to write data to a specified endpoint in a specified format. It currently supports single
table and single endpoint per configuration.

The data can be sent in two ways:

1. Send all content at once - either BINARY or JSON in chunks
2. [Iterate](/extend/generic-writer/configuration/#iterate-by-columns) through each row - where the data is sent in
   iterations specified in the input data. By default 1 row = 1 iteration. This allows to change the endpoint
   dynamically based on the input using placeholders: `www.example.com/api/user/{{id}}`. Or sending data with different
   user parameters that are present in the input table.

### Configuration parameters

*Click on the section names if you want to learn more.*

- [**api**](/extend/generic-writer/configuration/#api) --- [REQUIRED] sets the basic properties of the API.
    - [**base_url**](/extend/generic-writer/configuration/#base-url) ---  [REQUIRED] defines the URL to which the API requests
      should be sent.
    - [**authentication**](/extend/generic-writer/configuration/#authentication) --- needs to be configured for any API
      which is not public.
    - [**retry_config**](/extend/generic-writer/configuration/#retry-config) --- automatically, and repeatedly, retries
      failed HTTP requests.
    - [**default_query_parameters**](/extend/generic-writer/configuration/#default-query-parameters) --- sets the
      default query parameters sent with each API call.
    - [**default_headers**](/extend/generic-writer/configuration/#default-headers) --- sets the default query headers
      sent with each API call.
    - [**ssl_verification**](/extend/generic-writer/configuration/#ssl-verification) --- allows turning of the SSL certificate
      verification. Use with caution.
    - [**timeout**](/extend/generic-writer/configuration/#timeout) --- maximum time in seconds for which the component
      waits after each request (defaults to None if not set).
- [**user_parameters**](/extend/generic-writer/configuration/#user-parameters) --- user parameters to be used in various
  contexts, e.g. passwords. Supports dynamic functions.
- [**request_parameters**](/extend/generic-writer/configuration/#request-parameters) --- [REQUIRED] HTTP parameters of the request
    - [**method**](/extend/generic-writer/configuration/#method) --- [REQUIRED] defines the HTTP method of the requests.
    - [**endpoint_path**](/extend/generic-writer/configuration/#enpoint-path) --- [REQUIRED] relative path of the endpoint.
    - [**query_parameters**](/extend/generic-writer/configuration/#query-parameters) --- query parameters sent with each
      request
    - [**headers**](/extend/generic-writer/configuration/#headers) --- headers sent with each request
- [**request_content**](/extend/generic-writer/configuration/#request-content) --- [REQUIRED] defines how the data is sent
    - [**content_type**](/extend/generic-writer/configuration/#content-type) --- [REQUIRED] defines how the data is transferred (
      JSON, binary file, Empty, etc.)
    - [**json_mapping**](/extend/generic-writer/configuration/#json-mapping) --- defines the CSV 2 JSON conversion in
      case of JSON content type.
    - [**iterate_by_columns**](/extend/generic-writer/configuration/#iterate-by-columns) --- defines set of columns in
      the input data that are excluded from the content and may be used instead of placeholders within the
      request_options. The input table is iterated row by row, e.g. 1 row = 1 request
- [**debug**](/extend/generic-writer/configuration/#debug) --- Turns on more verbose logging for debugging purposes.

There are also simple pre-defined [**functions**](/extend/generic-writer/configuration/#dynamic-functions) available,
adding extra flexibility when needed.

### Configuration Map

The following sample configuration shows various configuration options and their nesting. You can use the map to
navigate between them.

{% highlight json %} {% include writer-config-map.json %} {% endhighlight %}

<script>
{% include writer-config-events.js %}
</script>
<style>
pre a {
    border-bottom: 1px dashed navy;
}
</style>

## Api

Defines the basic properties of the API that may be shared for multiple endpoints. Such as authentication, base url,
etc.

### Base URL

An URL of the endpoint where the payload is being sent. e.g. `www.example.com/api/v1`.

**NOTE** May contain placeholders for iterations wrapped in `[[]]`,e.g. ``www.example.com/api/v[[api_version]]``.  
But in most cases you would set this up on the `endpoint_path` level.

The parameter `api_version` needs to be specified in the `user_parameters` or in the source data itself if the column is
set as an iteration parameter column.

### Retry Config

Here you can set parameters of the request retry in case of failure.

- `max_retries` --- Number of maximum retries before failure (DEFAULT `1`)
- `codes` --- List of HTTP codes to retry on, e.g. [503, 429] (DEFAULT `(500, 502, 504)`)
- `backoff_factor` --- backoff factor of the exponential backoff. (DEFAULT `0.3`)

```json
{
  "api": {
    "base_url": "https://example.com/api",
    "retry_config": {
      "max_retries": 5,
      "backoff_factor": 0.3,
      "codes": [
        500,
        429
      ]
    }
  }
}
```

### Default Query Parameters

Allows you to define default query parameters that are being sent with each request. This is useful for
instance for authentication purposes. This is mostly useful for creating Generic Writer templates and registered
components.

**NOTE** That you can reference parameters defined in `user_parameters` using the `{"attr":"SOME_KEY"}` syntax.

```json
{
  "api": {
    "base_url": "https://example.com/api",
    "default_query_parameters": {
      "content_type": "json",
      "token": {
        "attr": "#token"
      }
    }
  }
}
```

### Default Headers

Allows you to define default query parameters that are being sent with each req This is mostly useful for
creating Generic Writer templates and registered components.

**NOTE** That you can reference parameters defined in `user_parameters` using the `{"attr":"SOME_KEY"}` syntax.

```json
 {
  "api": {
    "base_url": "https://example.com/api",
    "default_headers": {
      "Authorization": {
        "attr": "#token"
      }
    }
  }
}
```

### Authentication

Some APIs require authenticated requests to be made. This section allows selecting from predefined auth methods.

The Authentication object is always in following format:

```json

{
  "type": "{SUPPORTED_TYPE}",
  "parameters": {
    "some_parameter": "test_user"
  }
}
```

**NOTE** Parameters may be also referenced from the `user_parameters` section using the `{"attr":""}` syntax,
see [example 025](https://bitbucket.org/kds_consulting_team/kds-team.wr-generic/src/master/docs/examples/025-simple-json-basic-http-auth-from-user-params)

#### BasicHttp

Basic HTTP authentication using username and password.

**Example**:

```json
"api": {
  "base_url": "http://localhost:8000",
  "authentication": {
        "type": "BasicHttp",
        "parameters": {
            "username": "test_user",
            "#password": "pass"
        }
    }
}
```

See [example 024](https://bitbucket.org/kds_consulting_team/kds-team.wr-generic/src/master/docs/examples/024-simple-json-basic-http-auth)


#### BearerToken

Authorization using the `Bearer token` in the header. E.g. each request will be sent with
header: `"authorization": "Bearer XXXX""`

**Example**:

```json
{
  "api": {
    "base_url": "http://localhost:8000",
    "authentication": {
      "type": "BearerToken",
      "parameters": {
        "#token": "XXXX"
      }
    }
  }
}
```

See [example 030](https://bitbucket.org/kds_consulting_team/kds-team.wr-generic/src/master/docs/examples/030-bearer-token-auth)

### SSL Verification

Allows turning of the SSL certificate verification. Use with caution. When set to false, the certificate verification is
turned off.

```json

{
  "api": {
    "base_url": "http://localhost:8000",
    "ssl_verification": false
  }
}
```

### Timeout

An optional parameter which allows you to define maximum timeout for each request. If not set, it uses the default requests value: None.

Possible values: (int, float)

For more information, refer to [requests docs](https://requests.readthedocs.io/en/stable/user/advanced/#timeouts).


## User Parameters

In this section you can defined user parameters to be used in various contexts, e.g. passwords. This is also
the place to use the [dynamic functions]().

It allows referencing another values from `user_parameters` referenced by `{"attr":"par"}` notation.

**NOTE** Any parameters prefixed by `#` will be encrypted in the Keboola platform on configuration save.

```json
{
  "user_parameters": {
    "#token": "Bearer 123456",
    "date": {
      "function": "concat",
      "args": [
        {
          "function": "string_to_date",
          "args": [
            "yesterday",
            "%Y-%m-%d"
          ]
        },
        "T"
      ]
    }
  }
}
```

### Referencing parameters

All parameters defined here can be then referenced using the `{"attr":"PARAMETER_KEY"}` syntax. You may reference them
in the following sections:

- in the `user_parameters` section itself.
- [`api.default_query_parameters`](/extend/generic-writer/configuration/#default-query-parameters)
- [`api.default_headers`](/extend/generic-writer/configuration/#default-headers)
- [`request_parameters.headers`](/extend/generic-writer/configuration/#headers)
- [`request_parameters.query parameters`](/extend/generic-writer/configuration/#query-parameters)

See
example [010](https://bitbucket.org/kds_consulting_team/kds-team.wr-generic/src/master/docs/examples/010-simple-json-user-parameters-various)

## Request Parameters

Define parameters of the HTTP request sent.

### Method

Request method - POST, PUT, UPDATE, DELETE etc.

Supported methods: `['GET', 'POST', 'PATCH', 'UPDATE', 'PUT', 'DELETE']`

```json
"request_parameters": {
    "method": "POST",
    ...
```

### Endpoint path

A relative path of the endpoint. The final request URL is `base_url` and `endpoint_path` combined.

e.g. when `base_url` is set to `https://example.com/api` and `endpoint_path` to `/customer` the resulting URL
is `https://example.com/api/customer`

**NOTE** That it is possible to change the `enpoint_path` dynamically
using [iteration columns](/extend/generic-writer/configuration/#iterate-by-columns) e.g. `/orders/[[id]]` as seen
in [example 005](https://bitbucket.org/kds_consulting_team/kds-team.wr-generic/src/master/docs/examples/005-json-iterations/)

```json
{
  "request_parameters": {
    "method": "POST",
    "endpoint_path": "/customer"
  }
}
```

### Headers

Allows you to define default query parameters that are being sent with each request.

**NOTE** That you can reference parameters defined in `user_parameters` using the `{"attr":"SOME_KEY"}` syntax.

```json
{
  "request_parameters": {
    "method": "POST",
    "endpoint_path": "/customer",
    "headers": {
      "Last-updated": 123343534
    }
  }
}
```

See [example 006](https://bitbucket.org/kds_consulting_team/kds-team.wr-generic/src/master/docs/examples/006-simple-json-custom-headers/)

### Query parameters

Allows you to define default query parameters that are being sent with each request.

**NOTE** That you can reference parameters defined in `user_parameters` using the `{"attr":"SOME_KEY"}` syntax.

```json
 {
  "request_parameters": {
    "method": "POST",
    "endpoint_path": "/customer/[[id]]",
    "query_parameters": {
      "dryRun": true,
      "date": {
        "attr": "date"
      }
    }
  }
}
```

See [example 009](https://bitbucket.org/kds_consulting_team/kds-team.wr-generic/src/master/docs/examples/009-simple-json-request-parameters/)

## Request Content

Defines how to process the input and how the sent content should look like.

### Content Type

 Defines how the input table is translated to a request:

- `JSON` - input table is converted into a JSON (see `json_mapping`) sent as `application/json` type.
  See [example 001](https://bitbucket.org/kds_consulting_team/kds-team.wr-generic/src/master/docs/examples/001-simple-json/)
- `JSON_URL_ENCODED` - input table is converted into a JSON and sent as `application/x-www-form-urlencoded`.
  See [example 021](https://bitbucket.org/kds_consulting_team/kds-team.wr-generic/src/master/docs/examples/021-simple-json-url-encoded-form/)
- `BINARY` - input table is sent as binary data (just like `curl --data-binary`).
  See [example](https://bitbucket.org/kds_consulting_team/kds-team.wr-generic/src/master/tests/functional/binary_simple/)
- `BINARY-GZ` - input is sent as gzipped binary data.
  See [example](https://bitbucket.org/kds_consulting_team/kds-team.wr-generic/src/master/tests/functional/binary_gz/)
- `EMPTY_REQUEST` - sends just empty requests. Usefull for triggerring webhooks, DELETE calls, etc. As many requests as
  there are rows on the input are sent. Useful with `iterate_by_columns` enabled to trigger multiple endpoints.
  See [example 022](https://bitbucket.org/kds_consulting_team/kds-team.wr-generic/src/master/docs/examples/022-empty-request-iterations-delete/)

```json

"request_content": {
    "content_type": "JSON",
....
```

### JSON Mapping

[REQUIRED for JSON based content type] This section defines the CSV 2 JSON conversion in case of JSON content type.

#### Nesting delimiter

A string that is used for nesting. e.g. `__`. This way you can define nested objects based on column names.

e.g. When set to `__` a column value `address__streed` will be converted to `{"address"{"street":"COLUMN_VALUE"}}`

```json
"request_content": {
    "content_type": "JSON",
    "json_mapping": {
        "nesting_delimiter": "_",
...
```

See
example [008](https://bitbucket.org/kds_consulting_team/kds-team.wr-generic/src/master/docs/examples/008-simple-json-nested-object-delimiter/)

#### Chunk size

Defines how many rows are being sent in a single request. When set to `1` a single object is sent `{}` (
see [example 002](https://bitbucket.org/kds_consulting_team/kds-team.wr-generic/src/master/docs/examples/002-simple-json-chunked-single/))
, when set to >1 an array of objects is sent `[{}, {}]` (
see [example 003](https://bitbucket.org/kds_consulting_team/kds-team.wr-generic/src/master/docs/examples/003-simple-json-chunked-multi/))

```json
"request_content": {
    "content_type": "JSON",
    "json_mapping": {
        "nesting_delimiter": "_",
        "chunk_size": 1,
...
```

#### Column datatypes

Optional configuration of column types. This version supports nesting (three levels) and three datatypes:

- `bool` - Boolean value case-insensitive conversion: `t`, `true`, `yes`, `1`,`"1"` to `True` and `f`, `false`, `no`
  to `False`
- `string` - String
- `number` - Number
- `object` - Object - valid JSON array or JSON object, e.g. ["1","2"], {"key":"val"}

##### Autodetect

Default value `true
`
Set this option to `true` to make the parser automatically detect the above datatypes. It may be used in combination
with
`datatype_override` option to force datatype to some columns.

##### Column datatype override

[OPTIONAL]

The `autodetect` option in most cases takes care of the datatype conversion properly. But there are some scenarios where
you want make sure that the datatype conversion is forced. E.g. for `phone_number` column to be treated as String a
mapping should be defined as `"phone_number":"string"`.

Below are options that can be used as a datatype values:

if you want the value to be always a string, use `string`, if you want the value to be numeric, use `number`. If you
want it to be Boolean, use `bool`
(case-insensitive conversion: `t`, `true`, `yes` to `True` and `f`, `false`, `no` to `False`)
If the value should be an array or object `object` - valid JSON array or JSON object, e.g. ["1","2"], {"key":"val"}

**Note** If the `autodetect` option is turned off all unspecified column will be treated as a string.

```json
{
  "request_content": {
    "content_type": "JSON",
    "json_mapping": {
      "nesting_delimiter": "_",
      "chunk_size": 1,
      "column_data_types": {
        "autodetect": true,
        "datatype_override": [
          {
            "column": "phone",
            "type": "string"
          },
          {
            "column": "rank",
            "type": "number"
          },
          {
            "column": "is_active",
            "type": "bool"
          }
        ]
      }
    }
  }
}
```

See [example 007](https://bitbucket.org/kds_consulting_team/kds-team.wr-generic/src/master/docs/examples/007-simple-json-force-datatype/)

#### Request Data Wrapper

[OPTIONAL]

A wrapper/mask of the parsed data. It needs to be json-encoded json. E.g

```json
"request_content": {
    "content_type": "JSON",
    "json_mapping": {
        "nesting_delimiter": "__",
        "chunk_size": 1,
        "request_data_wrapper": "{ \"data\": [[data]]}",
    ...
}
```

Given a single column `user__id` and `chunksize` = 2, the above will cause each request being sent as:

```json
{
  "data": [
    {
      "user": {
        "id": 1
      }
    },
    {
      "user": {
        "id": 2
      }
    }
  ]
}
```

See
examples: [012](https://bitbucket.org/kds_consulting_team/kds-team.wr-generic/src/master/docs/examples/012-simple-json-request-data-wrapper/)

#### Column names override

You may override specific column names using the `column_names_override` parameter to be able to generate fields with
characters not supported in Storage column names.

**NOTE** that this is applied **after** the column type definition, so refer to original name in the `column_types`
config.

**NOTE2** It is possible to rename nested objects as well. The rename is applied to the leaf node.
E.g. `"address___city":"city.address"`
with delimiter set to `___` will result in `{"address":{"city.address":"SOME_VALUE"}}`.
See [example 23](https://bitbucket.org/kds_consulting_team/kds-team.wr-generic/src/master/docs/examples/023-simple-json-nested-object-rename-column/)

**Example:**

```json
"request_content": {
    "content_type": "JSON",
        "json_mapping": {
            "nesting_delimiter": "_",
            "chunk_size": 1,
            "column_names_override": {
                "field_id": "field-id",
                "full_name": "FULL.NAME"
            }
    }
...
}
```

For more details refer to
examples: [20](https://bitbucket.org/kds_consulting_team/kds-team.wr-generic/src/master/docs/examples/020-simple-json-column-name-override/)
and [23](https://bitbucket.org/kds_consulting_team/kds-team.wr-generic/src/master/docs/examples/023-simple-json-nested-object-rename-column/)

### Iterate By Columns

This parameter allows performing the requests in iterations based on provided parameters within data. The user specifies
columns in the source table that will be used as parameters for each request. The column values may be then used instead
of placeholders within the `request_options`. The input table is iterated row by row, e.g. 1 row = 1 request.

```json
"request_content": {
    "content_type": "JSON",
        "iterate_by_columns": [
          "id", "date"
        ]
}

```

These will be injected in:

- `request_parameters.endpoint_path` if placeholder is specified, e.g.  `/user/[[id]]`
- `user_parameters` section, any existing parameters with a same name will be replaced by the value from the data. This
  allows for example for changing request parameters dynamically `www.example.com/api/user?date=xx` where the `date`
  value is specified like:

```json
{
  "request_parameters": {
    "method": "POST",
    "endpoint_path": "/customer/[[id]]",
    "query_parameters": {
      "date": {
        "attr": "date"
      }
    }
  }
}



```

**NOTE** The iteration columns may be specified for requests of any content type. The `chunk_size` parameter in JSON
mapping is overridden to `1`.

See the example configurations:

- [ex. 005](https://bitbucket.org/kds_consulting_team/kds-team.wr-generic/src/master/docs/examples/005-json-iterations/)
- Empty request with
  iterations [ex. 004](https://bitbucket.org/kds_consulting_team/kds-team.wr-generic/src/master/docs/examples/004-empty-request-iterations/)
  ,
  [ex. 22](https://bitbucket.org/kds_consulting_team/kds-team.wr-generic/src/master/docs/examples/022-empty-request-iterations-delete/)
- [ex. 011 placeholders in query parameters](https://bitbucket.org/kds_consulting_team/kds-team.wr-generic/src/master/docs/examples/011-simple-json-user-parameters-from-iterations/)

##### Example

Let's have this table on the input:

| id | date       | name  | email      | address |
|----|------------|-------|------------|---------|
| 1  | 01.01.2020 | David | d@test.com | asd     |
| 2  | 01.02.2020 | Tom   | t@test.com | asd     |

Consider following request options:

```json
{
  "request_parameters": {
    "method": "POST",
    "endpoint_path": "/user/[[id]]",
    "query_parameters": {
      "date": {
        "attr": "date"
      }
    }
  },
  "request_content": {
    "content_type": "JSON",
    "iterate_by_columns": [
      "id",
      "date"
    ]
  }
}

```

The writer will run in two iterations:

**FIRST** With data

| name  | email      | address |
|-------|------------|---------|
| David | d@test.com | asd     |

Sent to `www.example.com/api/user/1?date=01.01.2020`

**SECOND** with data

| name  | email      | address |
|-------|------------|---------|
| Tom   | t@test.com | asd     |

Sent to `www.example.com/api/user/2?date=01.02.2020`

## Dynamic Functions

The application support functions that may be applied on parameters in the configuration to get dynamic values.

Currently these functions work only in the `user_parameters` scope. Place the required function object instead of the
user parameter value.

The function values may refer to another user params using `{"attr": "custom_par"}`

**NOTE:** If you are missing any function let us know or place a PR to
our [repository](https://bitbucket.org/kds_consulting_team/kds-team.wr-generic/src/). It's as simple as adding an
arbitrary method into
the [UserFunctions class](https://bitbucket.org/kds_consulting_team/kds-team.wr-generic/src/master/src/user_functions.py#lines-7)

**Function object**

```json
{
  "function": "string_to_date",
  "args": [
    "yesterday",
    "%Y-%m-%d"
  ]
}
```

#### Function Nesting

Nesting of functions is supported:

```json
{
  "user_parameters": {
    "url": {
      "function": "concat",
      "args": [
        "http://example.com",
        "/test?date=",
        {
          "function": "string_to_date",
          "args": [
            "yesterday",
            "%Y-%m-%d"
          ]
        }
      ]
    }
  }
}

```

#### string_to_date

Function converting string value into a datestring in specified format. The value may be either date in `YYYY-MM-DD`
format, or a relative period e.g. `5 hours ago`, `yesterday`,`3 days ago`, `4 months ago`, `2 years ago`, `today`.

The result is returned as a date string in the specified format, by default `%Y-%m-%d`

The function takes two arguments:

1. [REQ] Date string
2. [OPT] result date format. The format should be defined as in http://strftime.org/

**Example**

```json
{
  "user_parameters": {
    "yesterday_date": {
      "function": "string_to_date",
      "args": [
        "yesterday",
        "%Y-%m-%d"
      ]
    }
  }
}
```

The above value is then available in [supported contexts](/extend/generic-writer/configuration/#referencing-parameters)
as:

```json
"to_date": {"attr": "yesterday_date"}
```

#### concat

Concatenate an array of strings.

The function takes an array of strings to concatenate as an argument

**Example**

```json
{
  "user_parameters": {
    "url": {
      "function": "concat",
      "args": [
        "http://example.com",
        "/test"
      ]
    }
  }
}
```

The above value is then available in supported contexts as:

```json
"url": {"attr": "url"}
```

#### base64_encode

Encodes string in BASE64

**Example**

```json
{
  "user_parameters": {
    "token": {
      "function": "base64_encode",
      "args": [
        "user:pass"
      ]
    }
  }
}
```

The above value is then available in contexts as:

```json
"token": {"attr": "token"}
```

## Debug

By setting the root parameter `debug` to `true`, it is possible to enable more verbose logging that will help debugging.

**CAUTION** Note that higher verbosity causes the writer to print parts of the actual content into the job log, so use with caution. 
Always make sure to turn this option off after debugging to prevent any issues.

```json
{
  "debug": true,
  "api": {
    "base_url": "http://test.com/api/"
  },
  "user_parameters": {},
  "request_parameters": {
    "method": "POST",
    "endpoint_path": "users/[[id]]"
  },
  "request_content": {
    "content_type": "BINARY"
  }
}
```


================================================
File: extend/publish/checklist.md
================================================
---
title: Checklist
permalink: /extend/publish/checklist/
---

* TOC
{:toc}

This checklist is used for the last check of the component before sending the publish request.
See [Publish Component tutorial](/extend/publish/) for details.

**Developer Portal**
- <input type="checkbox"> The component name doesn't contain words like `extractor`, `application`, and `writer`.
- <input type="checkbox"> The component icon is representative and has reasonable quality. It is in `PNG` format and without background.
- <input type="checkbox"> The short description describes the **service**, NOT `This extractor extracts ...`.
- <input type="checkbox"> Licensing information is valid, and the vendor description is current.
- <input type="checkbox"> License and documentation URLs are publicly accessible, no link to a private repository.
- <input type="checkbox"> The tag is set to the expected value and uses [semantic versioning](https://semver.org/).
- <input type="checkbox"> The correct [data flow is set in UI options](/extend/publish/#component-name-and-description).


**Component Configuration**
- <input type="checkbox"> Sensitive values [use encryption](/overview/encryption/).
- [Configuration and Row schema](/extend/publish/#component-configuration)
    - <input type="checkbox"> Titles are short and without a colon, period, etc.
    - <input type="checkbox"> Required properties are listed in the field `required`.
    - <input type="checkbox"> Each property has defined `propertyOrder`.
    - <input type="checkbox"> Properties have an explanatory `description` if they are not trivial.
- Configuration description (if used)
  - <input type="checkbox"> Contains only level 3 `###` and level 4 `####` headers.
  - <input type="checkbox"> Doesn't repeat what is obvious from Configuration and Row schema.


**Component Internals**
- Job exits with an understandable [UserError](/extend/common-interface/environment/#return-values) if:
  - <input type="checkbox"> Empty configuration.
  - <input type="checkbox"> Invalid credentials.
  - <input type="checkbox"> Wrong data type used (e.g., string instead of array).
  - <input type="checkbox"> Missing required property.
  - <input type="checkbox"> Random/invalid data typed to the configuration properties.
  - <input type="checkbox"> External server/service is down.
  - <input type="checkbox"> An expected error occurs (e.g., not found, too many requests, ...).
- <input type="checkbox"> Internal messages (e.g., stack trace) with no meaning for the user are not logged.

**Publication Request**
- <input type="checkbox"> A link to the pull request with changes in the [documentation](https://help.keboola.com/) is included (if any). 


================================================
File: extend/publish/index.md
================================================
---
title: Publish Component
permalink: /extend/publish/
redirect_from:
    - /extend/registration/checklist/
    - /extend/registration/
---

* TOC
{:toc}

As described in the [architecture overview](/overview/), Keboola consists of many different components.
Only those components that are published in our **Component List** are generally available in Keboola.
The list can be found in our [Storage Component API](https://keboola.docs.apiary.io/#) in the dedicated [Components section](https://keboola.docs.apiary.io/#reference/components-and-configurations/list-components).
The list of components is managed using the Keboola [Developer Portal](https://components.keboola.com/).

That being said, any Keboola user can use any component, unless

- the Keboola user (or their token) has a [limited access to the component](https://help.keboola.com/storage/tokens/).
- the component itself limits where it can run (in what projects and for which users).

If you have not yet created your component, please go through the [tutorial](/extend/component/tutorial/), which will
navigate you through creating an account in the [Developer Portal](https://components.keboola.com/) and
[initializing the component](/extend/component/tutorial/).

## Publishing Component
A non-published component can be used without limitations, but it is not offered in the Keboola UI. It can only be used via
the [API](https://keboola.docs.apiary.io/#reference/components-and-configurations) or by directly visiting a link with the 
specific component ID:

    https://connection.keboola.com/admin/projects/{PROJECT_ID}/extractors/{COMPONENT_ID}

This way you can fully test your component before requesting its publication. Also, unpublished
components are not part of our [list of public components](https://components.keboola.com/components).
An existing configuration of a non-public component is accessible the same way as a configuration of any other component.

**Important:** Changes made in the Developer Portal take up to 5 minutes to propagate to all Keboola instances in all regions.

Before your component can be published, it must be approved by Keboola. Request the approval from the component list in
the [Developer Portal](https://components.keboola.com/). We will review your component and either publish it or contact you
with required changes.

{: .image-popup}
![Approval screenshot](/extend/publish/approve.png)

## Component Review
The goal of the component review is to maintain reasonable end-user experience and component reliability. Before
applying for component registration, make sure the same component does not already exist. If there is a similar one
(e.g., an extractor for the same service), clearly state the differences in the new component's description. During our
component review, the best practices in the next sections are followed.

### Component Name and Description
Before you name and describe your component, check out our YouTube, Facebook Pages, Dark Sky, and ECB Currency Rates 
components for inspiration.

- Names should not contain words like `extractor`, `application`, and `writer`.
<br>OK: *Cloudera Impala*
<br>WRONG: *Cloudera Extractor*
- The short description describes the **service** (helping the user find it) rather than the component.
Obviously for large services like Facebook or Gmail, describe the part of the service relevant to the component.
<br>OK: *Native analytic database for Apache Hadoop*
<br>WRONG: *This extractor extracts data from Cloudera Impala*
<br>OK: *Facebook Pages connect your business with people. Facebook Insights help you get good at it.*
<br>WRONG: *Facebook connects you with friends, family and other people you know, allows you to share photos and videos, send messages and get updates.*
- The long description provides **additional information about the extracted/written data**:
What will the end user get? What must the end user provide? Is the data going to be imported incrementally? Are there links to
available resources? <br>Configuration instructions should not be included in the long description, because the long description
is displayed before the end user starts configuring the component. However, if there are any special requirements (external approval,
specific account setting), they should be stated.
<br>OK: *This component allows you to extract currency exchange rates as published by the European Central Bank (ECB). The
exchange rates are available from a base currency (USD, EUR) to 30 destination currencies (AUD, BGN, BRL, CAD, CNY,
CZK, EUR, GBP, HKD, HRK, HUF, CHF, IDR, ILS, INR, JPY, KRW, MXN, MYR, NOK, NZD, PHP, PLN, RON, RUB, SEK, SGD, THB, TRY,
ZAR). The rates are available for all working days from 4 January 1999 up to present.*
- Component icons must be of representative and reasonable quality. Make sure the icon license allows you to use it.
- Components must correctly state the data flow --- [UI options](/extend/component/ui-options/). Use
`appInfo.dataOut` and `appInfo.dataIn` for this purpose:
    - Use `appInfo.dataIn` for extractors, which bring data into a Keboola project (omit `appInfo.dataOut` for extractors).
    - Use `appInfo.dataOut` for writers, which send data outside (omit `appInfo.dataIn` for writers).
    - Use `appInfo.dataIn` and/or `appInfo.dataOut` for applications.
- Use `appInfo.beta` in [UI options](/extend/component/ui-options/) if you suspect changes to the component behavior.
- Licensing information must be valid, and the vendor description must be current.

### Component Icon

- Use a PNG image that is at least 256x256px large and has transparent background.

### Component Configuration

- Use only the necessary [UI options](/extend/component/ui-options/) (i.e., if there are no output files, do not use `genericDockerUI-fileOutput`).
- For extractors, always use the [default bucket](/extend/common-interface/folders/#default-bucket) --- do not use the `genericDockerUI-tableOutput` flag.
- Use [encryption](/overview/encryption/) to store sensitive values. No plain-text passwords!
- Use a [configuration schema](/extend/component/ui-options/configuration-schema/).
    - List all properties in the `required` field.
    - Always use `propertyOrder` to explicitly define the order of the fields in the form.
    - Use your short `title` without a colon, period, etc.
    - Use `description` to provide an explanatory sentence if needed.
    <br>OK: ![Good Schema](/extend/publish/schema-good.png)
    <br>WRONG: ![Bad Schema](/extend/publish/schema-bad.png)
- Use a configuration description only if the configuration is not trivial/self-explanatory. Provide **links to resources**
(for instance, when creating an Elastic extractor, not everyone is familiar with the ElasticSearch query syntax). The
configuration description supports markdown. Your markdown should not start with a header and should use only level 3 and
level 4 headers (level 2 header is prepended before the configuration description). <br>OK: <br><code>some introduction text<br><br>### Input
Description<br>
description of input tables<br>
<br>#### First Table<br>
some other text<br>
</code>WRONG:<br><code>## Configuration Description<br>
some introduction text<br>
<br>#### Input Description<br>
description of input tables
</code>

### Component Internals

- Make sure that the amount of consumed **memory does not depend** on the amount of processed data. Use streaming or
processing in chunks to maintain a limited amount of consumed memory. If not possible, state the expected usage in
the **Component Limits**.
- The component must distinguish between [user and application errors](/extend/common-interface/environment/#return-values).
- The component must [validate](/extend/common-interface/config-file/#validation) its parameters; an invalid configuration must result in a user error. User error messages must clearly state what's wrong and what the user should do to fix the issue. E.g., `Invalid configuration.` is wrong, `Login failed, check your credentials.` is better.
- The events produced must be reasonable. Provide status messages if possible and with a reasonable frequency. Avoid internal messages with no meaning to the end user. Also avoid flooding the event log or sending data files in the event log.
- Set up [continuous deployment](/extend/component/deployment/) so that you can keep the component up to date.
- Use [semantic versioning](http://semver.org/) to mark and deploy versions of your component. Using other tags (e.g.,
`latest`, `master`) in production is not allowed.

### Checklist

Before requesting to publish a component, please check all rules using [this checklist](/extend/publish/checklist).


================================================
File: integrate/index.md
================================================
---
title: Integration
permalink: /integrate/
---

You can look at Keboola as a system of independent and loosely coupled microservices (components). 

Each microservice has its own code base, and a publicly accessible API and configuration.
We do not cheat or have any advantage over other developers; our UI and other components use only these public APIs.

As a result, it is very easy to, for example, write custom scripts to bootstrap a project, or do something that our UI does not offer.
Let's have a look into this!

One of the very important components is [Storage](/integrate/storage/), which not only stores all data in a 
project, but also provides additional functions such as managing other components and their configurations. 
When you are integrating your systems with Keboola, **chances are that you want to start with [Storage](/integrate/storage/)**.


{% comment %} 
 
 - gdwriter

  - Storage
    - API
    - Curl
    - Commandline
  - Transformation
    - API
    - IO Mapping
    - Sandbox
  - Extractors
    - ...
  - Writers
{% endcomment %}

================================================
File: integrate/artifacts/index.md
================================================
---
title: Artifacts
permalink: /integrate/artifacts/
---

* TOC
{:toc}

*Note: This is a preview feature and as such may change considerably in the future. The project must have an `artifacts` feature enabled.*

**Artifacts** are additional files that can be produced or consumed by a [component](/extend/component). 

See [Tutorial](/integrate/artifacts/tutorial) for step-by-step example.

## Introduction
In some cases it's useful if a component not only extracts, transforms or uploads data, but also generate some other output, metadata or other runtime-discovered data.
These could be for example:
- AI models
- performance graphs of such models
- status updates from long-running tasks
- documentation
- data quality checks from in-progress tasks

These additional information can be stored in artifacts and processed by another component or 3rd party tool.

## Storage
Artifacts are stored in Keboola File Storage.

## Types of artifacts
There are three types of artifacts for now `runs`, `custom` and `shared`. 
The type specifies which components will have access to the artifact or which artifacts to download for the component to process.
Types are used in a configuration of a consumer component to specify which artifacts to download. 

- **runs** - artifacts from previous runs of the same configuration

- **custom** - artifacts from previous runs of a different configuration. The configuration which produced the artifacts will be defined in the consumer configuration (configurationId, componentId, branchId)

- **shared** - artifacts shared within an orchestration

`runs` and `custom` types are the same from the producer point of view. To produce a `shared` artifact, it has to be written into a `shared` folder. Read more in [File structure](#file-structure) section.

## File structure
Artifact is a unique set of files associated with a successful job, component and configuration.
A component can either produce or consume artifacts or both.

### Produce
To produce an artifact, store one or more files in the following `output` directories. Subdirectories are also supported.
- `/data/artifacts/out/current` to create an artifact of type `runs` / `custom`. 
- `/data/artifacts/out/shared` to create an artifact of type `shared`, which can be accessed by any component within the same orchestration.

After the component job is finished all files and directories inside `current` and `shared` folders will be compressed into an archive and uploaded to File Storage with corresponding tags as a `artifact`.

### Consume
To consume created artifacts you have to specify, in the configuration of a component, which artifacts (type) to download.
 - `runs` to download artifacts produced by the same configuration and component. These will be stored in `/data/artifacts/in/runs/jobs/job-%job_id%` directory.
 - `custom` to download artifacts produced by another configuration or component. These will be stored in `/data/artifacts/in/custom/jobs/job-%job_id%` directory.
 - `shared` to download artifacts created within the same orchestration by any artifact producing component that has already finished. These will be stored in `/data/artifacts/in/shared/jobs/job-%job_id%` directory.

## Configuration
Each type of artifact has a separate node in configuration. All the types can be used simultaneously.
Each type node has an attribute "enabled", which enables or disables download of the corresponding artifact type.

### Runs
 - **enabled** [true|false] - enable or disable download of this artifact type
 - **filter** 
   - **date_since** - only artifacts from jobs younger than this will be downloaded
   - **limit** - maximum number of the latest jobs from which to download artifacts 

### Custom
- **enabled** [true|false] - enable or disable download of this artifact type
- **filter**
    - **branch_id**, **component_id**, **config_id**  - specify the configuration to download artifacts from
    - **date_since** - only artifacts from jobs younger than this will be downloaded
    - **limit** - maximum number of the latest jobs from which to download artifacts

### Shared
- **enabled** [true|false] - enable or disable download of this artifact type

Full configuration example with all artifact types:

```json
{
  "parameters": {},
  "artifacts": {
    "runs": {
      "enabled": true,
      "filter": {
        "date_since": "-7 days",
        "limit": 5
      }
    },
    "custom": {
      "enabled": true,
      "filter": {
        "component_id": "keboola.python-transformation",
        "config_id": "12345",
        "branch_id": "default",
        "date_since": "-7 days",
        "limit": 5
      }
    },
    "orchestration": {
      "enabled": true
    }
  }
}
```

## Artifacts life-cycle in a job
Job runner checks if the project has enabled `artifacts` feature.
Job runner checks the configuration of the component.
If artifacts are enabled, it downloads artifacts to corresponding folders as configured (i.e. `runs`, `custom`, `shared`) and unzips them.

Component process start and the component can:

- access and process the downloaded artifacts in shared or custom directory

- write  artifacts to `current` or `shared` directory

Component finishes and job runner does:

- gzip the content of runs/current

- tag the gzipped file with jobId, componentId, configId, runId, branchId and other tags if needed

- upload the file to File Storage 

## File size limit
All the artifacts produced by a job shouldn’t be bigger than 1 GB.


================================================
File: integrate/artifacts/tutorial.md
================================================
---
title: Artifacts Tutorial
permalink: /integrate/artifacts/tutorial/
---

* TOC
{:toc}

This tutorial will show you how to work with artifacts.
In the following example we will use Python Transformation component to produce and consume artifacts.
But these principles would work inside any component.

In the examples, we use the `curl` console tool to interact with our APIs.

*Note: `artifacts` feature needs to be enabled in your project. Please contact [support@keboola.com](mailto:support@keboola.com) to enable the feature in your project*
*Note 2: `artifacts` configuration can be created or edited only via [Configuration API](https://keboola.docs.apiary.io/#reference/components-and-configurations/component-configurations/create-configuration) for now*

## Examples

For each example we will need [Storage API Token](https://help.keboola.com/management/project/tokens/) to make the API call.

1. Obtain a Storage API token from the user interface of your project, see this [Guide](https://help.keboola.com/management/project/tokens).
2. Store the token and url to the environment variable.

    ```shell
    export STORAGE_API_HOST="https://connection.keboola.com"
    export TOKEN="..."
    ```

### 1. Produce artifact

This is very simple example. We will just create a Python Transformation, which will write a file to the artifacts "upload" folder.
This file will be then uploaded as "artifact" to File Storage. 

1. In your Keboola project, create a new Python transformation, and paste this code into it:
    ```
    import os        
    with open("/data/artifacts/out/current/myartifact1", "w") as file:
      file.write("this is my artifact file content")
    ```
   
    {: .image-popup}
    ![Artifacts - transformation](/integrate/artifacts/artifacts-tutorial-1.png)

2. Run the transformation - it should upload the file to File Storage as "artifact"

    {: .image-popup}
    ![Artifacts - Job](/integrate/artifacts/artifacts-tutorial-2.png)

3. The file is now visible in File Storage with appropriate tags

   {: .image-popup}
   ![Artifacts - File Storage](/integrate/artifacts/artifacts-tutorial-2.png)


### 2. Produce & consume artifacts

To consume (download) artifacts for component to work with, we need to enable and configure artifacts download in the configuration of a component.

We will create another configuration of the Python transformation via API.

The artifacts part of the configuration will look like this.
It will enable download of artifacts of type `runs` with limit 5, which means this will download artifacts created by the last 5 runs of the same component configuration

   ```json
   {
     "artifacts":{
       "runs":{
         "enabled":true,
         "filter":{
           "limit":5
         }
       }
     }
   }
   ```

The script of the transformation will look like following. 
Files read from `/data/artifacts/in/runs/*/*` will be displayed at output - these are the artifact files downloaded.
The script will also generate a new artifact and write it to `/data/artifacts/out/current/myartifact1` as in previous example.

    ```python
    import os
    import glob
   
    # Download
    print(glob.glob("/data/artifacts/in/runs/*/*")) 
   
    # Upload 
    with open("/data/artifacts/out/current/myartifact1", "w") as file:
      file.write("value1")
    ```
1. Run this curl command to create the configuration:

    ```shell
    curl -X POST "$STORAGE_API_HOST/v2/storage/branch/default/components/keboola.python-transformation-v2/configs" \
    -H "X-StorageApi-Token: $TOKEN" \
    -H 'Content-Type: application/x-www-form-urlencoded' \
    --data-urlencode 'configuration={"parameters":{"blocks":[{"name":"Block 1","codes":[{"name":"artifacts","script":["import os\nimport glob\n\n# Download\nprint(glob.glob(\"/data/artifacts/in/runs/*/*\")) \n\n# Upload\nwith open(\"/data/artifacts/out/current/myartifact1\", \"w\") as file:\n  file.write(\"value1\")"]}]}]},"artifacts":{"runs":{"enabled":true,"filter":{"limit":5}}}}' \
    --data-urlencode 'name=Artifacts upload & download' \
    --data-urlencode 'description=Test Artifacts upload & download'
    ```


### 3. Consume artifacts from different component
Similar to previous example we will create a configuration of Python Transformation component. 
But this time we will download artifacts produced by the configuration from `Example 2`.

1. Export the id of the previously created configuration into an environment variable:
    ```shell
    export CONFIG_ID="..."
    ```
   
2. Run curl command
    ```shell
    curl -X POST "$STORAGE_API_HOST/v2/storage/branch/default/components/keboola.python-transformation-v2/configs" \
    -H "X-StorageApi-Token: $TOKEN" \
    -H 'Content-Type: application/x-www-form-urlencoded' \
    --data-urlencode 'configuration={"parameters":{"blocks":[{"name":"Block 1","codes":[{"name":"artifacts","script":["import os\nimport glob\n\n# Download\nprint(glob.glob(\"/data/artifacts/in/custom/*/*\"))"]}]}]},"artifacts":{"custom":{"enabled":true,"component_id":"keboola.python-transformation","config_id":"$CONFIG_ID","branch_id":"default","filter":{"limit":5}}}}' \
    --data-urlencode 'name=Artifacts upload & download' \
    --data-urlencode 'description=Test Artifacts upload & download'    
    ```
   
The whole configuration now looks like this:

   ```json
    {
        "parameters": {
            "blocks": [
                {
                    "name": "Block 1",
                    "codes": [
                        {
                            "name": "artifacts",
                            "script": [
                                "import os\nimport glob\n\n# Download\nprint(glob.glob(\"/data/artifacts/in/custom/*/*\"))"
                            ]
                        }
                    ]
                }
            ]
        },
        "artifacts": {
            "custom": {
                "enabled": true,
                "component_id": "keboola.python-transformation",
                "config_id": "$CONFIG_ID",
                "branch_id": "default",
                "filter": {
                    "limit": 5
                }
            }
        }
    }
   ```

### 4. Shared artifacts
This example will show how to share artifacts within an orchestration
We will create two configurations of Python Transformation component.
One will produce a shared artifact and the other will consume it. 
Both configurations needs to be in the same orchestration.
The configuration producing artifact needs to be in a phase that precedes the consuming one.

1. Create "Producer" configuration
   The Python code will write a file into a shared folder:

   ```python
   import os
   with open(path+\"/myartifact-shared\", \"w\") as file:
     file.write(\"value1\")"
   ```
   
   Run curl command to create the configuration:

   ```shell
    curl -X POST "$STORAGE_API_HOST/v2/storage/branch/default/components/keboola.python-transformation-v2/configs" \
    -H "X-StorageApi-Token: $TOKEN" \
    -H 'Content-Type: application/x-www-form-urlencoded' \
    --data-urlencode 'configuration={"parameters":{"blocks":[{"name":"Block 1","codes":[{"name":"Upload shared","script":["import os\npath = \"/data/artifacts/out/shared\"\nwith open(path+\"/myartifact3\", \"w\") as file:\n  file.write(\"value1\")"]}]}]},"artifacts":{"runs":{"enabled":true,"filter":{"limit":5}}}}' \
    --data-urlencode 'name=Artifacts shared Producer' \
    --data-urlencode 'description=Artifacts upload shared'    
    ```

2. Create "Consumer" configuration

   The artifacts configuration:
   ```json
   {
      "artifacts": {
         "shared": {
            "enabled": true
         }
      }
   }
   ```
   
   The Python script:

   ```python
   import os
   import glob
   print(glob.glob("/data/artifacts/in/shared/*/*")) 
   ```
   
   Run curl command to create the configurtion:
   
   ```shell
    curl -X POST "$STORAGE_API_HOST/v2/storage/branch/default/components/keboola.python-transformation-v2/configs" \
    -H "X-StorageApi-Token: $TOKEN" \
    -H 'Content-Type: application/x-www-form-urlencoded' \
    --data-urlencode 'configuration={"parameters":{"blocks":[{"name":"Block 1","codes":[{"name":"Download shared","script":["import os\nimport glob\n\nprint(glob.glob(\"/data/artifacts/in/shared/*/*\")) "]}]}]},"artifacts":{"shared":{"enabled":true}}}' \
    --data-urlencode 'name=Artifacts shared Consumer' \
    --data-urlencode 'description=Artifacts download shared'    
    ```

3. Now put each of the configurations into an Orchestration. "Artifacts shared Producer" into phase 1 and "Artifacts shared Consumer" into phase 2.

   {: .image-popup}
   ![Artifacts orchestration](/integrate/artifacts/artifacts-tutorial-4.png)


================================================
File: integrate/data-streams/index.md
================================================
---
title: Data Streams
permalink: /integrate/data-streams/
redirect_from: /integrate/push-data/
---

<div class="clearfix"></div>

The Keboola Stream API allows you to ingest small, frequent events into your project's storage.

![data streams diagram](./push_data.drawio.png)

See the [tutorial](/integrate/data-streams/tutorial/) to learn how to create and manage event sources.

## Next Steps
- [Data Streams Tutorial](/integrate/data-streams/tutorial/)
- [Data Streams Overview](/integrate/data-streams/overview/)


================================================
File: integrate/data-streams/overview/index.md
================================================
---
title: Data Streams Overview
permalink: /integrate/data-streams/overview/
redirect_from: /integrate/push-data/overview/
---

* TOC
{:toc}

![Data Streams diagram](../push_data.drawio.png)

A source represents an endpoint for receiving events.

Sources are managed using the Stream API. The full API reference is available at https://stream.keboola.com/v1/documentation/, and the OpenAPI specification is available at https://stream.keboola.com/v1/documentation/openapi3.json.

Events are received via HTTP. Each source can be associated with up to 20 `sinks`, which represent `mappings` from event data to `columns` in a destination `table`. Data may be mapped using pre-defined mappings or a custom `template`.

## Columns

| Field | Type | Description |
|---|---|---|
| `name` | string | Name of the column. Names must be unique. |
| `type` | string | The type of the column. Available types and their descriptions are listed below. |
| `primaryKey` | boolean | Make this column a primary key. Multiple columns may be part of the primary key at the same time. |

The available column types are:

| Type | Description |
|---|---|
| `id`| Event ID |
| `datetime` | Time of the event |
| `ip` | IP of the event sender |
| `body` | The unaltered event body |
| `headers` | The unaltered request headers |
| `path` | A field from the JSON object |
| `template` | A custom mapping using a template language |

### Path

The `path` column type can be used to fetch a single field from a `JSON` object. Optionally, you can use `rawString` option to remove the quotes around a JSON string or the `defaultValue` option to define a value when the field doesn't exist.

```json
{
  "type": "json",
  "name": "id",
  "path": "issue.id",
  "defaultValue": "undefined", 
  "rawString": true
}
```

### Template (Jsonnet)

***Note:** It is recommended to use the faster `path` type instead of the `jsonnet` function `Body(string)` when possible.*

The `template` column type currently supports the `jsonnet` templating language. The following `jsonnet` globals are available:

|Name|Description|Usage example|Example value|
|:-|:-|:-|:-|
| `Ip()` | IP address of the client | `Ip()` | `127.0.0.1` |
| `Body()` | Get the entire request body as an object. | `Body()` | `{ "a": "b" }` |
| `Body(string)` | Get a field from the request body by path. Fails if the field does not exist; in that case, the record will not be saved. | `Body("deeply.nested.path")` | `1000` |
| `Body(string, any)` | Get a field from the request body by path, or a default value. | `Body("deeply.nested.path", 2000)` | `1000` |
| `BodyStr()` | Get the entire request body as a string. | `BodyStr()` | `"{\"a\":\"b\"}"` |
| `Header()` | Get all request headers. | `Header()` | `{ "Content-Type": "application/json" }` |
| `Header(string)` | Get the value of a single request header. Fails if the header does not exist; in that case, the record will not be saved. | `Header("Content-Type")` | `"application/json"` |
| `Header(string, string)` | Get the value of a single request header or a default value. | `Header("Content-Type")` | `"application/json"` |
| `HeaderStr()` | Get the request headers as a string, each line containing one "header: value" pair. The lines are sorted alphabetically. | `HeaderStr()` | `Content-Type: application/json` |
| `Now()` | Get the current UTC datetime as a string formatted using the default format. | `Now()` | `"2023-01-14T08:04:05.123Z"` |
| `Now(string)` | Get the current UTC datetime as a string with the custom [`strftime`](https://man7.org/linux/man-pages/man3/strftime.3.html)-compatible format. | `Now("%Y-%m-%d")` | `2023-01-14` |

### Conditions

Incoming events are mapped to the schema defined in each sink, and each new row is appended to a CSV file on the local hard disk (local storage).

When the local storage accumulates enough records or a short time passes, the records from local storage are appended to a CSV file stored in your Keboola project (staging storage).

Once certain conditions are met, the data from the file is imported into the destination table (target storage). These `conditions` are defined by the sink:

| Condition | Minimum | Maximum | Default |
|:-|:-:|:-:|:-:|
| `time` | 30 seconds |  24 hours | 1 minute |
| `size` | 100 B | 500 MB | 50 MB |
| `count` | 1 | 10 million | 50 thousand |

Changing these conditions will trigger an immediate import of waiting files, after which the stream will follow the updated conditions.

## Create Sources and Sinks

Sources can be created using the [`POST /v1/branches/{branchId}/sources`](https://stream.keboola.com/v1/documentation/#/configuration/CreateSource) endpoint.

If a source or sink `id` is omitted, it will be generated from the corresponding `name` field.

A source may be created without any sinks. The sinks can then be created separately using the [`POST /v1/branches/{branchId}/sources/{sourceId}/sinks`](https://stream.keboola.com/v1/documentation/#/configuration/CreateSink) endpoint.

***Warning**: Events sent to a source without any sinks will be permanently lost. This is because data is buffered per sink, not per source.*

The requests are asynchronous and create a task that must be completed before the source or sink is ready to use. The task status can be checked using the [`GET /v1/branches/{branchId}/sources/{sourceId}/tasks/{taskId}`](https://stream.keboola.com/v1/documentation/#/configuration/GetTask) endpoint.

Sink tables are created if they do not exist. If they already exist, the schema defined by `sink.columns` must match the existing schema. If the table schema is manually altered and it no longer matches, the import from staging storage to the table will fail. The data is kept in the staging storage for up to 7 days during which you can recover any failures.

## Delete Sources and Sinks

Sources may be deleted using the [`DELETE /v1/branches/{branchId}/sources/{sourceId}`](https://stream.keboola.com/v1/documentation/#/configuration/DeleteSource) endpoint. Sinks may be deleted using the [`DELETE /v1/branches/{branchId}/sources/{sourceId}/sinks/{sinkId}`](https://stream.keboola.com/v1/documentation/#/configuration/DeleteSink) endpoint.

## Update Sources and Sinks

A source may be updated using the [`PATCH /v1/branches/{branchId}/sources/{sourceId}`](https://stream.keboola.com/v1/documentation/#/configuration/UpdateSource) endpoint. Sinks maybe updated using the [`PATCH /v1/branches/{branchId}/sources/{sourceId}/sinks/{sinkId}`](https://stream.keboola.com/v1/documentation/#/configuration/UpdateSink) endpoint.

The `UpdateSource` endpoint may only update the source's name. Sinks may only be updated separately.

If a sink's `mapping.tableId` is updated, it is handled the same way as in the create operation. If the table exists, `mapping.columns` must match the existing table's schema. If the table does not exist, it is created.

## Source and Sink Settings

The import conditions mentioned above can be accessed using the [`GET /v1/branches/{branchId}/sources/{sourceId}/settings`](https://stream.keboola.com/v1/documentation/#/configuration/GetSourceSettings) endpoint and changed using the [`PATCH /v1/branches/{branchId}/sources/{sourceId}/settings`](https://stream.keboola.com/v1/documentation/#/configuration/PatchSourceSettings) endpoint.

Same settings also exist for a sink. Use the [`GET /v1/branches/{branchId}/sources/{sourceId}/sinks/{sinkId}/settings`](https://stream.keboola.com/v1/documentation/#/configuration/GetSinkSettings) endpoint and the [`PATCH /v1/branches/{branchId}/sources/{sourceId}/sinks/{sinkId}/settings`](https://stream.keboola.com/v1/documentation/#/configuration/PatchSinkSettings) endpoint in that case.

## Delivery Guarantees

Depending on your use case, you may require different delivery guarantees for your stream. Follow the guidelines below to ensure the desired outcome.

### At Most Once

To ensure that no record is delivered twice, make sure the client doesn't retry when sending the records. In this case, it's beneficial to use the setting endpoints to set `"storage.level.local.encoding.sync.wait"` to `false` to increase throughput.

### At Least Once

To ensure that every record is delivered at least once, the client needs to implement retries when sending the records. Also, use the setting endpoints to confirm that `"storage.level.local.encoding.sync.wait"` is set to `true` (default behavior). Note that this setting guarantees that the record is written to the local disk.

## Tokens

A token is generated for each source sink. These tokens have the minimum possible scope with `write` permission for the bucket in which the destination table is 
stored. You can view these tokens at `https://connection.keboola.com/admin/projects/<project-id>/tokens-settings`. Their description follows the format 
`[_internal] Stream Sink <source-id>/<sink-id>`.

These tokens should not be deleted or refreshed manually. To refresh a token, you can disable and re-enable the sink.

## Kafka Integration
To connect Keboola with [Apache Kafka®](https://kafka.apache.org/) and ingest data from Kafka topics via data streams, use the Kafka Connect HTTP Sink Connector
to establish a communication channel between Kafka and Keboola.

The Kafka Connect HTTP Sink Connector acts as a bridge, seamlessly integrating Kafka with Keboola's Data Stream HTTP API. Here's a breakdown of the process:

- Data Consumption: The connector continuously reads data records from one or more Kafka topics.
- Batching: Events can be efficiently grouped based on a predefined maximum size (batch.max.size).
- API Interaction: Data is sent as a POST request in JSON format to Keboola's Data Stream API URL.

**Key Points to Remember:**

- This integration relies on the Kafka Connect HTTP Sink Connector, which requires configuration on the Kafka side.
- Data records from Kafka topics are transformed into strings before being sent to Keboola.
- The target Keboola API URL corresponds to the data stream created in Keboola.
- Only POST HTTP methods are supported for data ingestion.

## Next Steps

- [Data Streams Tutorial](/integrate/data-streams/tutorial/)
- [Stream API Reference](https://stream.keboola.com/v1/documentation/)


================================================
File: integrate/data-streams/tutorial/index.md
================================================
---
title: Data Streams Tutorial
permalink: /integrate/data-streams/tutorial/
redirect_from: /integrate/push-data/tutorial/
---

* TOC
{:toc}


In this tutorial, we will set up a source for the [`issues`](https://docs.github.com/developers/webhooks-and-events/webhooks/webhook-events-and-payloads#issues) event from GitHub Webhooks. This will allow you to monitor and analyze activity related to issues in any of your GitHub repositories.

You will need your project's master token, and a GitHub repository where you have the `Admin` role.

## Creating a Source

To start ingesting events, you must first create a source. Send the following payload to the `https://stream.keboola.com/v1/branches/{branchId}/sources` endpoint:
```
{
  "name": "Github Issues",
  "exports": [
    {
      "name": "Events",
      "conditions": { "count": 1 },
      "mapping": {
        "tableId": "in.c-github.issues",
        "columns": [
          {
            "primaryKey": true,
            "type": "id",
            "name": "id"
          },
          { "type": "datetime", "name": "datetime" },
          { "type": "ip", "name": "ip" },
          { "type": "body", "name": "body" },
          { "type": "headers", "name": "headers" },
          {
            "type": "path",
            "name": "id",
            "path": "issue.id",
            "defaultValue": "undefined", 
            "rawString": true
          },
          {
            "type": "template",
            "name": "template",
            "template": {
              "language": "jsonnet",
              "content": "'#' + Body('issue.id') + ': ' + Body('issue.body', 'n/a')"
            }
          }
        ]
      }
    }
  ]
}
```

You can do this using `curl`, or anything else that allows you to send an HTTP request:
```
$ curl --header 'Content-Type: application/json' \
       --header 'X-StorageApi-Token: <YOUR_TOKEN>' \
       --data '{ ...the payload above... }' \
       https://stream.keboola.com/v1/branches/{branchId}/sources
```

The response will contain the task that has been created:
```
{
  "id": "2023-02-16T16:04:39.570Z_Pg7U4",
  "sourceId": "github-issues",
  "url": "https://stream.keboola.com/v1/branches/{branchId}/sources/github-issues/tasks/source.create/2023-02-16T16:04:39.570Z_Pg7U4",
  "type": "source.create",
  "createdAt": "2023-02-17T11:20:57.406Z",
  "isFinished": false,
  "result": ""
}
```

You can query the task's status by querying the `url` field and wait until the `isFinished` field is set to `true`:
```
{
  "id": "2023-02-16T16:04:39.570Z_Pg7U4",
  "sourceId": "github-issues",
  "url": "https://stream.keboola.com/v1/branches/{branchId}/sources/github-issues/tasks/source.create/2023-02-16T16:04:39.570Z_Pg7U4",
  "type": "source.create",
  "createdAt": "2023-02-17T11:20:57.406Z",
  "finishedAt": "2023-02-17T11:20:57.753Z",
  "isFinished": true,
  "duration": 343,
  "result": "source created"
}
```

Upon success, query the source URL `https://stream.keboola.com/v1/branches/{branchId}/sources/github-issues`, and the response will contain the source you've just created:
```
{
  "id": "github-issues",
  "url": "https://stream.keboola.com/stream/<YOUR_PROJECT_ID>/github-issues/<SECRET>"
  "name": "Github Issues",
  "exports": [
    {
      "id": "events",
      "name": "Events",
      "conditions": {
        "count": 1,
        "size": "5MB",
        "time": "5m"
      },
      "mapping": {
        "tableId": "in.c-github.issues",
        "columns": [
          {
            "primaryKey": true,
            "type": "id",
            "name": "id"
          },
          { "type": "datetime", "name": "datetime" },
          { "type": "ip", "name": "ip" },
          { "type": "body", "name": "body" },
          { "type": "headers", "name": "headers" },
          {
            "type": "path",
            "name": "id",
            "path": "issue.id",
            "defaultValue": "undefined", 
            "rawString": true
          },
          {
            "type": "template",
            "name": "template",
            "template": {
              "language": "jsonnet",
              "content": "'#' + Body('issue.id') + ': ' + Body('issue.body', 'n/a')",
            }
          }
        ]
      }
    }
  ]
}
```

The most important part of the response is the `url` field. This is the endpoint to which you will point your GitHub webhook. Once you've created the source and obtained its `url` field, you are ready to configure the GitHub webhook.

Normally, the URL only returns a short response to reduce traffic. You can add `?verbose=true` to the URL to receive more information about what happened with the request. Note that this makes the response slower, so we recommend using this parameter for testing purposes only.

## Configuring the Github Webhook

Go to the `Settings` tab of your repository.

![Github repository tabs](./gh-tabs.png)

Open the `Webhooks` page.

![Github settings pages](./gh-settings-webhook.png)

Click `Add webhook`.

![Github add webhook](./gh-settings-webhook-add.png)

Enter the source `url` into the `Payload URL` field, and set the `Content Type` to `application/json`.

For `Which events would you like to trigger this webhook?`, click `Let me select individual events`, then find `Issues` and tick it:

![Github webhook let me select individual events selected](./gh-settings-webhook-individual-events.png)
![Github webhook issues checkbox selected](./gh-settings-webhook-issues.png)

Click `Add webhook` at the bottom of the page.

Any events related to issues in your repository will now be buffered by the source, and uploaded to your table every minute.

To see your integration at work, head over to your repository and [open a few issues](https://docs.github.com/en/issues/tracking-your-work-with-issues/creating-an-issue).

## Results

The following token was generated.

![Keboola token settings screenshot showing the generated token](./token.png)

This token only has the minimal set of permissions, which, in this case, is access to a single bucket and the ability to manipulate files. Currently, files are used as staging storage to prevent data loss. You can see these files in your project's Storage.

![Keboola storage file](./github_webhook_export_file.png)

Since the table `in.c-github-issues` did not exist, it was created.

![Keboola storage table](./github_webhook_export_table.png)

Finally, you can take a look at the destination table's data sample to find your data, ready for further processing.

![Keboola storage table sample data](./github_webhook_export_table_data.png)


## Next Steps

- [Data Streams Overview](/integrate/data-streams/overview/)
- [Stream API Reference](https://stream.keboola.com/v1/documentation/)


================================================
File: integrate/database/index.md
================================================
---
title: SSH Database Connection
permalink: /integrate/database/
---

* TOC
{:toc}

If you wish to use [any of our database extractors](https://help.keboola.com/components/extractors/database/), we highly recommend
that you set up an SSH [Tunnel](https://en.wikipedia.org/wiki/Tunneling_protocol) between your and our private networks.
This way your database server will not be open to the whole internet.

A Secure Shell (SSH) tunnel consists of an encrypted tunnel created through an SSH protocol connection.
The SSH connection is encrypted and uses a public - private key pair for user authorization.

{: .image-popup}
![Schema - SSH tunnel](/integrate/database/ssh-tunnel.jpg)

## Usage
Before using an SSH tunnel with one of our database extractors, setup an *SSH proxy server*
to act as a gateway to your private network where your database server resides.
The extractor will then connect to this *SSH proxy server* and through it to the database server.

Complete the following steps to setup an SSH tunnel to your database server:

### 1. Setup SSH Proxy Server
Here is a very basic example [Dockerfile](https://docs.docker.com/engine/reference/builder/).
All it does is run an sshd daemon and exposes port 22. You can, of course, set this up in your system in
a similar way without using Docker.

{% highlight dockerfile %}
FROM ubuntu:14.04

RUN apt-get update

RUN apt-get install -y openssh-server
RUN mkdir /var/run/sshd

RUN echo 'root:root' |chpasswd

RUN sed -ri 's/^PermitRootLogin\s+.*/PermitRootLogin yes/' /etc/ssh/sshd_config
RUN sed -ri 's/UsePAM yes/#UsePAM yes/g' /etc/ssh/sshd_config

EXPOSE 22

CMD    ["/usr/sbin/sshd", "-D"]
{% endhighlight %}

This server should be in the same private network where your database server resides. It should be accessible publicly from the internet via SSH.
The default port for SSH is 22, but you can choose a different port.

See the following pages for more information about setting up SSH on your server:

- [OpenSSH configuration](https://help.ubuntu.com/community/SSH/OpenSSH/Configuring)
- [Dockerized SSH service](https://docs.docker.com/engine/examples/running_ssh_service/)


### 2. Generate SSH Key Pair
Setup or edit your database extractor in [Keboola](https://connection.keboola.com).
Go to **Database Credentials** and check **Enable SSH Tunnel**.
Generate an SSH key pair and copy the public key to your *SSH proxy server*.
Paste it to the *public.key* file and then append it to the authorized_keys file.

{% highlight bash %}
mkdir ~/.ssh
cat public.key >> ~/.ssh/authorized_keys
{% endhighlight %}

### 3. Setup DB Extractor

- **Host Name** - Address of the DB server in your private network
- **Port** - Port number of the DB server
- **Username** - DB username
- **Password** - DB password
- **Database** - DB name

- **Enable SSH Tunnel** - Check to enable
- **SSH host** - Public address of your *SSH proxy server*
- **SSH user** - User on your *SSH proxy server* with the generated public key
- **SSH port** - SSH port; default is 22

Run **Test Credentials** and see if everything is working.

Various DB extractors could have different fields, but the principle remains the same.

## Local Tunnel
It is also possible to use your database server as an *SSH proxy server* and setup your database to only accept connections from localhost.
In this case, set the *Host Name* to `127.0.0.1`.

**Important**: Do **not** use the word `localhost`! Our extractors have a problem with that.


================================================
File: integrate/jobs/index.md
================================================
---
title: Component Jobs
permalink: /integrate/jobs/
redirect_from: /overview/jobs/
---

* TOC
{:toc}

Most operations, such as extracting data or running an application are executed in Keboola as
background, asynchronous [jobs](https://help.keboola.com/management/jobs/). When an operation is triggered, for example, you run an extractor, a
*job* is created. The job starts executing or waits in the queue until it can start executing. 
The job execution and queuing are fully automatic. The job execution is asynchronous, so you need to

- *create* (run) a job, and
- *wait* for it to finish.

The core API for working with jobs is the [Queue API](https://app.swaggerhub.com/apis-docs/keboola/job-queue-api/). It provides operations for 
running/creating, terminating and listing jobs. 
[Components](/overview/) differ in their upper limits on how long a job can be executing and how much memory it is allowed to consume.
These limits are set by the component developer and act primarily as a safeguard. 

## Job Properties
When you create a job it automatically transitions through states until it reaches some of the final states.
When you create or retrieve a job, you'll obtain a JSON with Job object, whose properties are described below in more detail.

<details>
  <summary>Click to expand the response.</summary>

{% highlight json %}
{
    "id": "10440535",
    "runId": "10440530.10440533.10440534.10440535",
    "parentRunId": "10440530.10440533.10440534",
    "project": {
        "id": "66",
        "name": "Sandbox"
    },
    "token": {
        "id": "7455",
        "description": "[_internal] Scheduler"
    },
    "status": "success",
    "desiredStatus": "processing",
    "mode": "run",
    "component": "keboola.ex-db-snowflake",
    "config": "493493",
    "configData": [],
    "configRowIds": [
        "41510"
    ],
    "tag": "5.5.0",
    "createdTime": "2022-01-24T22:41:10+00:00",
    "startTime": "2022-01-24T22:41:13+00:00",
    "endTime": "2022-01-24T22:41:48+00:00",
    "durationSeconds": 35,
    "result": {
        "input": {
            "tables": []
        },
        "images": [
            [
                {
                    "id": "developer-portal-v2/keboola.ex-db-snowflake:5.5.0",
                    "digests": [
                        "developer-portal-v2/keboola.ex-db-snowflake@sha256:0f9428c52afea457ec3865cab7cfe457f4f875f3cf45d36f1876c709211da9cf"
                    ]
                }
            ]
        ],
        "output": {
            "tables": [
                {
                    "id": "in.c-keboola-ex-db-snowflake-493493.opportunity",
                    "name": "opportunity",
                    "columns": [
                        {
                            "name": "Id"
                        },
                        {
                            "name": "Name"
                        },
                        {
                            "name": "AccountId"
                        },
                        {
                            "name": "OwnerId"
                        },
                        {
                            "name": "Amount"
                        },
                        {
                            "name": "StageName"
                        },
                        {
                            "name": "CreatedDate"
                        },
                        {
                            "name": "CloseDate"
                        },
                        {
                            "name": "Probability"
                        },
                        {
                            "name": "Start_Date"
                        },
                        {
                            "name": "End_Date"
                        },
                        {
                            "name": "Record_Type_Name"
                        },
                        {
                            "name": "AdvertiserName"
                        },
                        {
                            "name": "Advertiser_Vertical"
                        },
                        {
                            "name": "Type"
                        }
                    ],
                    "displayName": "opportunity"
                }
            ]
        },
        "message": "Component processing finished.",
        "configVersion": "16"
    },
    "usageData": [],
    "isFinished": true,
    "url": "https://queue.north-europe.azure.keboola.com/jobs/10440535",
    "branchId": null,
    "variableValuesId": null,
    "variableValuesData": {
        "values": []
    },
    "backend": [],
    "metrics": {
        "backend": {
            "size": null
        },
        "storage": {
            "inputTablesBytesSum": 0
        }
    },
    "behavior": {
        "onError": null
    },
    "parallelism": "2",
    "type": "standard"
}
{% endhighlight %}
</details>

### Job Status
A job can have different values for `status`:
- `created` (the job is created, but has not started executing yet)
- `waiting` (the job is waiting for other jobs to finish)
- `processing` (job stuff is being done)
- `success` (the job is finished)
- `error` (the job is finished)
- `warning` (the job is finished, but one of its child jobs failed)
- `terminating` (the user has requested to abort the job)
- `cancelled` (the job was created, but it was aborted before its execution actually began)
- `terminated` (the job was created and it was aborted in the middle of its execution)

{: .image-popup}
![Job State transitions](/integrate/jobs/states.png)

When you create a job it is in the `created` state. In a success scenario it will transition to a `processing` state and when the actual work is done, to the
 `success` state. If you change your mind and terminate a job, it will enter `terminating` state and then ends with either `terminated` (execution terminated) 
 or `cancelled` (execution did not actually start). The difference is that you can be sure that a `cancelled` job did absolutely no operations, 
 whereas a terminated job, could've done even all of the work it was supposed to do.

 If a job cannot be executed, it will enter the `waiting` state. The waiting state means that the job cannot be executed due to reasons on the Keboola 
 project side. This means that the reasons for waiting jobs lie solely in what jobs are already running in the given project. There are three core reasons for waiting jobs:
 - If you run two jobs of the same configuration, the second one will wait until the first one is finished. This behavior is 
 called "configuration lock" and protects your project from [race conditions](https://en.wikipedia.org/wiki/Race_condition). 
 - Orchestration [phases](https://help.keboola.com/orchestrator/tasks/#organize-tasks). When you run an orchestration, the jobs for all phases are created. Phases that depend on other phases enter the `waiting` state.
 - Setting parallel limits. If you run a configuration with 10 tables and set parallelism to 2, then 10 jobs will be created, 2 will enter `processing` 
 state and 8 of them will immediately enter the `waiting` state. 
 
 If a job cannot be run due to platform reasons (e.g. insufficient resources, platform outage), it will remain in the `created` state. In rare situations 
 (e.g. hardware failure), the job may return back to created state. Moving the job out of the `created` state is out of the control of the end-user.
 
 Of all the states a job can be in, only the state `processing` is considered to be job runtime (see `durationSeconds` field) and therefore billable. 
 That means `waiting` or `created` jobs do not have any costs associated with them, they represent a plan of what is going to happen.

 The states `terminated`, `cancelled`, `success` and `error` are final and end the job transitions. When a job is in final state, the `isFinished` flag is true.
 The job object is both immutable and eventually consistent. Once you create a job, you cannot change any of it's properties. Any changing properties are
 self-modifying and they will stop modifying once the job reaches one of the final states. 

Apart from the `status` field, the job also has `desiredStatus` field. This is either `processing` or `terminating`. The desired status is 
processing until a job termination is requested. This changes the desired status to `terminating`. Other changes are not permitted.

### Job ID
When a job is created, an `id` and `runId` and optionally `parentRunId` are assigned to it. The `runId` and `parentRunId` represent 
parent-child relationship between jobs. Parent-child hierarchical relationship can be defined via the `X-KBC-RunId` header, when used the
newly created job will become child of the job with the provided `RunId`.

The `runId` field contains job `id`s with representing the job hierarchy. If there is no hierarchy, then `runId` is equal to `id`. If there is 
hierarchy then `runId` is `parentId` concatenated with `id`. The hierarchy delimiter is dot `.`. Examples:

- `id=123`, `runId=123`, `parentRunId=null` -- Job has no parent
- `id=345`, `runId=123.345`, `parentRunId=123` -- Job is a child of job `123`.
- `id=678`, `runId=123.345.678`, `parentRunId=123.345` -- Job is a child of job `345` which in turn is a child of job `123`.

Jobs may be nested without limits. The parent-child relationship itself is a weak relationship. By itself it does not mean anything 
special outside of UI grouping and the function that terminating a parent job issues a termination request to all its children. 
Running a job as a child of another job does not by itself cause the parent to wait for child 
completion or any other added functionality.
Such functionality is implemented in specific components (e.g. Orchestrator) or for specific [job types](todo).

### Job Configuration
To create a job, you must provide the [configuration](https://help.keboola.com/components/) to run. A configuration is always tied to a specific 
[component](/extend/component/).

A configuration can be provided in multiple ways. The easiest is to provide a reference to 
a stored configuration ID using the `config` field as shown above. Configurations can be stored and listed using the 
[Component Configurations API endpoint](https://keboola.docs.apiary.io/#reference/components-and-configurations/component-configurations/list-configurations).
When using a configuration which contains [Configuration Rows](https://help.keboola.com/components/#configuration-rows), the job can optionally execute 
only certain rows. Use the `configRowIds` field to list row IDs to execute. Note that if you do not list any rows, then all rows will be executed except 
for disabled rows. When you enumerate rows to execute, then the enumerated rows will be executed even if they are disabled. To run a job of 
a configuration in a branch, provide the [branch ID](https://keboola.docs.apiary.io/#reference/development-branches/branches/list-branches) 
in the `branchId` field. If you do not provide `branchId`, then the default branch is used. 
Take care that only the **combination of component ID, configuration ID and branch ID is unique**. It is possible for two configurations with the 
same ID to exist (either for different component or for a different branch).

Another option is to provide the entire configuration in the `configData` field. In that case the whole configuration data
has to be provided in the request. If you are retrieving a 
[stored configuration](https://keboola.docs.apiary.io/#reference/components-and-configurations/manage-configurations/configuration-detail), take 
note that the configuration data is the contents of the `configuration` node and not the entire 
response. When using the `configData` field, the `configRowIds` and `branchId` values are ignored. When using the `configData` field the `config` field 
is ignored for the purpose of reading the configuration, but may still be required in case the component is using 
[Default Bucket](https://developers.keboola.com/extend/component/tutorial/output-mapping/#configuring-default-bucket). In that case, the 
configuration referenced in `config` is used to generate the name of the output bucket. It still holds that configuration data is not read from it. 
That means that `configData` always fully overrides the `config` field.

### Job Mode
When creating a job, you need to provide `mode`. This can be one of `run`, `forceRun` and `debug`. The basic `mode` choice is `run`. 
Use the `forceRun` mode to run a configuration that is disabled. The `debug` can be used during [Component Development & Debugging](https://developers.keboola.com/extend/component/tutorial/debugging/).

### Job Runtime configuration
You may provide runtime settings for a job. Runtime settings do not affect what the job does, it affects how the job does it. Current 
available runtime settings are `backend` and `parallelism`. The `backend` parameter defines what Snowflake warehouse is used for the job and currently
affects mostly Snowflake transformations. Available values for backend size come from [Workspace Create API call](https://keboola.docs.apiary.io/#reference/workspaces/workspaces-collection/create-workspace) and are `small`, `medium`, `large`. 

The `parallelism` allows to run [Configuration Rows](https://help.keboola.com/components/#configuration-rows) (if present in the configuration) in
parallel. Allowed values are integer values and `infinity` which runs all rows in parallel. When parallelism is not specified, the rows are run sequentially. 
You may also specify `tag` if you want to run the component with a specific version of code. This is mostly used during component development, testing 
and debugging.

Runtime parameters can be specified on various levels. The values can be specified in the component configuration. They can also be specified 
when creating a job, in which case it overrides the configuration. It may also be specified for an orchestration, in which case it overrides what is specified 
in individual jobs of that orchestration.

### Job Type
Job can be of one of the four types `standard`, `container`, `phaseContainer` and `orchestrationContainer`. The `standard` is something which does actual work.
Only standard jobs consume billable time and are counted towards consumption of any resources. Other job types are virtual containers encapsulating standard jobs.

The `container` job represent a job containing [parallel executions](/integrate/jobs/#job-runtime-configuration) 
of configuration rows. `phaseContainer` type contains standard jobs in a single 
phase of an orchestration. `orchestrationContainer` job type represents an [orchestration](https://help.keboola.com/orchestrator/) and 
contains phase jobs of that orchestration. What these job types have in common is a strong 
[parent-child relationship](/integrate/jobs/#job-id). This means for example that when a child job fails, the container fails too. The 
behavior can be further controlled by the `onError` setting. You cannot specify job type when creating a job, it is selected automatically as needed.

## Working with the Jobs API
The main API to run the jobs is [Job Queue API](https://app.swaggerhub.com/apis-docs/keboola/job-queue-api). There are some API calls from other services 
which might be useful when working with jobs:

- [Create configurations](https://keboola.docs.apiary.io/#reference/components-and-configurations/component-configurations/create-configuration)
- [List Job Events](https://keboola.docs.apiary.io/#reference/events/events/events-list)
- [Encrypt values](https://keboolaencryption.docs.apiary.io/#reference/encrypt/encryption/encrypt-data)
- [Run Synchronous Actions](https://app.swaggerhub.com/apis/odinuv/sync-actions/1.0.0#/default/post_actions)
- [Subscribe to Job Events](https://app.swaggerhub.com/apis/odinuv/notifications-service/1.1.0#/Project%20Subscriptions/createSubscription)
- [Schedule jobs](https://app.swaggerhub.com/apis/odinuv/scheduler/1.0.0#/schedules/activate)

The component jobs are asynchronous operations, this means that you create it and then you have to actively wait for the result. Note that there 
are other *unrelated* cases of asynchronous operations in Keboola Platform which are in principle the same, but may differ in little details. 
The most common one is:
[Storage Jobs](https://keboola.docs.apiary.io/#reference/jobs/manage-jobs/job-detail), triggered, for instance, by
[asynchronous imports](https://keboola.docs.apiary.io/#reference/tables/create-table-asynchronously/create-new-table-from-csv-file-asynchronously)
or [exports](https://keboola.docs.apiary.io/#reference/tables/unload-data-asynchronously/asynchronous-export)

### Run a Job
You need to know the *component Id* and *configuration Id* to create a job. You can get these from the UI links. To use the API to obtain a 
list of all components available in the project, and their configuration, you can use the
[Get components](https://keboola.docs.apiary.io/#reference/components-and-configurations/list-components/get-components).
See an [example](https://documenter.getpostman.com/view/3086797/kbc-samples/77h845D?version=latest#9b9f3e7b-de3b-4c90-bad6-a8760e3852eb).
A snippet of the response is below:

{% highlight json %}
[
  {
    "id": "keboola.ex-db-snowflake",
    "type": "extractor",
    "name": "Snowflake",
    "description": "Cloud-Native Elastic Data Warehouse Service",
    "uri": "https://syrup.keboola.com/docker/keboola.ex-db-snowflake",
    "documentationUrl": "https://github.com/keboola/db-extractor-snowflake/blob/master/README.md",
    "configurations": [
        {
            "id": "554424643",
            "name": "Sample database",
            "description": "",
            "created": "2019-12-03T11:18:28+0100",
            "creatorToken": {
                "id": 199182,
                "description": "ondrej.popelka@keboola.com"
            },
            "version": 3,
            "changeDescription": "Quickstart config creation",
            "isDisabled": false,
            "isDeleted": false,
            "currentVersion": {
                "created": "2019-12-03T11:19:50+0100",
                "creatorToken": {
                    "id": 199182,
                    "description": "ondrej.popelka@keboola.com"
                },
                "changeDescription": "Quickstart config creation"
            }
        }
    ]
  }
]
{% endhighlight %}

From there, the important part is the `id` field and `configurations.id` field. For instance, in the
above, there is a database extractor with the `id` `keboola.ex-db-snowflake` and a
configuration with the id `554424643`.

Then use the [create a job](https://app.swaggerhub.com/apis-docs/keboola/job-queue-api/1.2.4#/Jobs/createJob)
API call and pass the configuration ID and component ID in request body:

```json
{
    "component": "keboola.ex-db-snowflake",
    "config": "554424643",
    "mode": "run"
}
```

See an [example](https://documenter.getpostman.com/view/3086797/kbc-samples/77h845D?version=latest#9b9f3e7b-de3b-4c90-bad6-a8760e3852eb).
When a job is created, you will obtain a response similar to this:

```json
{
    "id": "807932655",
    "runId": "807932655",
    "parentRunId": "",
    "project": {
        "id": "7150",
        "name": "Sandbox"
    },
    "token": {
        "id": "199182",
        "description": "ondrej.popelka@keboola.com"
    },
    "status": "created",
    "desiredStatus": "processing",
    "mode": "run",
    "component": "keboola.ex-db-snowflake",
    "config": "554424643",
    "configData": [],
    "configRowIds": [],
    "tag": "5.5.0",
    "createdTime": "2022-01-25T16:34:40+00:00",
    "startTime": null,
    "endTime": null,
    "durationSeconds": 0,
    "result": [],
    "usageData": [],
    "isFinished": false,
    "url": "https://queue.keboola.com/jobs/807932655",
    "branchId": null,
    "variableValuesId": null,
    "variableValuesData": {
        "values": []
    },
    "backend": [],
    "metrics": [],
    "behavior": {
        "onError": null
    },
    "parallelism": null,
    "type": "standard"
}
```

This means that the job was `created` and will automatically start executing.
From the above response, the most important part is `url`, which gives you the URL of the resource for
[Job status polling](https://en.wikipedia.org/wiki/Polling_(computer_science)).

### Job Polling
If you want to get the actual job result, poll the [Job API](https://app.swaggerhub.com/apis-docs/keboola/job-queue-api/1.2.4#/Jobs/getJob)
for the current state of the job. See an [example](https://documenter.getpostman.com/view/3086797/kbc-samples/77h845D?version=latest#9b9f3e7b-de3b-4c90-bad6-a8760e3852eb).

You will receive a response in the same format as when you crated the job:

```json
{
    "id": "807933826",
    "runId": "807933826",
    "parentRunId": "",
    "project": {
        "id": "7150",
        "name": "7150"
    },
    "token": {
        "id": "199182",
        "description": "ondrej.popelka@keboola.com"
    },
    "status": "processing",
    "desiredStatus": "processing",
    "mode": "run",
    "component": "keboola.ex-db-snowflake",
    "config": "554424643",
    "configData": [],
    "configRowIds": [],
    "tag": "5.5.0",
    "createdTime": "2022-01-25T16:41:12+00:00",
    "startTime": "2022-01-25T16:41:22+00:00",
    "endTime": null,
    "durationSeconds": 0,
    "result": [],
    "usageData": [],
    "isFinished": false,
    "url": "https://queue.keboola.com/jobs/807933826",
    "branchId": null,
    "variableValuesId": null,
    "variableValuesData": {
        "values": []
    },
    "backend": [],
    "metrics": [],
    "behavior": {
        "onError": null
    },
    "parallelism": null,
    "type": "standard"
}
```

From the above response, the most important part is the `status` field (`processing`, in this case). 
To obtain the Job result, periodically send the above API call until the job status changes
to one of the finished states or until `isFinished` is true.

### Run a Debug job
To run a debug job, use `debug` for the mode. Optionally you can provide the component version which should run
to [live test](/extend/component/deployment/#test-live-configurations) an image.

```json
{
    "component": "keboola.ex-db-snowflake",
    "config": "554424643",
    "mode": "debug",
    "tag": "5.5.0"
}
```

The debug mode creates a job that prepares the data folder including the serialized configuration files. Then it compresses the 
[data folder](/extend/component/running/#preparing-the-data-folder) and uploads it to your project's Files in Storage. This way you will get a snapshot 
of what the data folder looked like before the component started. If processors are used, a snapshot of the data folder is created before each processor. After the entire component finishes, another snapshot is made. For example, if you run component A with processor B and C in the after section, you will receive:

- `stage_0` file with contents of the data folder before component A was run
- `stage_1` file with contents of the data folder before processor B was run
- `stage_2` file with contents of the data folder before processor C was run
- `stage_output` file with contents of the data folder before output mapping was about to be performed (after C finished).

If configuration rows are used, then the above is repeated for each configuration row. If the job finishes with and error, only the stages before the error are uploaded.

This API call does not upload any tables or files to Storage. I.e. when the component finishes, its output is discarded and the output mapping to storage 
is not performed. This makes this API call generally very safe to call, because it cannot break the Keboola project in any way. However, keep 
in mind, that if the component has any outside side effects, these will get executed. This applies typically to writers which will write the data 
into the external system even with this debug API call.

Note that the snapshot archive will contain all files in the data folder including any temporary files produced be the component. The snapshot will not 
contain the output state.json file. This is because the snapshot is made before a component is run where the out state of the previous component is 
not available any more. Also note that all encrypted values are removed from the configuration file and there is no way to retrieve them. It is 
also advisable to run this command with limited input mapping so that you don't end up with gigabyte size archives.


================================================
File: integrate/orchestrator/index.md
================================================
---
title: Orchestrator
permalink: /integrate/orchestrator/
---

{% comment %}
spusteni jobu
API pro konfiguraci, nepouzivat normalni api
custom joby

sloucit s /automate/
{% endcomment %}

================================================
File: integrate/storage/docker-cli-client.md
================================================
---
title: Storage Docker CLI Client
permalink: /integrate/storage/docker-cli-client/
redirect_from: /integrate/storage/php-cli-client/
---

* TOC
{:toc}

The Storage API Docker command line interface (CLI) client is a portable command line client which provides
a simple implementation of [Storage API](https://keboola.docs.apiary.io/#).
It runs on any platform which has Docker installed.

Currently, the client implements

- functions for exporting and importing tables;
- functions for creating and deleting buckets; and additionally,
- the [project backup feature](https://help.keboola.com/management/project-export/).

The client source is available in our [Github repository](https://github.com/keboola/storage-api-cli).
The client docker image is available in the [Quay repository](https://quay.io/repository/keboola/storage-api-cli?tab=tags).

## Running in Docker
To print available commands:

{% highlight bash %}
docker run quay.io/keboola/storage-api-cli:latest
{% endhighlight %}

The `latest` image tag always refers to the latest tagged version.

## Running Phar

PHAR (PHP Archive) is now deprecated, but there are still some older versions available. See the [repository documentation](https://github.com/keboola/storage-api-cli#running-phar-deprecated).

### Example --- Creating a Table
To create a new table in Storage, use the `create-table` command. Provide the name of an
existing bucket, the name of the new table and a CSV file with the table's contents.

To create the`new-table` table in the `in.c-main` bucket, use

{% highlight bash %}
docker run --volume=$("pwd"):/data quay.io/keboola/storage-api-cli:latest create-table in.c-main new-table /data/new-table.csv --token=storage_token
{% endhighlight %}

or on Windows:

    docker run --volume=C:\Users\name\some-dir:/data quay.io/keboola/storage-api-cli:latest create-table in.c-main new-table /data/new-table.csv --token=storage_token

or when using other then [default US region](/overview/api/#regions-and-endpoints), you need to provide the Storage API address:

{% highlight bash %}
docker run --volume=$("pwd"):/data quay.io/keboola/storage-api-cli:latest create-table in.c-main new-table /data/new-table.csv --token=storage_token --url="https://connection.eu-central-1.keboola.com/"
{% endhighlight %}

Any of the above commands will import the contents of `new-table.csv` in the current directory into the newly
created table. You should see an output similar to this one:

    Authorized as: ondrej.popelka@keboola.com (Odinuv Sandbox)
    Bucket found ok
    Table create start
    Table create end
    Table id: in.c-main.new-table
    
*Please note that the Docker container can only access folders within the container, so you need to mount a local folder. 
In the example above, the local folder `$("pwd")` (replaced by the absolute path at runtime) is mounted as `/data` into the container. 
The table is then accessible in this folder. The same approach applies to all other commands working with local files.*

### Example --- Importing Data
If you only want to import new data into the table, use the `write-table` command and provide
the ID (*bucketName.tableName*) of an existing table.

To import data into the `new-table` table in the `in.c-main` bucket, use

{% highlight bash %}
docker run --volume=$("pwd"):/data quay.io/keboola/storage-api-cli:latest write-table in.c-main.new-table /data/new-data.csv --token=storage_token --incremental
{% endhighlight %}

The above command will import the contents of the `new-data.csv` file into the existing table. If the
`--incremental` parameter is supplied, the table contents will be appended. If the parameter is not
supplied, the table contents will be overwritten. You should see an output similar to this one:

    Authorized as: ondrej.popelka@keboola.com (Tutorial)
    Table found ok
    Import start
    Import done in 17 secs.

    Results:
    transaction:
    warnings:
    importedColumns:
        - id
        - secondCol
    totalRowsCount: 8
    totalDataSizeBytes: 4096


### Example --- Exporting Data
If you want to export a table from Storage, use the `export-table` command. Provide
the ID (*bucketName.tableName*) of an existing table.

To export data from the `old-table` table in the `in.c-main` bucket, use

{% highlight bash %}
docker run --volume=$("pwd"):/data quay.io/keboola/storage-api-cli:latest export-table in.c-main.old-table /data/old-data.csv --token=storage_token
{% endhighlight %}

The above command will export the table from Storage and save it as `old-data.csv` in
the current directory. You should see an output similar to this one:

    Authorized as: ondrej.popelka@keboola.com (Tutorial)
    Table found ok
    Export done in 17 secs.


================================================
File: integrate/storage/index.md
================================================
---
title: Storage
permalink: /integrate/storage/
---

* TOC
{:toc}

As the central Keboola component, Storage

- Keeps all data in [**buckets** and **tables**](https://help.keboola.com/storage/);
- Controls access to the data using **tokens**;
- Logs all data manipulations as **events**;
- Maintains the index of all other Keboola **components** and stores their **configurations**.

All this (and a few other things) is available through [Storage API (SAPI)](https://keboola.docs.apiary.io/#).
To authorize access to a specific project, most calls to Storage API require
a [Storage API Token](https://help.keboola.com/storage/tokens/) along with your request.
It is required regardless of whether you use the bare API or any of the clients.

## Storage API Clients
Although you can work directly with the API, we recommend using one of our Storage API clients, as they simplify some tasks.
There are four Storage clients with different feature sets available:

1. [PHP client library](https://github.com/keboola/storage-api-php-client) --- a PHP library supporting most of the Storage API features;
use it programmatically in PHP.
2. [R client library](/integrate/storage/r-client/) --- an R library supporting most data manipulation features of the Storage API;
use it programmatically in R.
3. [Python client library](/integrate/storage/python-client/) --- a Python library supporting most data manipulation features and
workspace manipulation features of the Storage API; use it programmatically in Python.
4. [Docker CLI client](https://github.com/keboola/storage-api-cli) --- a CLI (command line interface) application supporting
basic data manipulation features of the Storage API; use it from the command line provided that you have Docker available.

Additional tools:

- [Storage API Console](https://storage-api-console.keboola.com/) --- a UI to work with Keboola Storage;
this is accessible to anyone with a Storage Token (not necessarily a Keboola project administrator)
- [Table Importer Service](/integrate/storage/api/importer/) --- a service designed for simplified table loads

The client choice is purely up to you, but it is best to use the most straightforward solution.

## Table Imports and Exports
Tables are imported to and exported from Storage via asynchronous (background) jobs.

- When importing a table, the actual data is first transported to an Amazon S3 storage,
and then bulk is loaded into the internal database in Storage. Similarly,
- When exporting a table, the data is first offloaded to an Amazon S3 storage and downloaded from there.

While this process is much more complicated than a simple file upload or download,
it offers better **manageability** and **traceability** features.
Use one of the above mentioned clients to import and export your data. The client will handle the entire process
without you worrying about the technical details.

If all you need is to import data into Storage (for example, for project prototyping), you may
also use the [Storage Importer Service](/integrate/storage/api/importer/).

Still interested in handling the file uploads/downloads manually?
[Read on](/integrate/storage/api/import-export/).


================================================
File: integrate/storage/new-table.csv
================================================
"id","secondCol"
"1","a"
"2","b"
"3","c"
"4","d"

================================================
File: integrate/storage/php-client.md
================================================
---
title: Storage PHP Client Library
permalink: /integrate/storage/php-client/
---

* TOC
{:toc}

The Storage API PHP client library is a portable command line client providing
the most complete [Storage API](https://keboola.docs.apiary.io/#) implementation.
It runs on any platform which has PHP installed.
Currently this client implements almost all Storage API functions including, of course, exporting and importing tables.

The client source is available in our [Github repository](https://github.com/keboola/storage-api-php-client).

## Installation

The Library is available as a [Composer package](https://getcomposer.org/).
Unless you already have it, [install Composer](https://getcomposer.org/download/) on your system.
On *nix system, do so by running

{% highlight bash %}
curl -s http://getcomposer.org/installer | php
mv ./composer.phar ~/bin/composer # or /usr/local/bin/composer
{% endhighlight %}

On Windows, use the [installer](https://getcomposer.org/Composer-Setup.exe).

To install the library, run

{% highlight bash %}
composer require keboola/storage-api-client
{% endhighlight %}

in the root of your project. You should get an output similar to this one:

    Using version ^4.11 for keboola/storage-api-client
    ./composer.json has been created
    Loading composer repositories with package information
    Updating dependencies (including require-dev)
    - Installing aws/aws-sdk-php (3.18.18)
        Downloading: 100%
    ...
    - Installing keboola/storage-api-client (4.11.0)
        Downloading: 100%
    Writing lock file
    Generating autoload files

Then add the generated autoloader in your bootstrap script:

{% highlight php %}
require 'vendor/autoload.php';
{% endhighlight %}

You can read more in the [Composer documentation](https://getcomposer.org/doc/01-basic-usage.md). Packages
installable by Composer can be browsed at [Packagist package repository](https://packagist.org/).

## Usage
The Storage API client is implemented as a single class. To create an instance of the class, provide a Storage API token to the
constructor.

{% highlight php %}
<?php

require 'vendor/autoload.php';

use Keboola\StorageApi\Client;

$client = new Client([
  'token' => 'your-token',
]);
{% endhighlight %}


### Example --- Create a Table
To create a new table in Storage, it is recommended to use an additional
[php-csv](https://github.com/keboola/php-csv) library to work
with CSV files. The library will get installed
automatically with the Storage API client, so you can use it out of the box.
To create a new table and import CSV data in it, use the following PHP script:

{% highlight php %}
<?php
require 'vendor/autoload.php';

use Keboola\Csv\CsvFile;
use Keboola\StorageApi\Client;

$client = new Client([
    'token' => 'your-token',
]);
$csvFile = new CsvFile('./new-table.csv');
$client->createTableAsync('in.c-main', 'new-table', $csvFile);
{% endhighlight %}

### Example --- Import Data
To import CSV data into an existing table and overwrite its contents, use the following PHP script:

{% highlight php %}
<?php
require 'vendor/autoload.php';

use Keboola\Csv\CsvFile;
use Keboola\StorageApi\Client;

$client = new Client([
    'token' => 'your-token',
]);
$csvFile = new CsvFile('./new-table.csv');
$client->writeTableAsync('in.c-main.new-table', $csvFile);
{% endhighlight %}

### Example --- Import Data Incrementally
To import CSV data into an existing table and append the new data to the existing table contents, use the following PHP script:

{% highlight php %}
<?php
require 'vendor/autoload.php';

use Keboola\Csv\CsvFile;
use Keboola\StorageApi\Client;

$client = new Client([
    'token' => 'your-token',
]);
$csvFile = new CsvFile('./new-table.csv');
$client->writeTableAsync('in.c-main.new-table', $csvFile, ['incremental' => true]);
{% endhighlight %}

All available upload options are listed in the [API documentation](https://keboola.docs.apiary.io/#reference/tables/load-data-asynchronously/import-data-from-csv-file-asynchronously).

### Example --- Export Data
To export data from a Storage table to a CSV file, use the
`TableExporter` class. It is part of the client library. You can use the following script:

{% highlight php %}
<?php
require 'vendor/autoload.php';

use Keboola\StorageApi\Client;
use Keboola\StorageApi\TableExporter;

$client = new Client([
    'token' => 'your-token'
]);

$exporter = new TableExporter($client);
$exporter->exportTable('in.c-main.my-table', './old-table.csv');
{% endhighlight %}


================================================
File: integrate/storage/python-client.md
================================================
---
title: Python Client Library
permalink: /integrate/storage/python-client/
---

* TOC
{:toc}

The Python client library is a [Storage API client](https://keboola.docs.apiary.io/#) which you can use in your Python code.
The current implementation supports all basic data manipulations:

- Importing data
- Exporting data
- Creating and deleting buckets and tables
- Creating and deleting workspaces

The client source code is available in our [Github repository](https://github.com/keboola/sapi-python-client/).

## Installation
This library is available on [Github](https://github.com/keboola/sapi-python-client), so we
recommend that you use the `pip` package to install it:

    pip3 install git+https://github.com/keboola/sapi-python-client.git

## Usage
The client contains a `Client` class, which encapsulates all API endpoints and holds a storage token and URL. Each API endpoint is
represented by its own class (`Files`, `Buckets`, `Jobs`, etc.), which can be used standalone if you only work with one endpoint.
This means that the two following examples are equivalent:

{% highlight python %}
from kbcstorage.client import Client

client = Client('https://connection.keboola.com', 'your-token')
client.tables.detail('in.c-demo.some-table')
{% endhighlight %}

{% highlight python %}
from kbcstorage.tables import Tables

tables = Tables('https://connection.keboola.com', 'your-token')
tables.detail('in.c-demo.some-table')
{% endhighlight %}

### Example --- Create Table and Import Data
To create a new table in Storage, use the `create` function of the `Tables` class. Provide the name of an existing bucket,
the name of the new table and a CSV file with the table's contents.

To create the `new-table` table in the `in.c-main` bucket, use:

{% highlight python %}
from kbcstorage.client import Client

client = Client('https://connection.keboola.com', 'your-token')
client.tables.create(name='new-table',
                     bucket_id='in.c-main',
                     file_path='coords.csv',
                     primary_key=['id'])
{% endhighlight %}

The above command will import the contents of the `coords.csv` file into the newly created table. It will
also mark the `id` column as the primary key.
### Example --- Load to existing table, incrementally

To load data incrementally into an existing table, we can use the [load](https://github.com/keboola/sapi-python-client/blob/5a93926c2191ccd6b7402c9e24d9912884d87d4c/kbcstorage/tables.py#L207) method, where `table_id` is the ID of the table that you want to load into, and `path` is the path to your csv file containing the data:

{% highlight python %}

from kbcstorage.client import Client

client = Client('https://connection.keboola.com', 'your-token')

client.tables.load(table_id=table_id, file_path=path, is_incremental=True)

{% endhighlight %}
### Example --- Export Data
To export data from the `old-table` table in the `in.c-main` bucket, use:

{% highlight python %}
from kbcstorage.client import Client
import csv

client = Client('https://connection.keboola.com', 'your-token')
client.tables.export_to_file(table_id='in.c-main.new-table', path_name='.')
with open('./new-table', mode='rt', encoding='utf-8') as in_file:
    lazy_lines = (line.replace('\0', '') for line in in_file)
    reader = csv.reader(lazy_lines, lineterminator='\n')
    for row in reader:
        print(row)
{% endhighlight %}

The above command will export the table from Storage into the file `new-table` and read it using
[CSV Reader](https://docs.python.org/3.6/library/csv.html#reader-objects).

### Other Examples

{% highlight python %}
# create a client
client = Client('https://connection.keboola.com', 'your-token')

# create a bucket
client.buckets.create(name='demo', stage='in')

# list buckets
client.buckets.list()

# list all tables
client.tables.list()

# list all tables in a bucket
client.buckets.list_tables(bucket_id='in.c-demo')

# delete a table
client.tables.delete(table_id='in.c-demo.some-table')

# delete a bucket
client.buckets.delete(bucket_id='in.c-main', force=True)

{% endhighlight %}


================================================
File: integrate/storage/r-client.md
================================================
---
title: R Client Library
permalink: /integrate/storage/r-client/
---

* TOC
{:toc}

The R client library is a [Storage API client](https://keboola.docs.apiary.io/) which you can use in your R code.
The current implementation supports all basic data manipulations:

- Importing data
- Exporting data
- Creating and deleting buckets and tables

The client source code is available in our [Github repository](https://github.com/keboola/sapi-r-client).

## Installation
This library is available on [Github](https://github.com/keboola/sapi-r-client), so we
recommend that you use the `devtools` package to install it.

{% highlight r %}
# first install the devtools package if it isn't already installed
install.packages("devtools")

# install dependencies (another github package for aws requests)
devtools::install_github("cloudyr/aws.s3")

# install the SAPI R client package
devtools::install_github("keboola/sapi-r-client")

# load the library (dependencies will be loaded automatically)
library(keboola.sapi.r.client)
{% endhighlight %}

## Usage
To list available commands, run
{% highlight r %}
?keboola.sapi.r.client::SapiClient
{% endhighlight %}

**Important**: If you are running the code in R Studio, it might require a restart so that its help index is updated
and the above command works.

The client is implemented as an [RC class](http://adv-r.had.co.nz/R5.html). To work with it, create an instance of the client.
The only required argument to create it is a valid Storage API token.

{% highlight r %}
client <- SapiClient$new(
    token = 'your-token'
)
{% endhighlight %}

### Example --- Create a Table and Import Data
To create a new table in Storage, use the `saveTable` function. Provide the name of an existing bucket,
the name of the new table and a CSV file with the table's contents.

To create the `new-table` table in the `in.c-main` bucket, use

{% highlight r %}
myDataFrame <- data.frame(id = c(1,2,3,4), secondCol = c('a', 'b', 'c', 'd'))
client <- SapiClient$new(
    token = 'your-token'
)

table <- client$saveTable(
    df = myDataFrame,
    bucket = "in.c-main",
    tableName = "new-table",
    options = list(primaryKey = 'id')
)
{% endhighlight %}

The above command will import the contents of the `myDataFrame` variable into the newly created table. It will
also mark the `id` column as the primary key.

### Example --- Export Data
If you want to export a table from Storage and import it into R, use the `importTable` function. Provide
the ID (*bucketName.tableName*) of an existing table.

To export data from the `old-table` table in the `in.c-main` bucket, use

{% highlight r %}
client <- SapiClient$new(
  token = 'your-token'
)

data <- client$importTable('in.c-main.old-table')
{% endhighlight %}

The above command will export the table from Storage and save it in the `data` variable. The output is
a [data.table](https://cran.r-project.org/web/packages/data.table/index.html) object compatible with a `data.frame`.

### Other Examples

{% highlight r %}
# create a client
client <- SapiClient$new(
    token = 'your-token'
)

# verify the token
tokenDetails <- client$verifyToken()

# create a bucket
bucket <- client$createBucket("new_bucket", "in", "A brand new Bucket!")

# list buckets
buckets <- client$listBuckets()

# list all tables
tables <- client$listTables()

# list all tables in a bucket
tables <- client$listTables(bucket = bucket$id)

# delete a table
client$deleteTable(table$id)

# delete a bucket
client$deleteBucket(bucket$id)

{% endhighlight %}


================================================
File: integrate/storage/sys.c-table-importer.test-config.csv
================================================
"table","primaryKey","incremental","enclosure","delimiter","escapedBy","tag","rowId"
"in.c-main.new-table","","0","""",",","","new-data","1"


================================================
File: integrate/storage/api/configurations.md
================================================
---
title: Component Configurations API
permalink: /integrate/storage/api/configurations/
---

* TOC
{:toc}

[Configurations](https://help.keboola.com/storage/configurations/) are an important part of a Keboola project. Most operations are
available in the UI. Use the API if you want to manipulate the configurations programmatically.

Configurations represent component **instances** in a project. Each Keboola component has different configuration
options and requirements, which must be respected. As such, Keboola configurations provide a general framework for configuring
components, while the specific implementation details are left to the components themselves.

When working with the [Component Configurations API](https://keboola.docs.apiary.io/#reference/components-and-configurations),
you need to know the `componentId` of the component being configured.
You can see a list of public components in [the Developer Portal](https://components.keboola.com/components), or you can get
a list of all available components with the [API index call](https://keboola.docs.apiary.io/#reference/miscellaneous/api-index/component-list).
See our [example](https://documenter.getpostman.com/view/3086797/kbc-samples/77h845D?version=latest#9b9f3e7b-de3b-4c90-bad6-a8760e3852eb).

It will give you something like this:

{% highlight json %}
{
    "host": "4edece0b0052",
    "api": "storage",
    "version": "v2",
    "revision": "21fb56a0f6d61a307f350247a45950b1e4049625",
    "documentation": "https://keboola.docs.apiary.io/",
    "components": [
        {
            "id": "keboola.ex-aws-s3",
            "type": "extractor",
            "name": "AWS S3",
            "description": "AWS Simple Storage Service",
            "longDescription": "Download ... from AWS S3 and upload them to Storage.",
            "version": 23,
            "hasUI": false,
            "hasRun": false,
            "ico32": "https://ui.keboola-assets.com/.../keboola.ex-aws-s3/32/20.png",
            "ico64": "https://ui.keboola-assets.com/.../keboola.ex-aws-s3/64/20.png",
            "data": {
                "definition": {
                    "type": "aws-ecr",
                    "uri": "147946154733.../keboola.ex-aws-s3",
                    "tag": "v3.0.0",
                    "repository": {
                        "region": "us-east-1"
                    }
                },
                "vendor": {
                    "contact": [
                        "Keboola",
                        "Křižíkova 488/115\n186 00 Prague 8\nCzech Republic",
                        "support@keboola.com"
                    ],
                    "licenseUrl": "https://github.com/keboola/aws-s3-extractor/blob/master/LICENSE"
                },
                "configuration_format": "json",
                "network": "bridge",
                "memory": "512m",
                "forward_token": false,
                "forward_token_details": false,
                "default_bucket": true,
                "default_bucket_stage": "in",
                "staging_storage": {
                    "input": "local"
                }
            },
            "flags": [
                "genericDockerUI",
                "genericDockerUI-processors",
                "appInfo.dataIn"
            ],
            "configurationSchema": {},
            "emptyConfiguration": {},
            "uiOptions": {},
            "configurationDescription": null,
            "uri": "https://syrup.keboola.com/docker/keboola.ex-aws-s3",
            "documentationUrl": "https://help.keboola.com/extractors/other/aws-s3/"
        }
    ],
    "services": [...],
    "urlTemplates": {...}
}
{% endhighlight %}

From here, you can see all available information about a particular component. In the following examples, we
will use `keboola.ex-aws-s3` --- the AWS S3 extractor.

## Configuration Structure
Component configurations are largely dependent on the actual component being configured. This makes creating configurations manually
a bit tricky. Rather than starting from scratch, we recommend creating a configuration through the UI and then modifying it when you understand it.

### Inspecting Configuration
To obtain an existing configuration, you can either use the list of configurations above or
the [Configuration Detail](https://keboola.docs.apiary.io/#reference/components-and-configurations/manage-configurations/configuration-detail)
API call. See an [example](https://documenter.getpostman.com/view/3086797/kbc-samples/77h845D?version=latest#9b9f3e7b-de3b-4c90-bad6-a8760e3852eb) for obtaining a
configuration of the `keboola.ex-aws-s3` component. You will receive a response similar to this:

{% highlight json %}
{
    "id": "364479526",
    "name": "test",
    "description": "",
    "created": "2018-03-08T14:54:19+0100",
    "creatorToken": {
        "id": 27865,
        "description": "ondrej.popelka@keboola.com"
    },
    "version": 5,
    "changeDescription": "Table first table edited",
    "isDeleted": false,
    "configuration": {
        "parameters": {
            "accessKeyId": "AKIAIBZYEEXQILP46FCA",
            "#secretAccessKey": "KBC::ComponentProjectEncrypted==p5gvUw4RSGiVJjT2ayVORpqS7yiKhExi7NnQECntVm8haHaHtFNVDMT8X8b+htnixpXhPIQ9yV+ETrvr+hNeYfh+Ex+UpC//QPWnLcEOC8XOLgmQN8BNgRGSERWUziK0"
        }
    },
    "rowsSortOrder": [],
    "rows": [
        {
            "id": "364481153",
            "name": "first table",
            "description": "",
            "configuration": {
                "parameters": {
                    "bucket": "travis-php-db-import-tests-s3filesbucket-vm9zhtm5jd7s",
                    "key": "tw_accounts.csv",
                    "saveAs": "first-table",
                    "includeSubfolders": false,
                    "newFilesOnly": true
                },
                "processors": {
                    "after": [
                        {
                            "definition": {
                                "component": "keboola.processor-move-files"
                            },
                            "parameters": {
                                "direction": "tables",
                                "addCsvSuffix": true
                            }
                        },
                        {
                            "definition": {
                                "component": "keboola.processor-create-manifest"
                            },
                            "parameters": {
                                "delimiter": ",",
                                "enclosure": "\"",
                                "incremental": false,
                                "primary_key": [],
                                "columns": [],
                                "columns_from": "header"
                            }
                        },
                        {
                            "definition": {
                                "component": "keboola.processor-skip-lines"
                            },
                            "parameters": {
                                "lines": 1
                            }
                        }
                    ]
                }
            },
            "isDisabled": false,
            "version": 3,
            "created": "2018-03-08T14:58:33+0100",
            "creatorToken": {
                "id": 27865,
                "description": "ondrej.popelka@keboola.com"
            },
            "changeDescription": "Table first table edited",
            "state": {
                "lastDownloadedFileTimestamp": "1511176959",
                "processedFilesInLastTimestampSecond": [
                    "tw_accounts.csv"
                ]
            }
        }
    ],
    "state": {},
    "currentVersion": {
        "created": "2018-03-08T23:27:37+0100",
        "creatorToken": {
            "id": 27865,
            "description": "ondrej.popelka@keboola.com"
        },
        "changeDescription": "Table first table edited"
    }
}
{% endhighlight %}

The actual component configuration is split into three parts:

- `configuration` node, containing an arbitrary component configuration
- `state` node, containing a component [state file](/extend/common-interface/config-file/#state-file)
- `rows` node, containing iterations of `configuration` and `state`

The important part is the ID of the configuration you want to work with. In the following examples, we will use
`364479526`.

### Configuration
The `configuration` node maps to the [configuration file](/extend/common-interface/config-file/#configuration-file-structure).
It can contain the `storage`, `parameters`, `processors` and `authorization` child nodes (the `image_parameters` and `action` nodes found in the config file
are injected at runtime and are not stored in the configuration). The `authorization` node is set in the configuration only when
[credentials injection](/extend/common-interface/oauth/#credentials-injection) should be used, otherwise it is also set during the runtime.
The `processors` node defines the [processors and their configuration](/extend/component/processors/).
The most common sub-nodes stored in the `configuration` node are therefore `parameters` (containing an arbitrary component configuration)
and `storage` (containing [input](/extend/component/tutorial/input-mapping/) and [output mapping](/extend/component/tutorial/output-mapping/)).
Both are transferred to the
configuration file without modification; that means that the [`storage` configuration](/extend/common-interface/config-file/#configuration-file-structure)
is directly usable in the `configuration` node. The `parameters` node is fully dependent on the component and has no universal specification or rules.

In the above example, the `configuration` node contains the following:

{% highlight json %}
"parameters": {
    "accessKeyId": "AKIAIBZYEEXQILP46FCA",
    "#secretAccessKey": "KBC::ComponentProjectEncrypted==p5gvUw4RSGiVJjT2ayVORpqS7yiKhExi7NnQECntVm8haHaHtFNVDMT8X8b+htnixpXhPIQ9yV+ETrvr+hNeYfh+Ex+UpC//QPWnLcEOC8XOLgmQN8BNgRGSERWUziK0"
}
{% endhighlight %}

That means that the component is not using input mapping nor output mapping. The allowed contents of `parameters` are described
in the [AWS S3 extractor code documentation](https://github.com/keboola/aws-s3-extractor#configuration-options).

### Configuration Rows
The `rows` node contains iterations of the configuration. The interpretation of configuration rows is again dependent on the
component implementation. In the presented case of the `keboola.ex-aws-s3` component, each row corresponds to a single extracted table.
When `rows` node is non-empty, the component behavior is slightly modified. It behaves as if it were executed as many times as
there are rows. For each row, the `configuration` node from `root` and the `configuration` node from `rows` are merged, with
the latter overwriting the former in the case of conflict.

Given the above configuration, the **effective configuration** passed to the component
[configuration file](/extend/common-interface/config-file/#configuration-file-structure) will be as follows:

{% highlight json %}
{
    "parameters": {
        "accessKeyId": "AKIAIBZYEEXQILP46FCA",
        "#secretAccessKey": "KBC::ComponentProjectEncrypted==p5gvUw4RSGiVJjT2ayVORpqS7yiKhExi7NnQECntVm8haHaHtFNVDMT8X8b+htnixpXhPIQ9yV+ETrvr+hNeYfh+Ex+UpC//QPWnLcEOC8XOLgmQN8BNgRGSERWUziK0"
        "bucket": "travis-php-db-import-tests-s3filesbucket-vm9zhtm5jd7s",
        "key": "tw_accounts.csv",
        "saveAs": "first-table",
        "includeSubfolders": false,
        "newFilesOnly": true
    }
}
{% endhighlight %}

The first two parameters (`accessKeyId` and `#secretAccessKey`) are taken from the root `configuration`, the other
parameters are taken from the first rows' `configuration`. The `processors` node is never passed to the configuration file.
With the above configuration, the component will be executed only once, because there is one row. If there are no rows, the
component will still be executed once. If there were two rows, the component would be executed twice.

If the component is executed more than once, the operations are executed in the following order:

- input mapping for the first row
- run with the first row configuration (merged with root configuration)
- output mapping for the first row
- input mapping for the second row
- run with the second row configuration (merged with root configuration)
- output mapping for the second row

All of these are executed in a single [job](/integrate/jobs/). However, even though multiple rows are executed in a single
job, the actual executions are still completely isolated. I.e., there is no way to share anything between the rows
(apart from the common `configuration`). It also means that the outputs of the first row are available in the Keboola project before
the second row starts, and the inputs for the second row are read only after the first row finishes processing.

What is considered 'first' and 'second' -- i.e. the order of rows -- is defined by the order of items in the `rows` array.
See [below](#modifying-a-configuration) for an example of modifying the row order.

Theoretically, configuration rows are supported for every component as long as the effective configuration matches what
the component expects. Configuration rows can be used to split the configuration into a common part (typically credentials) and an
iterable part which is repeated many times. Keep in mind that configurations heavily modified through the API might **not be supported
in the UI**.

### State
The `state` node contains the content of the [state file](/extend/common-interface/config-file/#state-file). The
`state` is read from the state file and then supplied to the state file on the next run. In the above configuration,
the state is:

{% highlight json %}
{
    "lastDownloadedFileTimestamp": "1511176959",
    "processedFilesInLastTimestampSecond": [
        "tw_accounts.csv"
    ]
}
{% endhighlight %}

`State` is considered an internal property of a component and you should avoid modifying it. The only reasonable modification of
`state` is to delete it -- in that case, the configuration will run as if it were run for the first time. To delete the `state`, set it to `{}`.
If configuration rows are used, then the `state` is stored separately for each row and the `state` node in configuration root is
not used.

## Working with Configurations
Here, the most common operations done with configurations are described in examples. Feel free to go through the
[API reference](https://keboola.docs.apiary.io/#reference/components-and-configurations) for a full authoritative list of configuration features.

### List Configurations
To obtain configuration details, use the [List Configs call](https://keboola.docs.apiary.io/#reference/components-and-configurations/component-configurations/list-configurations),
which will return all the configuration details. This means

- the configuration itself (`configuration`) --- [section on configuration](#modifying-a-configuration) follows;
- configuration rows (`rows`) --- additional data of the configuration; and
- configuration state (`state`) --- [component state](/extend/common-interface/config-file/#state-file).

Please note that the contents
of the `configuration`, `rows` and `state` sections depend purely on the component itself. See an [example](https://documenter.getpostman.com/view/3086797/kbc-samples/77h845D?version=latest#9b9f3e7b-de3b-4c90-bad6-a8760e3852eb).

A sample result for the AWS S3 extractor looks like this:

{% highlight json %}
[
    {
        "id": "364479526",
        "name": "test",
        "description": "",
        "created": "2018-03-08T14:54:19+0100",
        "creatorToken": {
            "id": 27865,
            "description": "ondrej.popelka@keboola.com"
        },
        "version": 4,
        "changeDescription": "Table first table edited",
        "isDeleted": false,
        "configuration": {
            "parameters": {
                "accessKeyId": "AKIAIBZYEEXQILP46FCA",
                "#secretAccessKey": "KBC::ComponentProjectEncrypted==p5gvUw4RSGiVJjT2ayVORpqS7yiKhExi7NnQECntVm8haHaHtFNVDMT8X8b+htnixpXhPIQ9yV+ETrvr+hNeYfh+Ex+UpC//QPWnLcEOC8XOLgmQN8BNgRGSERWUziK0"
            }
        },
        "rowsSortOrder": [],
        "rows": [
            {
                "id": "364481153",
                "name": "first table",
                "description": "",
                "configuration": {...},
                "isDisabled": false,
                "version": 2,
                "created": "2018-03-08T14:58:33+0100",
                "creatorToken": {
                    "id": 27865,
                    "description": "ondrej.popelka@keboola.com"
                },
                "changeDescription": "Table first table edited",
                "state": {}
            }
        ],
        "state": {},
        "currentVersion": {
            "created": "2018-03-08T15:21:28+0100",
            "creatorToken": {
                "id": 27865,
                "description": "ondrej.popelka@keboola.com"
            },
            "changeDescription": "Table first table edited"
        }
    }
]
{% endhighlight %}

### Modifying Configuration
**Note: Configurations modified through the API might not be editable in the Keboola UI.** They can be run or used in an orchestration without any problems.

Modifying a configuration means that a new version of that configuration is created.
For modifying a configuration, use the
[Update Configuration](https://keboola.docs.apiary.io/#reference/components-and-configurations/manage-configurations/update-configuration) API call.
See an [example](https://documenter.getpostman.com/view/3086797/kbc-samples/77h845D?version=latest#9b9f3e7b-de3b-4c90-bad6-a8760e3852eb) in which the
configuration is modified to the following to set new credentials:

{% highlight json %}
{
	"parameters": {
		"accessKeyId": "a",
		"#secretAccessKey": "b"
	}
}
{% endhighlight %}

Notice that the configuration must be sent in the form field `configuration` as the endpoint does not accept pure JSON (yet).
Take great care to pass **only the contents** of the `configuration` node as in the above example. The configuration **must not be wrapped** in the
`configuration` node, otherwise the component will not
receive the configuration it expects. Also take care to properly escape the JSON using [URL encoding](https://en.wikipedia.org/wiki/Percent-encoding),
otherwise it may be misinterpreted. The raw HTTP request should look similar to this:

    curl --request PUT \
    --url https://connection.keboola.com/v2/storage/components/keboola.ex-aws-s3/configs/364479526 \
    --header "Content-Type: application/json" \
    --header 'X-StorageAPI-Token: {{token}}' \
    --data-binary "{
        \"configuration\": {
            \"parameters\": {
                \"accessKeyId\": \"a\",
                \"#secretAccessKey\": \"b\"
            }
        }
    }"

Also note that the entire configuration must be always sent, there is no way to patch only part of it.
The same way the `configuration` is modified, other properties can be modified too. For example, you may want to
reset `state` by setting it to `{}`, or you can change the order of the configuration rows by setting the `rowsSortOrder` property.
The `rowsSortOrder` is an array of row ids -- see an [example](https://documenter.getpostman.com/view/3086797/kbc-samples/77h845D?version=latest#9b9f3e7b-de3b-4c90-bad6-a8760e3852eb) (Set Row order of S3 extractor)
for the exact example request.

### Modifying Configuration Row
Very similar to modifying a configuration, modifying a configuration **row** means that a new version of
the **entire configuration** is created. For modifying a configuration row, use the
[Update Row](https://keboola.docs.apiary.io/#reference/components-and-configurations/manage-configuration-rows/update-configuration-row) API call.

See an [example](https://documenter.getpostman.com/view/3086797/kbc-samples/77h845D?version=latest#9b9f3e7b-de3b-4c90-bad6-a8760e3852eb) in which the
configuration row is modified to:

{% highlight json %}
{
    "parameters": {
        "bucket": "some-bucket",
        "key": "sample.csv",
        "includeSubfolders": false,
        "newFilesOnly": true
    }
}
{% endhighlight %}

The rules for updating a configuration row are the same as for [updating a configuration](#modifying-a-configuration). Also note that
a configuration row is never evaluated alone, it is always merged with the root `configuration`. If the same properties are defined
in the root `configuration` and row `configuration`, the values from the row are used. There is also an
[example](https://documenter.getpostman.com/view/3086797/kbc-samples/77h845D?version=latest#9b9f3e7b-de3b-4c90-bad6-a8760e3852eb) of how to reset the row
state by setting `state` to `{}`.

### Configuration Versions
When you [update a configuration](https://keboola.docs.apiary.io/#reference/components-and-configurations/manage-configurations/update-configuration),
a new configuration version is actually created. In the above calls, only the last (active/published) configuration
is returned. To obtain a list of all recorded versions, use the
[List Versions API call](https://keboola.docs.apiary.io/#reference/components-and-configurations/list-configuration-versions/versions-list).
See this [example](https://documenter.getpostman.com/view/3086797/kbc-samples/77h845D?version=latest#9b9f3e7b-de3b-4c90-bad6-a8760e3852eb)
which would give you an output similar to the one below:

{% highlight json %}
[
    {
        "version": 4,
        "created": "2018-03-08T15:21:28+0100",
        "creatorToken": {
            "id": 27865,
            "description": "ondrej.popelka@keboola.com"
        },
        "changeDescription": "Table first table edited",
        "isDeleted": false,
        "name": "test",
        "description": ""
    },
    {
        "version": 3,
        "created": "2018-03-08T14:58:33+0100",
        "creatorToken": {
            "id": 27865,
            "description": "ondrej.popelka@keboola.com"
        },
        "changeDescription": "Table first table added",
        "isDeleted": false,
        "name": "test",
        "description": ""
    },
    {
        "version": 2,
        "created": "2018-03-08T14:55:50+0100",
        "creatorToken": {
            "id": 27865,
            "description": "ondrej.popelka@keboola.com"
        },
        "changeDescription": "AWS Credentials edited",
        "isDeleted": false,
        "name": "test",
        "description": ""
    },
    {
        "version": 1,
        "created": "2018-03-08T14:54:19+0100",
        "creatorToken": {
            "id": 27865,
            "description": "ondrej.popelka@keboola.com"
        },
        "changeDescription": "",
        "isDeleted": false,
        "name": "test",
        "description": ""
    }
]
{% endhighlight %}

The field `version` represents the `version_id` in the following API example.

### Rollback Configuration
After choosing a particular version, you can revert to that version by
[rolling back](https://keboola.docs.apiary.io/#reference/components-and-configurations/rollback-configuration-version/rollback-version),
i.e., making a new version identical to the chosen one.  See an [example](https://documenter.getpostman.com/view/3086797/kbc-samples/77h845D#2050856a-66b3-4120-9552-d1278a96621e)
of how to rollback the configuration `364479526` of the `keboola.ex-aws-s3` component to version `3`.

It will create a new version of the configuration and return the ID of the version:
{% highlight json %}
{
  "version": "26"
}
{% endhighlight %}

### Creating Configuration Copy
After choosing a particular version, you can create a new independent
[configuration copy](https://keboola.docs.apiary.io/#reference/components-and-configurations/copy-configurations/create-configuration-copy)
of it. See an [example](https://documenter.getpostman.com/view/3086797/kbc-samples/77h845D?version=latest#9b9f3e7b-de3b-4c90-bad6-a8760e3852eb)
of how to create a new configuration called `test-copy` from version `3` of the `364479526` configuration
for the `keboola.ex-aws-s3` component.

It will return the ID of the newly created configuration:
{% highlight json %}
{
    "id": "364494012"
}
{% endhighlight %}



================================================
File: integrate/storage/api/import-export.md
================================================
---
title: Manually Importing and Exporting Data
permalink: /integrate/storage/api/import-export/
---

* TOC
{:toc}

## Working with Data
Keboola Table Storage (Tables) and Keboola File Storage (File Uploads) are heavily connected together.
Keboola File Storage is technically a layer on top of the Amazon S3 service, and Keboola Table
Storage is a layer on top of a [database backend](https://help.keboola.com/storage/#backends).

To upload a table, take the following steps:

- Request a [file upload](https://keboola.docs.apiary.io/#reference/files/upload-file/create-file-resource) from
Keboola File Storage. You will be given a destination for the uploaded file on an S3 server.
- Upload the file there. When the upload is finished, the data file will be available in the *File Uploads* section.
- Initiate an [asynchronous table import](https://keboola.docs.apiary.io/#reference/tables/load-data-asynchronously/import-data-from-csv-file-asynchronously)
from the uploaded file (use it as the `dataFileId` parameter) into the destination table.
The import is asynchronous, so the request only creates a job and you need to poll for its results.
The imported files must conform to the [RFC4180 Specification](https://tools.ietf.org/html/rfc4180).

{: .image-popup}
![Schema of file upload process](/integrate/storage/api/async-import-handling.svg)

Exporting a table from Storage is analogous to its importing. First, data is [asynchronously
exported](https://keboola.docs.apiary.io/#reference/tables/unload-data-asynchronously/asynchronous-export) from
Table Storage into File Uploads. Then you can request to [download
the file](https://keboola.docs.apiary.io/#reference/files/manage-files/file-detail), which will give you
access to an S3 server for the actual file download.

### Manually Uploading a File
To upload a file to Keboola File Storage, follow the instructions outlined in the
[API documentation](https://keboola.docs.apiary.io/#reference/files/upload-file/create-file-resource).
First create a file resource; to create a new file called
[`new-file.csv`](/integrate/storage/new-table.csv) with `52` bytes, call:

{% highlight bash %}
curl --request POST --header "Content-Type: application/json" --header "X-StorageApi-Token:storage-token" --data-binary "{ \"name\": \"new-file.csv\", \"sizeBytes\": 52, \"federationToken\": 1 }" https://connection.keboola.com/v2/storage/files/prepare
{% endhighlight %}

Which will return a response similar to this:

{% highlight json %}
{
  "id": 192726698,
  "created": "2016-06-22T10:44:35+0200",
  "isPublic": false,
  "isSliced": false,
  "isEncrypted": false,
  "name": "new_file2.csv",
  "url": "https://s3.amazonaws.com/kbc-sapi-files/exp-15/1134/files/2016/06/22/192726697.new_file2?X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAJ2N244XSWYVVYVLQ%2F20160622%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20160622T084435Z&X-Amz-SignedHeaders=host&X-Amz-Expires=3600&X-Amz-Signature=86136cced74cdf919953cde9e2a0b837bd0b8f147aa6b7b30c2febde3b92d83d",
  "region": "us-east-1",
  "sizeBytes": 52,
  "tags": [],
  "maxAgeDays": 15,
  "runId": null,
  "runIds": [],
  "creatorToken": {
    "id": 53044,
    "description": "ondrej.popelka@keboola.com"
  },
  "uploadParams": {
    "key": "exp-15/1134/files/2016/06/22/192726697.new_file2.csv",
    "bucket": "kbc-sapi-files",
    "acl": "private",
    "credentials": {
      "AccessKeyId": "ASI...H7Q",
      "SecretAccessKey": "QbO...7qu",
      "SessionToken": "Ago...bsF",
      "Expiration": "2016-06-22T20:44:35+00:00"
    }
  }
}
{% endhighlight %}

The important parts are: `id` of the file, which will be needed later, the `uploadParams.credentials` node,
which gives you credentials to AWS S3 to upload your file, and
the `key` and `bucket` nodes, which define the target S3 destination as *s3://`bucket`/`key`*.
To upload the files to S3, you need an S3 client. There are a large number of clients available:
for example, use the
[S3 AWS command line client](https://docs.aws.amazon.com/cli/latest/userguide/cli-chap-install.html).
Before using it, [pass the credentials](https://docs.aws.amazon.com/cli/latest/topic/config-vars.html#credentials)
by executing, for instance, the following commands

on *nix systems:
{% highlight bash %}
export AWS_ACCESS_KEY_ID=ASI...H7Q
export AWS_SECRET_ACCESS_KEY=QbO...7qu
export AWS_SESSION_TOKEN=Ago...wU=
{% endhighlight %}

or on Windows:
{% highlight bash %}
SET AWS_ACCESS_KEY_ID=ASI...H7Q
SET AWS_SECRET_ACCESS_KEY=QbO...7qu
SET AWS_SESSION_TOKEN=Ago...bsF
{% endhighlight %}

Then you can actually upload the `new-table.csv` file by executing the AWS S3 CLI [cp command](https://docs.aws.amazon.com/cli/latest/reference/s3/cp.html):
{% highlight bash %}
aws s3 cp new-table.csv s3://kbc-sapi-files/exp-15/1134/files/2016/06/22/192726697.new_file2.csv
{% endhighlight %}

After that, import the file into Table Storage, by calling either
[Create Table API call](https://keboola.docs.apiary.io/#reference/tables/create-table-asynchronously/create-new-table-from-csv-file-asynchronously)
(for a new table) or
[Load Data API call](https://keboola.docs.apiary.io/#reference/tables/load-data-asynchronously/import-data-from-csv-file-asynchronously)
(for an existing table).

{% highlight bash %}
curl --request POST --header "Content-Type: application/json" --header "X-StorageApi-Token:storage-token" --data-binary "{ \"dataFileId\": 192726698, \"name\": \"new-table\" }" https://connection.keboola.com/v2/storage/buckets/in.c-main/tables-async
{% endhighlight %}

This will create an asynchronous job, importing data from the `192726698` file into the `new-table` destination table in the `in.c-main` bucket.
Then [poll for the job results](/integrate/jobs/#job-polling), or review its status in the UI.

#### Python Example
The above process is implemented in the following example script in Python. This script uses the
[Requests](https://2.python-requests.org/en/master/) library for sending HTTP requests and
the [Boto 3](https://github.com/boto/boto3) library for working with Amazon S3. Both libraries can be
installed using pip:

{% highlight bash %}
pip install boto3
pip install requests
{% endhighlight %}

{% highlight python %}
{% include async-create.py %}
{% endhighlight %}

#### Upload Files Using Storage API Importer
For production setup, we recommend using the approach [outlined above](#manually-uploading-a-file)
with direct upload to S3 as it is more reliable and universal.
In case you need to avoid using an S3 client, it is also possible to upload the 
file by a simple HTTP request to [Storage API Importer Service](/integrate/storage/api/importer/).

{% highlight bash %}
curl --request POST --header "X-StorageApi-Token:storage-token" --form "data=@new-file.csv" https://import.keboola.com/upload-file
{% endhighlight %}

The above will return a response similar to this:

{% highlight json %}
{
  "id": 418137780,
  "created": "2018-07-17T13:48:57+0200",
  "isPublic": false,
  "isSliced": false,
  "isEncrypted": true,
  "name": "404.md",
  "url": "https:\/\/kbc-sapi-files.s3.amazonaws.com\/exp-15\/4088\/files\/2018\/07\/17\/418137779.new-file.csv...truncated",
  "region": "us-east-1",
  "sizeBytes": 1765,
  "tags": [],
  "maxAgeDays": 15,
  "runId": null,
  "runIds": [],
  "creatorToken": {
    "id": 144880,
    "description": "file upload"
  }
}
{% endhighlight %}

After that, import the file into Table Storage by calling either
[Create Table API call](https://keboola.docs.apiary.io/#reference/tables/create-table-asynchronously/create-new-table-from-csv-file-asynchronously)
(for a new table) or
[Load Data API call](https://keboola.docs.apiary.io/#reference/tables/load-data-asynchronously/import-data-from-csv-file-asynchronously)
(for an existing table).

### Working with Sliced Files
Depending on the backend and table size, the data file may be sliced into chunks.
Requirements for uploading sliced files are described in the respective part of the
[API documentation](https://keboola.docs.apiary.io/#reference/files/upload-file/create-file-resource).

When you attempt to download a sliced file, you will instead obtain its manifest
listing the individual parts. Download the parts individually and join them
together. For a reference implementation of this process, see
our [TableExporter class](https://github.com/keboola/storage-api-php-client/blob/master/src/Keboola/StorageApi/TableExporter.php).

**Important:** When exporting a table through the *Table* --- *Export* UI, the file will
be already merged and listed in the *File Uploads* section with the `storage-merged-export` tag.

If you want to download a sliced file, [get credentials](https://keboola.docs.apiary.io/#reference/files/manage-files/file-detail)
to download the file from AWS S3. Assuming that the file ID is 192611596, for example, call

{% highlight bash %}
curl --header "X-StorageAPI-Token: storage-token" https://connection.keboola.com/v2/storage/files/192611596?federationToken=1
{% endhighlight %}

which will return a response similar to this:

{% highlight json %}
{
  "id": 192611596,
  "created": "2016-06-21T15:25:35+0200",
  "name": "in.c-redshift.blog-data.csv",
  "url": "https://s3.amazonaws.com/kbc-sapi-files/exp-2/578/table-exports/in/c-redshift/blog-data/192611594.csvmanifest?X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAJ2N244XSWYVVYVLQ%2F20160621%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20160621T135137Z&X-Amz-SignedHeaders=host&X-Amz-Expires=3600&X-Amz-Signature=ee69d94f0af06bcf924df0f710dcd92e6503a13c8a11a86be2606552bf9a8b26",
  "region": "us-east-1",
  "sizeBytes": 24541,
  "tags": [
    "table-export"
  ],
  ...
  "s3Path": {
    "bucket": "kbc-sapi-files",
    "key": "exp-2/578/table-exports/in/c-redshift/blog-data/192611594.csv"
  },
  "credentials": {
    "AccessKeyId": "ASI...UQQ",
    "SecretAccessKey": "LHU...HAp",
    "SessionToken": "Ago...uwU=",
    "Expiration": "2016-06-22T01:51:37+00:00"
  }
}
{% endhighlight %}

The field `url` contains the URL to the file manifest. Upon downloading it, you will get a JSON file with contents
similar to this:

{% highlight json %}
{
  "entries": [
    {"url":"s3://kbc-sapi-files/exp-2/578/table-exports/in/c-redshift/blog-data/192611594.csv0000_part_00"},
    {"url":"s3://kbc-sapi-files/exp-2/578/table-exports/in/c-redshift/blog-data/192611594.csv0001_part_00"}
  ]
}
{% endhighlight %}

Now you can download the actual data file slices. URLs are provided in the manifest file, and credentials to them
are returned as part of the previous file info call. To download the files from S3, you need an S3 client. There
are a wide number of clients available; for example, use the
[S3 AWS command line client](https://docs.aws.amazon.com/cli/latest/userguide/cli-chap-install.html). Before
using it, [pass the credentials](https://docs.aws.amazon.com/cli/latest/topic/config-vars.html#credentials)
by executing , for instance, the following commands

on *nix systems:
{% highlight bash %}  
export AWS_ACCESS_KEY_ID=ASI...UQQ
export AWS_SECRET_ACCESS_KEY=LHU...HAp
export AWS_SESSION_TOKEN=Ago...wU=
{% endhighlight %}

or on Windows:
{% highlight bash %}
SET AWS_ACCESS_KEY_ID=ASI...UQQ
SET AWS_SECRET_ACCESS_KEY=LHU...HAp
SET AWS_SESSION_TOKEN=Ago...wU=
{% endhighlight %}

Then you can actually download the files by executing the AWS S3 CLI [cp command](https://docs.aws.amazon.com/cli/latest/reference/s3/cp.html):
{% highlight bash %}
aws s3 cp s3://kbc-sapi-files/exp-2/578/table-exports/in/c-redshift/blog-data/192611594.csv0000_part_00 192611594.csv0000_part_00
aws s3 cp s3://kbc-sapi-files/exp-2/578/table-exports/in/c-redshift/blog-data/192611594.csv0001_part_00 192611594.csv0001_part_00
{% endhighlight %}

After that, merge the files together by executing the following commands

on *nix systems:
{% highlight bash %}
cat 192611594.csv0000_part_00 192611594.csv0001_part_00 > merged.csv
{% endhighlight %}

or on Windows:
{% highlight bash %}
copy 192611594.csv0000_part_00 /B +192611594.csv0001_part_00 /B merged2.csv
{% endhighlight %}


================================================
File: integrate/storage/api/importer.md
================================================
---
title: Storage API Importer
permalink: /integrate/storage/api/importer/
---

* TOC
{:toc}

The [whole process of importing](/integrate/storage/api/) a table into Storage can be simplified with the
Storage API Importer Service.
The Storage API Importer allows you to make an HTTP POST request and import a file directly into an existing Storage table.

The HTTP request must contain the `tableId` and `data` form fields. The specified table must already exist in [Storage](https://help.keboola.com/storage/).
Therefore to upload the `my-table.csv` CSV file (and replace the contents) into the `my-table` table in the `in.c-main` bucket,
call:

{% highlight bash %}
curl --request POST --header "X-StorageApi-Token:storage-token" --form "tableId=in.c-main.my-table" --form "data=@my-table.csv" "https://import.keboola.com/write-table"
{% endhighlight %}

Using the Storage API Importer is the easiest way to upload data into Storage (except for
using one of the [API clients](/integrate/storage/#clients)). However, the disadvantage is that the whole data file
has to be posted in a single HTTP request. **The maximum limit for a file size is 2GB and the transfer time is 45 minutes**.
This means that for substantially large files (usually more than hundreds of MB)
you may experience timeouts. If that happens, use the above outlined approach and upload the
files [directly to S3](/integrate/storage/api/import-export/#manually-uploading-a-file).

## Parameters

- `tableId` (required) Storage Table ID, example: in.c-main.users
- `data` (required) Uploaded CSV file. Raw file or compressed by [gzip](http://www.gzip.org/)
- `delimiter` (optional) Field delimiter used in a CSV file. The default value is ' , '. Use '\t' or type the tab char for tabulator.
- `enclosure` (optional) Field enclosure used in a CSV file. The default value is '"'.
- `escapedBy` (optional) CSV escape character; empty by default.
- `incremental` (optional) If incremental is set to 0 (its default), the target table is truncated before each import.

Full list of avaialable parameters is available in the [API documentation](https://app.swaggerhub.com/apis-docs/keboola/import/1.0.0).

## Examples
To load data incrementally (append new data to existing contents):

{% highlight bash %}
curl --request POST --header "X-StorageApi-Token:storage-token" --form "incremental=1" --form "tableId=in.c-main.my-table" --form "data=@my-table.csv" "https://import.keboola.com/write-table"
{% endhighlight %}

To load data with a non-default delimiter (tabulator) and enclosure (empty):

{% highlight bash %}
curl --request POST --header "X-StorageApi-Token:storage-token" --form "delimiter=\t" --form "enclosure=" --form "tableId=in.c-main.my-table" --form "data=@my-table.csv" "https://import.keboola.com/write-table"
{% endhighlight %}


================================================
File: integrate/storage/api/index.md
================================================
---
title: Storage API
permalink: /integrate/storage/api/
---

* TOC
{:toc}

If you are new to Keboola, you should make yourself familiar with
the [Storage component](https://help.keboola.com/storage/) before you start using it.
For a general introduction to working with Keboola APIs, see the [API Introduction](/overview/api/).
[Storage API](https://keboola.docs.apiary.io/) provides a number of functions. These are the most important ones:

- [Component configurations](https://keboola.docs.apiary.io/#reference/components-and-configurations)
- [Storage tables](https://keboola.docs.apiary.io/#reference/tables)
- [File uploads](https://keboola.docs.apiary.io/#reference/files)
- [Storage buckets](https://keboola.docs.apiary.io/#reference/buckets)

Virtually, all API calls require a [Storage API token](https://help.keboola.com/storage/tokens/) to
be passed as the `X-StorageApi-Token` header.
Please note that the Storage API calls require the request to be sent
as `form-data` (unlike the rest of Keboola API, which is sent as `application/json`).

For exporting tables from and importing tables to Storage, we highly recommend that you use one of the
[available clients](/integrate/storage/) or the [Storage API Importer service](/integrate/storage/api/importer/).
All imports and exports are done using CSV files. See
the [RFC4180 Specification](https://tools.ietf.org/html/rfc4180) for the format
and encoding specification, and
[User documentation](https://help.keboola.com/storage/tables/csv-files/) for help on how to create such files.

Continue reading the following sections for guidance on how to get started:

- [Storage importer service for the easiest upload of data via API](/integrate/storage/api/importer/)
- [Getting started with component configurations](/integrate/storage/api/configurations/)
- [Importing and exporting data](/integrate/storage/api/import-export/)
- [TDE exporter for exporting data to Tableau Data Extracts](/integrate/storage/api/tde-exporter/)


================================================
File: integrate/storage/api/tde-exporter.md
================================================
---
title: TDE Exporter
permalink: /integrate/storage/api/tde-exporter/
---

* TOC
{:toc}

[TDE Exporter](https://github.com/keboola/tde-exporter) exports tables from Keboola Storage into the
[TDE file format (Tableau Data Extract)](https://www.tableau.com/about/blog/2014/7/understanding-tableau-data-extracts-part1).
This component is normally a part of the [Tableau Writer](https://help.keboola.com/tutorial/write/),
but it can also be used as a standalone component.

Users can [run a TDE exporter job](/integrate/jobs/) as any other Keboola component or register it
as an orchestration task. After the exporter finishes, the resulting TDE files will be available in the
*Storage* --- *File uploads* section where you can download them via UI or [API](/integrate/storage/api/import-export/).

##  Running the Component
The TDE Exporter is a Keboola [component](/extend/component/) supporting both
[stored](/integrate/storage/api/configurations/) and
custom configurations supplied directly in the `run` request.

### Stored Configuration
To run the TDE exporter with a stored configuration, first
[create the configuration](https://keboola.docs.apiary.io/#reference/components-and-configurations/component-configurations/create-configuration).
See [below](#custom-configuration) for the required configuration contents.
This call will give you the ID of the newly created configuration (for instance, `new-configuration-id`).
Then [create a job](/integrate/jobs/) with the specified configuration:

{% highlight json %}
{
    "config": "new-configuration-id"
}
{% endhighlight %}

### Custom Configuration
You can specify the entire configuration in the API call. The JSON configuration conforms
to the [general configuration format](/extend/common-interface/config-file/). The specific part
is only the `parameters` section. A sample request to the `in.c-main.old-table` export table would look like this:

{% highlight json %}
{
	"configData": {
		"storage": {
			"input": {
				"tables": [{
					"source": "in.c-main.old-table"
				}]
			}
		},
		"parameters": {
			"tags": ["sometag"],
			"typedefs": {
				"in.c-main.old-table": {
					"id": {
						"type": "number"
					},
					"col1": {
						"type": "string"
					}
				}
			}
		}
	}
}
{% endhighlight %}

The `parameters` section contains:

- `tags`: array of tags that will be assigned to the resulting file in Storage File Uploads.
- `typedefs`: definitions of data types mapping source tables columns to destination TDE columns.

The type definitions are entered as an object whose name must match the name of the table in the
`storage.input.tables.source` node (`in.c-main.old-table` in the above example). Object properties
are names of the table columns; each must have the `type` property which is one of the
[supported column types](https://help.tableau.com/current/pro/desktop/en-us/datafields_typesandroles_datatypes.htm):
`boolean`, `number`, `decimal`, `date`, `datetime` and `string`.

## Date and DateTime
Data for these data types can be specified in the format used
in the [strptime function](https://pubs.opengroup.org/onlinepubs/009695399/functions/strptime.html). The format is specified as part of the column's type definition. For example:

{% highlight json %}
{
    "col1": {
        "type": "date",
        "format":"%m-%d-%Y"
    }
}
{% endhighlight %}

If no format is specified, the following default formats are used:

- For `date`: `%Y-%m-%d`
- For `datetime`: `%Y-%m-%d %H:%M:%S or %Y-%m-%d %H:%M:%S.%f`


================================================
File: integrate/variables/countries.csv
================================================
"COUNTRY","CARS"
"Belgium","6293781"
"Finland","3358232"
"Italy","41393877"
"Romania","6541260"
"Turkey","20193915"
"Bulgaria","2823705"
"France","38720798"
"Netherlands","8977994"
"Russia","42201083"
"Ukraine","8655700"
"Czech Republic","5116750"
"Germany","47418800"
"Poland","20671278"
"Spain","27528877"
"United Kingdom","33792233"
"Azerbaijan","1080912"
"Denmark","2723040"
"Hungary","3393075"
"Portugal","5650428"
"Sweden","5126572"


================================================
File: integrate/variables/index.md
================================================
---
title: Variables
permalink: /integrate/variables/
---

* TOC
{:toc}

*Note: This is a preview feature and as such may change considerably in the future.*

**Variables** are placeholders used in [configurations](/integrate/storage/api/configurations/). Their value is 
resolved at [job runtime](/integrate/jobs/). 

**Important:** Make sure you're familiar with the [Configuration API](/integrate/storage/api/configurations/) and 
the [Job API](/integrate/jobs/) before reading on.

See [Tutorial](/integrate/variables/tutorial) for step-by-step example.

## Introduction
When using variables, the configuration is treated as a [Moustache template](https://mustache.github.io/mustache.5.html). 
You can enter variables anywhere in the JSON of the configuration body. The configuration body is the contents of 
the `configuration` node when you [retrieve a configuration](https://keboola.docs.apiary.io/#reference/components-and-configurations/manage-configurations/configuration-detail).
This means that you can't use variables in a name or in a configuration description. 

Variables are entered using the [Moustache syntax](https://mustache.github.io/mustache.5.html), 
i.e., `{{ "{{ variableName " }}}}`. To work with variables, three things are needed:

- Main configuration -- the configuration in which variables are replaced (used); this can be a configuration of any component (e.g., a configuration of a transformation, extractor, writer, etc.).
- Variable configuration -- a configuration in which variables are defined; this is a configuration of a special `keboola.variables` component.
- Variable values -- actual values that will be placed in the main configuration.

To enable replacement of variables, the *main configuration* has to reference the *variable configuration*. 
If there is no *variable configuration* referenced, no replacement is made (the *main configuration* is completely
static). Variables can be used in any place of any configuration except legacy transformations (the component with 
the ID `transformation`; it can still be used in a specific transformation -- e.g., `keboola.python-transformation-v2` 
or `keboola.snowflake-transformation`, etc.), and an orchestrator (see [below](#orchestrator-integration)). 

## Variable Configuration
A *variable configuration* is a standard configuration tied to a special dedicated `keboola.variables` component. 
The variable configuration defines names of variables to be replaced in the main configuration. You can create 
the configuration using the 
[Create Configuration API call](https://keboola.docs.apiary.io/#reference/components-and-configurations/component-configurations/create-configuration). 
This is an example of the contents of such a configuration:

{% highlight json %}
{
    "variables": [
        {
            "name": "firstVariable",
            "type": "string"
        },
        {
            "name": "secondVariable",
            "type": "string"
        }
    ]
}
{% endhighlight %}

Note that `type` is always `string`.

## Main Configuration
When you create a variable configuration, you'll obtain an ID of the configuration - e.g., `807940806`. 
In the *main configuration*, you have to reference the *variable configuration* ID using the `variables_id` node. 
Then you can use the variables in the configuration body:

{% highlight json %}
{% raw %}
{
    "storage": {
        "input": {
            "tables": [
                {
                    "source": "in.c-application-testing.{{firstVariable}}",
                    "destination": "{{firstVariable}}.csv"
                }
            ]
        },
        "output": {
            "tables": [
                {
                    "source": "new-table.csv",
                    "destination": "out.c-transformation-test.cars"
                }
            ]
        }
    },
    "parameters": {
        "script": [
            "print('{{firstVariable}}')"
        ]
    },
    "variables_id": "807940806"
}
{% endraw %}
{% endhighlight %}

## Variable Values 
You can either store the variable values as [configuration rows](/integrate/storage/api/configurations/#configuration-rows) of the 
*variable configuration* and provide the row ID of the stored values at run time, or you can provide the variable values directly at run 
time. There are three options how you can provide values to the variables:

- Reference values using `variables_values_id` property in the *main configuration* (default values).
- Reference values using `variablesValuesId` property in job parameters.
- Provide values using  `variableValuesData` property in job parameters.

The structure of variable values, regardless of whether it is stored in configuration or provided at runtime, is as follows:

{% highlight json %}
{
    "values": [
        {
            "name": "firstVariable",
            "value": "batman"
        }
    ]
}
{% endhighlight %}

## Variable Delimiter
The default variable delimiter is `{{ "{{" }}` and `}}`. If the delimiter interferes with your code, it can
be changed as per the [Moustache docs](https://mustache.github.io/mustache.5.html). For example the 
following piece of code

{% highlight json %}
{
    "code": "SELECT \"COUNTRY\" || '{{ "{{ alias " }}}}' || '{{ "{{=<< >>=" }}}} {{ "{{ as-is " }}}} <<={{ "{{ " }}}}=>>' 
    AS \"COUNTRY\", \"CARS\" || '{{ "{{ size " }}}}' AS \"CARS\" FROM \"my-table\""
}
{% endhighlight %}

will be interpreted as (assuming the variables `alias=batman` and `size=big` are defined):

{% highlight json %}
{
    "code": "SELECT \"COUNTRY\" || 'batman' || '{{ "{{ as-is " }}}}' 
    AS \"COUNTRY\", \"CARS\" || 'big' AS \"CARS\" FROM \"my-table\""
}
{% endhighlight %}


## Example Using Python Transformations
In this example, we will configure a Python transformation using variables. Note that we are using the new 
transformations and bypassing the current 
[Transformation Service](https://keboolatransformationapi.docs.apiary.io/#). Such configurations are not 
supported in the UI yet.

### Step 1 -- Create Variable Configuration
Use the [Create Configuration API call](https://keboola.docs.apiary.io/#reference/components-and-configurations/component-configurations/create-configuration) 
for the `keboola.variables` component with the following content:

{% highlight json %}
{
    "variables": [
        {
            "name": "alias",
            "type": "string"
        },
        {
            "name": "size",
            "type": "string"
        }
    ]
}
{% endhighlight %}

See an [example](https://documenter.getpostman.com/view/3086797/77h845D?version=latest#16a5d721-b6a4-4daa-9196-8e90250ed16b).

### Step 2 -- Create Default Values for Variables
Note that this step is optional -- you can use variables without default values.
In the previous step, you obtained an ID of the variable configuration. Use the 
[Create Configuration Row API call](https://keboola.docs.apiary.io/#reference/components-and--configurations/create-or-list-configuration-rows/create-configuration-row).
Use the ID of the variable configuration and `keboola.variables` as a component. Use the following body:

{% highlight json %}
{
    "values": [
        {
            "name": "alias",
            "value": "batman"
        },
        {
            "name": "size",
            "value": "42"
        }
    ]
}
{% endhighlight %}

See an [example](https://documenter.getpostman.com/view/3086797/77h845D?version=latest#72de2851-1853-4fe3-bec3-856fcc9e2270)

### Step 3 -- Create Main Configuration
Now it is time to create the actual configuration which will contain a Python transformation.
Use the following configuration body. The `storage` section describes the standard [input](/extend/common-interface/config-file/#input-mapping--basic) 
and [output](/extend/common-interface/config-file/#output-mapping--basic) mapping.

{% highlight json %}
{% raw %}
{
    "storage": {
        "input": {
            "tables": [
                {
                    "source": "in.c-variable-testing.{{alias}}",
                    "destination": "{{alias}}.csv"
                }
            ]
        },
        "output": {
            "tables": [
                {
                    "source": "new-table.csv",
                    "destination": "out.c-variable-testing.cars"
                }
            ]
        }
    },
    "parameters": {
        "blocks": [
            {
                "name": "First Block",
                "codes": [
                    {
                        "name": "First Code",
                        "script": [
                            "import csv\ncsvlt = '\\n'\ncsvdel = ','\ncsvquo = '\"'\nwith open('in/tables/{{alias}}.csv', mode='rt', encoding='utf-8') as in_file, open('out/tables/new-table.csv', mode='wt', encoding='utf-8') as out_file:\n    writer = csv.DictWriter(out_file, fieldnames=['COUNTRY', 'CARS'], lineterminator=csvlt, delimiter=csvdel, quotechar=csvquo)\n    writer.writeheader()\n\n    lazy_lines = (line.replace('\\0', '') for line in in_file)\n    reader = csv.DictReader(lazy_lines, lineterminator=csvlt, delimiter=csvdel, quotechar=csvquo)\n    for row in reader:\n        writer.writerow({'COUNTRY': row['COUNTRY'] + '{{ alias }}', 'CARS': row['CARS'] + '{{ size }}'})\nfrom pathlib import Path\nimport sys\ncontents = Path('/data/config.json').read_text()\nprint(contents, file=sys.stdout)"
                        ]
                    }
                ]
            }
        ]
    }
    "variables_id": "807968875",
    "variables_values_id": "807952812"
}
{% endraw %}
{% endhighlight %}

The `variables_id` property contains the ID of the [variable configuration](/integrate/variables/#step-1--create-variables-configuration) - e.g., `807968875`. The
`variables_values_id` property is optional and contains the ID of the [row with default values](/integrate/variables/#step-2--create-default-values-for-variable) - e.g., `807952812`.
The `parameters` section contains a script with the following Python code:

{% highlight python %}
{% raw %}
import csv
csvlt = '\n'
csvdel = ','
csvquo = '"'
with open('in/tables/{{alias}}.csv', mode='rt', encoding='utf-8') as in_file, open('out/tables/new-table.csv', mode='wt', encoding='utf-8') as out_file:
    writer = csv.DictWriter(out_file, fieldnames=['COUNTRY', 'CARS'], lineterminator=csvlt, delimiter=csvdel, quotechar=csvquo)
        writer.writeheader()
        lazy_lines = (line.replace('\0', '') for line in in_file)
        reader = csv.DictReader(lazy_lines, lineterminator=csvlt, delimiter=csvdel, quotechar=csvquo)
        for row in reader:
            writer.writerow({'COUNTRY': row['COUNTRY'] + '{{ alias }}', 'CARS': row['CARS'] + '{{ size }}'})

from pathlib import Path
import sys
contents = Path('/data/config.json').read_text()
print(contents, file=sys.stdout)
{% endraw %}
{% endhighlight %}

The script reads a file given by the alias, modifies the two columns **COUNTRY** and **CARS**, and 
prints the contents of the configuration file to output.

See an [example](https://documenter.getpostman.com/view/3086797/77h845D?version=latest#732e4b66-4f2d-46ab-80ba-7a7d07ddb94b).

### Step 4 -- Run Job
There are three options for providing variable values when running a job:

- Relying on default variables
- Providing ID of values using the `variablesValuesId` property in job parameters
- Providing values using the `variableValuesData` property in job parameters

Following the rules for running a job, you always **have to** provide values for the defined variables. 
Note that it is important which variables are *defined* in the variable configuration, not which
variables you actually use in the main configuration. For example, the main configuration references a variable 
configuration with *firstVar* and *secondVar* variables, but you're using `{{ "{{ firstVar " }}}}` and
`{{ "{{ thirdVar " }}}}` in the configuration code. Then you have to provide values at least for *firstVar* 
and *secondVar* variables. If you provide values for all *firstVar*, *secondVar*, and *thirdVar*, all of them will 
be replaced. If you omit *thirdVar*, it will be replaced by an empty string. If you omit one of *firstVar*, 
*secondVar*, an error will be raised.

The second rule is that the three options of passing values are mutually exclusive. If you provide values using 
`variablesValuesId` or `variableValuesData`, it overrides the default values (if provided). You can't use 
`variablesValuesId` and `variableValuesData` together in a single call. If you do that, an error will be raised.
If no default values are set and none of the `variablesValuesId` or `variableValuesData` is provided, an error 
will be raised.

#### Option 1 -- Rely on default variables
If you created the default values, you can now directly run the job. Use the [Create Job API call](https://app.swaggerhub.com/apis-docs/keboola/job-queue-api/1.2.4#/Jobs/createJob)
with the following body:

{% highlight json %}
{
    "component": "keboola.python-transformation-v2",
    "config": "807943784",
    "mode": "run"
}
{% endhighlight %}

The `config` property contains the ID of the [main configuration](/integrate/variables/#step-3--create-main-configuration).
Before executing the API call, you have to create the source table. Unless you modified the mapping in the 
[example](/integrate/variables/#step-3--create-main-configuration), you have to create a bucket named
**variable-testing** in the **in** stage. Then create a table called **batman** with columns  **COUNTRY** 
and **CARS**. You can use this [sample CSV file](/integrate/variables/countries.csv).

After you create the input table, you can run the job. 
See an [example](https://documenter.getpostman.com/view/3086797/77h845D?version=latest#31486ac2-ea52-4f19-a039-2ee1b1ae5863). 
It will create a new table in Storage -- **out.c-variable-testing.cars**. The tables should contain the default 
values, e.g.:

|COUNTRY|CARS|
|---|---|
|Belgiumbatman|629378142|
|Finlandbatman|335823242|
|Italybatman|4139387742|
|Romaniabatman|654126042|

The events of the job will contain the contents of the [configuration file](/extend/common-interface/config-file/) 
where you can verify that the variables were replaced.

<details>
  <summary>Click to expand the configuration.</summary>
{% highlight json %}
{
    "storage": {
        "input": {
            "tables": [
                {
                    "source": "in.c-variable-testing.batman",
                    "destination": "batman.csv",
                    "columns": [],
                    "where_values": [],
                    "where_operator": "eq"
                }
            ],
            "files": []
        },
        "output": {
            "tables": [
                {
                    "source": "new-table.csv",
                    "destination": "out.c-variable-testing.cars",
                    "incremental": false,
                    "primary_key": [],
                    "columns": [],
                    "delete_where_values": [],
                    "delete_where_operator": "eq",
                    "delimiter": ",",
                    "enclosure": "\"",
                    "metadata": [],
                    "column_metadata": []
                }
            ],
            "files": []
        }
    },
    "parameters": {
        "blocks": [
            {
                "name": "First Block",
                "codes": [
                    {
                        "name": "First Code",
                        "script": [
                            "import csv\ncsvlt = '\\n'\ncsvdel = ','\ncsvquo = '\"'\nwith open('in/tables/{{alias}}.csv', mode='rt', encoding='utf-8') as in_file, open('out/tables/new-table.csv', mode='wt', encoding='utf-8') as out_file:\n    writer = csv.DictWriter(out_file, fieldnames=['COUNTRY', 'CARS'], lineterminator=csvlt, delimiter=csvdel, quotechar=csvquo)\n    writer.writeheader()\n\n    lazy_lines = (line.replace('\\0', '') for line in in_file)\n    reader = csv.DictReader(lazy_lines, lineterminator=csvlt, delimiter=csvdel, quotechar=csvquo)\n    for row in reader:\n        writer.writerow({'COUNTRY': row['COUNTRY'] + '{{ alias }}', 'CARS': row['CARS'] + '{{ size }}'})\nfrom pathlib import Path\nimport sys\ncontents = Path('/data/config.json').read_text()\nprint(contents, file=sys.stdout)"
                        ]
                    }
                ]
            }
        ]
    },
    "variables_id": "807943784",
    "variables_values_id": "807952812",
    "image_parameters": {},
    "action": "run",
    "authorization": {}
}
{% endhighlight %}
</details>

#### Option 2 -- Run a job with stored values
Similarly to the [default values](http://localhost:4000/integrate/variables/#step-2--create-default-values-for-variable), 
you can store another set of values. Let's add another configuration row to the *existing* variable configuration:

{% highlight json %}
{
    "values": [
        {
            "name": "alias",
            "value": "WATMAN"
        },
        {
            "name": "size",
            "value": "4200"
        }
    ]
}
{% endhighlight %}

See an [example](https://documenter.getpostman.com/view/3086797/77h845D?version=latest#fbe487b5-cd68-4318-8219-7c067ebef795). 
You will obtain an ID of the row. Then create a table called **watman** with 
columns  **COUNTRY** and **CARS**. You can use this [sample CSV file](/integrate/variables/countries.csv).

Run a job with parameters and provide the ID of the main configuration in the `config` property and 
the ID of the value row in `variableValuesId`:

{% highlight json %}
{
    "component": "keboola.python-transformation-v2",
    "config": "807968875,
    "mode": "run",
    "variableValuesId": "807957572"
}
{% endhighlight %}

See an [example](https://documenter.getpostman.com/view/3086797/77h845D?version=latest#f883eb13-3f20-4e03-bf1b-36e9c889f773). 
The output table now contains:

|COUNTRY|CARS|
|---|---|
|BelgiumWATMAN|62937814200|
|FinlandWATMAN|33582324200|
|ItalyWATMAN|413938774200|

#### Option 3 -- Run a job with inline values
The last option to provide the values for variables is to enter them directly when running a job. 
Variable values are entered in the `variableValuesData` property:

{% highlight json %}
{
    "component": "keboola.python-transformation-v2",
    "config": "807968875",
    "mode": "run",
    "variableValuesData": {
        "values": [
            {
                "name": "alias",
                "value": "batman"
            },
            {
                "name": "size",
                "value": "scatman"
            }
        ]
	}
}
{% endhighlight %}

See an [example](https://documenter.getpostman.com/view/3086797/77h845D?version=latest#2c38d6ca-2eda-4c7e-9888-071fad3d31d8).

The output table will contain:

|COUNTRY|CARS|
|---|---|
|Belgiumbatman|6293781scatman|
|Finlandbatman|3358232scatman|
|Italybatman|41393877scatman|

## Orchestrator Integration
Variables in a configuration interact with an orchestrator in two ways:

- Variables can be entered in task configuration.
- Variables can be entered when running an orchestration.

Entering variable values in task configurations allows the orchestration to run configurations with variables. 
Variable values are entered in the `actionParameters` property. The parameters are identical to 
[running a job](/integrate/variables/#step-4--run-job).

When running an orchestration, you can also provide variable values for an entire orchestration. In that case, 
the provided values will override those set in individual orchestration tasks. The parameters are identical 
to [running a job](/integrate/variables/#step-4--run-job).

### Step 5 -- Create Orchestration
You have to use the 
[Create Configuration API call](https://keboola.docs.apiary.io/#reference/components-and-configurations/component-configurations/create-configuration)
to create a configuration of the `keboola.orchestrator` component. 
You can use the following data in the configuration:

{% highlight json %}
{
    "phases": [
        {
            "id": 2468,
            "name": "Extractors",
            "dependsOn": []
        }
    ],
    "tasks": [
        {
            "id": 13579,
            "name": "Example",
            "phase": 2468,
            "task": {
                "componentId": "keboola.python-transformation-v2",
                "configId": "807968875",
                "mode": "run",
                "variableValuesId": "807952812"
            },
            "continueOnFailure": false,
            "enabled": true
        }
    ]
}
{% endhighlight %}

The contents of the `task` property are identical to the body 
of the [run job API call](/integrate/variables/#step-4--run-job). Here, the value `807968875` refers to the ID 
of the main configuration, and `807952812` refers to the ID of the configuration row with variable values.
You can use the `variableValuesData` field in the same manner.
Creating the above configuration will return a response containing the configuration ID, e.g., `807969959`.
See an [example](https://documenter.getpostman.com/view/3086797/77h845D?version=latest#9f2f9da0-59eb-4f33-a206-e5add24725d1).

### Step 6 -- Run Orchestration
When running an orchestration which contains configurations referencing variables, you have to provide their
values. You can either rely on the stored values (either at the component configuration or in the orchestration task) 
or you can provide the values at runtime.

#### Option 1 -- Rely on stored values
Use the [Run Job API call](https://app.swaggerhub.com/apis-docs/keboola/job-queue-api/1.2.4#/Jobs/createJob) 
to run an orchestration. In its simplest form, the request body needs to contain just the ID of the orchestration
(obtained in the previous step):

{% highlight json %}
{
    "component": "keboola.orchestrator",
    "config": "807969959",
    "mode": "run"
}
{% endhighlight %}

As long as the variable values can be found somewhere, this is sufficient. See [an example](https://documenter.getpostman.com/view/3086797/77h845D?version=latest#3ebdc3f5-a940-4f0d-860b-ec311f704a7e).

#### Option 2 -- Provide values
Use the [Run Job API call](https://app.swaggerhub.com/apis-docs/keboola/job-queue-api/1.2.4#/Jobs/createJob) 
to run an orchestration. Additionally, you can use the `variableValuesId` or `variableValuesData` property 
to override variable values set to individual tasks. The calling convention is the same as shown in the 
[basic job run](/integrate/variables/#step-4--run-job). The same rules also apply, notably that you can't 
use `variableValuesId` and `variableValuesData` together. 
A sample request body:

{% highlight json %}
{
    "component": "keboola.orchestrator",
    "config": "807969959",
    "mode": "run",
    "variableValuesData": {
        "values": [
            {
                "name": "alias",
                "value": "batman"
            },
            {
                "name": "size",
                "value": "scatman"
            }
        ]
    }
}
{% endhighlight %}

See [an example](https://documenter.getpostman.com/view/3086797/77h845D?version=latest#f4fcf7af-afbe-4c29-999e-0f4c50aa477b).

## Variables Evaluation Sequence
There is a number of places where variable values can be provided (either as a reference to an existing row with 
values or as an array of `values`):

- Parameters in the orchestration
- Parameters in `task` setting of the orchestration
- Parameters in the component job itself
- Default values stored in configuration (`variables_values_id` property)

The following diagram shows the parameters mentioned on this page and to what they refer to:

{: .image-popup}
![Screenshot -- Properties references](/integrate/variables/variables.svg)

In a nutshell, `variableValuesId` always refers to the row of the variable configuration associated with the 
main configuration. The main configuration is referenced in the `config` parameter. From another point of view,
the `config` parameter represents the configuration (either a component or an orchestration) to be run.
Note that in stored configurations snake_case is used instead of camelCase.

The following rules describe the evaluation sequence:

- Values provided in job parameters (a component job or an orchestration job) override the stored values.
- Values provided in an orchestration job override the stored values in `task`.
- Values provided in `task` override values stored in the component configuration.
- `variableValuesData` and `variableValuesId` can't be used together, so neither of them takes precedence. A reference to stored values can't be mixed with providing the values inline. 
- If no values are provided anywhere, the default values are used. If no default values are present, an error is raised.

## Shared Code
Related to variables is the Shared Code feature. Shared code allows to share parts of configuration code. In a 
configuration it is also replaced using the [Moustache syntax](https://mustache.github.io/mustache.5.html). Shared code
is referenced using `shared_code_id` and `shared_code_row_ids` configuration nodes. Unlike variables, shared code can't 
be overridden at runtime (so there are no parameters to set when running a job or in orchestration).
Shared code can, however, contain its own variables which need to be merged to those of the main configuration.

### Creating Shared Code
Shared code pieces is stored as configuration rows of a dedicated component `keboola.shared-code`. Before creating a 
piece of a shared code, you first have to create a configuration. Notice that the UI uses certain configurations for
certain components so you might want to check the existing configurations of `keboola.shared-code` component before
crating a new configuration.

To create a configuration, use the [create configuration API call](https://keboola.docs.apiary.io/#reference/components-and-configurations/component-configurations/create-configuration). The configuration content is ignored, i.e all you need to provide is name:

{% highlight bash %}
curl --location --request POST 'https://connection.keboola.com/v2/storage/components/keboola.shared-code/configs' \
--header 'X-StorageAPI-Token: my-token' \
--header 'Content-Type: application/x-www-form-urlencoded' \
--data-urlencode 'name=python-code'
{% endhighlight %}

Let's assume that the created configuration ID is `618884794`.
Next step is to create the shared code piece itself. To do this create a configuration row of the above configuration
with the configuration row content containing a piece of share code, for example:

{% highlight json %}
{
    "code_content": [
        "from os import listdir\nfrom os.path import isfile, join\n\nmypath = '\''/data/in/files'\''\nonlyfiles = [f for f in listdir(mypath)]\nprint(onlyfiles)\nmypath = '\''/data/in/user'\''\nonlyfiles = [f for f in listdir(mypath)]\nprint(onlyfiles)"
    ]
}
{% endhighlight %}

It is advisable to set a reasonable `rowId` of the row, because it will be used later to reference the shared code:

{% highlight bash %}
curl --location --request POST 'https://connection.keboola.com/v2/storage/components/keboola.shared-code/configs/618884794/rows' \
--header 'X-StorageApi-Token: my-token' \
--header 'Content-Type: application/x-www-form-urlencoded' \
--data-urlencode 'configuration={
	"code_content": ["from os import listdir\nfrom os.path import isfile, join\n\nmypath = '\''/data/in/files'\''\nonlyfiles = [f for f in listdir(mypath)]\nprint(onlyfiles)\nmypath = '\''/data/in/user'\''\nonlyfiles = [f for f in listdir(mypath)]\nprint(onlyfiles)"]
}
' \
--data-urlencode 'rowId=dumpfiles'
{% endhighlight %}

The above example creates a piece of shared python code named `dumpfiles` which contains the 
following python code:

{% highlight python %}
from os import listdir
from os.path import isfile, join

mypath = '/data/in/files'
onlyfiles = [f for f in listdir(mypath)]
print(onlyfiles)
mypath = '/data/in/user'
onlyfiles = [f for f in listdir(mypath)]
print(onlyfiles)
{% endhighlight %}

### Using Shared Code
To use a piece of shared code, you have to reference it in a configuration using `shared_code_id` which is the ID of the shared code configuration and `shared_code_row_ids` which is an array of IDS of shared code pieces. With the above example you need to add the following nodes to the configuration:

{% highlight json %}
{
    "storage": {...},
    "parameters": {...},
    "shared_code_id": "618884794",
    "shared_code_row_ids": ["dumpfiles"]
}
{% endhighlight %}

With that all moustache references to `{{ "{{ dumpfiles " }}}}` will be replaced by the shared code piece. All other
moustache references will be kept untouched and be treated like variables. E.g: the following configuration:

{% highlight json %}
{
    "storage": {},
    "parameters": {
        "blocks": [
            {
                "name": "Main block",
                "codes": [
                    {
                        "name": "Main code",
                        "script": ["{{ "{{ someOtherPlaceholder " }}}}"]
                    },
                    {
                        "name": "Debug",
                        "script": ["{{ "{{ dumpfiles " }}}}"]
                    }
                ]
            }
        ]
    },
    "variables_id": "618878103",
    "variables_values_id": "618878104",
    "shared_code_id": "618884794",
    "shared_code_row_ids": ["dumpfiles"]
}
{% endhighlight %}

Will be modified to:

{% highlight json %}
{
    "storage": {},
    "parameters": {
        "blocks": [
            {
                "name": "Main block",
                "codes": [
                    {
                        "name": "Main code",
                        "script": ["{{ "{{ someOtherPlaceholder "}}}}"]
                    },
                    {
                        "name": "Debug",
                        "script": ["from os import listdir\nfrom os.path import isfile, join\n\nmypath = '\''/data/in/files'\''\nonlyfiles = [f for f in listdir(mypath)]\nprint(onlyfiles)\nmypath = '\''/data/in/user'\''\nonlyfiles = [f for f in listdir(mypath)]\nprint(onlyfiles)"]
                    }
                ]
            }
        ]
    },
    "variables_id": "618878103",
    "variables_values_id": "618878104",
    "shared_code_id": "618884794",
    "shared_code_row_ids": ["dumpfiles"]
}
{% endhighlight %}


The variables then need to contain `someOtherPlaceholder` variable in order to produce a fully functional configuration.
The same way if the shared code piece contains any variables, they have to be set when running the configuration.

**Important:** The replacement of the shared code piece occurs only within an array of the configuration JSON. In the above code, the shared code reference is `"script": ["{{ "{{ someOtherPlaceholder "}}}}"]` which is the only valid form of a Shared Code reference. For example
`"script": ["some code {{ "{{ someOtherPlaceholder "}}}} some other code"]` or `"script": "{{ "{{ someOtherPlaceholder "}}}}"` are invalid Shared Code references which may not be replaced the way you intend.

**Important:** The replacement of the shared code piece merges the `code_content` array containing the shared code definition with the array containing the shared code reference. With a shared code reference in form `"script": ["a", "{{ "{{ someOtherPlaceholder "}}}}", "b"]` and shared code definition in form `"code_content": ["c", "d"]` the resulting replacement would be `"script": ["a", "c", "d", "b"]`.


================================================
File: integrate/variables/tutorial.md
================================================
---
title: Variables Tutorial
permalink: /integrate/variables/tutorial/
---

* TOC
{:toc}

This tutorial will guide you through basic usage of [Variables](/integrate/variables/) in the component configuration.
The result will be the parametrized configuration of the [Generic Extractor](/extend/generic-extractor),
but this approach can be applied to any component. 

In the examples, we use the `curl` console tool to interact with our APIs.

## Define API endpoints

First, store the [API endpoints](/overview/api/) as environment variables, so we don't have to repeat ourselves.

We will need:
- [Storage API](/integrate/storage/api/) to store the variable definitions and the extractor configuration -
- [Docker Runner API](/extend/docker-runner/) to run the extractor job from the configuration.

```shell
export STORAGE_API_HOST="https://connection.keboola.com"
export RUNNER_API_HOST="https://docker-runner.keboola.com"
```

## Obtain Storage API Token

A [Storage API Token](https://help.keboola.com/management/project/tokens/) is needed to interact with the Storage and Docker Runner APIs.

Obtain a Storage API token from the user interface of your project, see this [Guide](https://help.keboola.com/management/project/tokens).

Then store the token to the environment variable.
```shell
export TOKEN="..."
```

## Define variables

The next step is to define the variables in a [Variable Configuration](/integrate/variables/#variable-configuration).

Define name and type of the variables.
```shell
export VARIABLE_CONFIG_NAME="Extractor variables"
export VARIABLE_CONFIG='
{
    "variables": [
        {
            "name": "outputBucket",
            "type": "string"
        },
        {
            "name": "id",
            "type": "int"
        }
    ]
}
'
```

Use [Create Configuration API call](https://keboola.docs.apiary.io/#reference/components-and-configurations/component-configurations/create-configuration) to store *variable configuration*.
```shell
curl --include \
     --request POST \
     --header "Content-Type: application/x-www-form-urlencoded" \
     --header "X-StorageApi-Token: $TOKEN" \
     --data-urlencode "name=$VARIABLE_CONFIG_NAME" \
     --data-urlencode "configuration=$VARIABLE_CONFIG" \
"$STORAGE_API_HOST/v2/storage/components/keboola.variables/configs"
```

Example API call result.
```json
{
  "id":"1234",
  "name":"Extractor variables",
  "description":"..."
}
```

Save *variable configuration* `id` from the the result to the environment variable.
```shell
export VARIABLE_CONFIG_ID="1234"
```

**The created *variable configuration* defines the names and types of variables.**

You can create additional configurations that contain (default) [Variable Values](/integrate/variables/#variable-values).

In this example, the values of the variables are entered directly to the [run API call](#run-extractor-configuration) (see bellow),
so configuration with the variable values is not used.

## Create extractor configuration

Define *extractor configuration* with variables {% raw %}`{{placeholders}}`{% endraw %}.

```shell
{% raw %}
export COMPONENT_ID="ex-generic-v2"
export EXTRACTOR_CONFIG_NAME="Extractor configuration"
export EXTRACTOR_CONFIG='
{
    "parameters": {
        "api": {
            "baseUrl": "https://jsonplaceholder.typicode.com/"
        },
        "config": {
            "debug": true,
            "outputBucket": "{{outputBucket}}",
            "jobs": [
                {
                    "endpoint": "posts/{{id}}/comments"
                }
            ]
        }
    },
    "variables_id": "'$VARIABLE_CONFIG_ID'"
}
'
{% endraw %}
```

Use [Create Configuration API call](https://keboola.docs.apiary.io/#reference/components-and-configurations/component-configurations/create-configuration) to store extractor configuration.
```shell
curl --include \
     --request POST \
     --header "Content-Type: application/x-www-form-urlencoded" \
     --header "X-StorageApi-Token: $TOKEN" \
     --data-urlencode "name=$EXTRACTOR_CONFIG_NAME" \
     --data-urlencode "configuration=$EXTRACTOR_CONFIG" \
"$STORAGE_API_HOST/v2/storage/components/$COMPONENT_ID/configs"
```

Example API call result.
```json
{
    "id":"4567",
    "name":"Extractor configuration",
    "description":"..."
}
```

Save *extractor configuration* `id` from the result to the environment variable.
```shell
export EXTRACTOR_CONFIG_ID="4567"
```

## Run extractor configuration

Define values of the variables.
```shell
export VARIABLES_VALUES='
[
    {"name": "outputBucket", "value": "my-bucket"},
    {"name": "id", "value": 1}
]
'
```

In this example are values of the variables part of the run job request.

For other ways to define values see the [Variables documentation](/integrate/variables/#variable-values).

Use [Run Job API call](https://kebooladocker.docs.apiary.io/#reference/run/create-a-job/run-job) to run *extractor configuration*.
```shell
curl --include \
     --request POST \
     --header "Content-Type: application/json" \
     --header "X-StorageApi-Token: $TOKEN" \
     --data-binary '
        {
            "config": "'$EXTRACTOR_CONFIG_ID'",
            "variableValuesData": {
                "values": '$VARIABLES_VALUES'
            }
        }
     ' \
"$RUNNER_API_HOST/docker/$COMPONENT_ID/run"
```

## Check the job result

The status of a running job can be seen via API or UI.

In the picture we can see that the entered values of the variables were used.

{: .image-popup}
![Screenshot -- Job](/integrate/variables/tutorial-1.png)

A note about the replaced variables is in the job logs.

{: .image-popup}
![Screenshot -- Job Logs](/integrate/variables/tutorial-2.png)

See the [Variables documentation](/integrate/variables/#variable-values) for more information.



================================================
File: overview/encryption.md
================================================
---
title: Encryption
permalink: /overview/encryption/
---

* TOC
{:toc}

Many [Keboola components](/overview/) use the Encryption API to encrypt sensitive values
intended for secure storage. These values are then decrypted within the component itself. 
This process ensures that the encrypted values are only accessible inside the components and not
by API users. Additionally, no decryption API is available, meaning end-users cannot decrypt
these values.

Decryption occurs solely during the serialization of configuration to the Docker container's 
configuration file. The decrypted data are stored on the Docker host drive and are promptly 
deleted after the container's completion. The component code exclusively accesses the decrypted data.

## UI Interaction
When saving arbitrary configuration data, if a key is prefixed with the `#` character, the associated value is automatically encrypted.
For instance, consider the following configuration:

{: .image-popup}
![Screenshot - Configuration editor - before](/overview/encryption-1.png)

After saving, the configuration appears as follows:

{: .image-popup}
![Screenshot - Configuration editor - after](/overview/encryption-2.png)

Once saved, the value becomes encrypted and irreversible. The component defines which values are
encrypted, indicating that not all values can be encrypted unless explicitly supported by the component.

For example, a component requiring the following configuration:

{% highlight json %}
{
    "username": "JohnDoe",
    "#password": "password"
}
{% endhighlight %}

indicates that the password will be encrypted while the username will not. Adding a
prefix `#` to `username` is ineffective, as the component does not recognize such a key,
even though its value would be encrypted and decrypted normally. Internally, the
[Encryption API](#encrypting-data-with-api) encrypts these values before saving.

### UI Configuration Adjustment
The UI prioritizes encrypted values over plain ones. If both `password` and `#password` are provided, only `#password` will be retained.
Consequently, this configuration:

{% highlight json %}
{
    "username": "JohnDoe",
    "#password": "KBC::ProjectSecure::ENCODEDSTRING",
    "password": "secret",
}
{% endhighlight %}

will be transformed to:

{% highlight json %}
{
    "username": "JohnDoe",
    "#password": "KBC::ProjectSecure::ENCODEDSTRING"
}
{% endhighlight %}

## Encrypting Data with API
The [Encryption API](https://keboolaencryption.docs.apiary.io/#reference/encrypt/encryption/encrypt-data) can handle
both strings and arbitrary JSON data. For strings, the entire string is encrypted. In JSON data,
only scalar keys starting with `#` are encrypted. For example, encrypting the following:

{% highlight json %}
{
    "foo": "bar",
    "#encryptMe": "secret",
    "#encryptMeToo": {
        "another": "secret"
    }
}
{% endhighlight %}

results in:

{% highlight json %}
{
    "foo": "bar",
    "#encryptMe": "KBC::ProjectSecure::ENCODEDSTRING",
    "#encryptMeToo": {
        "another": "secret"
    }
}
{% endhighlight %}

To encrypt a single string, such as a password, submit the text string for encryption
(no JSON or quotation is used). For example, encrypting

    mySecretPassword

yields

    KBC::ProjectSecure::ENCODEDSTRING

The `Content-Type` header in the request differentiates whether the body is treated as a string (`text/plain`) or JSON (`application/json`).

Use the [Console in Apiary](https://keboolaencryption.docs.apiary.io/#reference/encrypt/encryption/encrypt-data?console=1) to
call the API resource endpoint.

{: .image-popup}
![Console screenshot](/overview/encryption-console.png)

### Encryption Parameters
The [Encryption API](https://keboolaencryption.docs.apiary.io/#reference/encrypt/encryption/encrypt-data)
accepts the following **optional** parameters:

- `componentId` --- ID of a [Keboola component](/extend/component/tutorial/#creating-a-component),
- `projectId` --- ID of a Keboola project,
- `configId` --- ID of a component configuration, and
- `branchType` --- Branch type --- either `default` (meaning the default production branch) or `dev` (meaning any development branch other than the production).

The cipher created depends on the provided parameters:

- With only `componentId`, the cipher starts with `KBC::ComponentSecure::` and is decryptable
across all configurations of that component. This is recommended for **component-specific secrets** 
applicable across all customers (e.g., as a master authorization token).

- Adding `projectId` to the `componentId` changes the prefix to `KBC::ProjectSecure::`, making the cipher decryptable within
the project's component configurations. This is recommended for **all secrets** used within a typical Keboola project.

- Providing all three IDs (`componentId`, `projectId`, `configId`) generates a cipher starting with
`KBC::ConfigSecure::`, limiting decryption to a specific configuration. This is useful for preventing the copying of configurations.

- Using only `projectId` yields a cipher that begins with `KBC::ProjectWideSecure::`, decryptable across the project's configurations.
This cipher type helps encrypt information shared across multiple components, e.g., SSH tunnel settings.

- Adding `branchType` restricts the encryption to the default production branch or to development branches. This means an encrypted value with this setting cannot be moved between production and development branches or vice versa. It is not possible to encrypt a value for just one development branch.

	- Using `branchType` with `componentId` and `projectId` results in a cipher beginning with `KBC::BranchTypeSecure::`. This allows decryption either in the production or in the development configuration of the specified component in the project.

	- Using `branchType` with all three IDs  (`componentId`, `projectId`, `configId`) creates a cipher that starts with `KBC::BranchTypeConfigSecure::`. It can only be decrypted within a specific production or development component configuration in a specific project. 

	- Using `branchType` with `projectId` creates a cipher beginning with `KBC::ProjectWideBranchTypeSecure::`. This cipher allows decryption either in the production or in the development configurations in the project. 

The following rules apply to all ciphers:

- Providing only a `configId` without a `projectId` is not allowed. Similarly, providing only `branchType` without `projectId` is also not allowed.
- Cipher decryption is only possible in the [region](/overview/api/#regions-and-endpoints) where the cipher was created. For example, ciphers with prefixes `KBC::ProjectSecureKV::` (Azure) or `KBC::ProjectSecureGKMS::` (GCP), instead of `KBC::ProjectSecure::` (AWS), use the same business logic but are specific to their region and technology and are not interchangeable.
- There is no decryption API; the cipher is decrypted internally before a component is run.
- Ciphering a value that is already encrypted does not change its encryption.
- There is no way to retrieve the component, project, configuration ID, or branch type from the cipher.
- The IDs referenced during cipher creation do not need to exist then. For example, you can create a cipher for a component not yet registered, which will start working as soon as the component is registered. Similarly, ciphers can be created for projects and configurations without access to them.

By default, values encrypted in component configurations are encrypted using the `KBC::ProjectSecure::` cipher, meaning
the cipher is not transferable between regions, components, or projects. It is transferable between 
different configurations of the same component within the project where it was created. If you create a configuration containing `KBC::ConfigSecure::` ciphers, 
note that the configuration will not work when copied.


================================================
File: overview/index.md
================================================
---
title: Keboola Overview
permalink: /overview/
---

* TOC
{:toc}

Keboola is an open system of many components orchestrated together
through (mostly REST) APIs. Although quite complex, it is modular and therefore
you rarely need to work with more than a few components.

***Note:** Initially, the Keboola platform was referred to as Keboola Connection (KBC). While it is now simply known as Keboola, references to "Connection" or the abbreviation "KBC" might still appear in various places.*

## Keboola Architecture
The following chart shows how Keboola is structured. All Keboola parts are briefly described [here](https://help.keboola.com/overview/).

![Overview of Keboola Components](/kbc_structure.png){: .img-responsive}

## Working with Keboola
Everything you can do in the Keboola UI can be done programatically using the API of the corresponding component.
All of our components have API documentation on [Apiary](https://keboola.docs.apiary.io/#) and
most of them have a public [Github repository](https://github.com/keboola/).
Our Docker components are built either on [DockerHub](https://github.com/keboola/), [Quay](https://quay.io/organization/keboola) or privately on [AWS ECR](https://aws.amazon.com/ecr/).

This means that there are virtually **endless possibilities of what can be done with Keboola programmatically**.

## Important Components
There are some components which are probably more important than others:

- [Storage](/integrate/storage/) component which is used to store all data in your Keboola projects (data in tables,
file uploads, configurations and logs)
- [Docker Runner](/extend/docker-runner) component which is used internally to run almost all
[components](/extend/component/); therefore all extractors, writers and applications share its features
- [Transformations](https://help.keboola.com/transformations/) component which encapsulates all types of transformations (SQL with
various backends, R, Python)
- [Orchestrator](/automate/) component which takes care of grouping different tasks together and
running them regularly at scheduled times

## Component Common Features
All components share some common behaviour such as [*Component Configuration*](/integrate/storage/api/configurations/)
[Running Jobs](/integrate/jobs/), which allows each component to be run in [Orchestrations](https://help.keboola.com/orchestrator/).
This means that once worked your way through one component, you have seen them all.
**Most of our components are open source**. If you are interested in their code, have a look at
[our repositories](/overview/repositories/).
Apart from that common features, some components define additional [synchronous actions](/extend/common-interface/actions/).
This (and many other information) can be retrieved using the [Developer Portal API](https://kebooladeveloperportal.docs.apiary.io/#)
(specifically the [Get app detail call](https://kebooladeveloperportal.docs.apiary.io/#reference/0/public-api/get-app-detail)
which lists all components available in Keboola.

### Running Jobs
What each component does is defined purely by that component, and so is the content of the configuration.
Each component has a `/run` API call that accepts either a reference to component configuration
(`config` field) or full component configuration (`configData` field) in JSON body, and
[queues an asynchronous job](/integrate/jobs/).

For more details, see
[full API description](https://kebooladocker.docs.apiary.io/#reference/run/run-job).

### Components Configuration
All components store their configuration in [Storage](/integrate/storage/). Management of the
configurations is done through
[Storage Components Configurations API](https://keboola.docs.apiary.io/#reference/components-and-configurations).
Stored configurations can be referenced in `/run` API calls.

Configuration can be defined with a JSON schema stored within the Component detail.
Docker Components without their own schemas can use a generic [Docker Component schema](/extend/docker-runner/#configuration).

## Specific Components

Apart from the above common API, some components offer other API calls:

  - [Storage](/integrate/storage/)
  - [Transformations](/integrate/transformations/)



================================================
File: overview/repositories.md
================================================
---
title: Keboola Repositories
permalink: /overview/repositories/
---

{% comment %}
Most of our components are open source (actually, we have 337 repositories) with only 5 of them being private.

There are some repositories which contain examples specific to the documentation

travis
{% endcomment %}

================================================
File: overview/api/index.md
================================================
---
title: Our APIs
permalink: /overview/api/
---

* TOC
{:toc}

All our [Keboola components](/overview/) have a public API on [apiary](https://apiary.io/). We recommend using either the Apiary Console or Postman Client for sending requests to our
API. Most of our APIs accept and return data in JSON format.
Many of these APIs require a *Storage API token*, specified in the `X-StorageApi-Token` header.

## List of Keboola APIs

All parts of the Keboola platform can be controlled via an API.
The main APIs for our components are:

| API | Description |
|---|---|
| [Keboola Storage API](https://keboola.docs.apiary.io/) | [Storage](/integrate/storage/) is the main Keboola component storing all data. |
| [Keboola Management API](https://keboolamanagementapi.docs.apiary.io/) | API managing Keboola projects and users (and notifications and features). |
| [Encryption API](https://keboolaencryption.docs.apiary.io/#) | Provides [Encryption](/overview/encryption/). |
| [Docker Runner API](https://kebooladocker.docs.apiary.io/#) | [Docker Runner](/extend/docker-runner/) is the component running other Keboola components. |
| [JSON Parser API](https://jsonparserapi.docs.apiary.io/#) | JSON Parser is a service [converting JSON files to CSV](https://json-parser.keboola.com/). |
| [Transformation API](https://keboolatransformationapi.docs.apiary.io/#) | [Transformations](/integrate/transformations/) is the component running [SQL/R/Python transformations](https://help.keboola.com/manipulation/transformations/). |
| [Provisioning API](https://provisioningapi.docs.apiary.io/#) | Provisioning is a service creating accounts for [sandboxes](https://help.keboola.com/manipulation/transformations/sandbox/), [transformations](https://help.keboola.com/manipulation/transformations/) and database writers. |
| [Provisioning Management API](https://provisioningmanagementapi.docs.apiary.io/#) | API managing servers for [sandboxes](https://help.keboola.com/manipulation/transformations/sandbox/), [transformations](https://help.keboola.com/manipulation/transformations/). |
| [Syrup Queue API](https://syrupqueue.docs.apiary.io/#) | Syrup Queue is a component managing [Jobs](/integrate/jobs/). Being replaced by Queue API. |
| [Queue API](https://app.swaggerhub.com/apis-docs/keboola/job-queue-api) | Queue is a service for [running components](/extend/docker-runner/) and managing [Jobs](/integrate/jobs/). |
| [OAuth Broker API](https://oauthapi3.docs.apiary.io/#) | OAuth Broker is a component managing [OAuth authorizations](/extend/common-interface/oauth/#authorize) of other components. |
| [Orchestrator API](https://keboolaorchestratorv2api.docs.apiary.io/#) | Orchestrator is a component used for [automating and scheduling tasks](https://help.keboola.com/tutorial/automate/) in your project. Note: This applies to legacy orchestrations only. For Orchestrator V2, please refer to the [Storage API](/integrate/storage/). |
| [Importer API](https://app.swaggerhub.com/apis-docs/keboola/import) | [Importer](/integrate/storage/api/importer/) is a helper service for easy table imports |
| [Developer Portal API](https://kebooladeveloperportal.docs.apiary.io/#) | Developer Portal is an application separated from Keboola for [creating components](/extend/component/). |
| [Billing API](https://keboolabillingapi.docs.apiary.io/#) | Billing API for Pay as You Go projects. |
| [Workspaces API](https://sandboxes.keboola.com/documentation) | Workspaces API for V2 workspaces. |
| [Synchronous Actions API](https://app.swaggerhub.com/apis/odinuv/sync-actions) | API to trigger [Synchronous Actions](/extend/common-interface/actions/). This is a partial replacement of Docker Runner API and may not be available on all stacks. |
| [Scheduler API](https://app.swaggerhub.com/apis/odinuv/scheduler) | API to automate configurations |
| [Notifications API](https://app.swaggerhub.com/apis/odinuv/notifications-service) | API to subscribe to events, e.g., failed orchestrations (replacement for Orchestrator API) |
| [Templates API](https://templates.keboola.com/v1/documentation/) | The Keboola Templates API allows you to apply a [template](/cli/templates/). |
| [Stream API](https://stream.keboola.com/v1/documentation/) | The Keboola Stream API allows you to ingest small and frequent events into your project’s storage. |
| [Vault](https://vault.keboola.com/docs/swagger.yaml) | Service handling variables & credentials storage. |

If you're unsure which API to use, refer to our [integration guide](/integrate/). It describes the roles of different APIs and contains examples of commonly
performed actions.

## Stacks and Endpoints
Keboola is available in multiple [stacks](https://help.keboola.com/overview/#stacks), which can be 
either multi-tenant or single-tenant. Current multi-tenant stacks are:

- US Virginia AWS – [connection.keboola.com](https://connection.keboola.com/)
- US Virginia GCP - [connection.us-east4.gcp.keboola.com](https://connection.us-east4.gcp.keboola.com/)
- EU Frankfurt AWS – [connection.eu-central-1.keboola.com](https://connection.eu-central-1.keboola.com/)
- EU Ireland Azure – [connection.north-europe.azure.keboola.com](https://connection.north-europe.azure.keboola.com/)
- EU Frankfurt GCP - [connection.europe-west3.gcp.keboola.com](https://connection.europe-west3.gcp.keboola.com/)

Each stack operates as an independent instance of Keboola services.
In all the API documentation above, the AWS US stack is used.

Single-tenant stacks are available for a single enterprise customer, with a domain name 
in the format `connection.CUSTOMER_NAME.keboola.com`.

If you are using another stack, modify the endpoints accordingly.
Otherwise, you may encounter `Invalid Token` or unauthorized errors. The *authoritative list* of available endpoints is provided by the [Storage API Index Call](https://keboola.docs.apiary.io/#reference/miscellaneous/api-index/component-list). The following is a sample response:

{% highlight json %}
{
    ...,
  "services": [
        {
            "id": "docker-runner",
            "url": "https://docker-runner.keboola.com"
        },
        {
            "id": "import",
            "url": "https://import.keboola.com"
        },
        {
            "id": "syrup",
            "url": "https://syrup.keboola.com"
        },
        {
            "id": "oauth",
            "url": "https://oauth.keboola.com"
        },
        {
            "id": "queue",
            "url": "https://queue.keboola.com"
        },
        {
            "id": "billing",
            "url": "https://billing.keboola.com"
        },
        {
            "id": "encryption",
            "url": "https://encryption.keboola.com"
        },
        {
            "id": "sandboxes",
            "url": "https://sandboxes.keboola.com"
        },
        {
            "id": "mlflow",
            "url": "https://mlflow.keboola.com"
        },
        {
            "id": "spark",
            "url": "https://spark.keboola.com"
        },
        {
            "id": "scheduler",
            "url": "https://scheduler.keboola.com"
        },
        {
            "id": "sync-actions",
            "url": "https://sync-actions.keboola.com"
        },
        {
            "id": "notification",
            "url": "https://notification.keboola.com"
        },
        {
            "id": "templates",
            "url": "https://templates.keboola.com"
        }
    ],
}
{% endhighlight %}

The services listed above are:

- `docker-runner` --- [Legacy Service for Running Sync Actions](/extend/common-interface/actions/)
- `import` --- [Storage Importer Service](/integrate/storage/api/importer/)
- `syrup` --- [Service for Running Components](/extend/docker-runner/)
- `oauth` --- [OAuth Manager Service](/extend/common-interface/oauth/)
- `queue` --- [Service for Running Components](/extend/docker-runner/)
- `billing` --- Service for Computing Credits
- `encryption` --- Service for [Encryption](https://developers.keboola.com/overview/encryption/)
- `sandboxes` --- Workspace Manager Service
- `mlflow` --- MLFlow Models Manager Service
- `scheduler` --- [Service for Configuring Schedules](https://developers.keboola.com/automate/set-schedule/)
- `sync-actions` --- [Service for Running Synchronous Actions](/extend/common-interface/actions/)
- `notification` --- Service for Configuring Job Notifications
- `templates` --- [Service for Applying Templates](https://developers.keboola.com/cli/templates/)

For convenience, the following table lists active services and their URLs, though for an authoritative answer 
and in application integrations, we strongly suggest using the above API call.

| API                    | Service        | Region           | URL                                                 |
|------------------------|----------------|------------------|-----------------------------------------------------|
| Billing                | `billing`      | US Virginia AWS  | https://billing.keboola.com                         |
| Billing                | `billing`      | US Virginia GCP  | https://billing.us-east4.gcp.keboola.com            |
| Billing                | `billing`      | EU Frankfurt AWS | https://billing.eu-central-1.keboola.com            |
| Billing                | `billing`      | EU Ireland Azure | https://billing.north-europe.azure.keboola.com      |
| Billing                | `billing`      | EU Frankfurt GCP | https://billing.europe-west3.gcp.keboola.com        |
| Encryption             | `encryption`   | US Virginia AWS  | https://encryption.keboola.com                      |
| Encryption             | `encryption`   | US Virginia GCP  | https://encryption.us-east4.gcp.keboola.com         |
| Encryption             | `encryption`   | EU Frankfurt AWS | https://encryption.eu-central-1.keboola.com         |
| Encryption             | `encryption`   | EU Ireland Azure | https://encryption.north-europe.azure.keboola.com   |
| Encryption             | `encryption`   | EU Frankfurt GCP | https://encryption.europe-west3.gcp.keboola.com     |
| Importer               | `import`       | US Virginia AWS  | https://import.keboola.com                          |
| Importer               | `import`       | US Virginia GCP  | https://import.us-east4.gcp.keboola.com             |
| Importer               | `import`       | EU Frankfurt AWS | https://import.eu-central-1.keboola.com             |
| Importer               | `import`       | EU Ireland Azure | https://import.north-europe.azure.keboola.com       |
| Importer               | `import`       | EU Frankfurt GCP | https://import.europe-west3.gcp.keboola.com         |
| MLFlow                 | `mlflow`       | US Virginia AWS  | https://mlflow.keboola.com                          |
| MLFlow                 | `mlflow`       | EU Frankfurt AWS | https://mlflow.eu-central-1.keboola.com             |
| MLFlow                 | `mlflow`       | EU Ireland Azure | https://mlflow.north-europe.azure.keboola.com       |
| Notification           | `notification` | US Virginia AWS  | https://notification.keboola.com                    |
| Notification           | `notification` | US Virginia GCP  | https://notification.us-east4.gcp.keboola.com       |
| Notification           | `notification` | EU Frankfurt AWS | https://notification.eu-central-1.keboola.com       |
| Notification           | `notification` | EU Ireland Azure | https://notification.north-europe.azure.keboola.com |
| Notification           | `notification` | EU Frankfurt GCP | https://notification.europe-west3.gcp.keboola.com   |
| OAuth                  | `oauth`        | US Virginia AWS  | https://oauth.keboola.com                           |
| OAuth                  | `oauth`        | US Virginia GCP  | https://oauth.europe-west3.gcp.keboola.com          |
| OAuth                  | `oauth`        | EU Frankfurt AWS | https://oauth.eu-central-1.keboola.com              |
| OAuth                  | `oauth`        | EU Ireland Azure | https://oauth.north-europe.azure.keboola.com        |
| OAuth                  | `oauth`        | EU Frankfurt GCP | https://oauth.europe-west3.gcp.keboola.com          |
| Queue                  | `queue`        | US Virginia AWS  | https://queue.keboola.com                           |
| Queue                  | `queue`        | US Virginia GCP  | https://queue.us-east4.gcp.keboola.com              |
| Queue                  | `queue`        | EU Frankfurt AWS | https://queue.eu-central-1.keboola.com              |
| Queue                  | `queue`        | EU Ireland Azure | https://queue.north-europe.azure.keboola.com        |
| Queue                  | `queue`        | EU Frankfurt GCP | https://queue.europe-west3.gcp.keboola.com          |
| Scheduler              | `scheduler`    | US Virginia AWS  | https://scheduler.keboola.com                       |
| Scheduler              | `scheduler`    | US Virginia GCP  | https://scheduler.us-east4.gcp.keboola.com          |
| Scheduler              | `scheduler`    | EU Frankfurt AWS | https://scheduler.eu-central-1.keboola.com          |
| Scheduler              | `scheduler`    | EU Ireland Azure | https://scheduler.north-europe.azure.keboola.com    |
| Scheduler              | `scheduler`    | EU Frankfurt GCP | https://scheduler.europe-west3.gcp.keboola.com      |
| Storage                |                | US Virginia AWS  | https://connection.keboola.com/                     |
| Storage                |                | US Virginia GCP  | https://connection.us-east4.gcp.keboola.com         |
| Storage                |                | EU Frankfurt AWS | https://connection.eu-central-1.keboola.com/        |
| Storage                |                | EU Ireland Azure | https://connection.north-europe.azure.keboola.com/  |
| Storage                |                | EU Frankfurt GCP | https://connection.europe-west3.gcp.keboola.com/    |
| Sync Actions           | `sync-actions` | US Virginia AWS  | https://sync-actions.keboola.com/                   |
| Sync Actions           | `sync-actions` | US Virginia GCP  | https://sync-actions.us-east4.gcp.keboola.com       |
| Sync Actions           | `sync-actions` | EU Frankfurt AWS | https://sync-actions.eu-central-1.keboola.com       |
| Sync Actions           | `sync-actions` | EU Ireland Azure | https://sync-actions.north-europe.azure.keboola.com |
| Sync Actions           | `sync-actions` | EU Frankfurt GCP | https://sync-actions.europe-west3.gcp.keboola.com   |
| Templates              | `templates`    | US Virginia AWS  | https://templates.keboola.com                       |
| Templates              | `templates`    | US Virginia GCP  | https://templates.us-east4.gcp.keboola.com          |
| Templates              | `templates`    | EU Frankfurt AWS | https://templates.eu-central-1.keboola.com          |
| Templates              | `templates`    | EU Ireland Azure | https://templates.north-europe.azure.keboola.com    |
| Templates              | `templates`    | EU Frankfurt GCP | https://templates.europe-west3.gcp.keboola.com      |
| Workspaces / Sandboxes | `sandboxes`    | US Virginia AWS  | https://sandboxes.keboola.com                       |
| Workspaces / Sandboxes | `sandboxes`    | US Virginia GCP  | https://sandboxes.us-east4.gcp.keboola.com          |
| Workspaces / Sandboxes | `sandboxes`    | EU Frankfurt AWS | https://sandboxes.eu-central-1.keboola.com          |
| Workspaces / Sandboxes | `sandboxes`    | EU Ireland Azure | https://sandboxes.north-europe.azure.keboola.com    |
| Workspaces / Sandboxes | `sandboxes`    | EU Frankfurt GCP | https://sandboxes.europe-west3.gcp.keboola.com      |


***Important**: Each stack also uses its own set of [IP addresses](https://help.keboola.com/extractors/ip-addresses/).*

## Calling API

There are several ways to send requests to our APIs:

### Apiary Console
Send requests to our API directly from the Apiary console by clicking on **Switch to console** or **Try**.
Fill in the request headers and parameters, then click **Call Resource**.

{: .image-popup}
![Apiary console](/overview/api/apiary-console.png)

The Apiary console is fine if you send API requests only occasionally. It requires no application installation;
however, it has no history and no other useful features.

### Postman Client
[Postman](https://www.getpostman.com/) is a generic HTTP API client, suitable for more regular API work.
We also provide a collection of [useful API calls](https://documenter.getpostman.com/view/3086797/kbc-samples/77h845D?version=latest#9b9f3e7b-de3b-4c90-bad6-a8760e3852eb) with examples.
The collection contains code examples in various languages; the requests can also be imported into the Postman application.

{: .image-popup}
![Postman Docs](/overview/api/postman-import.png)

### cURL
[cURL](https://curl.haxx.se/) is a common library with a [command-line interface (CLI)](https://curl.haxx.se/docs/manpage.html).
You can use the cURL CLI to create simple scripts for interacting with Keboola APIs. For example, to [run a job](/integrate/jobs/):

{% highlight shell %}
curl --data "{\"config\": \"sampledatabase\"}" --header "X-StorageAPI-Token: YourStorageToken" https://syrup.keboola.com/keboola.ex-db-mysql/run
{% endhighlight %}


================================================
File: .github/PULL_REQUEST_TEMPLATE.md
================================================
<!-- if proofreading is needed, create issue in PROOF project, optionally link also other issues 
    if not, ask someone for review, if you are unsure who, ask hhanova
-->

Jira issue(s): PROOF-XXX

<!-- briefly describe what are you changing and why -->

Changes:

-

---

<!-- provide additional notes -->


================================================
File: .github/workflows/branch.yml
================================================
name: Build

on:
  pull_request:
    branches:
      - main

jobs:
  build:
    name: "Build"
    runs-on: ubuntu-latest
    steps:
      - name: "Checkout"
        uses: actions/checkout@v2
      - name: "Pull images"
        run: docker compose pull
      - name: "Build"
        run: docker compose run --rm -e JEKYLL_ENV=production jekyll jekyll build


================================================
File: .github/workflows/main.yml
================================================
name: "Build and deploy"

env:
  AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
  AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}

on:
  push:
    branches:
      - main

jobs:
  build-and-deploy:
    name: "Build and deploy"
    runs-on: ubuntu-latest
    steps:
      - name: "Checkout"
        uses: actions/checkout@v3
      - name: "Pull images"
        run: docker compose pull
      - name: "Build"
        run: docker compose run --rm -e JEKYLL_ENV=production jekyll jekyll build
      - name: "Deploy"
        run: |
          docker compose run --rm -e AWS_ACCESS_KEY_ID=$AWS_ACCESS_KEY_ID -e AWS_SECRET_ACCESS_KEY=$AWS_SECRET_ACCESS_KEY aws s3 rm s3://developers.keboola.com --recursive --region us-east-1
          docker compose run --rm -e AWS_ACCESS_KEY_ID=$AWS_ACCESS_KEY_ID -e AWS_SECRET_ACCESS_KEY=$AWS_SECRET_ACCESS_KEY aws s3 cp _site s3://developers.keboola.com --recursive --acl "public-read" --cache-control "max-age=600" --region us-east-1


